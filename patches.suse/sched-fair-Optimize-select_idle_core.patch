From 0c43e443f960920addf38c4273d352942eba325e Mon Sep 17 00:00:00 2001
From: Srikar Dronamraju <srikar@linux.vnet.ibm.com>
Date: Tue, 21 Jan 2020 14:50:55 +0000
Subject: [PATCH] sched/fair: Optimize select_idle_core

References: bnc#1155798 (CPU scheduler functional and performance backports)
Patch-mainline: Queued in subsystem maintainer repository
Git-repo: git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip.git
Git-commit: b94236adc60add30dfe2f6a2f4b3d2f31b99e600

Currently we loop through all threads of a core to evaluate if the core
is idle or not. This is unnecessary. If a thread of a core is not
idle, skip evaluating other threads of a core.

Signed-off-by: Srikar Dronamraju <srikar@linux.vnet.ibm.com>
Signed-off-by: Mel Gorman <mgorman@suse.de>
---
 kernel/sched/fair.c | 6 ++++--
 1 file changed, 4 insertions(+), 2 deletions(-)

diff --git a/kernel/sched/fair.c b/kernel/sched/fair.c
index b9fd3d4b9da1..13bbf7ee50e2 100644
--- a/kernel/sched/fair.c
+++ b/kernel/sched/fair.c
@@ -5784,10 +5784,12 @@ static int select_idle_core(struct task_struct *p, struct sched_domain *sd, int
 		bool idle = true;
 
 		for_each_cpu(cpu, cpu_smt_mask(core)) {
-			__cpumask_clear_cpu(cpu, cpus);
-			if (!available_idle_cpu(cpu))
+			if (!available_idle_cpu(cpu)) {
 				idle = false;
+				break;
+			}
 		}
+		cpumask_andnot(cpus, cpus, cpu_smt_mask(core));
 
 		if (idle)
 			return core;
