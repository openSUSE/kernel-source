From: Peter Zijlstra <peterz@infradead.org>
Date: Tue, 12 Aug 2025 12:39:09 +0200
Subject: perf: Make RB allocation branch self sufficient
Git-commit: 191759e5ea9f6995171ed2ffcc41a2377f946a3a
Patch-mainline: v6.18-rc1
References: perf-events-v6.19-update

Ensure @rb usage doesn't extend out of the branch block.

Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
Reviewed-by: Lorenzo Stoakes <lorenzo.stoakes@oracle.com>
Link: https://lore.kernel.org/r/20250812104019.605285302@infradead.org

Signed-off-by: Tony Jones <tonyj@suse.de>
---
 kernel/events/core.c | 6 +-----
 1 file changed, 1 insertion(+), 5 deletions(-)

diff --git a/kernel/events/core.c b/kernel/events/core.c
index e76afd9c1759..875c27b28e9b 100644
--- a/kernel/events/core.c
+++ b/kernel/events/core.c
@@ -7116,8 +7116,6 @@ static int perf_mmap(struct file *file, struct vm_area_struct *vma)
 				 * multiple times.
 				 */
 				ret = 0;
-				/* We need the rb to map pages. */
-				rb = event->rb;
 				perf_mmap_account(vma, user_extra, extra);
 				atomic_inc(&event->mmap_count);
 				goto unlock;
@@ -7136,8 +7134,6 @@ static int perf_mmap(struct file *file, struct vm_area_struct *vma)
 			goto unlock;
 		}
 
-		WARN_ON(!rb && event->rb);
-
 		if (vma->vm_flags & VM_WRITE)
 			flags |= RING_BUFFER_WRITABLE;
 
@@ -7190,7 +7186,7 @@ static int perf_mmap(struct file *file, struct vm_area_struct *vma)
 	 * full cleanup in this case and therefore does not invoke
 	 * vmops::close().
 	 */
-	ret = map_range(rb, vma);
+	ret = map_range(event->rb, vma);
 	if (ret)
 		perf_mmap_close(vma);
 

