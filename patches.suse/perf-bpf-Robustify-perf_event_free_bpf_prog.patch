From: Peter Zijlstra <peterz@infradead.org>
Date: Mon, 4 Nov 2024 14:39:22 +0100
Subject: perf/bpf: Robustify perf_event_free_bpf_prog()
Git-commit: c5b96789575b670b1e776071bb243e0ed3d3abaa
Patch-mainline: v6.15-rc1
References: git-fixes
X-Info: dependent patch for 7ed9138a72829d2035ecbd8dbd35b1bc3c137c40

Ensure perf_event_free_bpf_prog() is safe to call a second time;
notably without making any references to event->pmu when there is no
prog left.

Note: perf_event_detach_bpf_prog() might leave a stale event->prog

Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
Signed-off-by: Ingo Molnar <mingo@kernel.org>
Reviewed-by: Ravi Bangoria <ravi.bangoria@amd.com>
Cc: Alexei Starovoitov <ast@kernel.org>
Cc: Daniel Borkmann <daniel@iogearbox.net>
Cc: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20241104135518.978956692@infradead.org

Signed-off-by: Tony Jones <tonyj@suse.de>
---
 kernel/events/core.c | 3 +++
 1 file changed, 3 insertions(+)

diff --git a/kernel/events/core.c b/kernel/events/core.c
index 525c64ee7925..ab4e497087da 100644
--- a/kernel/events/core.c
+++ b/kernel/events/core.c
@@ -10905,6 +10905,9 @@ int perf_event_set_bpf_prog(struct perf_event *event, struct bpf_prog *prog,
 
 void perf_event_free_bpf_prog(struct perf_event *event)
 {
+	if (!event->prog)
+		return;
+
 	if (!perf_event_is_tracing(event)) {
 		perf_event_free_bpf_handler(event);
 		return;

