From: Shung-Hsi Yu <shung-hsi.yu@suse.com>
Subject: kABI: bpf: struct bpf_link and bpf_link_ops kABI workaround
Patch-mainline: never, kabi
References: bsc#1224531 CVE-2024-35860

Upstream commit 1a80dbcb2dba ("bpf: support deferring bpf_link dealloc to
after RCU grace period") changed struct bpf_link and struct bpf_link_ops and
thus breaks kABI.

For the struct work_struct -> union{ struct work_struct | struct rcu_head }
change in struct bpf_link we simply restore the field to the origin struct
work_struct when generating ksyms, and add a size check to make sure the new
union is not larger than the original struct work_struct; and additionally
hide use of rcu field in bpf_link_free().

As for the new operation/field dealloc_deferred in struct bpf_link_ops we
simply move the new field to the end, and hide it when generating ksyms. This
works because all struct bpf_link_ops are declared statically as constant.

Signed-off-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>
---
 include/linux/bpf.h  |   22 +++++++++++++++++-----
 kernel/bpf/syscall.c |    2 ++
 2 files changed, 19 insertions(+), 5 deletions(-)

--- a/include/linux/bpf.h
+++ b/include/linux/bpf.h
@@ -7,6 +7,7 @@
 #include <uapi/linux/bpf.h>
 #include <uapi/linux/filter.h>
 
+#include <linux/build_bug.h>
 #include <linux/workqueue.h>
 #include <linux/file.h>
 #include <linux/percpu.h>
@@ -1529,26 +1530,30 @@ struct bpf_link {
 	enum bpf_link_type type;
 	const struct bpf_link_ops *ops;
 	struct bpf_prog *prog;
+#ifndef __GENKSYMS__
 	/* rcu is used before freeing, work can be used to schedule that
 	 * RCU-based freeing before that, so they never overlap
 	 */
 	union {
 		struct rcu_head rcu;
+#endif
 		struct work_struct work;
+#ifndef __GENKSYMS__
 	};
+#endif
 };
 
+#ifndef __GENKSYMS__
+/* Make sure the anonymous union above is not larger than before */
+static_assert(sizeof(struct rcu_head) <= sizeof(struct work_struct));
+#endif
+
 struct bpf_link_ops {
 	void (*release)(struct bpf_link *link);
 	/* deallocate link resources callback, called without RCU grace period
 	 * waiting
 	 */
 	void (*dealloc)(struct bpf_link *link);
-	/* deallocate link resources callback, called after RCU grace period;
-	 * if underlying BPF program is sleepable we go through tasks trace
-	 * RCU GP and then "classic" RCU GP
-	 */
-	void (*dealloc_deferred)(struct bpf_link *link);
 	int (*detach)(struct bpf_link *link);
 	int (*update_prog)(struct bpf_link *link, struct bpf_prog *new_prog,
 			   struct bpf_prog *old_prog);
@@ -1557,6 +1562,13 @@ struct bpf_link_ops {
 			      struct bpf_link_info *info);
 	int (*update_map)(struct bpf_link *link, struct bpf_map *new_map,
 			  struct bpf_map *old_map);
+#ifndef __GENKSYMS__
+	/* deallocate link resources callback, called after RCU grace period;
+	 * if underlying BPF program is sleepable we go through tasks trace
+	 * RCU GP and then "classic" RCU GP
+	 */
+	void (*dealloc_deferred)(struct bpf_link *link);
+#endif
 };
 
 struct bpf_tramp_link {
--- a/kernel/bpf/syscall.c
+++ b/kernel/bpf/syscall.c
@@ -2907,6 +2907,7 @@ static void bpf_link_free(struct bpf_lin
 		link->ops->release(link);
 		bpf_prog_put(link->prog);
 	}
+#ifndef __GENKSYMS__
 	if (link->ops->dealloc_deferred) {
 		/* schedule BPF link deallocation; if underlying BPF program
 		 * is sleepable, we need to first wait for RCU tasks trace
@@ -2917,6 +2918,7 @@ static void bpf_link_free(struct bpf_lin
 		else
 			call_rcu(&link->rcu, bpf_link_defer_dealloc_rcu_gp);
 	}
+#endif
 	if (link->ops->dealloc)
 		link->ops->dealloc(link);
 }
