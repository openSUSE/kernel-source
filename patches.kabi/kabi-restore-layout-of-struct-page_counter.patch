From: Michal Koutný <mkoutny@suse.com
Date: Tue, 24 Jun 2025 17:11:31 +0200
Subject: kabi: restore layout of struct page_counter
Patch-mainline: Never, kabi workaround
References: jsc#PED-12551

page_counter shouldn't be allocated nor copied by 3rd party users, however, it
is embedded in mem_cgroup (for which similar applies).

We're looking for 8B for the new
 	unsigned long local_watermark;
instead of extending page_counter and mem_cgroup unnecessarily.

pahole -C page_counter # 6.4.0-150600.23.47-default

struct page_counter {
	atomic_long_t              usage;                /*     0     8 */

	/* XXX 56 bytes hole, try to pack */

	/* --- cacheline 1 boundary (64 bytes) --- */
	struct cacheline_padding   _pad1_;               /*    64     0 */
	long unsigned int          emin __attribute__((__aligned__(64))); /*    64     8 */
	atomic_long_t              min_usage;            /*    72     8 */
	atomic_long_t              children_min_usage;   /*    80     8 */
	long unsigned int          elow;                 /*    88     8 */
	atomic_long_t              low_usage;            /*    96     8 */
	atomic_long_t              children_low_usage;   /*   104     8 */
	long unsigned int          watermark;            /*   112     8 */
	long unsigned int          failcnt;              /*   120     8 */
	/* --- cacheline 2 boundary (128 bytes) --- */
	struct cacheline_padding   _pad2_;               /*   128     0 */
	long unsigned int          min;                  /*   128     8 */
	long unsigned int          low;                  /*   136     8 */
	long unsigned int          high;                 /*   144     8 */
	long unsigned int          max;                  /*   152     8 */
	struct page_counter *      parent;               /*   160     8 */

	/* size: 192, cachelines: 3, members: 16 */
	/* sum members: 112, holes: 1, sum holes: 56 */
	/* padding: 24 */
	/* forced alignments: 1 */
} __attribute__((__aligned__(64)));

Keep the first cacheline exclusive for atomic as designed by upstream and place
the counter to the padding at the end of the structure.
(It'd be nicer to have watermark and local_watermark in the same cacheline but
we cannot have everything. The locality with parent pointer makes sense from
page_counter_charge traversal too.)

Signed-off-by: Michal Koutný <mkoutny@suse.com

---
 include/linux/page_counter.h |   39 +++++++++++++++++++++++++++++++++++++++
 1 file changed, 39 insertions(+)

--- a/include/linux/page_counter.h
+++ b/include/linux/page_counter.h
@@ -6,6 +6,8 @@
 #include <linux/cache.h>
 #include <linux/kernel.h>
 #include <asm/page.h>
+#include <linux/build_bug.h>  /* for static_assert() */
+#include <linux/stddef.h>     /* for offsetof() */
 
 struct page_counter {
 	/*
@@ -26,8 +28,41 @@ struct page_counter {
 	atomic_long_t children_low_usage;
 
 	unsigned long watermark;
+	unsigned long failcnt;
+
+	/* Keep all the read most fields in a separete cacheline. */
+	CACHELINE_PADDING(_pad2_);
+
+	unsigned long min;
+	unsigned long low;
+	unsigned long high;
+	unsigned long max;
+	struct page_counter *parent;
+#ifndef __GENKSYMS__
 	/* Latest cg2 reset watermark */
 	unsigned long local_watermark;
+#endif
+} ____cacheline_internodealigned_in_smp;
+
+struct __orig_page_counter {
+	/*
+	 * Make sure 'usage' does not share cacheline with any other field. The
+	 * memcg->memory.usage is a hot member of struct mem_cgroup.
+	 */
+	atomic_long_t usage;
+	CACHELINE_PADDING(_pad1_);
+
+	/* effective memory.min and memory.min usage tracking */
+	unsigned long emin;
+	atomic_long_t min_usage;
+	atomic_long_t children_min_usage;
+
+	/* effective memory.low and memory.low usage tracking */
+	unsigned long elow;
+	atomic_long_t low_usage;
+	atomic_long_t children_low_usage;
+
+	unsigned long watermark;
 	unsigned long failcnt;
 
 	/* Keep all the read most fields in a separete cacheline. */
@@ -40,6 +75,10 @@ struct page_counter {
 	struct page_counter *parent;
 } ____cacheline_internodealigned_in_smp;
 
+#ifndef CONFIG_ARM
+static_assert(sizeof(struct __orig_page_counter) == sizeof(struct page_counter));
+#endif
+
 #if BITS_PER_LONG == 32
 #define PAGE_COUNTER_MAX LONG_MAX
 #else
