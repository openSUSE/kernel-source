From: Shung-Hsi Yu <shung-hsi.yu@suse.com>
Date: Thu Nov 27 02:20:34 PM CST 2025
Subject: kABI workaround for bpf: Enforce expected_attach_type for tailcall compatibility
Patch-mainline: Never, kABI workaround
References: CVE-2025-40123 bsc#1253365

Backport of upstream commit 4540aed51b12 ("bpf: Enforce expected_attach_type
for tailcall compatibility") break kABI by introducing a 'enum bpf_attach_type
expected_attach_type' field into 'struct bpf_map.owner'. Fortunately there is a
hole in struct bpf_map.owner, so put the new field in that space and wrap it in
__GENKSYMS__.

On default flavor the hole is 6 bytes, but for rt there is only 2 bytes, so we
need to further change the type from 'enum' into 'unsigned char'. This works
because  the value of 'enum bpf_attach_type' never exceeds 127:

	enum bpf_attach_type {
		BPF_CGROUP_INET_INGRESS = 0,
		BPF_CGROUP_INET_EGRESS = 1,
		BPF_CGROUP_INET_SOCK_CREATE = 2,
		...
		BPF_NETKIT_PEER = 55,
		BPF_TRACE_KPROBE_SESSION = 56,
		__MAX_BPF_ATTACH_TYPE = 57,
	};

Lastly, use suse_kabi_static_assert() to ensure there is a suitable hole across
all build targets.

Signed-off-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>
Reviewed-by: Takashi Iwai <tiwai@suse.de>
Acked-by: Vasant Karasulli <vkarasulli@suse.de>
---
 include/linux/bpf.h |   60 +++++++++++++++++++++++++++++++++++++++++++++++++++-
 kernel/bpf/core.c   |    4 +--
 2 files changed, 61 insertions(+), 3 deletions(-)

--- a/include/linux/bpf.h
+++ b/include/linux/bpf.h
@@ -30,6 +30,7 @@
 #include <linux/static_call.h>
 #include <linux/memcontrol.h>
 #include <linux/cfi.h>
+#include <linux/build_bug.h>
 
 struct bpf_verifier_env;
 struct bpf_verifier_log;
@@ -299,7 +300,62 @@ struct bpf_map {
 		enum bpf_prog_type type;
 		bool jited;
 		bool xdp_has_frags;
-		enum bpf_attach_type expected_attach_type;
+#ifndef __GENKSYMS__
+		unsigned char expected_attach_type;
+#endif
+	} owner;
+	bool bypass_spec_v1;
+	bool frozen; /* write-once; write-protected by freeze_mutex */
+	bool free_after_mult_rcu_gp;
+	bool free_after_rcu_gp;
+	atomic64_t sleepable_refcnt;
+	s64 __percpu *elem_count;
+	void *suse_kabi_padding;
+};
+
+struct __orig_bpf_map {
+	const struct bpf_map_ops *ops;
+	struct bpf_map *inner_map_meta;
+#ifdef CONFIG_SECURITY
+	void *security;
+#endif
+	enum bpf_map_type map_type;
+	u32 key_size;
+	u32 value_size;
+	u32 max_entries;
+	u64 map_extra; /* any per-map-type extra fields */
+	u32 map_flags;
+	u32 id;
+	struct btf_record *record;
+	int numa_node;
+	u32 btf_key_type_id;
+	u32 btf_value_type_id;
+	u32 btf_vmlinux_value_type_id;
+	struct btf *btf;
+#ifdef CONFIG_MEMCG
+	struct obj_cgroup *objcg;
+#endif
+	char name[BPF_OBJ_NAME_LEN];
+	struct mutex freeze_mutex;
+	atomic64_t refcnt;
+	atomic64_t usercnt;
+	/* rcu is used before freeing and work is only used during freeing */
+	union {
+		struct work_struct work;
+		struct rcu_head rcu;
+	};
+	atomic64_t writecnt;
+	/* 'Ownership' of program-containing map is claimed by the first program
+	 * that is going to use this map or by the first program which FD is
+	 * stored in the map to make sure that all callers and callees have the
+	 * same prog type, JITed flag and xdp_has_frags flag.
+	 */
+	struct {
+		const struct btf_type *attach_func_proto;
+		spinlock_t lock;
+		enum bpf_prog_type type;
+		bool jited;
+		bool xdp_has_frags;
 	} owner;
 	bool bypass_spec_v1;
 	bool frozen; /* write-once; write-protected by freeze_mutex */
@@ -310,6 +366,8 @@ struct bpf_map {
 	void *suse_kabi_padding;
 };
 
+suse_kabi_static_assert(offsetof(struct bpf_map, bypass_spec_v1) == offsetof(struct __orig_bpf_map, bypass_spec_v1));
+
 static inline const char *btf_field_type_name(enum btf_field_type type)
 {
 	switch (type) {
--- a/kernel/bpf/core.c
+++ b/kernel/bpf/core.c
@@ -2321,7 +2321,7 @@ static bool __bpf_prog_map_compatible(st
 		map->owner.type  = prog_type;
 		map->owner.jited = fp->jited;
 		map->owner.xdp_has_frags = aux->xdp_has_frags;
-		map->owner.expected_attach_type = fp->expected_attach_type;
+		map->owner.expected_attach_type = (unsigned char) fp->expected_attach_type;
 		map->owner.attach_func_proto = aux->attach_func_proto;
 		ret = true;
 	} else {
@@ -2330,7 +2330,7 @@ static bool __bpf_prog_map_compatible(st
 		      map->owner.xdp_has_frags == aux->xdp_has_frags;
 		if (ret &&
 		    map->map_type == BPF_MAP_TYPE_PROG_ARRAY &&
-		    map->owner.expected_attach_type != fp->expected_attach_type)
+		    map->owner.expected_attach_type != (unsigned char) fp->expected_attach_type)
 			ret = false;
 		if (ret &&
 		    map->owner.attach_func_proto != aux->attach_func_proto) {
