Automatically created from "patch-3.1" by xen-port-patches.py

From: Linux Kernel Mailing List <linux-kernel@vger.kernel.org>
Subject: Linux: 3.1
Patch-mainline: 3.1

 This patch contains the differences between 3.0 and 3.1.

Acked-by: jbeulich@suse.com

--- head-2011-11-03.orig/arch/x86/Kconfig	2011-09-12 10:54:53.000000000 +0200
+++ head-2011-11-03/arch/x86/Kconfig	2011-09-12 10:54:53.000000000 +0200
@@ -20,7 +20,7 @@ config X86
 	select HAVE_UNSTABLE_SCHED_CLOCK
 	select HAVE_IDE
 	select HAVE_OPROFILE
-	select HAVE_PCSPKR_PLATFORM
+	select HAVE_PCSPKR_PLATFORM if !XEN_UNPRIVILEGED_GUEST
 	select HAVE_PERF_EVENTS
 	select HAVE_IRQ_WORK
 	select HAVE_IOREMAP_PROT
@@ -71,7 +71,7 @@ config X86
 	select IRQ_FORCED_THREADING
 	select USE_GENERIC_SMP_HELPERS if SMP
 	select HAVE_BPF_JIT if (X86_64 && NET)
-	select CLKEVT_I8253
+	select CLKEVT_I8253 if !XEN
 	select ARCH_HAVE_NMI_SAFE_CMPXCHG
 
 config INSTRUCTION_DECODER
@@ -100,7 +100,7 @@ config GENERIC_CLOCKEVENTS
 
 config ARCH_CLOCKSOURCE_DATA
 	def_bool y
-	depends on X86_64
+	depends on X86_64 && !XEN
 
 config GENERIC_CLOCKEVENTS_BROADCAST
 	def_bool y
--- head-2011-11-03.orig/arch/x86/ia32/ia32entry-xen.S	2011-07-01 15:19:34.000000000 +0200
+++ head-2011-11-03/arch/x86/ia32/ia32entry-xen.S	2011-09-08 16:54:08.000000000 +0200
@@ -135,7 +135,7 @@ ENTRY(ia32_sysenter_target)
 	movq	%r10,8(%rsp)
 	movq	%rax,(%rsp)
 	cld
-	SAVE_ARGS 0,0,1
+	SAVE_ARGS 0,1,0
  	/* no need to do an access_ok check here because rbp has been
  	   32bit zero extended */ 
 1:	movl	(%rbp),%ebp
@@ -206,7 +206,7 @@ ENTRY(ia32_cstar_target)
 	CFI_REL_OFFSET	rip,RIP-RIP+16
 	movl 	%eax,%eax	/* zero extension */
 	movl	RSP-RIP+16(%rsp),%r8d
-	SAVE_ARGS -8,1,1
+	SAVE_ARGS -8,0,0
 	movq	%rax,ORIG_RAX-ARGOFFSET(%rsp)
 	movq	%rbp,RCX-ARGOFFSET(%rsp) /* this lies slightly to ptrace */
 	movl	%ebp,%ecx
@@ -301,7 +301,7 @@ ENTRY(ia32_syscall)
 	cld
 	/* note the registers are not zero extended to the sf.
 	   this could be a problem. */
-	SAVE_ARGS 0,0,1
+	SAVE_ARGS 0,1,0
 	GET_THREAD_INFO(%r10)
 	orl   $TS_COMPAT,TI_status(%r10)
 	testl $_TIF_WORK_SYSCALL_ENTRY,TI_flags(%r10)
@@ -560,7 +560,7 @@ ia32_sys_call_table:
 	.quad sys32_vm86_warning	/* vm86 */ 
 	.quad quiet_ni_syscall	/* query_module */
 	.quad sys_poll
-	.quad compat_sys_nfsservctl
+	.quad quiet_ni_syscall /* old nfsservctl */
 	.quad sys_setresgid16	/* 170 */
 	.quad sys_getresgid16
 	.quad sys_prctl
--- head-2011-11-03.orig/arch/x86/include/asm/ptrace.h	2011-09-07 15:37:41.000000000 +0200
+++ head-2011-11-03/arch/x86/include/asm/ptrace.h	2011-09-12 13:18:42.000000000 +0200
@@ -133,6 +133,8 @@ struct pt_regs {
 #include <linux/init.h>
 #ifdef CONFIG_PARAVIRT
 #include <asm/paravirt_types.h>
+#elif defined(CONFIG_X86_64_XEN)
+#include <xen/interface/xen.h>
 #endif
 
 struct cpuinfo_x86;
@@ -193,7 +195,13 @@ static inline int v8086_mode(struct pt_r
 #ifdef CONFIG_X86_64
 static inline bool user_64bit_mode(struct pt_regs *regs)
 {
-#ifndef CONFIG_PARAVIRT
+#if defined(CONFIG_XEN)
+	/*
+	 * On Xen, these are the only long mode CPL 3 selectors.
+	 * We do not allow long mode selectors in the LDT.
+	 */
+	return regs->cs == __USER_CS || regs->cs == FLAT_USER_CS64;
+#elif !defined(CONFIG_PARAVIRT)
 	/*
 	 * On non-paravirt systems, this is the only long mode CPL 3
 	 * selector.  We do not allow long mode selectors in the LDT.
--- head-2011-11-03.orig/arch/x86/include/mach-xen/asm/desc.h	2011-07-01 15:21:58.000000000 +0200
+++ head-2011-11-03/arch/x86/include/mach-xen/asm/desc.h	2011-09-08 16:54:08.000000000 +0200
@@ -27,8 +27,8 @@ static inline void fill_ldt(struct desc_
 
 	desc->base2		= (info->base_addr & 0xff000000) >> 24;
 	/*
-	 * Don't allow setting of the lm bit. It is useless anyway
-	 * because 64bit system calls require __USER_CS:
+	 * Don't allow setting of the lm bit. It would confuse
+	 * user_64bit_mode and would get overridden by sysret anyway.
 	 */
 	desc->l			= 0;
 }
--- head-2011-11-03.orig/arch/x86/include/mach-xen/asm/fixmap.h	2011-02-01 15:41:35.000000000 +0100
+++ head-2011-11-03/arch/x86/include/mach-xen/asm/fixmap.h	2011-09-08 16:54:08.000000000 +0200
@@ -78,6 +78,7 @@ enum fixed_addresses {
 	VSYSCALL_LAST_PAGE,
 	VSYSCALL_FIRST_PAGE = VSYSCALL_LAST_PAGE
 			    + ((VSYSCALL_END-VSYSCALL_START) >> PAGE_SHIFT) - 1,
+	VVAR_PAGE,
 	VSYSCALL_HPET,
 #endif
 	FIX_DBGP_BASE,
--- head-2011-11-03.orig/arch/x86/include/mach-xen/asm/irqflags.h	2011-02-01 15:09:47.000000000 +0100
+++ head-2011-11-03/arch/x86/include/mach-xen/asm/irqflags.h	2011-09-08 16:54:08.000000000 +0200
@@ -4,6 +4,7 @@
 #include <asm/smp-processor-id.h>
 
 #ifndef __ASSEMBLY__
+#include <linux/types.h>
 /*
  * The use of 'barrier' in the following reflects their use as local-lock
  * operations. Reentrancy must be prevented (e.g., __cli()) /before/ following
--- head-2011-11-03.orig/arch/x86/include/mach-xen/asm/mmu_context.h	2011-02-08 10:25:49.000000000 +0100
+++ head-2011-11-03/arch/x86/include/mach-xen/asm/mmu_context.h	2011-09-08 16:54:08.000000000 +0200
@@ -2,7 +2,7 @@
 #define _ASM_X86_MMU_CONTEXT_H
 
 #include <asm/desc.h>
-#include <asm/atomic.h>
+#include <linux/atomic.h>
 #include <asm/pgalloc.h>
 #include <asm/tlbflush.h>
 
--- head-2011-11-03.orig/arch/x86/include/mach-xen/asm/perf_event.h	2011-02-01 15:41:55.000000000 +0100
+++ head-2011-11-03/arch/x86/include/mach-xen/asm/perf_event.h	2011-09-08 16:54:08.000000000 +0200
@@ -30,6 +30,11 @@
 	(regs)->bp = caller_frame_pointer();			\
 	(regs)->cs = __KERNEL_CS;				\
 	regs->flags = 0;					\
+	asm volatile(						\
+		_ASM_MOV "%%"_ASM_SP ", %0\n"			\
+		: "=m" ((regs)->sp)				\
+		:: "memory"					\
+	);							\
 }
 
 #endif
--- head-2011-11-03.orig/arch/x86/include/mach-xen/asm/pgtable_types.h	2011-05-23 11:27:06.000000000 +0200
+++ head-2011-11-03/arch/x86/include/mach-xen/asm/pgtable_types.h	2011-09-08 16:54:08.000000000 +0200
@@ -121,7 +121,8 @@ extern unsigned int __kernel_page_user;
 #define __PAGE_KERNEL_NOCACHE		(__PAGE_KERNEL | _PAGE_PCD | _PAGE_PWT)
 #define __PAGE_KERNEL_UC_MINUS		(__PAGE_KERNEL | _PAGE_PCD)
 #define __PAGE_KERNEL_VSYSCALL		(__PAGE_KERNEL_RX | _PAGE_USER)
-#define __PAGE_KERNEL_VSYSCALL_NOCACHE	(__PAGE_KERNEL_VSYSCALL | _PAGE_PCD | _PAGE_PWT)
+#define __PAGE_KERNEL_VVAR		(__PAGE_KERNEL_RO | _PAGE_USER)
+#define __PAGE_KERNEL_VVAR_NOCACHE	(__PAGE_KERNEL_VVAR | _PAGE_PCD | _PAGE_PWT)
 #define __PAGE_KERNEL_LARGE		(__PAGE_KERNEL | _PAGE_PSE)
 #define __PAGE_KERNEL_LARGE_NOCACHE	(__PAGE_KERNEL | _PAGE_CACHE_UC | _PAGE_PSE)
 #define __PAGE_KERNEL_LARGE_EXEC	(__PAGE_KERNEL_EXEC | _PAGE_PSE)
@@ -143,7 +144,8 @@ extern unsigned int __kernel_page_user;
 #define PAGE_KERNEL_LARGE_NOCACHE	__pgprot(__PAGE_KERNEL_LARGE_NOCACHE)
 #define PAGE_KERNEL_LARGE_EXEC		__pgprot(__PAGE_KERNEL_LARGE_EXEC)
 #define PAGE_KERNEL_VSYSCALL		__pgprot(__PAGE_KERNEL_VSYSCALL)
-#define PAGE_KERNEL_VSYSCALL_NOCACHE	__pgprot(__PAGE_KERNEL_VSYSCALL_NOCACHE)
+#define PAGE_KERNEL_VVAR		__pgprot(__PAGE_KERNEL_VVAR)
+#define PAGE_KERNEL_VVAR_NOCACHE	__pgprot(__PAGE_KERNEL_VVAR_NOCACHE)
 
 #define PAGE_KERNEL_IO			__pgprot(__PAGE_KERNEL_IO)
 #define PAGE_KERNEL_IO_NOCACHE		__pgprot(__PAGE_KERNEL_IO_NOCACHE)
--- head-2011-11-03.orig/arch/x86/include/mach-xen/asm/processor.h	2011-07-01 15:19:34.000000000 +0200
+++ head-2011-11-03/arch/x86/include/mach-xen/asm/processor.h	2011-09-08 16:54:08.000000000 +0200
@@ -705,8 +705,6 @@ static inline void __sti_mwait(unsigned 
 		     :: "a" (eax), "c" (ecx));
 }
 
-extern void mwait_idle_with_hints(unsigned long eax, unsigned long ecx);
-
 extern void select_idle_routine(const struct cpuinfo_x86 *c);
 extern void init_amd_e400_c1e_mask(void);
 
--- head-2011-11-03.orig/arch/x86/include/mach-xen/asm/spinlock.h	2011-07-12 11:15:37.000000000 +0200
+++ head-2011-11-03/arch/x86/include/mach-xen/asm/spinlock.h	2011-09-08 16:54:08.000000000 +0200
@@ -1,8 +1,7 @@
 #ifndef _ASM_X86_SPINLOCK_H
 #define _ASM_X86_SPINLOCK_H
 
-#include <asm/atomic.h>
-#include <asm/rwlock.h>
+#include <linux/atomic.h>
 #include <asm/page.h>
 #include <asm/processor.h>
 #include <linux/compiler.h>
@@ -368,7 +367,7 @@ static inline void arch_spin_unlock_wait
  */
 static inline int arch_read_can_lock(arch_rwlock_t *lock)
 {
-	return (int)(lock)->lock > 0;
+	return lock->lock > 0;
 }
 
 /**
@@ -377,12 +376,12 @@ static inline int arch_read_can_lock(arc
  */
 static inline int arch_write_can_lock(arch_rwlock_t *lock)
 {
-	return (lock)->lock == RW_LOCK_BIAS;
+	return lock->write == WRITE_LOCK_CMP;
 }
 
 static inline void arch_read_lock(arch_rwlock_t *rw)
 {
-	asm volatile(LOCK_PREFIX " subl $1,(%0)\n\t"
+	asm volatile(LOCK_PREFIX READ_LOCK_SIZE(dec) " (%0)\n\t"
 		     "jns 1f\n"
 		     "call __read_lock_failed\n\t"
 		     "1:\n"
@@ -391,47 +390,55 @@ static inline void arch_read_lock(arch_r
 
 static inline void arch_write_lock(arch_rwlock_t *rw)
 {
-	asm volatile(LOCK_PREFIX " subl %1,(%0)\n\t"
+	asm volatile(LOCK_PREFIX WRITE_LOCK_SUB(%1) "(%0)\n\t"
 		     "jz 1f\n"
 		     "call __write_lock_failed\n\t"
 		     "1:\n"
-		     ::LOCK_PTR_REG (rw), "i" (RW_LOCK_BIAS) : "memory");
+		     ::LOCK_PTR_REG (&rw->write), "i" (RW_LOCK_BIAS)
+		     : "memory");
 }
 
 static inline int arch_read_trylock(arch_rwlock_t *lock)
 {
-	atomic_t *count = (atomic_t *)lock;
+	READ_LOCK_ATOMIC(t) *count = (READ_LOCK_ATOMIC(t) *)lock;
 
-	if (atomic_dec_return(count) >= 0)
+	if (READ_LOCK_ATOMIC(dec_return)(count) >= 0)
 		return 1;
-	atomic_inc(count);
+	READ_LOCK_ATOMIC(inc)(count);
 	return 0;
 }
 
 static inline int arch_write_trylock(arch_rwlock_t *lock)
 {
-	atomic_t *count = (atomic_t *)lock;
+	atomic_t *count = (atomic_t *)&lock->write;
 
-	if (atomic_sub_and_test(RW_LOCK_BIAS, count))
+	if (atomic_sub_and_test(WRITE_LOCK_CMP, count))
 		return 1;
-	atomic_add(RW_LOCK_BIAS, count);
+	atomic_add(WRITE_LOCK_CMP, count);
 	return 0;
 }
 
 static inline void arch_read_unlock(arch_rwlock_t *rw)
 {
-	asm volatile(LOCK_PREFIX "incl %0" :"+m" (rw->lock) : : "memory");
+	asm volatile(LOCK_PREFIX READ_LOCK_SIZE(inc) " %0"
+		     :"+m" (rw->lock) : : "memory");
 }
 
 static inline void arch_write_unlock(arch_rwlock_t *rw)
 {
-	asm volatile(LOCK_PREFIX "addl %1, %0"
-		     : "+m" (rw->lock) : "i" (RW_LOCK_BIAS) : "memory");
+	asm volatile(LOCK_PREFIX WRITE_LOCK_ADD(%1) "%0"
+		     : "+m" (rw->write) : "i" (RW_LOCK_BIAS) : "memory");
 }
 
 #define arch_read_lock_flags(lock, flags) arch_read_lock(lock)
 #define arch_write_lock_flags(lock, flags) arch_write_lock(lock)
 
+#undef READ_LOCK_SIZE
+#undef READ_LOCK_ATOMIC
+#undef WRITE_LOCK_ADD
+#undef WRITE_LOCK_SUB
+#undef WRITE_LOCK_CMP
+
 #define arch_spin_relax(lock)	cpu_relax()
 #define arch_read_relax(lock)	cpu_relax()
 #define arch_write_relax(lock)	cpu_relax()
--- head-2011-11-03.orig/arch/x86/include/mach-xen/asm/spinlock_types.h	2011-02-01 14:55:46.000000000 +0100
+++ head-2011-11-03/arch/x86/include/mach-xen/asm/spinlock_types.h	2011-09-08 16:54:08.000000000 +0200
@@ -46,10 +46,6 @@ typedef union {
 
 #define __ARCH_SPIN_LOCK_UNLOCKED	{ 0 }
 
-typedef struct {
-	unsigned int lock;
-} arch_rwlock_t;
-
-#define __ARCH_RW_LOCK_UNLOCKED		{ RW_LOCK_BIAS }
+#include <asm/rwlock.h>
 
 #endif /* _ASM_X86_SPINLOCK_TYPES_H */
--- head-2011-11-03.orig/arch/x86/kernel/apic/io_apic-xen.c	2011-07-04 14:54:36.000000000 +0200
+++ head-2011-11-03/arch/x86/kernel/apic/io_apic-xen.c	2011-09-08 16:54:08.000000000 +0200
@@ -1357,6 +1357,16 @@ static int setup_ioapic_entry(int apic_i
 		 * irq handler will do the explicit EOI to the io-apic.
 		 */
 		ir_entry->vector = pin;
+
+		apic_printk(APIC_VERBOSE, KERN_DEBUG "IOAPIC[%d]: "
+			"Set IRTE entry (P:%d FPD:%d Dst_Mode:%d "
+			"Redir_hint:%d Trig_Mode:%d Dlvry_Mode:%X "
+			"Avail:%X Vector:%02X Dest:%08X "
+			"SID:%04X SQ:%X SVT:%X)\n",
+			apic_id, irte.present, irte.fpd, irte.dst_mode,
+			irte.redir_hint, irte.trigger_mode, irte.dlvry_mode,
+			irte.avail, irte.vector, irte.dest_id,
+			irte.sid, irte.sq, irte.svt);
 	} else
 #endif
 	{
@@ -1407,9 +1417,9 @@ static void setup_ioapic_irq(int apic_id
 
 	apic_printk(APIC_VERBOSE,KERN_DEBUG
 		    "IOAPIC[%d]: Set routing entry (%d-%d -> 0x%x -> "
-		    "IRQ %d Mode:%i Active:%i)\n",
+		    "IRQ %d Mode:%i Active:%i Dest:%d)\n",
 		    apic_id, mpc_ioapic_id(apic_id), pin, cfg->vector,
-		    irq, trigger, polarity);
+		    irq, trigger, polarity, dest);
 
 
 	if (setup_ioapic_entry(mpc_ioapic_id(apic_id), irq, &entry,
@@ -1604,10 +1614,12 @@ __apicdebuginit(void) print_IO_APIC(void
 	printk(KERN_DEBUG ".......    : LTS          : %X\n", reg_00.bits.LTS);
 
 	printk(KERN_DEBUG ".... register #01: %08X\n", *(int *)&reg_01);
-	printk(KERN_DEBUG ".......     : max redirection entries: %04X\n", reg_01.bits.entries);
+	printk(KERN_DEBUG ".......     : max redirection entries: %02X\n",
+		reg_01.bits.entries);
 
 	printk(KERN_DEBUG ".......     : PRQ implemented: %X\n", reg_01.bits.PRQ);
-	printk(KERN_DEBUG ".......     : IO APIC version: %04X\n", reg_01.bits.version);
+	printk(KERN_DEBUG ".......     : IO APIC version: %02X\n",
+		reg_01.bits.version);
 
 	/*
 	 * Some Intel chipsets with IO APIC VERSION of 0x1? don't have reg_02,
@@ -1632,31 +1644,60 @@ __apicdebuginit(void) print_IO_APIC(void
 
 	printk(KERN_DEBUG ".... IRQ redirection table:\n");
 
-	printk(KERN_DEBUG " NR Dst Mask Trig IRR Pol"
-			  " Stat Dmod Deli Vect:\n");
+	if (intr_remapping_enabled) {
+		printk(KERN_DEBUG " NR Indx Fmt Mask Trig IRR"
+			" Pol Stat Indx2 Zero Vect:\n");
+	} else {
+		printk(KERN_DEBUG " NR Dst Mask Trig IRR Pol"
+			" Stat Dmod Deli Vect:\n");
+	}
 
 	for (i = 0; i <= reg_01.bits.entries; i++) {
-		struct IO_APIC_route_entry entry;
+		if (intr_remapping_enabled) {
+			struct IO_APIC_route_entry entry;
+			struct IR_IO_APIC_route_entry *ir_entry;
 
-		entry = ioapic_read_entry(apic, i);
+			entry = ioapic_read_entry(apic, i);
+			ir_entry = (struct IR_IO_APIC_route_entry *) &entry;
+			printk(KERN_DEBUG " %02x %04X ",
+				i,
+				ir_entry->index
+			);
+			printk("%1d   %1d    %1d    %1d   %1d   "
+				"%1d    %1d     %X    %02X\n",
+				ir_entry->format,
+				ir_entry->mask,
+				ir_entry->trigger,
+				ir_entry->irr,
+				ir_entry->polarity,
+				ir_entry->delivery_status,
+				ir_entry->index2,
+				ir_entry->zero,
+				ir_entry->vector
+			);
+		} else {
+			struct IO_APIC_route_entry entry;
 
-		printk(KERN_DEBUG " %02x %03X ",
-			i,
-			entry.dest
-		);
-
-		printk("%1d    %1d    %1d   %1d   %1d    %1d    %1d    %02X\n",
-			entry.mask,
-			entry.trigger,
-			entry.irr,
-			entry.polarity,
-			entry.delivery_status,
-			entry.dest_mode,
-			entry.delivery_mode,
-			entry.vector
-		);
+			entry = ioapic_read_entry(apic, i);
+			printk(KERN_DEBUG " %02x %02X  ",
+				i,
+				entry.dest
+			);
+			printk("%1d    %1d    %1d   %1d   %1d    "
+				"%1d    %1d    %02X\n",
+				entry.mask,
+				entry.trigger,
+				entry.irr,
+				entry.polarity,
+				entry.delivery_status,
+				entry.dest_mode,
+				entry.delivery_mode,
+				entry.vector
+			);
+		}
 	}
 	}
+
 	printk(KERN_DEBUG "IRQ to pin mappings:\n");
 	for_each_active_irq(irq) {
 		struct irq_pin_list *entry;
@@ -1874,7 +1915,7 @@ __apicdebuginit(int) print_ICs(void)
 	return 0;
 }
 
-fs_initcall(print_ICs);
+late_initcall(print_ICs);
 
 
 /* Where if anywhere is the i8259 connect in external int mode */
--- head-2011-11-03.orig/arch/x86/kernel/cpu/common-xen.c	2011-07-01 15:19:34.000000000 +0200
+++ head-2011-11-03/arch/x86/kernel/cpu/common-xen.c	2011-09-08 16:54:08.000000000 +0200
@@ -21,7 +21,7 @@
 #include <linux/topology.h>
 #include <linux/cpumask.h>
 #include <asm/pgtable.h>
-#include <asm/atomic.h>
+#include <linux/atomic.h>
 #include <asm/proto.h>
 #include <asm/setup.h>
 #include <asm/apic.h>
--- head-2011-11-03.orig/arch/x86/kernel/entry_32-xen.S	2011-04-26 09:19:58.000000000 +0200
+++ head-2011-11-03/arch/x86/kernel/entry_32-xen.S	2011-09-12 10:17:44.000000000 +0200
@@ -54,6 +54,7 @@
 #include <asm/ftrace.h>
 #include <asm/irq_vectors.h>
 #include <asm/cpufeature.h>
+#include <asm/alternative-asm.h>
 #include <xen/interface/xen.h>
 
 /* Avoid __ASSEMBLER__'ifying <linux/audit.h> just for this.  */
@@ -1088,12 +1089,7 @@ ENTRY(simd_coprocessor_error)
 661:	pushl_cfi $do_general_protection
 662:
 .section .altinstructions,"a"
-	.balign 4
-	.long 661b
-	.long 663f
-	.word X86_FEATURE_XMM
-	.byte 662b-661b
-	.byte 664f-663f
+	altinstruction_entry 661b, 663f, X86_FEATURE_XMM, 662b-661b, 664f-663f
 .previous
 .section .altinstr_replacement,"ax"
 663:	pushl $do_simd_coprocessor_error
@@ -1343,8 +1339,6 @@ return_to_handler:
 	jmp *%ecx
 #endif
 
-#include <asm/alternative-asm.h>
-
 	# pv syscall call handler stub
 ENTRY(ia32pv_cstar_target)
 	RING0_INT_FRAME
--- head-2011-11-03.orig/arch/x86/kernel/entry_64-xen.S	2011-10-07 11:41:39.000000000 +0200
+++ head-2011-11-03/arch/x86/kernel/entry_64-xen.S	2011-10-07 11:45:32.000000000 +0200
@@ -12,6 +12,8 @@
 /*
  * entry.S contains the system-call and fault low-level handling routines.
  *
+ * Some of this is documented in Documentation/x86/entry_64.txt
+ *
  * NOTE: This code handles signal-recognition, which happens every time
  * after an interrupt and after each system call.
  *
@@ -331,27 +333,26 @@ NMI_MASK = 0x80000000
 
 #ifndef CONFIG_XEN
 /* save partial stack frame */
-	.pushsection .kprobes.text, "ax"
-ENTRY(save_args)
-	XCPT_FRAME
+	.macro SAVE_ARGS_IRQ
 	cld
-	/*
-	 * start from rbp in pt_regs and jump over
-	 * return address.
-	 */
-	movq_cfi rdi, RDI+8-RBP
-	movq_cfi rsi, RSI+8-RBP
-	movq_cfi rdx, RDX+8-RBP
-	movq_cfi rcx, RCX+8-RBP
-	movq_cfi rax, RAX+8-RBP
-	movq_cfi  r8,  R8+8-RBP
-	movq_cfi  r9,  R9+8-RBP
-	movq_cfi r10, R10+8-RBP
-	movq_cfi r11, R11+8-RBP
-
-	leaq -RBP+8(%rsp),%rdi	/* arg1 for handler */
-	movq_cfi rbp, 8		/* push %rbp */
-	leaq 8(%rsp), %rbp		/* mov %rsp, %ebp */
+	/* start from rbp in pt_regs and jump over */
+	movq_cfi rdi, RDI-RBP
+	movq_cfi rsi, RSI-RBP
+	movq_cfi rdx, RDX-RBP
+	movq_cfi rcx, RCX-RBP
+	movq_cfi rax, RAX-RBP
+	movq_cfi  r8,  R8-RBP
+	movq_cfi  r9,  R9-RBP
+	movq_cfi r10, R10-RBP
+	movq_cfi r11, R11-RBP
+
+	/* Save rbp so that we can unwind from get_irq_regs() */
+	movq_cfi rbp, 0
+
+	/* Save previous stack value */
+	movq %rsp, %rsi
+
+	leaq -RBP(%rsp),%rdi	/* arg1 for handler */
 	testl $3, CS(%rdi)
 	je 1f
 	SWAPGS
@@ -363,19 +364,14 @@ ENTRY(save_args)
 	 */
 1:	incl PER_CPU_VAR(irq_count)
 	jne 2f
-	popq_cfi %rax			/* move return address... */
 	mov PER_CPU_VAR(irq_stack_ptr),%rsp
 	EMPTY_FRAME 0
-	pushq_cfi %rbp			/* backlink for unwinder */
-	pushq_cfi %rax			/* ... to the new stack */
-	/*
-	 * We entered an interrupt context - irqs are off:
-	 */
-2:	TRACE_IRQS_OFF
-	ret
-	CFI_ENDPROC
-END(save_args)
-	.popsection
+
+2:	/* Store previous stack value */
+	pushq %rsi
+	/* We entered an interrupt context - irqs are off: */
+	TRACE_IRQS_OFF
+	.endm
 #endif
 
 ENTRY(save_rest)
@@ -491,7 +487,7 @@ END(ret_from_fork)
 
 ENTRY(system_call)
 	INTR_FRAME start=2 offset=2*8
-	SAVE_ARGS -8,1
+	SAVE_ARGS -8,0
 	movq  %rax,ORIG_RAX-ARGOFFSET(%rsp)
 	GET_THREAD_INFO(%rcx)
 	testl $_TIF_WORK_SYSCALL_ENTRY,TI_flags(%rcx)
@@ -522,7 +518,7 @@ sysret_check:
 	 * sysretq will re-enable interrupts:
 	 */
 	TRACE_IRQS_ON
-	RESTORE_ARGS 0,8,1,1
+	RESTORE_ARGS 1,8,0,0
 	xor %ecx,%ecx
 	xor %r11,%r11
         HYPERVISOR_IRET VGCF_IN_SYSCALL
@@ -778,7 +774,7 @@ retint_restore_args:	/* return to kernel
 	andb $1,%al			# EAX[0] == IRET_EFLAGS.IF & event_mask
 	jnz restore_all_enable_events	#        != 0 => enable event delivery
 		
-	RESTORE_ARGS 0,8,0
+	RESTORE_ARGS 1,8,1
 	HYPERVISOR_IRET 0
 	
 	/* edi: workmask, edx: work */
@@ -874,11 +870,6 @@ apicinterrupt THRESHOLD_APIC_VECTOR \
 apicinterrupt THERMAL_APIC_VECTOR \
 	thermal_interrupt smp_thermal_interrupt
 
-#ifdef CONFIG_X86_MCE
-apicinterrupt MCE_SELF_VECTOR \
-	mce_self_interrupt smp_mce_self_interrupt
-#endif
-
 #ifdef CONFIG_SMP
 apicinterrupt CALL_FUNCTION_SINGLE_VECTOR \
 	call_function_single_interrupt smp_call_function_single_interrupt
@@ -999,7 +990,7 @@ scrit:	/**** START OF CRITICAL REGION **
 	__TEST_PENDING
 	CFI_REMEMBER_STATE
 	jnz  14f			# process more events if necessary...
-        RESTORE_ARGS 0,8,0
+        RESTORE_ARGS 1,8,1
         HYPERVISOR_IRET 0
         
 	CFI_RESTORE_STATE
--- head-2011-11-03.orig/arch/x86/kernel/process-xen.c	2011-07-01 15:45:35.000000000 +0200
+++ head-2011-11-03/arch/x86/kernel/process-xen.c	2011-09-08 16:54:08.000000000 +0200
@@ -391,29 +391,6 @@ void cpu_idle_wait(void)
 EXPORT_SYMBOL_GPL(cpu_idle_wait);
 
 #ifndef CONFIG_XEN
-/*
- * This uses new MONITOR/MWAIT instructions on P4 processors with PNI,
- * which can obviate IPI to trigger checking of need_resched.
- * We execute MONITOR against need_resched and enter optimized wait state
- * through MWAIT. Whenever someone changes need_resched, we would be woken
- * up from MWAIT (without an IPI).
- *
- * New with Core Duo processors, MWAIT can take some hints based on CPU
- * capability.
- */
-void mwait_idle_with_hints(unsigned long ax, unsigned long cx)
-{
-	if (!need_resched()) {
-		if (this_cpu_has(X86_FEATURE_CLFLUSH_MONITOR))
-			clflush((void *)&current_thread_info()->flags);
-
-		__monitor((void *)&current_thread_info()->flags, 0, 0);
-		smp_mb();
-		if (!need_resched())
-			__mwait(ax, cx);
-	}
-}
-
 /* Default MONITOR/MWAIT with no hints, used for default C1 state */
 static void mwait_idle(void)
 {
--- head-2011-11-03.orig/arch/x86/kernel/process_32-xen.c	2011-07-01 15:19:35.000000000 +0200
+++ head-2011-11-03/arch/x86/kernel/process_32-xen.c	2011-09-08 16:54:08.000000000 +0200
@@ -38,6 +38,7 @@
 #include <linux/uaccess.h>
 #include <linux/io.h>
 #include <linux/kdebug.h>
+#include <linux/cpuidle.h>
 
 #include <asm/pgtable.h>
 #include <asm/system.h>
@@ -112,7 +113,8 @@ void cpu_idle(void)
 			local_irq_disable();
 			/* Don't trace irqs off for idle */
 			stop_critical_timings();
-			xen_idle();
+			if (cpuidle_idle_call())
+				xen_idle();
 			start_critical_timings();
 		}
 		tick_nohz_restart_sched_tick();
--- head-2011-11-03.orig/arch/x86/kernel/process_64-xen.c	2011-07-01 15:19:35.000000000 +0200
+++ head-2011-11-03/arch/x86/kernel/process_64-xen.c	2011-09-08 16:54:08.000000000 +0200
@@ -40,6 +40,7 @@
 #include <linux/uaccess.h>
 #include <linux/io.h>
 #include <linux/ftrace.h>
+#include <linux/cpuidle.h>
 
 #include <asm/pgtable.h>
 #include <asm/system.h>
@@ -140,7 +141,8 @@ void cpu_idle(void)
 			enter_idle();
 			/* Don't trace irqs off for idle */
 			stop_critical_timings();
-			xen_idle();
+			if (cpuidle_idle_call())
+				xen_idle();
 			start_critical_timings();
 
 			/* In many cases the interrupt that ended idle
--- head-2011-11-03.orig/arch/x86/kernel/time-xen.c	2011-08-23 13:57:06.000000000 +0200
+++ head-2011-11-03/arch/x86/kernel/time-xen.c	2011-09-12 10:55:04.000000000 +0200
@@ -32,10 +32,6 @@ extern void do_timer(unsigned long ticks
 #include <xen/sysctl.h>
 #include <xen/interface/vcpu.h>
 
-#include <asm/i8253.h>
-DEFINE_RAW_SPINLOCK(i8253_lock);
-EXPORT_SYMBOL(i8253_lock);
-
 #ifdef CONFIG_X86_64
 DEFINE_VVAR(volatile unsigned long, jiffies) = INITIAL_JIFFIES;
 #endif
--- head-2011-11-03.orig/arch/x86/kernel/traps-xen.c	2011-07-21 12:21:48.000000000 +0200
+++ head-2011-11-03/arch/x86/kernel/traps-xen.c	2011-09-08 16:54:08.000000000 +0200
@@ -49,7 +49,7 @@
 #include <asm/stacktrace.h>
 #include <asm/processor.h>
 #include <asm/debugreg.h>
-#include <asm/atomic.h>
+#include <linux/atomic.h>
 #include <asm/system.h>
 #include <asm/traps.h>
 #include <asm/desc.h>
--- head-2011-11-03.orig/arch/x86/kernel/vsyscall_64-xen.c	2011-07-01 15:19:35.000000000 +0200
+++ head-2011-11-03/arch/x86/kernel/vsyscall_64-xen.c	2011-11-03 12:58:44.000000000 +0100
@@ -2,6 +2,8 @@
  *  Copyright (C) 2001 Andrea Arcangeli <andrea@suse.de> SuSE
  *  Copyright 2003 Andi Kleen, SuSE Labs.
  *
+ *  [ NOTE: this mechanism is now deprecated in favor of the vDSO. ]
+ *
  *  Thanks to hpa@transmeta.com for some useful hint.
  *  Special thanks to Ingo Molnar for his early experience with
  *  a different vsyscall implementation for Linux/IA32 and for the name.
@@ -11,15 +13,11 @@
  *  vsyscalls. One vsyscall can reserve more than 1 slot to avoid
  *  jumping out of line if necessary. We cannot add more with this
  *  mechanism because older kernels won't return -ENOSYS.
- *  If we want more than four we need a vDSO.
  *
- *  Note: the concept clashes with user mode linux. If you use UML and
- *  want per guest time just set the kernel.vsyscall64 sysctl to 0.
+ *  Note: the concept clashes with user mode linux.  UML users should
+ *  use the vDSO.
  */
 
-/* Disable profiling for userspace code: */
-#define DISABLE_BRANCH_PROFILING
-
 #include <linux/time.h>
 #include <linux/init.h>
 #include <linux/kernel.h>
@@ -32,9 +30,12 @@
 #include <linux/cpu.h>
 #include <linux/smp.h>
 #include <linux/notifier.h>
+#include <linux/syscalls.h>
+#include <linux/ratelimit.h>
 
 #include <asm/vsyscall.h>
 #include <asm/pgtable.h>
+#include <asm/compat.h>
 #include <asm/page.h>
 #include <asm/unistd.h>
 #include <asm/fixmap.h>
@@ -44,18 +45,38 @@
 #include <asm/desc.h>
 #include <asm/topology.h>
 #include <asm/vgtod.h>
+#include <asm/traps.h>
 
-#define __vsyscall(nr) \
-		__attribute__ ((unused, __section__(".vsyscall_" #nr))) notrace
-#define __syscall_clobber "r11","cx","memory"
+#define CREATE_TRACE_POINTS
+#include "vsyscall_trace.h"
 
 DEFINE_VVAR(int, vgetcpu_mode);
 DEFINE_VVAR(struct vsyscall_gtod_data, vsyscall_gtod_data) =
 {
 	.lock = __SEQLOCK_UNLOCKED(__vsyscall_gtod_data.lock),
-	.sysctl_enabled = 1,
 };
 
+static enum { EMULATE, NATIVE, NONE } vsyscall_mode = NATIVE;
+
+static int __init vsyscall_setup(char *str)
+{
+	if (str) {
+		if (!strcmp("emulate", str))
+			vsyscall_mode = EMULATE;
+		else if (!strcmp("native", str))
+			vsyscall_mode = NATIVE;
+		else if (!strcmp("none", str))
+			vsyscall_mode = NONE;
+		else
+			return -EINVAL;
+
+		return 0;
+	}
+
+	return -EINVAL;
+}
+early_param("vsyscall", vsyscall_setup);
+
 void update_vsyscall_tz(void)
 {
 	unsigned long flags;
@@ -72,179 +93,145 @@ void update_vsyscall(struct timespec *wa
 	unsigned long flags;
 
 	write_seqlock_irqsave(&vsyscall_gtod_data.lock, flags);
+
 	/* copy vsyscall data */
-	vsyscall_gtod_data.clock.vread = clock->vread;
-	vsyscall_gtod_data.clock.cycle_last = clock->cycle_last;
-	vsyscall_gtod_data.clock.mask = clock->mask;
-	vsyscall_gtod_data.clock.mult = mult;
-	vsyscall_gtod_data.clock.shift = clock->shift;
-	vsyscall_gtod_data.wall_time_sec = wall_time->tv_sec;
-	vsyscall_gtod_data.wall_time_nsec = wall_time->tv_nsec;
-	vsyscall_gtod_data.wall_to_monotonic = *wtm;
-	vsyscall_gtod_data.wall_time_coarse = __current_kernel_time();
+#ifndef CONFIG_XEN
+	vsyscall_gtod_data.clock.vclock_mode	= clock->archdata.vclock_mode;
+#endif
+	vsyscall_gtod_data.clock.cycle_last	= clock->cycle_last;
+	vsyscall_gtod_data.clock.mask		= clock->mask;
+	vsyscall_gtod_data.clock.mult		= mult;
+	vsyscall_gtod_data.clock.shift		= clock->shift;
+	vsyscall_gtod_data.wall_time_sec	= wall_time->tv_sec;
+	vsyscall_gtod_data.wall_time_nsec	= wall_time->tv_nsec;
+	vsyscall_gtod_data.wall_to_monotonic	= *wtm;
+	vsyscall_gtod_data.wall_time_coarse	= __current_kernel_time();
+
 	write_sequnlock_irqrestore(&vsyscall_gtod_data.lock, flags);
 }
 
-/* RED-PEN may want to readd seq locking, but then the variable should be
- * write-once.
- */
-static __always_inline void do_get_tz(struct timezone * tz)
+static void warn_bad_vsyscall(const char *level, struct pt_regs *regs,
+			      const char *message)
 {
-	*tz = VVAR(vsyscall_gtod_data).sys_tz;
-}
+	static DEFINE_RATELIMIT_STATE(rs, DEFAULT_RATELIMIT_INTERVAL, DEFAULT_RATELIMIT_BURST);
+	struct task_struct *tsk;
 
-static __always_inline int gettimeofday(struct timeval *tv, struct timezone *tz)
-{
-	int ret;
-	asm volatile("syscall"
-		: "=a" (ret)
-		: "0" (__NR_gettimeofday),"D" (tv),"S" (tz)
-		: __syscall_clobber );
-	return ret;
+	if (!show_unhandled_signals || !__ratelimit(&rs))
+		return;
+
+	tsk = current;
+
+	printk("%s%s[%d] %s ip:%lx cs:%lx sp:%lx ax:%lx si:%lx di:%lx\n",
+	       level, tsk->comm, task_pid_nr(tsk),
+	       message, regs->ip, regs->cs,
+	       regs->sp, regs->ax, regs->si, regs->di);
 }
 
-static __always_inline long time_syscall(long *t)
+static int addr_to_vsyscall_nr(unsigned long addr)
 {
-	long secs;
-	asm volatile("syscall"
-		: "=a" (secs)
-		: "0" (__NR_time),"D" (t) : __syscall_clobber);
-	return secs;
+	int nr;
+
+	if ((addr & ~0xC00UL) != VSYSCALL_START)
+		return -EINVAL;
+
+	nr = (addr & 0xC00UL) >> 10;
+	if (nr >= 3)
+		return -EINVAL;
+
+	return nr;
 }
 
-static __always_inline void do_vgettimeofday(struct timeval * tv)
+bool emulate_vsyscall(struct pt_regs *regs, unsigned long address)
 {
-	cycle_t now, base, mask, cycle_delta;
-	unsigned seq;
-	unsigned long mult, shift, nsec;
-	cycle_t (*vread)(void);
-	do {
-		seq = read_seqbegin(&VVAR(vsyscall_gtod_data).lock);
+	struct task_struct *tsk;
+	unsigned long caller;
+	int vsyscall_nr;
+	long ret;
+
+	/*
+	 * No point in checking CS -- the only way to get here is a user mode
+	 * trap to a high address, which means that we're in 64-bit user code.
+	 */
 
-		vread = VVAR(vsyscall_gtod_data).clock.vread;
-		if (unlikely(!VVAR(vsyscall_gtod_data).sysctl_enabled ||
-			     !vread)) {
-			gettimeofday(tv,NULL);
-			return;
-		}
+	WARN_ON_ONCE(address != regs->ip);
 
-		now = vread();
-		base = VVAR(vsyscall_gtod_data).clock.cycle_last;
-		mask = VVAR(vsyscall_gtod_data).clock.mask;
-		mult = VVAR(vsyscall_gtod_data).clock.mult;
-		shift = VVAR(vsyscall_gtod_data).clock.shift;
+	if (vsyscall_mode == NONE) {
+		warn_bad_vsyscall(KERN_INFO, regs,
+				  "vsyscall attempted with vsyscall=none");
+		return false;
+	}
 
-		tv->tv_sec = VVAR(vsyscall_gtod_data).wall_time_sec;
-		nsec = VVAR(vsyscall_gtod_data).wall_time_nsec;
-	} while (read_seqretry(&VVAR(vsyscall_gtod_data).lock, seq));
+	vsyscall_nr = addr_to_vsyscall_nr(address);
 
-	/* calculate interval: */
-	cycle_delta = (now - base) & mask;
-	/* convert to nsecs: */
-	nsec += (cycle_delta * mult) >> shift;
+	trace_emulate_vsyscall(vsyscall_nr);
 
-	while (nsec >= NSEC_PER_SEC) {
-		tv->tv_sec += 1;
-		nsec -= NSEC_PER_SEC;
+	if (vsyscall_nr < 0) {
+		warn_bad_vsyscall(KERN_WARNING, regs,
+				  "misaligned vsyscall (exploit attempt or buggy program) -- look up the vsyscall kernel parameter if you need a workaround");
+		goto sigsegv;
 	}
-	tv->tv_usec = nsec / NSEC_PER_USEC;
-}
 
-int __vsyscall(0) vgettimeofday(struct timeval * tv, struct timezone * tz)
-{
-	if (tv)
-		do_vgettimeofday(tv);
-	if (tz)
-		do_get_tz(tz);
-	return 0;
-}
+	if (get_user(caller, (unsigned long __user *)regs->sp) != 0) {
+		warn_bad_vsyscall(KERN_WARNING, regs,
+				  "vsyscall with bad stack (exploit attempt?)");
+		goto sigsegv;
+	}
 
-/* This will break when the xtime seconds get inaccurate, but that is
- * unlikely */
-time_t __vsyscall(1) vtime(time_t *t)
-{
-	unsigned seq;
-	time_t result;
-	if (unlikely(!VVAR(vsyscall_gtod_data).sysctl_enabled))
-		return time_syscall(t);
-
-	do {
-		seq = read_seqbegin(&VVAR(vsyscall_gtod_data).lock);
-
-		result = VVAR(vsyscall_gtod_data).wall_time_sec;
-
-	} while (read_seqretry(&VVAR(vsyscall_gtod_data).lock, seq));
-
-	if (t)
-		*t = result;
-	return result;
-}
-
-/* Fast way to get current CPU and node.
-   This helps to do per node and per CPU caches in user space.
-   The result is not guaranteed without CPU affinity, but usually
-   works out because the scheduler tries to keep a thread on the same
-   CPU.
-
-   tcache must point to a two element sized long array.
-   All arguments can be NULL. */
-long __vsyscall(2)
-vgetcpu(unsigned *cpu, unsigned *node, struct getcpu_cache *tcache)
-{
-	unsigned int p;
-	unsigned long j = 0;
-
-	/* Fast cache - only recompute value once per jiffies and avoid
-	   relatively costly rdtscp/cpuid otherwise.
-	   This works because the scheduler usually keeps the process
-	   on the same CPU and this syscall doesn't guarantee its
-	   results anyways.
-	   We do this here because otherwise user space would do it on
-	   its own in a likely inferior way (no access to jiffies).
-	   If you don't like it pass NULL. */
-	if (tcache && tcache->blob[0] == (j = VVAR(jiffies))) {
-		p = tcache->blob[1];
-	} else if (VVAR(vgetcpu_mode) == VGETCPU_RDTSCP) {
-		/* Load per CPU data from RDTSCP */
-		native_read_tscp(&p);
-	} else {
-		/* Load per CPU data from GDT */
-		asm("lsl %1,%0" : "=r" (p) : "r" (__PER_CPU_SEG));
+	tsk = current;
+	if (seccomp_mode(&tsk->seccomp))
+		do_exit(SIGKILL);
+
+	switch (vsyscall_nr) {
+	case 0:
+		ret = sys_gettimeofday(
+			(struct timeval __user *)regs->di,
+			(struct timezone __user *)regs->si);
+		break;
+
+	case 1:
+		ret = sys_time((time_t __user *)regs->di);
+		break;
+
+	case 2:
+		ret = sys_getcpu((unsigned __user *)regs->di,
+				 (unsigned __user *)regs->si,
+				 0);
+		break;
+	default:
+		ret = -ENOSYS;
+		break;
 	}
-	if (tcache) {
-		tcache->blob[0] = j;
-		tcache->blob[1] = p;
+
+	if (ret == -EFAULT) {
+		/*
+		 * Bad news -- userspace fed a bad pointer to a vsyscall.
+		 *
+		 * With a real vsyscall, that would have caused SIGSEGV.
+		 * To make writing reliable exploits using the emulated
+		 * vsyscalls harder, generate SIGSEGV here as well.
+		 */
+		warn_bad_vsyscall(KERN_INFO, regs,
+				  "vsyscall fault (exploit attempt?)");
+		goto sigsegv;
 	}
-	if (cpu)
-		*cpu = p & 0xfff;
-	if (node)
-		*node = p >> 12;
-	return 0;
-}
 
-static long __vsyscall(3) venosys_1(void)
-{
-	return -ENOSYS;
-}
+	regs->ax = ret;
 
-#ifdef CONFIG_SYSCTL
-static ctl_table kernel_table2[] = {
-	{ .procname = "vsyscall64",
-	  .data = &vsyscall_gtod_data.sysctl_enabled, .maxlen = sizeof(int),
-	  .mode = 0644,
-	  .proc_handler = proc_dointvec },
-	{}
-};
+	/* Emulate a ret instruction. */
+	regs->ip = caller;
+	regs->sp += 8;
 
-static ctl_table kernel_root_table2[] = {
-	{ .procname = "kernel", .mode = 0555,
-	  .child = kernel_table2 },
-	{}
-};
-#endif
+	return true;
 
-/* Assume __initcall executes before all user space. Hopefully kmod
-   doesn't violate that. We'll find out if it does. */
+sigsegv:
+	force_sig(SIGSEGV, current);
+	return true;
+}
+
+/*
+ * Assume __initcall executes before all user space. Hopefully kmod
+ * doesn't violate that. We'll find out if it does.
+ */
 static void __cpuinit vsyscall_set_cpu(int cpu)
 {
 	unsigned long d;
@@ -255,13 +242,15 @@ static void __cpuinit vsyscall_set_cpu(i
 	if (cpu_has(&cpu_data(cpu), X86_FEATURE_RDTSCP))
 		write_rdtscp_aux((node << 12) | cpu);
 
-	/* Store cpu number in limit so that it can be loaded quickly
-	   in user space in vgetcpu.
-	   12 bits for the CPU and 8 bits for the node. */
+	/*
+	 * Store cpu number in limit so that it can be loaded quickly
+	 * in user space in vgetcpu. (12 bits for the CPU and 8 bits for the node)
+	 */
 	d = 0x0f40000000000ULL;
 	d |= cpu;
 	d |= (node & 0xf) << 12;
 	d |= (node >> 4) << 48;
+
 	write_gdt_entry(get_cpu_gdt_table(cpu), GDT_ENTRY_PER_CPU, &d, DESCTYPE_S);
 }
 
@@ -275,37 +264,40 @@ static int __cpuinit
 cpu_vsyscall_notifier(struct notifier_block *n, unsigned long action, void *arg)
 {
 	long cpu = (long)arg;
+
 	if (action == CPU_ONLINE || action == CPU_ONLINE_FROZEN)
 		smp_call_function_single(cpu, cpu_vsyscall_init, NULL, 1);
+
 	return NOTIFY_DONE;
 }
 
 void __init map_vsyscall(void)
 {
-	extern char __vsyscall_0;
-	unsigned long physaddr_page0 = __pa_symbol(&__vsyscall_0);
-
-	/* Note that VSYSCALL_MAPPED_PAGES must agree with the code below. */
-	__set_fixmap(VSYSCALL_FIRST_PAGE, physaddr_page0, PAGE_KERNEL_VSYSCALL);
+	extern char __vsyscall_page;
+	unsigned long physaddr_vsyscall = __pa_symbol(&__vsyscall_page);
+	extern char __vvar_page;
+	unsigned long physaddr_vvar_page = __pa_symbol(&__vvar_page);
+
+	__set_fixmap(VSYSCALL_FIRST_PAGE, physaddr_vsyscall,
+		     vsyscall_mode == NATIVE
+		     ? PAGE_KERNEL_VSYSCALL
+		     : PAGE_KERNEL_VVAR);
+	BUILD_BUG_ON((unsigned long)__fix_to_virt(VSYSCALL_FIRST_PAGE) !=
+		     (unsigned long)VSYSCALL_START);
+
+	__set_fixmap(VVAR_PAGE, physaddr_vvar_page, PAGE_KERNEL_VVAR);
+	BUILD_BUG_ON((unsigned long)__fix_to_virt(VVAR_PAGE) !=
+		     (unsigned long)VVAR_ADDRESS);
 }
 
 static int __init vsyscall_init(void)
 {
-	BUG_ON(((unsigned long) &vgettimeofday !=
-			VSYSCALL_ADDR(__NR_vgettimeofday)));
-	BUG_ON((unsigned long) &vtime != VSYSCALL_ADDR(__NR_vtime));
-	BUG_ON((VSYSCALL_ADDR(0) != __fix_to_virt(VSYSCALL_FIRST_PAGE)));
-	BUG_ON((unsigned long) &vgetcpu != VSYSCALL_ADDR(__NR_vgetcpu));
-#ifdef CONFIG_XEN
-	vsyscall_gtod_data.sysctl_enabled = 0; /* disable vgettimeofay() */
-#endif
-#ifdef CONFIG_SYSCTL
-	register_sysctl_table(kernel_root_table2);
-#endif
+	BUG_ON(VSYSCALL_ADDR(0) != __fix_to_virt(VSYSCALL_FIRST_PAGE));
+
 	on_each_cpu(cpu_vsyscall_init, NULL, 1);
 	/* notifier priority > KVM */
 	hotcpu_notifier(cpu_vsyscall_notifier, 30);
+
 	return 0;
 }
-
 __initcall(vsyscall_init);
--- head-2011-11-03.orig/arch/x86/mm/fault-xen.c	2011-08-15 11:06:42.000000000 +0200
+++ head-2011-11-03/arch/x86/mm/fault-xen.c	2011-09-08 16:54:08.000000000 +0200
@@ -17,6 +17,7 @@
 #include <asm/traps.h>			/* dotraplinkage, ...		*/
 #include <asm/pgalloc.h>		/* pgd_*(), ...			*/
 #include <asm/kmemcheck.h>		/* kmemcheck_*(), ...		*/
+#include <asm/vsyscall.h>
 
 /*
  * Page fault error code bits:
@@ -105,8 +106,7 @@ check_prefetch_opcode(struct pt_regs *re
 		 * but for now it's good enough to assume that long
 		 * mode only uses well known segments or kernel.
 		 */
-		return (!user_mode(regs)) || (regs->cs == __USER_CS)
-		       || (regs->cs == FLAT_USER_CS64);
+		return (!user_mode(regs) || user_64bit_mode(regs));
 #endif
 	case 0x60:
 		/* 0x64 thru 0x67 are valid prefixes in all modes. */
@@ -730,6 +730,18 @@ __bad_area_nosemaphore(struct pt_regs *r
 		if (is_errata100(regs, address))
 			return;
 
+#ifdef CONFIG_X86_64
+		/*
+		 * Instruction fetch faults in the vsyscall page might need
+		 * emulation.
+		 */
+		if (unlikely((error_code & PF_INSTR) &&
+			     ((address & ~0xfff) == VSYSCALL_START))) {
+			if (emulate_vsyscall(regs, address))
+				return;
+		}
+#endif
+
 		if (unlikely(show_unhandled_signals))
 			show_signal_msg(regs, error_code, address, tsk);
 
@@ -1086,7 +1098,7 @@ do_page_fault(struct pt_regs *regs, unsi
 	if (unlikely(error_code & PF_RSVD))
 		pgtable_bad(regs, error_code, address);
 
-	perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS, 1, 0, regs, address);
+	perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS, 1, regs, address);
 
 	/*
 	 * If we're in an interrupt, have no user context or are running
@@ -1188,11 +1200,11 @@ good_area:
 	if (flags & FAULT_FLAG_ALLOW_RETRY) {
 		if (fault & VM_FAULT_MAJOR) {
 			tsk->maj_flt++;
-			perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MAJ, 1, 0,
+			perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MAJ, 1,
 				      regs, address);
 		} else {
 			tsk->min_flt++;
-			perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MIN, 1, 0,
+			perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MIN, 1,
 				      regs, address);
 		}
 		if (fault & VM_FAULT_RETRY) {
--- head-2011-11-03.orig/arch/x86/mm/init_64-xen.c	2011-08-09 11:14:57.000000000 +0200
+++ head-2011-11-03/arch/x86/mm/init_64-xen.c	2011-09-12 13:55:43.000000000 +0200
@@ -439,7 +439,6 @@ static __ref void unmap_low_page(void *a
 
 static inline int __meminit make_readonly(unsigned long paddr)
 {
-	extern char __vsyscall_0;
 	int readonly = 0;
 
 	/* Make new page tables read-only on the first pass. */
@@ -457,16 +456,12 @@ static inline int __meminit make_readonl
 	/*
 	 * No need for writable mapping of kernel image. This also ensures that
 	 * page and descriptor tables embedded inside don't have writable
-	 * mappings. Exclude the vsyscall area here, allowing alternative
-	 * instruction patching to work. The range must be in sync with that
-	 * passed to reserve_early() (as "TEXT DATA BSS"), since all other
-	 * regions can be allocated from under CONFIG_NO_BOOTMEM and thus must
-	 * be writable.
+	 * mappings. The range must be in sync with that passed to
+	 * reserve_early() (as "TEXT DATA BSS"), since all other regions can be
+	 * allocated from under CONFIG_NO_BOOTMEM and thus must be writable.
 	 */
 	if ((paddr >= __pa_symbol(&_text))
-            && (paddr < (__pa_symbol(__bss_stop) & PAGE_MASK))
-	    && !(paddr >= __pa_symbol(&__vsyscall_0)
-	         && paddr < __pa_symbol(&__vsyscall_0) + PAGE_SIZE))
+            && (paddr < (__pa_symbol(__bss_stop) & PAGE_MASK)))
 		readonly = 1;
 
 	return readonly;
--- head-2011-11-03.orig/arch/x86/mm/pgtable-xen.c	2011-04-12 15:59:10.000000000 +0200
+++ head-2011-11-03/arch/x86/mm/pgtable-xen.c	2011-09-08 17:12:17.000000000 +0200
@@ -861,6 +861,7 @@ void xen_set_fixmap(enum fixed_addresses
 	extern pte_t level1_fixmap_pgt[PTRS_PER_PTE];
 
 	case VSYSCALL_LAST_PAGE ... VSYSCALL_FIRST_PAGE:
+	case VVAR_PAGE:
 		pte = pfn_pte(phys >> PAGE_SHIFT, flags);
 		set_pte_vaddr_pud(level3_user_pgt, address, pte);
 		break;
--- head-2011-11-03.orig/arch/x86/vdso/vclock_gettime.c	2011-11-03 13:58:09.000000000 +0100
+++ head-2011-11-03/arch/x86/vdso/vclock_gettime.c	2011-09-12 13:44:31.000000000 +0200
@@ -25,6 +25,13 @@
 
 #define gtod (&VVAR(vsyscall_gtod_data))
 
+#ifndef CONFIG_XEN
+#define using_vclock likely(gtod->clock.vclock_mode != VCLOCK_NONE)
+#else
+#define using_vclock 0
+#define VCLOCK_TSC (-1)
+#endif
+
 notrace static cycle_t vread_tsc(void)
 {
 	cycle_t ret;
@@ -158,11 +165,11 @@ notrace int __vdso_clock_gettime(clockid
 {
 	switch (clock) {
 	case CLOCK_REALTIME:
-		if (likely(gtod->clock.vclock_mode != VCLOCK_NONE))
+		if (using_vclock)
 			return do_realtime(ts);
 		break;
 	case CLOCK_MONOTONIC:
-		if (likely(gtod->clock.vclock_mode != VCLOCK_NONE))
+		if (using_vclock)
 			return do_monotonic(ts);
 		break;
 	case CLOCK_REALTIME_COARSE:
@@ -179,7 +186,7 @@ int clock_gettime(clockid_t, struct time
 notrace int __vdso_gettimeofday(struct timeval *tv, struct timezone *tz)
 {
 	long ret;
-	if (likely(gtod->clock.vclock_mode != VCLOCK_NONE)) {
+	if (using_vclock) {
 		if (likely(tv != NULL)) {
 			BUILD_BUG_ON(offsetof(struct timeval, tv_usec) !=
 				     offsetof(struct timespec, tv_nsec) ||
--- head-2011-11-03.orig/drivers/gpu/drm/i915/intel_display.c	2011-11-03 13:58:09.000000000 +0100
+++ head-2011-11-03/drivers/gpu/drm/i915/intel_display.c	2011-10-07 11:45:41.000000000 +0200
@@ -7718,6 +7718,7 @@ void gen6_update_ring_freq(struct drm_i9
 	int gpu_freq, ia_freq, max_ia_freq;
 	int scaling_factor = 180;
 
+#ifndef CONFIG_XEN
 	max_ia_freq = cpufreq_quick_get_max(0);
 	/*
 	 * Default to measured freq if none found, PCU will ensure we don't go
@@ -7725,6 +7726,9 @@ void gen6_update_ring_freq(struct drm_i9
 	 */
 	if (!max_ia_freq)
 		max_ia_freq = tsc_khz;
+#else
+	max_ia_freq = cpu_khz;
+#endif
 
 	/* Convert from kHz to MHz */
 	max_ia_freq /= 1000;
--- head-2011-11-03.orig/drivers/hwmon/coretemp-xen.c	2011-10-07 14:02:01.000000000 +0200
+++ head-2011-11-03/drivers/hwmon/coretemp-xen.c	2011-11-03 13:59:03.000000000 +0100
@@ -33,18 +33,29 @@
 #include <linux/mutex.h>
 #include <linux/list.h>
 #include <linux/platform_device.h>
+#include <linux/cpu.h>
 #include <linux/pci.h>
 #include <linux/smp.h>
+#include <linux/moduleparam.h>
 #include <asm/msr.h>
 #include <xen/pcpu.h>
 #include "../xen/core/domctl.h"
 
 #define DRVNAME	"coretemp"
 
+/*
+ * force_tjmax only matters when TjMax can't be read from the CPU itself.
+ * When set, it replaces the driver's suboptimal heuristic.
+ */
+static int force_tjmax;
+module_param_named(tjmax, force_tjmax, int, 0444);
+MODULE_PARM_DESC(tjmax, "TjMax value in degrees Celsius");
+
 #define BASE_SYSFS_ATTR_NO	2	/* Sysfs Base attr no for coretemp */
 #define NUM_REAL_CORES		16	/* Number of Real cores per cpu */
 #define CORETEMP_NAME_LENGTH	17	/* String Length of attrs */
-#define MAX_ATTRS		5	/* Maximum no of per-core attrs */
+#define MAX_CORE_ATTRS		4	/* Maximum no of basic attrs */
+#define TOTAL_ATTRS		(MAX_CORE_ATTRS + 1)
 #define MAX_CORE_DATA		(NUM_REAL_CORES + BASE_SYSFS_ATTR_NO)
 
 #define TO_PHYS_ID(cpu)		({ \
@@ -61,6 +72,7 @@
  *		This value is passed as "id" field to rdmsr/wrmsr functions.
  * @status_reg: One of IA32_THERM_STATUS or IA32_PACKAGE_THERM_STATUS,
  *		from where the temperature values should be read.
+ * @attr_size:  Total number of pre-core attrs displayed in the sysfs.
  * @is_pkg_data: If this is 1, the temp_data holds pkgtemp data.
  *		Otherwise, temp_data holds coretemp data.
  * @valid: If this is 1, the current temperature is valid.
@@ -73,10 +85,11 @@ struct temp_data {
 	unsigned int cpu;
 	u32 cpu_core_id;
 	u32 status_reg;
+	int attr_size;
 	bool is_pkg_data;
 	bool valid;
-	struct sensor_device_attribute sd_attrs[MAX_ATTRS];
-	char attr_name[MAX_ATTRS][CORETEMP_NAME_LENGTH];
+	struct sensor_device_attribute sd_attrs[TOTAL_ATTRS];
+	char attr_name[TOTAL_ATTRS][CORETEMP_NAME_LENGTH];
 	struct mutex update_lock;
 };
 
@@ -85,7 +98,6 @@ struct platform_data {
 	struct device *hwmon_dev;
 	u16 phys_proc_id;
 	u8 x86_model, x86_mask;
-	u32 ucode_rev;
 	struct temp_data *core_data[MAX_CORE_DATA];
 	struct device_attribute name_attr;
 };
@@ -282,7 +294,6 @@ static int adjust_tjmax(struct platform_
 
 static int get_tjmax(struct platform_data *c, u32 id, struct device *dev)
 {
-	/* The 100C is default for both mobile and non mobile CPUs */
 	int err;
 	u32 eax, edx;
 	u32 val;
@@ -293,7 +304,8 @@ static int get_tjmax(struct platform_dat
 	 */
 	err = rdmsr_safe_on_pcpu(id, MSR_IA32_TEMPERATURE_TARGET, &eax, &edx);
 	if (err < 0) {
-		dev_warn(dev, "Unable to read TjMax from CPU.\n");
+		if (c->x86_model > 0xe && c->x86_model != 0x1c)
+			dev_warn(dev, "Unable to read TjMax from CPU %u\n", id);
 	} else {
 		val = (eax >> 16) & 0xff;
 		/*
@@ -301,11 +313,17 @@ static int get_tjmax(struct platform_dat
 		 * will be used
 		 */
 		if (val) {
-			dev_info(dev, "TjMax is %d C.\n", val);
+			dev_dbg(dev, "TjMax is %d degrees C\n", val);
 			return val * 1000;
 		}
 	}
 
+	if (force_tjmax) {
+		dev_notice(dev, "TjMax forced to %d degrees C by user\n",
+			   force_tjmax);
+		return force_tjmax * 1000;
+	}
+
 	/*
 	 * An assumption is made for early CPUs and unreadable MSR.
 	 * NOTE: the calculated value may not be correct.
@@ -313,21 +331,6 @@ static int get_tjmax(struct platform_dat
 	return adjust_tjmax(c, id, dev);
 }
 
-static int get_pkg_tjmax(unsigned int cpu, struct device *dev)
-{
-	int err;
-	u32 eax, edx, val;
-
-	err = rdmsr_safe_on_pcpu(cpu, MSR_IA32_TEMPERATURE_TARGET, &eax, &edx);
-	if (err >= 0) {
-		val = (eax >> 16) & 0xff;
-		if (val)
-			return val * 1000;
-	}
-	dev_warn(dev, "Unable to read Pkg-TjMax from CPU:%u\n", cpu);
-	return 100000; /* Default TjMax: 100 degree celsius */
-}
-
 static int create_name_attr(struct platform_data *pdata, struct device *dev)
 {
 	sysfs_attr_init(&pdata->name_attr.attr);
@@ -341,23 +344,22 @@ static int create_core_attrs(struct temp
 				int attr_no)
 {
 	int err, i;
-	static ssize_t (*const rd_ptr[MAX_ATTRS]) (struct device *dev,
+	static ssize_t (*const rd_ptr[TOTAL_ATTRS]) (struct device *dev,
 			struct device_attribute *devattr, char *buf) = {
-			show_label, show_crit_alarm, show_ttarget,
-			show_temp, show_tjmax };
-	static const char *const names[MAX_ATTRS] = {
+			show_label, show_crit_alarm, show_temp, show_tjmax,
+			show_ttarget };
+	static const char *const names[TOTAL_ATTRS] = {
 					"temp%d_label", "temp%d_crit_alarm",
-					"temp%d_max", "temp%d_input",
-					"temp%d_crit" };
+					"temp%d_input", "temp%d_crit",
+					"temp%d_max" };
 
-	for (i = 0; i < MAX_ATTRS; i++) {
+	for (i = 0; i < tdata->attr_size; i++) {
 		snprintf(tdata->attr_name[i], CORETEMP_NAME_LENGTH, names[i],
 			attr_no);
 		sysfs_attr_init(&tdata->sd_attrs[i].dev_attr.attr);
 		tdata->sd_attrs[i].dev_attr.attr.name = tdata->attr_name[i];
 		tdata->sd_attrs[i].dev_attr.attr.mode = S_IRUGO;
 		tdata->sd_attrs[i].dev_attr.show = rd_ptr[i];
-		tdata->sd_attrs[i].dev_attr.store = NULL;
 		tdata->sd_attrs[i].index = attr_no;
 		err = device_create_file(dev, &tdata->sd_attrs[i].dev_attr);
 		if (err)
@@ -371,43 +373,9 @@ exit_free:
 	return err;
 }
 
-static void update_ttarget(__u8 cpu_model, struct temp_data *tdata,
-				struct device *dev)
-{
-	int err;
-	u32 eax, edx;
-
-	/*
-	 * Initialize ttarget value. Eventually this will be
-	 * initialized with the value from MSR_IA32_THERM_INTERRUPT
-	 * register. If IA32_TEMPERATURE_TARGET is supported, this
-	 * value will be over written below.
-	 * To Do: Patch to initialize ttarget from MSR_IA32_THERM_INTERRUPT
-	 */
-	tdata->ttarget = tdata->tjmax - 20000;
 
-	/*
-	 * Read the still undocumented IA32_TEMPERATURE_TARGET. It exists
-	 * on older CPUs but not in this register,
-	 * Atoms don't have it either.
-	 */
-	if (cpu_model > 0xe && cpu_model != 0x1c) {
-		err = rdmsr_safe_on_pcpu(tdata->cpu,
-				MSR_IA32_TEMPERATURE_TARGET, &eax, &edx);
-		if (err < 0) {
-			dev_warn(dev,
-			"Unable to read IA32_TEMPERATURE_TARGET MSR\n");
-		} else {
-			tdata->ttarget = tdata->tjmax -
-					((eax >> 8) & 0xff) * 1000;
-		}
-	}
-}
-
-static int chk_ucode_version(struct platform_device *pdev)
+static int chk_ucode_version(unsigned int cpu, const struct cpu_info *c)
 {
-	struct platform_data *c = platform_get_drvdata(pdev);
-
 	/*
 	 * Check if we have problem with errata AE18 of Core processors:
 	 * Readings might stop update when processor visited too deep sleep,
@@ -416,14 +384,12 @@ static int chk_ucode_version(struct plat
 	if (c->x86_model == 0xe && c->x86_mask < 0xc) {
 		/* check for microcode update */
 		if (!(c->ucode_rev + 1)) {
-			dev_err(&pdev->dev,
-				"Cannot determine microcode revision of "
-				"PKG#%u!\n", pdev->id);
+			pr_err("Cannot determine microcode revision of "
+			       "CPU#%u!\n", cpu);
 			return -ENODEV;
 		} else if (c->ucode_rev < 0x39) {
-			dev_err(&pdev->dev,
-				"Errata AE18 not fixed, update BIOS or "
-				"microcode of the CPU!\n");
+			pr_err("Errata AE18 not fixed, update BIOS or "
+			       "microcode of the CPU!\n");
 			return -ENODEV;
 		}
 	}
@@ -462,6 +428,7 @@ static struct temp_data *init_temp_data(
 	tdata->is_pkg_data = pkg_flag;
 	tdata->cpu = cpu;
 	tdata->cpu_core_id = c->cpu_core_id;
+	tdata->attr_size = MAX_CORE_ATTRS;
 	mutex_init(&tdata->update_lock);
 	return tdata;
 }
@@ -506,12 +473,23 @@ static int create_core_data(struct platf
 		goto exit_free;
 
 	/* We can access status register. Get Critical Temperature */
-	if (pkg_flag)
-		tdata->tjmax = get_pkg_tjmax(cpu, &pdev->dev);
-	else
-		tdata->tjmax = get_tjmax(pdata, cpu, &pdev->dev);
+	tdata->tjmax = get_tjmax(pdata, cpu, &pdev->dev);
+
+	/*
+	 * Read the still undocumented bits 8:15 of IA32_TEMPERATURE_TARGET.
+	 * The target temperature is available on older CPUs but not in this
+	 * register. Atoms don't have the register at all.
+	 */
+	if (c->x86_model > 0xe && c->x86_model != 0x1c) {
+		err = rdmsr_safe_on_pcpu(cpu, MSR_IA32_TEMPERATURE_TARGET,
+					 &eax, &edx);
+		if (err >= 0) {
+			tdata->ttarget
+			  = tdata->tjmax - ((eax >> 8) & 0xff) * 1000;
+			tdata->attr_size++;
+		}
+	}
 
-	update_ttarget(pdata->x86_model, tdata, &pdev->dev);
 	pdata->core_data[attr_no] = tdata;
 
 	/* Create sysfs interfaces */
@@ -544,7 +522,7 @@ static void coretemp_remove_core(struct 
 	struct temp_data *tdata = pdata->core_data[indx];
 
 	/* Remove the sysfs attributes */
-	for (i = 0; i < MAX_ATTRS; i++)
+	for (i = 0; i < tdata->attr_size; i++)
 		device_remove_file(dev, &tdata->sd_attrs[i].dev_attr);
 
 	kfree(pdata->core_data[indx]);
@@ -556,11 +534,6 @@ static int coretemp_probe(struct platfor
 	struct platform_data *pdata = platform_get_drvdata(pdev);
 	int err;
 
-	/* Check the microcode version of the CPU */
-	err = chk_ucode_version(pdev);
-	if (err)
-		return err;
-
 	/* Initialize the per-package data structures */
 	err = create_name_attr(pdata, &pdev->dev);
 	if (err)
@@ -629,7 +602,6 @@ static int coretemp_device_add(unsigned 
 	pdata->phys_proc_id = c->phys_proc_id;
 	pdata->x86_model = c->x86_model;
 	pdata->x86_mask = c->x86_mask;
-	pdata->ucode_rev = c->ucode_rev;
 	platform_set_drvdata(pdev, pdata);
 
 	pdev_entry = kzalloc(sizeof(struct pdev_entry), GFP_KERNEL);
@@ -750,6 +722,10 @@ static void get_core_online(unsigned int
 		return;
 
 	if (!pdev) {
+		/* Check the microcode version of the CPU */
+		if (chk_ucode_version(cpu, &info))
+			return;
+
 		/*
 		 * Alright, we have DTS support.
 		 * We are bringing the _first_ core in this pkg
--- head-2011-11-03.orig/drivers/hwmon/via-cputemp-xen.c	2011-02-01 16:40:53.000000000 +0100
+++ head-2011-11-03/drivers/hwmon/via-cputemp-xen.c	2011-09-12 11:45:20.000000000 +0200
@@ -27,12 +27,14 @@
 #include <linux/init.h>
 #include <linux/slab.h>
 #include <linux/hwmon.h>
+#include <linux/hwmon-vid.h>
 #include <linux/sysfs.h>
 #include <linux/hwmon-sysfs.h>
 #include <linux/err.h>
 #include <linux/mutex.h>
 #include <linux/list.h>
 #include <linux/platform_device.h>
+#include <linux/cpu.h>
 #include <asm/msr.h>
 #include <xen/pcpu.h>
 #include "../xen/core/domctl.h"
@@ -51,7 +53,9 @@ struct pdev_entry {
 	struct device *hwmon_dev;
 	const char *name;
 	u8 x86_model;
-	u32 msr;
+	u8 vrm;
+	u32 msr_temp;
+	u32 msr_vid;
 };
 #define via_cputemp_data pdev_entry
 
@@ -80,13 +84,27 @@ static ssize_t show_temp(struct device *
 	u32 eax, edx;
 	int err;
 
-	err = rdmsr_safe_on_pcpu(data->pdev->id, data->msr, &eax, &edx);
+	err = rdmsr_safe_on_pcpu(data->pdev->id, data->msr_temp, &eax, &edx);
 	if (err < 0)
 		return -EAGAIN;
 
 	return sprintf(buf, "%lu\n", ((unsigned long)eax & 0xffffff) * 1000);
 }
 
+static ssize_t show_cpu_vid(struct device *dev,
+			    struct device_attribute *devattr, char *buf)
+{
+	struct via_cputemp_data *data = dev_get_drvdata(dev);
+	u32 eax, edx;
+	int err;
+
+	err = rdmsr_safe_on_pcpu(data->pdev->id, data->msr_vid, &eax, &edx);
+	if (err < 0)
+		return -EAGAIN;
+
+	return sprintf(buf, "%d\n", vid_from_reg(~edx & 0x7f, data->vrm));
+}
+
 static SENSOR_DEVICE_ATTR(temp1_input, S_IRUGO, show_temp, NULL,
 			  SHOW_TEMP);
 static SENSOR_DEVICE_ATTR(temp1_label, S_IRUGO, show_name, NULL, SHOW_LABEL);
@@ -103,6 +121,9 @@ static const struct attribute_group via_
 	.attrs = via_cputemp_attributes,
 };
 
+/* Optional attributes */
+static DEVICE_ATTR(cpu0_vid, S_IRUGO, show_cpu_vid, NULL);
+
 static int via_cputemp_probe(struct platform_device *pdev)
 {
 	struct via_cputemp_data *data = platform_get_drvdata(pdev);
@@ -116,18 +137,19 @@ static int via_cputemp_probe(struct plat
 		/* C7 A */
 	case 0xD:
 		/* C7 D */
-		data->msr = 0x1169;
+		data->msr_temp = 0x1169;
+		data->msr_vid = 0x198;
 		break;
 	case 0xF:
 		/* Nano */
-		data->msr = 0x1423;
+		data->msr_temp = 0x1423;
 		break;
 	default:
 		return -ENODEV;
 	}
 
 	/* test if we can access the TEMPERATURE MSR */
-	err = rdmsr_safe_on_pcpu(pdev->id, data->msr, &eax, &edx);
+	err = rdmsr_safe_on_pcpu(pdev->id, data->msr_temp, &eax, &edx);
 	if (err < 0) {
 		dev_err(&pdev->dev,
 			"Unable to access TEMPERATURE MSR, giving up\n");
@@ -138,6 +160,15 @@ static int via_cputemp_probe(struct plat
 	if (err)
 		return err;
 
+	if (data->msr_vid)
+		data->vrm = vid_which_vrm();
+
+	if (data->vrm) {
+		err = device_create_file(&pdev->dev, &dev_attr_cpu0_vid);
+		if (err)
+			goto exit_remove;
+	}
+
 	data->hwmon_dev = hwmon_device_register(&pdev->dev);
 	if (IS_ERR(data->hwmon_dev)) {
 		err = PTR_ERR(data->hwmon_dev);
@@ -149,6 +180,8 @@ static int via_cputemp_probe(struct plat
 	return 0;
 
 exit_remove:
+	if (data->vrm)
+		device_remove_file(&pdev->dev, &dev_attr_cpu0_vid);
 	sysfs_remove_group(&pdev->dev.kobj, &via_cputemp_group);
 	return err;
 }
@@ -158,6 +191,8 @@ static int via_cputemp_remove(struct pla
 	struct via_cputemp_data *data = platform_get_drvdata(pdev);
 
 	hwmon_device_unregister(data->hwmon_dev);
+	if (data->vrm)
+		device_remove_file(&pdev->dev, &dev_attr_cpu0_vid);
 	sysfs_remove_group(&pdev->dev.kobj, &via_cputemp_group);
 	return 0;
 }
--- head-2011-11-03.orig/drivers/iommu/Kconfig	2011-11-03 13:58:09.000000000 +0100
+++ head-2011-11-03/drivers/iommu/Kconfig	2011-09-09 17:53:01.000000000 +0200
@@ -4,6 +4,7 @@ config IOMMU_API
 
 menuconfig IOMMU_SUPPORT
 	bool "IOMMU Hardware Support"
+	depends on !XEN
 	default y
 	---help---
 	  Say Y here if you want to compile device drivers for IO Memory
--- head-2011-11-03.orig/drivers/virtio/Kconfig	2011-11-03 13:58:09.000000000 +0100
+++ head-2011-11-03/drivers/virtio/Kconfig	2011-09-09 17:52:44.000000000 +0200
@@ -8,6 +8,7 @@ config VIRTIO_RING
 	depends on VIRTIO
 
 menu "Virtio drivers"
+	depends on !XEN
 
 config VIRTIO_PCI
 	tristate "PCI driver for virtio devices (EXPERIMENTAL)"
--- head-2011-11-03.orig/drivers/xen/Kconfig	2011-11-03 12:51:08.000000000 +0100
+++ head-2011-11-03/drivers/xen/Kconfig	2011-11-03 12:54:35.000000000 +0100
@@ -125,70 +125,6 @@ config XEN_NETDEV_LOOPBACK
 	  A two-interface loopback device to emulate a local netfront-netback
 	  connection. If unsure, it is probably safe to say N here.
 
-config XEN_PCIDEV_BACKEND
-	tristate "PCI-device backend driver"
-	depends on PCI && XEN_PRIVILEGED_GUEST && XEN_BACKEND
-	default XEN_BACKEND
-	help
-	  The PCI device backend driver allows the kernel to export arbitrary
-	  PCI devices to other guests. If you select this to be a module, you
-	  will need to make sure no other driver has bound to the device(s)
-	  you want to make visible to other guests.
-
-choice
-	prompt "PCI Backend Mode"
-	depends on XEN_PCIDEV_BACKEND
-	default XEN_PCIDEV_BACKEND_CONTROLLER if IA64
-	default XEN_PCIDEV_BACKEND_VPCI
-
-config XEN_PCIDEV_BACKEND_VPCI
-	bool "Virtual PCI"
-	---help---
-	  This PCI Backend hides the true PCI topology and makes the frontend
-	  think there is a single PCI bus with only the exported devices on it.
-	  For example, a device at 03:05.0 will be re-assigned to 00:00.0. A
-	  second device at 02:1a.1 will be re-assigned to 00:01.1.
-
-config XEN_PCIDEV_BACKEND_PASS
-	bool "Passthrough"
-	---help---
-	  This PCI Backend provides a real view of the PCI topology to the
-	  frontend (for example, a device at 06:01.b will still appear at
-	  06:01.b to the frontend). This is similar to how Xen 2.0.x exposed
-	  PCI devices to its driver domains. This may be required for drivers
-	  which depend on finding their hardward in certain bus/slot
-	  locations.
-
-config XEN_PCIDEV_BACKEND_SLOT
-	bool "Slot"
-	---help---
-	  This PCI Backend hides the true PCI topology and makes the frontend
-	  think there is a single PCI bus with only the exported devices on it.
-	  Contrary to the virtual PCI backend, a function becomes a new slot.
-	  For example, a device at 03:05.2 will be re-assigned to 00:00.0. A
-	  second device at 02:1a.1 will be re-assigned to 00:01.0.
-
-config XEN_PCIDEV_BACKEND_CONTROLLER
-	bool "Controller"
-	depends on IA64
-	---help---
-	  This PCI backend virtualizes the PCI bus topology by providing a
-	  virtual bus per PCI root device.  Devices which are physically under
-	  the same root bus will appear on the same virtual bus.  For systems
-	  with complex I/O addressing, this is the only backend which supports
-	  extended I/O port spaces and MMIO translation offsets.  This backend
-	  also supports slot virtualization.  For example, a device at
-	  0000:01:02.1 will be re-assigned to 0000:00:00.0.  A second device
-	  at 0000:02:05.0 (behind a P2P bridge on bus 0000:01) will be
-	  re-assigned to 0000:00:01.0.  A third device at 0000:16:05.0 (under
-	  a different PCI root bus) will be re-assigned to 0000:01:00.0.
-
-endchoice
-
-config XEN_PCIDEV_BE_DEBUG
-	bool "PCI Backend Debugging"
-	depends on XEN_PCIDEV_BACKEND
-
 config XEN_TPMDEV_BACKEND
 	tristate "TPM-device backend driver"
         depends on XEN_BACKEND
@@ -372,7 +308,7 @@ config XEN_BALLOON
 
 config XEN_SELFBALLOONING
 	bool "Dynamically self-balloon kernel memory to target"
-	depends on XEN && XEN_BALLOON && CLEANCACHE && SWAP && XEN_TMEM
+	depends on PARAVIRT_XEN && XEN_BALLOON && CLEANCACHE && SWAP && XEN_TMEM
 	default n
 	help
 	  Self-ballooning dynamically balloons available kernel memory driven
@@ -390,7 +326,7 @@ config XEN_SELFBALLOONING
 config XEN_BALLOON_MEMORY_HOTPLUG
 	bool "Memory hotplug support for Xen balloon driver"
 	default n
-	depends on XEN_BALLOON && MEMORY_HOTPLUG
+	depends on PARAVIRT_XEN && XEN_BALLOON && MEMORY_HOTPLUG
 	help
 	  Memory hotplug support for Xen balloon driver allows expanding memory
 	  available for the system above limit declared at system startup.
@@ -528,8 +464,8 @@ config XEN_TMEM
 
 config XEN_PCIDEV_BACKEND
 	tristate "Xen PCI-device backend driver"
-	depends on PCI && X86 && XEN
-	depends on XEN_BACKEND
+	depends on PCI && ((X86 && PARAVIRT_XEN_BACKEND) || (XEN_PRIVILEGED_GUEST && XEN_BACKEND))
+	default XEN_BACKEND if XEN
 	default m
 	help
 	  The PCI device backend driver allows the kernel to export arbitrary
@@ -537,15 +473,102 @@ config XEN_PCIDEV_BACKEND
 	  will need to make sure no other driver has bound to the device(s)
 	  you want to make visible to other guests.
 
-	  The parameter "passthrough" allows you specify how you want the PCI
-	  devices to appear in the guest. You can choose the default (0) where
-	  PCI topology starts at 00.00.0, or (1) for passthrough if you want
-	  the PCI devices topology appear the same as in the host.
-
 	  The "hide" parameter (only applicable if backend driver is compiled
 	  into the kernel) allows you to bind the PCI devices to this module
 	  from the default device drivers. The argument is the list of PCI BDFs:
 	  xen-pciback.hide=(03:00.0)(04:00.0)
 
 	  If in doubt, say m.
+
+menu "PCI Backend Mode"
+	depends on XEN_PCIDEV_BACKEND
+
+choice
+	prompt "Default PCI backend mode"
+	default XEN_PCIDEV_BACKEND_DEFAULT_CONTROLLER if IA64
+	default XEN_PCIDEV_BACKEND_DEFAULT_VPCI
+
+config XEN_PCIDEV_BACKEND_DEFAULT_VPCI
+	bool "Virtual PCI"
+	select XEN_PCIDEV_BACKEND_VPCI
+
+config XEN_PCIDEV_BACKEND_DEFAULT_PASSTHROUGH
+	bool "Passthrough"
+	select XEN_PCIDEV_BACKEND_PASSTHROUGH
+
+config XEN_PCIDEV_BACKEND_DEFAULT_SLOT
+	bool "Slot"
+	select XEN_PCIDEV_BACKEND_SLOT
+
+config XEN_PCIDEV_BACKEND_DEFAULT_CONTROLLER
+	bool "Controller"
+	depends on IA64
+	select XEN_PCIDEV_BACKEND_CONTROLLER
+
+endchoice
+
+config XEN_PCIDEV_BACKEND_DEFAULT
+	string
+	default "vpci" if XEN_PCIDEV_BACKEND_DEFAULT_VPCI
+	default "passthrough" if XEN_PCIDEV_BACKEND_DEFAULT_PASSTHROUGH
+	default "slot" if XEN_PCIDEV_BACKEND_DEFAULT_SLOT
+	default "controller" if XEN_PCIDEV_BACKEND_DEFAULT_CONTROLLER
+
+config XEN_PCIDEV_BACKEND_VPCI
+	bool "Virtual PCI"
+	default X86
+	---help---
+	  This PCI Backend hides the true PCI topology and makes the frontend
+	  think there is a single PCI bus with only the exported devices on it.
+	  For example, a device at 03:05.0 will be re-assigned to 00:00.0. A
+	  second device at 02:1a.1 will be re-assigned to 00:01.1.
+
+	  If not the default, the parameter "mode=vpci" allows you to use this
+	  mode.
+
+config XEN_PCIDEV_BACKEND_PASSTHROUGH
+	bool "Passthrough"
+	---help---
+	  This PCI Backend provides a real view of the PCI topology to the
+	  frontend (for example, a device at 06:01.b will still appear at
+	  06:01.b to the frontend). This is similar to how Xen 2.0.x exposed
+	  PCI devices to its driver domains. This may be required for drivers
+	  which depend on finding their hardward in certain bus/slot
+	  locations.
+
+	  If not the default, the parameter "mode=passthrough" allows you to
+	  use this mode.
+
+config XEN_PCIDEV_BACKEND_SLOT
+	bool "Slot"
+	---help---
+	  This PCI Backend hides the true PCI topology and makes the frontend
+	  think there is a single PCI bus with only the exported devices on it.
+	  Contrary to the virtual PCI backend, a function becomes a new slot.
+	  For example, a device at 03:05.2 will be re-assigned to 00:00.0. A
+	  second device at 02:1a.1 will be re-assigned to 00:01.0.
+
+	  If not the default, the parameter "mode=slot" allows you to use this
+	  mode.
+
+config XEN_PCIDEV_BACKEND_CONTROLLER
+	bool "Controller"
+	depends on IA64
+	---help---
+	  This PCI backend virtualizes the PCI bus topology by providing a
+	  virtual bus per PCI root device.  Devices which are physically under
+	  the same root bus will appear on the same virtual bus.  For systems
+	  with complex I/O addressing, this is the only backend which supports
+	  extended I/O port spaces and MMIO translation offsets.  This backend
+	  also supports slot virtualization.  For example, a device at
+	  0000:01:02.1 will be re-assigned to 0000:00:00.0.  A second device
+	  at 0000:02:05.0 (behind a P2P bridge on bus 0000:01) will be
+	  re-assigned to 0000:00:01.0.  A third device at 0000:16:05.0 (under
+	  a different PCI root bus) will be re-assigned to 0000:01:00.0.
+
+	  If not the default, the parameter "mode=controller" allows you to
+	  use this mode.
+
+endmenu
+
 endmenu
--- head-2011-11-03.orig/drivers/xen/Makefile	2011-07-01 16:01:23.000000000 +0200
+++ head-2011-11-03/drivers/xen/Makefile	2011-11-03 12:54:39.000000000 +0100
@@ -8,7 +8,6 @@ xen-balloon_$(CONFIG_XEN)	:= balloon/
 obj-$(CONFIG_XEN)		+= core/
 obj-$(CONFIG_XEN)		+= console/
 obj-y				+= xenbus/
-obj-y				+= tmem.o
 obj-$(CONFIG_XEN)		+= char/
 
 xen-backend-$(CONFIG_XEN_BACKEND)	:= util.o
@@ -27,14 +26,17 @@ obj-$(CONFIG_BLOCK)			+= $(xen-biomerge-
 obj-$(CONFIG_HOTPLUG_CPU)		+= $(xen-hotplug-y)
 obj-$(CONFIG_XEN_XENCOMM)		+= xencomm.o
 obj-$(CONFIG_XEN_BALLOON)		+= $(xen-balloon_y)
+obj-$(CONFIG_XEN_SELFBALLOONING)	+= xen-selfballoon.o
 obj-$(CONFIG_XEN_DEV_EVTCHN)		+= $(xen-evtchn-name-y).o
 obj-$(CONFIG_XEN_GNTDEV)		+= xen-gntdev.o
 obj-$(CONFIG_XENFS)			+= xenfs/
 obj-$(CONFIG_XEN_GRANT_DEV_ALLOC)	+= xen-gntalloc.o
 obj-$(CONFIG_XEN_SYS_HYPERVISOR)	+= sys-hypervisor.o
 obj-$(CONFIG_XEN_PLATFORM_PCI)		+= xen-platform-pci.o
+obj-$(CONFIG_XEN_TMEM)			+= tmem.o
 obj-$(CONFIG_SWIOTLB_XEN)		+= swiotlb-xen.o
 obj-$(CONFIG_XEN_DOM0)			+= pci.o
+obj-$(CONFIG_XEN_PCIDEV_BACKEND)	+= xen-pciback/
 
 xen-evtchn-y				:= evtchn.o
 xen-gntdev-y				:= gntdev.o
@@ -51,7 +53,6 @@ obj-$(CONFIG_XEN_NETDEV_BACKEND)	+= netb
 obj-$(CONFIG_XEN_TPMDEV_BACKEND)	+= tpmback/
 obj-$(CONFIG_XEN_BLKDEV_FRONTEND)	+= blkfront/
 obj-$(CONFIG_XEN_NETDEV_FRONTEND)	+= netfront/
-obj-$(CONFIG_XEN_PCIDEV_BACKEND)	+= pciback/
 obj-$(CONFIG_XEN_PCIDEV_FRONTEND)	+= pcifront/
 obj-$(CONFIG_XEN_FRAMEBUFFER)		+= fbfront/
 obj-$(CONFIG_XEN_KEYBOARD)		+= fbfront/
--- head-2011-11-03.orig/drivers/xen/blkback/blkback.c	2011-04-14 17:15:22.000000000 +0200
+++ head-2011-11-03/drivers/xen/blkback/blkback.c	2011-11-03 12:54:31.000000000 +0100
@@ -680,3 +680,4 @@ static int __init blkif_init(void)
 module_init(blkif_init);
 
 MODULE_LICENSE("Dual BSD/GPL");
+MODULE_ALIAS("xen-backend:vbd");
--- head-2011-11-03.orig/drivers/xen/blkfront/block.h	2011-07-01 16:34:26.000000000 +0200
+++ head-2011-11-03/drivers/xen/blkfront/block.h	2011-09-09 09:39:27.000000000 +0200
@@ -41,6 +41,7 @@
 #include <linux/sched.h>
 #include <linux/slab.h>
 #include <linux/string.h>
+#include <linux/atomic.h>
 #include <linux/errno.h>
 #include <linux/fs.h>
 #include <linux/hdreg.h>
@@ -53,7 +54,6 @@
 #include <xen/interface/io/blkif.h>
 #include <xen/interface/io/ring.h>
 #include <asm/io.h>
-#include <asm/atomic.h>
 #include <asm/uaccess.h>
 
 #define DPRINTK(_f, _a...) pr_debug(_f, ## _a)
--- head-2011-11-03.orig/drivers/xen/blktap/blktap.c	2011-04-11 15:06:35.000000000 +0200
+++ head-2011-11-03/drivers/xen/blktap/blktap.c	2011-09-14 16:22:16.000000000 +0200
@@ -1757,3 +1757,4 @@ module_init(blkif_init);
 
 MODULE_LICENSE("Dual BSD/GPL");
 MODULE_ALIAS("devname:xen/blktap0");
+MODULE_ALIAS("xen-backend:tap");
--- head-2011-11-03.orig/drivers/xen/core/evtchn.c	2011-04-14 17:11:44.000000000 +0200
+++ head-2011-11-03/drivers/xen/core/evtchn.c	2011-09-09 09:39:05.000000000 +0200
@@ -38,7 +38,7 @@
 #include <linux/kernel_stat.h>
 #include <linux/ftrace.h>
 #include <linux/version.h>
-#include <asm/atomic.h>
+#include <linux/atomic.h>
 #include <asm/system.h>
 #include <asm/ptrace.h>
 #include <asm/synch_bitops.h>
--- head-2011-11-03.orig/drivers/xen/gntdev/gntdev.c	2011-02-01 15:09:47.000000000 +0100
+++ head-2011-11-03/drivers/xen/gntdev/gntdev.c	2011-09-09 09:39:43.000000000 +0200
@@ -16,7 +16,7 @@
  * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
  */
 
-#include <asm/atomic.h>
+#include <linux/atomic.h>
 #include <linux/module.h>
 #include <linux/kernel.h>
 #include <linux/init.h>
--- head-2011-11-03.orig/drivers/xen/netback/accel.c	2011-02-01 14:50:44.000000000 +0100
+++ head-2011-11-03/drivers/xen/netback/accel.c	2011-09-09 09:39:54.000000000 +0200
@@ -31,7 +31,7 @@
  */
 
 #include <linux/list.h>
-#include <asm/atomic.h>
+#include <linux/atomic.h>
 #include <xen/xenbus.h>
 #include <linux/mutex.h>
 
--- head-2011-11-03.orig/drivers/xen/netback/netback.c	2011-04-13 17:01:32.000000000 +0200
+++ head-2011-11-03/drivers/xen/netback/netback.c	2011-09-09 08:56:36.000000000 +0200
@@ -1706,3 +1706,4 @@ static int __init netback_init(void)
 module_init(netback_init);
 
 MODULE_LICENSE("Dual BSD/GPL");
+MODULE_ALIAS("xen-backend:vif");
--- head-2011-11-03.orig/drivers/xen/netfront/accel.c	2011-02-01 14:38:38.000000000 +0100
+++ head-2011-11-03/drivers/xen/netfront/accel.c	2011-09-12 10:44:16.000000000 +0200
@@ -547,7 +547,8 @@ static void accelerator_remove_hooks(str
 
 			/* Last chance to get statistics from the accelerator */
 			vif_state->hooks->get_stats(vif_state->np->netdev,
-						    &vif_state->np->netdev->stats);
+						    &vif_state->np->netdev->stats,
+						    this_cpu_ptr(vif_state->np->stats));
 
 			spin_unlock_irqrestore(&accelerator->vif_states_lock,
 					       flags);
@@ -604,7 +605,8 @@ static int do_remove(struct netfront_inf
 
 		/* Last chance to get statistics from the accelerator */
 		np->accel_vif_state.hooks->get_stats(np->netdev,
-						     &np->netdev->stats);
+						     &np->netdev->stats,
+						     this_cpu_ptr(np->stats));
 
 		spin_unlock_irqrestore(&accelerator->vif_states_lock, 
 				       flags);
@@ -818,8 +820,8 @@ int netfront_accelerator_call_get_stats(
 		spin_lock_irqsave(&accelerator->vif_states_lock, flags); 
 		if (np->accel_vif_state.hooks && 
 		    np->accelerator == accelerator)
- 			rc = np->accel_vif_state.hooks->get_stats(dev,
-								  &dev->stats);
+ 			rc = np->accel_vif_state.hooks->get_stats(dev, &dev->stats,
+								  this_cpu_ptr(np->stats));
 		spin_unlock_irqrestore(&accelerator->vif_states_lock, flags);
 	}
 	return rc;
--- head-2011-11-03.orig/drivers/xen/netfront/netfront.c	2011-09-09 09:32:36.000000000 +0200
+++ head-2011-11-03/drivers/xen/netfront/netfront.c	2011-09-09 09:20:16.000000000 +0200
@@ -318,6 +318,8 @@ static int __devexit netfront_remove(str
 
 	unregister_netdev(info->netdev);
 
+	free_percpu(info->stats);
+
 	free_netdev(info->netdev);
 
 	return 0;
@@ -925,6 +927,7 @@ static int network_start_xmit(struct sk_
 {
 	unsigned short id;
 	struct netfront_info *np = netdev_priv(dev);
+	struct netfront_stats *stats = this_cpu_ptr(np->stats);
 	struct netif_tx_request *tx;
 	struct netif_extra_info *extra;
 	char *data = skb->data;
@@ -1014,8 +1017,10 @@ static int network_start_xmit(struct sk_
 	if (notify)
 		notify_remote_via_irq(np->irq);
 
-	dev->stats.tx_bytes += skb->len;
-	dev->stats.tx_packets++;
+	u64_stats_update_begin(&stats->syncp);
+	stats->tx_bytes += skb->len;
+	stats->tx_packets++;
+	u64_stats_update_end(&stats->syncp);
 	dev->trans_start = jiffies;
 
 	/* Note: It is not safe to access skb after network_tx_buf_gc()! */
@@ -1303,6 +1308,7 @@ static int xennet_set_skb_gso(struct sk_
 static int netif_poll(struct napi_struct *napi, int budget)
 {
 	struct netfront_info *np = container_of(napi, struct netfront_info, napi);
+	struct netfront_stats *stats = this_cpu_ptr(np->stats);
 	struct net_device *dev = np->netdev;
 	struct sk_buff *skb;
 	struct netfront_rx_info rinfo;
@@ -1414,8 +1420,10 @@ err:	
 		else
 			skb->ip_summed = CHECKSUM_NONE;
 
-		dev->stats.rx_packets++;
-		dev->stats.rx_bytes += skb->len;
+		u64_stats_update_begin(&stats->syncp);
+		stats->rx_packets++;
+		stats->rx_bytes += skb->len;
+		u64_stats_update_end(&stats->syncp);
 
 		__skb_queue_tail(&rxq, skb);
 
@@ -1663,14 +1671,6 @@ static int network_close(struct net_devi
 }
 
 
-static struct net_device_stats *network_get_stats(struct net_device *dev)
-{
-	struct netfront_info *np = netdev_priv(dev);
-
-	netfront_accelerator_call_get_stats(np, dev);
-	return &dev->stats;
-}
-
 static int xennet_set_mac_address(struct net_device *dev, void *p)
 {
 	struct netfront_info *np = netdev_priv(dev);
@@ -1698,6 +1698,40 @@ static int xennet_change_mtu(struct net_
 	return 0;
 }
 
+static struct rtnl_link_stats64 *xennet_get_stats64(struct net_device *dev,
+						    struct rtnl_link_stats64 *tot)
+{
+	struct netfront_info *np = netdev_priv(dev);
+	int cpu;
+
+	netfront_accelerator_call_get_stats(np, dev);
+
+	for_each_possible_cpu(cpu) {
+		struct netfront_stats *stats = per_cpu_ptr(np->stats, cpu);
+		u64 rx_packets, rx_bytes, tx_packets, tx_bytes;
+		unsigned int start;
+
+		do {
+			start = u64_stats_fetch_begin_bh(&stats->syncp);
+
+			rx_packets = stats->rx_packets;
+			tx_packets = stats->tx_packets;
+			rx_bytes = stats->rx_bytes;
+			tx_bytes = stats->tx_bytes;
+		} while (u64_stats_fetch_retry_bh(&stats->syncp, start));
+
+		tot->rx_packets += rx_packets;
+		tot->tx_packets += tx_packets;
+		tot->rx_bytes   += rx_bytes;
+		tot->tx_bytes   += tx_bytes;
+	}
+
+	tot->rx_errors  = dev->stats.rx_errors;
+	tot->tx_dropped = dev->stats.tx_dropped;
+
+	return tot;
+}
+
 static const struct xennet_stat {
 	char name[ETH_GSTRING_LEN];
 	u16 offset;
@@ -2049,7 +2083,7 @@ static const struct net_device_ops xenne
 	.ndo_fix_features       = xennet_fix_features,
 	.ndo_set_features       = xennet_set_features,
 	.ndo_change_mtu	        = xennet_change_mtu,
-	.ndo_get_stats          = network_get_stats,
+	.ndo_get_stats64        = xennet_get_stats64,
 };
 
 static struct net_device * __devinit create_netdev(struct xenbus_device *dev)
@@ -2081,6 +2115,11 @@ static struct net_device * __devinit cre
 	np->rx_refill_timer.data = (unsigned long)netdev;
 	np->rx_refill_timer.function = rx_refill_timeout;
 
+	err = -ENOMEM;
+	np->stats = alloc_percpu(struct netfront_stats);
+	if (np->stats == NULL)
+		goto exit;
+
 	/* Initialise {tx,rx}_skbs as a free chain containing every entry. */
 	for (i = 0; i <= NET_TX_RING_SIZE; i++) {
 		np->tx_skbs[i] = (void *)((unsigned long) i+1);
@@ -2097,7 +2136,7 @@ static struct net_device * __devinit cre
 					  &np->gref_tx_head) < 0) {
 		pr_alert("#### netfront can't alloc tx grant refs\n");
 		err = -ENOMEM;
-		goto exit;
+		goto exit_free_stats;
 	}
 	/* A grant for every rx ring slot */
 	if (gnttab_alloc_grant_references(RX_MAX_TARGET,
@@ -2132,6 +2171,8 @@ static struct net_device * __devinit cre
 
  exit_free_tx:
 	gnttab_free_grant_references(np->gref_tx_head);
+ exit_free_stats:
+	free_percpu(np->stats);
  exit:
 	free_netdev(netdev);
 	return ERR_PTR(err);
--- head-2011-11-03.orig/drivers/xen/netfront/netfront.h	2011-02-09 15:03:03.000000000 +0100
+++ head-2011-11-03/drivers/xen/netfront/netfront.h	2011-09-12 10:22:05.000000000 +0200
@@ -48,6 +48,14 @@
 #include <xen/platform-compat.h>
 #endif
 
+struct netfront_stats {
+	u64			rx_packets;
+	u64			tx_packets;
+	u64			rx_bytes;
+	u64			tx_bytes;
+	struct u64_stats_sync	syncp;
+};
+
 /* 
  * Function pointer table for hooks into a network acceleration
  * plugin.  These are called at appropriate points from the netfront
@@ -90,7 +98,8 @@ struct netfront_accel_hooks {
 	 * Get the fastpath network statistics
 	 */
 	int (*get_stats)(struct net_device *dev,
-			 struct net_device_stats *stats);
+			 struct net_device_stats *dev_stats,
+			 struct netfront_stats *link_stats);
 };
 
 
@@ -194,6 +203,7 @@ struct netfront_info {
 	struct mmu_update rx_mmu[NET_RX_RING_SIZE];
 
 	/* Statistics */
+	struct netfront_stats __percpu *stats;
 	unsigned long rx_gso_csum_fixups;
 
 	/* Private pointer to state internal to accelerator module */
--- head-2011-11-03.orig/drivers/xen/pcifront/pcifront.h	2011-02-01 15:03:03.000000000 +0100
+++ head-2011-11-03/drivers/xen/pcifront/pcifront.h	2011-09-09 09:40:06.000000000 +0200
@@ -13,7 +13,7 @@
 #include <xen/interface/io/pciif.h>
 #include <linux/interrupt.h>
 #include <xen/pcifront.h>
-#include <asm/atomic.h>
+#include <linux/atomic.h>
 #include <linux/workqueue.h>
 
 struct pci_bus_entry {
--- head-2011-11-03.orig/drivers/xen/scsiback/scsiback.c	2011-04-11 15:06:01.000000000 +0200
+++ head-2011-11-03/drivers/xen/scsiback/scsiback.c	2011-09-23 09:52:08.000000000 +0200
@@ -729,3 +729,4 @@ module_exit(scsiback_exit);
 
 MODULE_DESCRIPTION("Xen SCSI backend driver");
 MODULE_LICENSE("Dual BSD/GPL");
+MODULE_ALIAS("xen-backend:vscsi");
--- head-2011-11-03.orig/drivers/xen/sfc_netfront/accel_netfront.c	2009-04-07 13:58:48.000000000 +0200
+++ head-2011-11-03/drivers/xen/sfc_netfront/accel_netfront.c	2011-09-12 11:46:42.000000000 +0200
@@ -189,7 +189,8 @@ static int netfront_accel_check_ready(st
 
 
 static int netfront_accel_get_stats(struct net_device *net_dev,
-				    struct net_device_stats *stats)
+				    struct net_device_stats *devst,
+				    struct netfront_stats *lnkst)
 {
 	netfront_accel_vnic *vnic = NETFRONT_ACCEL_VNIC_FROM_NETDEV(net_dev);
 	struct netfront_accel_netdev_stats now;
@@ -203,17 +204,17 @@ static int netfront_accel_get_stats(stru
 	now.fastpath_tx_bytes  = vnic->netdev_stats.fastpath_tx_bytes;
 	now.fastpath_tx_errors = vnic->netdev_stats.fastpath_tx_errors;
 	
-	stats->rx_packets += (now.fastpath_rx_pkts - 
+	lnkst->rx_packets += (now.fastpath_rx_pkts -
 			      vnic->stats_last_read.fastpath_rx_pkts);
-	stats->rx_bytes   += (now.fastpath_rx_bytes -
+	lnkst->rx_bytes   += (now.fastpath_rx_bytes -
 			      vnic->stats_last_read.fastpath_rx_bytes);
-	stats->rx_errors  += (now.fastpath_rx_errors - 
+	devst->rx_errors  += (now.fastpath_rx_errors -
 			      vnic->stats_last_read.fastpath_rx_errors);
-	stats->tx_packets += (now.fastpath_tx_pkts - 
+	lnkst->tx_packets += (now.fastpath_tx_pkts -
 			      vnic->stats_last_read.fastpath_tx_pkts);
-	stats->tx_bytes   += (now.fastpath_tx_bytes - 
+	lnkst->tx_bytes   += (now.fastpath_tx_bytes -
 			      vnic->stats_last_read.fastpath_tx_bytes);
-	stats->tx_errors  += (now.fastpath_tx_errors - 
+	devst->tx_errors  += (now.fastpath_tx_errors -
 			      vnic->stats_last_read.fastpath_tx_errors);
 	
 	vnic->stats_last_read = now;
--- head-2011-11-03.orig/drivers/xen/tpmback/tpmback.c	2011-01-31 17:56:27.000000000 +0100
+++ head-2011-11-03/drivers/xen/tpmback/tpmback.c	2011-09-14 16:27:59.000000000 +0200
@@ -944,3 +944,4 @@ static void __exit tpmback_exit(void)
 module_exit(tpmback_exit)
 
 MODULE_LICENSE("Dual BSD/GPL");
+MODULE_ALIAS("xen-backend:vtpm");
--- head-2011-11-03.orig/drivers/xen/usbback/usbback.c	2011-04-11 15:05:47.000000000 +0200
+++ head-2011-11-03/drivers/xen/usbback/usbback.c	2011-09-23 09:52:15.000000000 +0200
@@ -1195,3 +1195,4 @@ module_exit(usbback_exit);
 MODULE_AUTHOR("");
 MODULE_DESCRIPTION("Xen USB backend driver (usbback)");
 MODULE_LICENSE("Dual BSD/GPL");
+MODULE_ALIAS("xen-backend:vusb");
--- head-2011-11-03.orig/drivers/xen/xen-pciback/Makefile	2011-11-03 13:58:09.000000000 +0100
+++ head-2011-11-03/drivers/xen/xen-pciback/Makefile	2011-09-19 13:15:03.000000000 +0200
@@ -1,7 +1,13 @@
-obj-$(CONFIG_XEN_PCIDEV_BACKEND) += xen-pciback.o
+pcibk-$(CONFIG_PARAVIRT_XEN) := xen-pciback
+pcibk-$(CONFIG_XEN) := pciback
 
-xen-pciback-y := pci_stub.o pciback_ops.o xenbus.o
-xen-pciback-y += conf_space.o conf_space_header.o \
+obj-$(CONFIG_XEN_PCIDEV_BACKEND) := $(pcibk-y).o
+
+$(pcibk-y)-y := pci_stub.o pciback_ops.o xenbus.o
+$(pcibk-y)-y += conf_space.o conf_space_header.o \
 		 conf_space_capability.o \
-		 conf_space_quirks.o vpci.o \
-		 passthrough.o
+		 conf_space_quirks.o
+$(pcibk-y)-$(CONFIG_XEN_PCIDEV_BACKEND_VPCI) += vpci.o
+$(pcibk-y)-$(CONFIG_XEN_PCIDEV_BACKEND_PASSTHROUGH) += passthrough.o
+$(pcibk-y)-$(CONFIG_XEN_PCIDEV_BACKEND_SLOT) += slot.o
+$(pcibk-y)-$(CONFIG_XEN_PCIDEV_BACKEND_CONTROLLER) += controller.o
--- head-2011-11-03.orig/drivers/xen/xen-pciback/conf_space.c	2011-11-03 13:58:09.000000000 +0100
+++ head-2011-11-03/drivers/xen/xen-pciback/conf_space.c	2011-09-16 17:49:50.000000000 +0200
@@ -15,7 +15,6 @@
 #include "conf_space.h"
 #include "conf_space_quirks.h"
 
-#define DRV_NAME	"xen-pciback"
 static int permissive;
 module_param(permissive, bool, 0644);
 
--- head-2011-11-03.orig/drivers/xen/xen-pciback/conf_space_capability.c	2011-11-03 13:58:09.000000000 +0100
+++ head-2011-11-03/drivers/xen/xen-pciback/conf_space_capability.c	2011-09-16 14:20:03.000000000 +0200
@@ -140,6 +140,21 @@ static int pm_ctrl_write(struct pci_dev 
 		goto out;
 	}
 
+#ifdef CONFIG_XEN
+	/*
+	 * Device may lose PCI config info on D3->D0 transition. This
+	 * is a problem for some guests which will not reset BARs. Even
+	 * those that have a go will be foiled by our BAR-write handler
+	 * which will discard the write! Since Linux won't re-init
+	 * the config space automatically in all cases, we do it here.
+	 * Future: Should we re-initialise all first 64 bytes of config space?
+	 */
+	if (new_state == PCI_D0 &&
+	    (old_state == PCI_D3hot || old_state == PCI_D3cold) &&
+	    !(old_value & PCI_PM_CTRL_NO_SOFT_RESET))
+		pci_restore_bars(dev);
+#endif
+
  out:
 	return err;
 }
--- head-2011-11-03.orig/drivers/xen/xen-pciback/conf_space_header.c	2011-11-03 13:58:09.000000000 +0100
+++ head-2011-11-03/drivers/xen/xen-pciback/conf_space_header.c	2011-09-16 14:59:36.000000000 +0200
@@ -15,7 +15,6 @@ struct pci_bar_info {
 	int which;
 };
 
-#define DRV_NAME	"xen-pciback"
 #define is_enable_cmd(value) ((value)&(PCI_COMMAND_MEMORY|PCI_COMMAND_IO))
 #define is_master_cmd(value) ((value)&PCI_COMMAND_MASTER)
 
@@ -25,7 +24,7 @@ static int command_read(struct pci_dev *
 	int ret;
 
 	ret = xen_pcibk_read_config_word(dev, offset, value, data);
-	if (!atomic_read(&dev->enable_cnt))
+	if (!pci_is_enabled(dev))
 		return ret;
 
 	for (i = 0; i < PCI_ROM_RESOURCE; i++) {
@@ -40,10 +39,11 @@ static int command_read(struct pci_dev *
 
 static int command_write(struct pci_dev *dev, int offset, u16 value, void *data)
 {
-	struct xen_pcibk_dev_data *dev_data;
+#ifndef CONFIG_XEN
+	struct xen_pcibk_dev_data *dev_data = dev_data = pci_get_drvdata(dev);
+#endif
 	int err;
 
-	dev_data = pci_get_drvdata(dev);
 	if (!pci_is_enabled(dev) && is_enable_cmd(value)) {
 		if (unlikely(verbose_request))
 			printk(KERN_DEBUG DRV_NAME ": %s: enable\n",
@@ -51,15 +51,19 @@ static int command_write(struct pci_dev 
 		err = pci_enable_device(dev);
 		if (err)
 			return err;
+#ifndef CONFIG_XEN
 		if (dev_data)
 			dev_data->enable_intx = 1;
+#endif
 	} else if (pci_is_enabled(dev) && !is_enable_cmd(value)) {
 		if (unlikely(verbose_request))
 			printk(KERN_DEBUG DRV_NAME ": %s: disable\n",
 			       pci_name(dev));
 		pci_disable_device(dev);
+#ifndef CONFIG_XEN
 		if (dev_data)
 			dev_data->enable_intx = 0;
+#endif
 	}
 
 	if (!dev->is_busmaster && is_master_cmd(value)) {
@@ -187,7 +191,7 @@ static inline void read_dev_bar(struct p
 
 	bar_info->val = res[pos].start |
 			(res[pos].flags & PCI_REGION_FLAG_MASK);
-	bar_info->len_val = res[pos].end - res[pos].start + 1;
+	bar_info->len_val = resource_size(res + pos);
 }
 
 static void *bar_init(struct pci_dev *dev, int offset)
--- head-2011-11-03.orig/drivers/xen/xen-pciback/conf_space_quirks.c	2011-11-03 13:58:09.000000000 +0100
+++ head-2011-11-03/drivers/xen/xen-pciback/conf_space_quirks.c	2011-09-16 15:04:18.000000000 +0200
@@ -12,7 +12,6 @@
 #include "conf_space_quirks.h"
 
 LIST_HEAD(xen_pcibk_quirks);
-#define	DRV_NAME	"xen-pciback"
 static inline const struct pci_device_id *
 match_one_device(const struct pci_device_id *id, const struct pci_dev *dev)
 {
@@ -36,7 +35,7 @@ static struct xen_pcibk_config_quirk *xe
 			goto out;
 	tmp_quirk = NULL;
 	printk(KERN_DEBUG DRV_NAME
-	       ":quirk didn't match any device xen_pciback knows about\n");
+	       ": quirk didn't match any device known\n");
 out:
 	return tmp_quirk;
 }
--- head-2011-11-03.orig/drivers/xen/xen-pciback/controller.c	2009-03-18 10:39:32.000000000 +0100
+++ head-2011-11-03/drivers/xen/xen-pciback/controller.c	2011-09-19 14:55:15.000000000 +0200
@@ -25,9 +25,6 @@
  */
 
 #include <linux/acpi.h>
-#include <linux/list.h>
-#include <linux/pci.h>
-#include <linux/spinlock.h>
 #include "pciback.h"
 
 #define PCI_MAX_BUSSES	255
@@ -56,22 +53,22 @@ struct controller_dev_data {
 };
 
 struct walk_info {
-	struct pciback_device *pdev;
+	struct xen_pcibk_device *pdev;
 	int resource_count;
 	int root_num;
 };
 
-struct pci_dev *pciback_get_pci_dev(struct pciback_device *pdev,
-				    unsigned int domain, unsigned int bus,
-				    unsigned int devfn)
+static struct pci_dev *_xen_pcibk_get_pci_dev(struct xen_pcibk_device *pdev,
+					      unsigned int domain,
+					      unsigned int bus,
+					      unsigned int devfn)
 {
 	struct controller_dev_data *dev_data = pdev->pci_dev_data;
 	struct controller_dev_entry *dev_entry;
 	struct controller_list_entry *cntrl_entry;
 	struct pci_dev *dev = NULL;
-	unsigned long flags;
 
-	spin_lock_irqsave(&dev_data->lock, flags);
+	mutex_lock(&dev_data->lock);
 
 	list_for_each_entry(cntrl_entry, &dev_data->list, list) {
 		if (cntrl_entry->domain != domain ||
@@ -86,22 +83,22 @@ struct pci_dev *pciback_get_pci_dev(stru
 		}
 	}
 found:
-	spin_unlock_irqrestore(&dev_data->lock, flags);
+	mutex_unlock(&dev_data->lock);
 
 	return dev;
 }
 
-int pciback_add_pci_dev(struct pciback_device *pdev, struct pci_dev *dev,
-			int devid, publish_pci_dev_cb publish_cb)
+static int _xen_pcibk_add_pci_dev(struct xen_pcibk_device *pdev,
+				  struct pci_dev *dev, int devid,
+				  publish_pci_dev_cb publish_cb)
 {
 	struct controller_dev_data *dev_data = pdev->pci_dev_data;
 	struct controller_dev_entry *dev_entry;
 	struct controller_list_entry *cntrl_entry;
 	struct pci_controller *dev_controller = PCI_CONTROLLER(dev);
-	unsigned long flags;
 	int ret = 0, found = 0;
 
-	spin_lock_irqsave(&dev_data->lock, flags);
+	mutex_lock(&dev_data->lock);
 
 	/* Look to see if we already have a domain:bus for this controller */
 	list_for_each_entry(cntrl_entry, &dev_data->list, list) {
@@ -165,22 +162,22 @@ int pciback_add_pci_dev(struct pciback_d
 	cntrl_entry->next_devfn += PCI_DEVFN(1, 0);
 
 out:
-	spin_unlock_irqrestore(&dev_data->lock, flags);
+	mutex_unlock(&dev_data->lock);
 
 	/* TODO: Publish virtual domain:bus:slot.func here. */
 
 	return ret;
 }
 
-void pciback_release_pci_dev(struct pciback_device *pdev, struct pci_dev *dev)
+static void _xen_pcibk_release_pci_dev(struct xen_pcibk_device *pdev,
+				       struct pci_dev *dev)
 {
 	struct controller_dev_data *dev_data = pdev->pci_dev_data;
 	struct controller_list_entry *cntrl_entry;
 	struct controller_dev_entry *dev_entry = NULL;
 	struct pci_dev *found_dev = NULL;
-	unsigned long flags;
 
-	spin_lock_irqsave(&dev_data->lock, flags);
+	mutex_lock(&dev_data->lock);
 
 	list_for_each_entry(cntrl_entry, &dev_data->list, list) {
 		if (cntrl_entry->controller != PCI_CONTROLLER(dev))
@@ -195,7 +192,7 @@ void pciback_release_pci_dev(struct pcib
 	}
 
 	if (!found_dev) {
-		spin_unlock_irqrestore(&dev_data->lock, flags);
+		mutex_unlock(&dev_data->lock);
 		return;
 	}
 
@@ -207,11 +204,11 @@ void pciback_release_pci_dev(struct pcib
 		kfree(cntrl_entry);
 	}
 
-	spin_unlock_irqrestore(&dev_data->lock, flags);
+	mutex_unlock(&dev_data->lock);
 	pcistub_put_pci_dev(found_dev);
 }
 
-int pciback_init_devices(struct pciback_device *pdev)
+static int _xen_pcibk_init_devices(struct xen_pcibk_device *pdev)
 {
 	struct controller_dev_data *dev_data;
 
@@ -219,7 +216,7 @@ int pciback_init_devices(struct pciback_
 	if (!dev_data)
 		return -ENOMEM;
 
-	spin_lock_init(&dev_data->lock);
+	mutex_init(&dev_data->lock);
 
 	INIT_LIST_HEAD(&dev_data->list);
 
@@ -294,8 +291,8 @@ static acpi_status write_xenbus_resource
 	return AE_OK;
 }
 
-int pciback_publish_pci_roots(struct pciback_device *pdev,
-			      publish_pci_root_cb publish_root_cb)
+static int _xen_pcibk_publish_pci_roots(struct xen_pcibk_device *pdev,
+					publish_pci_root_cb publish_root_cb)
 {
 	struct controller_dev_data *dev_data = pdev->pci_dev_data;
 	struct controller_list_entry *cntrl_entry;
@@ -304,7 +301,7 @@ int pciback_publish_pci_roots(struct pci
 	char str[64];
 	struct walk_info info;
 
-	spin_lock(&dev_data->lock);
+	mutex_lock(&dev_data->lock);
 
 	list_for_each_entry(cntrl_entry, &dev_data->list, list) {
 		/* First publish all the domain:bus info */
@@ -381,12 +378,12 @@ int pciback_publish_pci_roots(struct pci
 			    "%lx", (sizeof(struct acpi_resource) * 2) + 1);
 
 out:
-	spin_unlock(&dev_data->lock);
+	mutex_unlock(&dev_data->lock);
 
 	return err;
 }
 
-void pciback_release_devices(struct pciback_device *pdev)
+static void _xen_pcibk_release_devices(struct xen_pcibk_device *pdev)
 {
 	struct controller_dev_data *dev_data = pdev->pci_dev_data;
 	struct controller_list_entry *cntrl_entry, *c;
@@ -407,17 +404,17 @@ void pciback_release_devices(struct pcib
 	pdev->pci_dev_data = NULL;
 }
 
-int pciback_get_pcifront_dev(struct pci_dev *pcidev, 
-		struct pciback_device *pdev, 
-		unsigned int *domain, unsigned int *bus, unsigned int *devfn)
+static int _xen_pcibk_get_pcifront_dev(struct pci_dev *pcidev,
+				       struct xen_pcibk_device *pdev,
+				       unsigned int *domain,
+				       unsigned int *bus, unsigned int *devfn)
 {
 	struct controller_dev_data *dev_data = pdev->pci_dev_data;
 	struct controller_dev_entry *dev_entry;
 	struct controller_list_entry *cntrl_entry;
-	unsigned long flags;
 	int found = 0;
-	spin_lock_irqsave(&dev_data->lock, flags);
 
+	mutex_lock(&dev_data->lock);
 	list_for_each_entry(cntrl_entry, &dev_data->list, list) {
 		list_for_each_entry(dev_entry, &cntrl_entry->dev_list, list) {
 			if ( (dev_entry->dev->bus->number == 
@@ -436,8 +433,18 @@ int pciback_get_pcifront_dev(struct pci_
 		}
 	}
 out:
-	spin_unlock_irqrestore(&dev_data->lock, flags);
+	mutex_unlock(&dev_data->lock);
 	return found;
 
 }
 
+const struct xen_pcibk_backend xen_pcibk_controller_backend = {
+	.name		= "controller",
+	.init		= _xen_pcibk_init_devices,
+	.free		= _xen_pcibk_release_devices,
+	.find		= _xen_pcibk_get_pcifront_dev,
+	.publish	= _xen_pcibk_publish_pci_roots,
+	.release	= _xen_pcibk_release_pci_dev,
+	.add		= _xen_pcibk_add_pci_dev,
+	.get		= _xen_pcibk_get_pci_dev,
+};
--- head-2011-11-03.orig/drivers/xen/xen-pciback/passthrough.c	2011-11-03 13:58:09.000000000 +0100
+++ head-2011-11-03/drivers/xen/xen-pciback/passthrough.c	2011-09-19 12:21:15.000000000 +0200
@@ -7,13 +7,13 @@
 
 #include <linux/list.h>
 #include <linux/pci.h>
-#include <linux/spinlock.h>
+#include <linux/mutex.h>
 #include "pciback.h"
 
 struct passthrough_dev_data {
 	/* Access to dev_list must be protected by lock */
 	struct list_head dev_list;
-	spinlock_t lock;
+	struct mutex lock;
 };
 
 static struct pci_dev *__xen_pcibk_get_pci_dev(struct xen_pcibk_device *pdev,
@@ -24,9 +24,8 @@ static struct pci_dev *__xen_pcibk_get_p
 	struct passthrough_dev_data *dev_data = pdev->pci_dev_data;
 	struct pci_dev_entry *dev_entry;
 	struct pci_dev *dev = NULL;
-	unsigned long flags;
 
-	spin_lock_irqsave(&dev_data->lock, flags);
+	mutex_lock(&dev_data->lock);
 
 	list_for_each_entry(dev_entry, &dev_data->dev_list, list) {
 		if (domain == (unsigned int)pci_domain_nr(dev_entry->dev->bus)
@@ -37,7 +36,7 @@ static struct pci_dev *__xen_pcibk_get_p
 		}
 	}
 
-	spin_unlock_irqrestore(&dev_data->lock, flags);
+	mutex_unlock(&dev_data->lock);
 
 	return dev;
 }
@@ -48,7 +47,6 @@ static int __xen_pcibk_add_pci_dev(struc
 {
 	struct passthrough_dev_data *dev_data = pdev->pci_dev_data;
 	struct pci_dev_entry *dev_entry;
-	unsigned long flags;
 	unsigned int domain, bus, devfn;
 	int err;
 
@@ -57,9 +55,9 @@ static int __xen_pcibk_add_pci_dev(struc
 		return -ENOMEM;
 	dev_entry->dev = dev;
 
-	spin_lock_irqsave(&dev_data->lock, flags);
+	mutex_lock(&dev_data->lock);
 	list_add_tail(&dev_entry->list, &dev_data->dev_list);
-	spin_unlock_irqrestore(&dev_data->lock, flags);
+	mutex_unlock(&dev_data->lock);
 
 	/* Publish this device. */
 	domain = (unsigned int)pci_domain_nr(dev->bus);
@@ -76,9 +74,8 @@ static void __xen_pcibk_release_pci_dev(
 	struct passthrough_dev_data *dev_data = pdev->pci_dev_data;
 	struct pci_dev_entry *dev_entry, *t;
 	struct pci_dev *found_dev = NULL;
-	unsigned long flags;
 
-	spin_lock_irqsave(&dev_data->lock, flags);
+	mutex_lock(&dev_data->lock);
 
 	list_for_each_entry_safe(dev_entry, t, &dev_data->dev_list, list) {
 		if (dev_entry->dev == dev) {
@@ -88,7 +85,7 @@ static void __xen_pcibk_release_pci_dev(
 		}
 	}
 
-	spin_unlock_irqrestore(&dev_data->lock, flags);
+	mutex_unlock(&dev_data->lock);
 
 	if (found_dev)
 		pcistub_put_pci_dev(found_dev);
@@ -102,7 +99,7 @@ static int __xen_pcibk_init_devices(stru
 	if (!dev_data)
 		return -ENOMEM;
 
-	spin_lock_init(&dev_data->lock);
+	mutex_init(&dev_data->lock);
 
 	INIT_LIST_HEAD(&dev_data->dev_list);
 
@@ -116,14 +113,14 @@ static int __xen_pcibk_publish_pci_roots
 {
 	int err = 0;
 	struct passthrough_dev_data *dev_data = pdev->pci_dev_data;
-	struct pci_dev_entry *dev_entry, *e, *tmp;
+	struct pci_dev_entry *dev_entry, *e;
 	struct pci_dev *dev;
 	int found;
 	unsigned int domain, bus;
 
-	spin_lock(&dev_data->lock);
+	mutex_lock(&dev_data->lock);
 
-	list_for_each_entry_safe(dev_entry, tmp, &dev_data->dev_list, list) {
+	list_for_each_entry(dev_entry, &dev_data->dev_list, list) {
 		/* Only publish this device as a root if none of its
 		 * parent bridges are exported
 		 */
@@ -142,16 +139,13 @@ static int __xen_pcibk_publish_pci_roots
 		bus = (unsigned int)dev_entry->dev->bus->number;
 
 		if (!found) {
-			spin_unlock(&dev_data->lock);
 			err = publish_root_cb(pdev, domain, bus);
 			if (err)
 				break;
-			spin_lock(&dev_data->lock);
 		}
 	}
 
-	if (!err)
-		spin_unlock(&dev_data->lock);
+	mutex_unlock(&dev_data->lock);
 
 	return err;
 }
@@ -182,7 +176,7 @@ static int __xen_pcibk_get_pcifront_dev(
 	return 1;
 }
 
-struct xen_pcibk_backend xen_pcibk_passthrough_backend = {
+const struct xen_pcibk_backend xen_pcibk_passthrough_backend = {
 	.name           = "passthrough",
 	.init           = __xen_pcibk_init_devices,
 	.free		= __xen_pcibk_release_devices,
--- head-2011-11-03.orig/drivers/xen/xen-pciback/pci_stub.c	2011-11-03 13:58:09.000000000 +0100
+++ head-2011-11-03/drivers/xen/xen-pciback/pci_stub.c	2011-09-19 14:47:15.000000000 +0200
@@ -14,15 +14,18 @@
 #include <linux/wait.h>
 #include <linux/sched.h>
 #include <linux/atomic.h>
+#ifndef CONFIG_XEN
 #include <xen/events.h>
 #include <asm/xen/pci.h>
 #include <asm/xen/hypervisor.h>
+#else
+#include <xen/evtchn.h>
+#endif
+#include <xen/xen.h>
 #include "pciback.h"
 #include "conf_space.h"
 #include "conf_space_quirks.h"
 
-#define DRV_NAME	"xen-pciback"
-
 static char *pci_devs_to_hide;
 wait_queue_head_t xen_pcibk_aer_wait_queue;
 /*Add sem for sync AER handling and xen_pcibk remove/reconfigue ops,
@@ -92,7 +95,9 @@ static void pcistub_device_release(struc
 
 	dev_dbg(&psdev->dev->dev, "pcistub_device_release\n");
 
+#ifndef CONFIG_XEN
 	xen_unregister_device_domain_owner(psdev->dev);
+#endif
 
 	/* Clean-up the device */
 	xen_pcibk_reset_device(psdev->dev);
@@ -292,19 +297,25 @@ static int __devinit pcistub_init_device
 	 * would need to be called somewhere to free the memory allocated
 	 * here and then to call kfree(pci_get_drvdata(psdev->dev)).
 	 */
+#ifndef CONFIG_XEN
 	dev_data = kzalloc(sizeof(*dev_data) +  strlen(DRV_NAME "[]")
 				+ strlen(pci_name(dev)) + 1, GFP_ATOMIC);
+#else
+	dev_data = kzalloc(sizeof(*dev_data), GFP_ATOMIC);
+#endif
 	if (!dev_data) {
 		err = -ENOMEM;
 		goto out;
 	}
 	pci_set_drvdata(dev, dev_data);
 
+#ifndef CONFIG_XEN
 	/*
 	 * Setup name for fake IRQ handler. It will only be enabled
 	 * once the device is turned on by the guest.
 	 */
 	sprintf(dev_data->irq_name, DRV_NAME "[%s]", pci_name(dev));
+#endif
 
 	dev_dbg(&dev->dev, "initializing config\n");
 
@@ -441,6 +452,16 @@ static int __devinit pcistub_probe(struc
 
 		dev_info(&dev->dev, "seizing device\n");
 		err = pcistub_seize(dev);
+#ifdef CONFIG_PCI_GUESTDEV
+	} else if (dev->hdr_type == PCI_HEADER_TYPE_NORMAL) {
+		if (!pci_is_guestdev(dev)) {
+			err = -ENODEV;
+			goto out;
+		}
+
+		dev_info(&dev->dev, "seizing device\n");
+		err = pcistub_seize(dev);
+#endif /* CONFIG_PCI_GUESTDEV */
 	} else
 		/* Didn't find the device */
 		err = -ENODEV;
@@ -514,12 +535,14 @@ static void kill_domain_by_device(struct
 	int err;
 	char nodename[PCI_NODENAME_MAX];
 
-	if (!psdev)
+	if (!psdev) {
 		dev_err(&psdev->dev->dev,
 			"device is NULL when do AER recovery/kill_domain\n");
+		return;
+	}
+
 	snprintf(nodename, PCI_NODENAME_MAX, "/local/domain/0/backend/pci/%d/0",
 		psdev->pdev->xdev->otherend_id);
-	nodename[strlen(nodename)] = '\0';
 
 again:
 	err = xenbus_transaction_start(&xbt);
@@ -605,7 +628,7 @@ static pci_ers_result_t common_process(s
 	if (test_bit(_XEN_PCIF_active,
 		(unsigned long *)&psdev->pdev->sh_info->flags)) {
 		dev_dbg(&psdev->dev->dev,
-			"schedule pci_conf service in xen_pcibk\n");
+			"schedule pci_conf service in " DRV_NAME "\n");
 		xen_pcibk_test_and_schedule_op(psdev->pdev);
 	}
 
@@ -848,8 +871,10 @@ static struct pci_error_handlers xen_pci
  */
 
 static struct pci_driver xen_pcibk_pci_driver = {
+#ifndef CONFIG_XEN
 	/* The name should be xen_pciback, but until the tools are updated
 	 * we will keep it as pciback. */
+#endif
 	.name = "pciback",
 	.id_table = pcistub_ids,
 	.probe = pcistub_probe,
@@ -995,8 +1020,7 @@ out:
 		err = count;
 	return err;
 }
-
-DRIVER_ATTR(new_slot, S_IWUSR, NULL, pcistub_slot_add);
+static DRIVER_ATTR(new_slot, S_IWUSR, NULL, pcistub_slot_add);
 
 static ssize_t pcistub_slot_remove(struct device_driver *drv, const char *buf,
 				   size_t count)
@@ -1015,8 +1039,7 @@ out:
 		err = count;
 	return err;
 }
-
-DRIVER_ATTR(remove_slot, S_IWUSR, NULL, pcistub_slot_remove);
+static DRIVER_ATTR(remove_slot, S_IWUSR, NULL, pcistub_slot_remove);
 
 static ssize_t pcistub_slot_show(struct device_driver *drv, char *buf)
 {
@@ -1039,9 +1062,9 @@ static ssize_t pcistub_slot_show(struct 
 
 	return count;
 }
+static DRIVER_ATTR(slots, S_IRUSR, pcistub_slot_show, NULL);
 
-DRIVER_ATTR(slots, S_IRUSR, pcistub_slot_show, NULL);
-
+#ifndef CONFIG_XEN
 static ssize_t pcistub_irq_handler_show(struct device_driver *drv, char *buf)
 {
 	struct pcistub_device *psdev;
@@ -1069,8 +1092,7 @@ static ssize_t pcistub_irq_handler_show(
 	spin_unlock_irqrestore(&pcistub_devices_lock, flags);
 	return count;
 }
-
-DRIVER_ATTR(irq_handlers, S_IRUSR, pcistub_irq_handler_show, NULL);
+static DRIVER_ATTR(irq_handlers, S_IRUSR, pcistub_irq_handler_show, NULL);
 
 static ssize_t pcistub_irq_handler_switch(struct device_driver *drv,
 					  const char *buf,
@@ -1106,7 +1128,8 @@ out:
 		err = count;
 	return err;
 }
-DRIVER_ATTR(irq_handler_state, S_IWUSR, NULL, pcistub_irq_handler_switch);
+static DRIVER_ATTR(irq_handler_state, S_IWUSR, NULL, pcistub_irq_handler_switch);
+#endif
 
 static ssize_t pcistub_quirk_add(struct device_driver *drv, const char *buf,
 				 size_t count)
@@ -1170,8 +1193,7 @@ out:
 
 	return count;
 }
-
-DRIVER_ATTR(quirks, S_IRUSR | S_IWUSR, pcistub_quirk_show, pcistub_quirk_add);
+static DRIVER_ATTR(quirks, S_IRUSR | S_IWUSR, pcistub_quirk_show, pcistub_quirk_add);
 
 static ssize_t permissive_add(struct device_driver *drv, const char *buf,
 			      size_t count)
@@ -1236,8 +1258,22 @@ static ssize_t permissive_show(struct de
 	spin_unlock_irqrestore(&pcistub_devices_lock, flags);
 	return count;
 }
+static DRIVER_ATTR(permissive, S_IRUSR | S_IWUSR, permissive_show, permissive_add);
+
+#if defined(CONFIG_XEN) && defined(CONFIG_PCI_MSI)
+static int xen_pcibk_get_owner(struct pci_dev *dev)
+{
+	struct pcistub_device *psdev;
+
+	psdev = pcistub_device_find(pci_domain_nr(dev->bus), dev->bus->number,
+			PCI_SLOT(dev->devfn), PCI_FUNC(dev->devfn));
+
+	if (!psdev || !psdev->pdev)
+		return -1;
 
-DRIVER_ATTR(permissive, S_IRUSR | S_IWUSR, permissive_show, permissive_add);
+	return psdev->pdev->xdev->otherend_id;
+}
+#endif
 
 static void pcistub_exit(void)
 {
@@ -1248,10 +1284,14 @@ static void pcistub_exit(void)
 	driver_remove_file(&xen_pcibk_pci_driver.driver, &driver_attr_quirks);
 	driver_remove_file(&xen_pcibk_pci_driver.driver,
 			   &driver_attr_permissive);
+#ifndef CONFIG_XEN
 	driver_remove_file(&xen_pcibk_pci_driver.driver,
 			   &driver_attr_irq_handlers);
 	driver_remove_file(&xen_pcibk_pci_driver.driver,
 			   &driver_attr_irq_handler_state);
+#else
+	WARN_ON(unregister_msi_get_owner(xen_pcibk_get_owner));
+#endif
 	pci_unregister_driver(&xen_pcibk_pci_driver);
 }
 
@@ -1311,11 +1351,15 @@ static int __init pcistub_init(void)
 					 &driver_attr_permissive);
 
 	if (!err)
+#ifdef CONFIG_XEN
+		err = register_msi_get_owner(xen_pcibk_get_owner);
+#else
 		err = driver_create_file(&xen_pcibk_pci_driver.driver,
 					 &driver_attr_irq_handlers);
 	if (!err)
 		err = driver_create_file(&xen_pcibk_pci_driver.driver,
 					&driver_attr_irq_handler_state);
+#endif
 	if (err)
 		pcistub_exit();
 
@@ -1374,3 +1418,4 @@ module_init(xen_pcibk_init);
 module_exit(xen_pcibk_cleanup);
 
 MODULE_LICENSE("Dual BSD/GPL");
+MODULE_ALIAS("xen-backend:pci");
--- head-2011-11-03.orig/drivers/xen/xen-pciback/pciback.h	2011-11-03 13:58:09.000000000 +0100
+++ head-2011-11-03/drivers/xen/xen-pciback/pciback.h	2011-09-19 14:59:20.000000000 +0200
@@ -10,11 +10,17 @@
 #include <linux/interrupt.h>
 #include <xen/xenbus.h>
 #include <linux/list.h>
-#include <linux/spinlock.h>
+#include <linux/mutex.h>
 #include <linux/workqueue.h>
 #include <linux/atomic.h>
 #include <xen/interface/io/pciif.h>
 
+#ifndef CONFIG_XEN
+#define DRV_NAME	"xen-pciback"
+#else
+#define DRV_NAME	"pciback"
+#endif
+
 struct pci_dev_entry {
 	struct list_head list;
 	struct pci_dev *dev;
@@ -27,11 +33,14 @@ struct pci_dev_entry {
 
 struct xen_pcibk_device {
 	void *pci_dev_data;
-	spinlock_t dev_lock;
+	struct mutex dev_lock;
 	struct xenbus_device *xdev;
 	struct xenbus_watch be_watch;
 	u8 be_watching;
 	int evtchn_irq;
+#ifdef CONFIG_XEN
+	struct vm_struct *sh_area;
+#endif
 	struct xen_pci_sharedinfo *sh_info;
 	unsigned long flags;
 	struct work_struct op_work;
@@ -41,12 +50,14 @@ struct xen_pcibk_dev_data {
 	struct list_head config_fields;
 	unsigned int permissive:1;
 	unsigned int warned_on_write:1;
+#ifndef CONFIG_XEN
 	unsigned int enable_intx:1;
 	unsigned int isr_on:1; /* Whether the IRQ handler is installed. */
 	unsigned int ack_intr:1; /* .. and ACK-ing */
 	unsigned long handled;
 	unsigned int irq; /* Saved in case device transitions to MSI/MSI-X */
 	char irq_name[0]; /* xen-pcibk[000:04:00.0] */
+#endif
 };
 
 /* Used by XenBus and xen_pcibk_ops.c */
@@ -84,12 +95,14 @@ typedef int (*publish_pci_dev_cb) (struc
 typedef int (*publish_pci_root_cb) (struct xen_pcibk_device *pdev,
 				    unsigned int domain, unsigned int bus);
 
-/* Backend registration for the two types of BDF representation:
+/* Backend registration for the different types of BDF representation:
  *  vpci - BDFs start at 00
  *  passthrough - BDFs are exactly like in the host.
+ *  slot - like vpci, but each function becoming a separate slot
+ *  controller - devices on same host bus will also be on same virtual bus
  */
 struct xen_pcibk_backend {
-	char *name;
+	const char *name;
 	int (*init)(struct xen_pcibk_device *pdev);
 	void (*free)(struct xen_pcibk_device *pdev);
 	int (*find)(struct pci_dev *pcidev, struct xen_pcibk_device *pdev,
@@ -104,9 +117,11 @@ struct xen_pcibk_backend {
 			       unsigned int devfn);
 };
 
-extern struct xen_pcibk_backend xen_pcibk_vpci_backend;
-extern struct xen_pcibk_backend xen_pcibk_passthrough_backend;
-extern struct xen_pcibk_backend *xen_pcibk_backend;
+extern const struct xen_pcibk_backend __weak xen_pcibk_vpci_backend;
+extern const struct xen_pcibk_backend __weak xen_pcibk_passthrough_backend;
+extern const struct xen_pcibk_backend __weak xen_pcibk_slot_backend;
+extern const struct xen_pcibk_backend __weak xen_pcibk_controller_backend;
+extern const struct xen_pcibk_backend *xen_pcibk_backend;
 
 static inline int xen_pcibk_add_pci_dev(struct xen_pcibk_device *pdev,
 					struct pci_dev *dev,
@@ -116,13 +131,14 @@ static inline int xen_pcibk_add_pci_dev(
 	if (xen_pcibk_backend && xen_pcibk_backend->add)
 		return xen_pcibk_backend->add(pdev, dev, devid, publish_cb);
 	return -1;
-};
+}
+
 static inline void xen_pcibk_release_pci_dev(struct xen_pcibk_device *pdev,
 					     struct pci_dev *dev)
 {
 	if (xen_pcibk_backend && xen_pcibk_backend->free)
 		return xen_pcibk_backend->release(pdev, dev);
-};
+}
 
 static inline struct pci_dev *
 xen_pcibk_get_pci_dev(struct xen_pcibk_device *pdev, unsigned int domain,
@@ -131,7 +147,8 @@ xen_pcibk_get_pci_dev(struct xen_pcibk_d
 	if (xen_pcibk_backend && xen_pcibk_backend->get)
 		return xen_pcibk_backend->get(pdev, domain, bus, devfn);
 	return NULL;
-};
+}
+
 /**
 * Add for domain0 PCIE-AER handling. Get guest domain/bus/devfn in xen_pcibk
 * before sending aer request to pcifront, so that guest could identify
@@ -148,25 +165,29 @@ static inline int xen_pcibk_get_pcifront
 		return xen_pcibk_backend->find(pcidev, pdev, domain, bus,
 					       devfn);
 	return -1;
-};
+}
+
 static inline int xen_pcibk_init_devices(struct xen_pcibk_device *pdev)
 {
 	if (xen_pcibk_backend && xen_pcibk_backend->init)
 		return xen_pcibk_backend->init(pdev);
 	return -1;
-};
+}
+
 static inline int xen_pcibk_publish_pci_roots(struct xen_pcibk_device *pdev,
 					      publish_pci_root_cb cb)
 {
 	if (xen_pcibk_backend && xen_pcibk_backend->publish)
 		return xen_pcibk_backend->publish(pdev, cb);
 	return -1;
-};
+}
+
 static inline void xen_pcibk_release_devices(struct xen_pcibk_device *pdev)
 {
 	if (xen_pcibk_backend && xen_pcibk_backend->free)
 		return xen_pcibk_backend->free(pdev);
-};
+}
+
 /* Handles events from front-end */
 irqreturn_t xen_pcibk_handle_event(int irq, void *dev_id);
 void xen_pcibk_do_op(struct work_struct *data);
--- head-2011-11-03.orig/drivers/xen/xen-pciback/pciback_ops.c	2011-11-03 13:58:09.000000000 +0100
+++ head-2011-11-03/drivers/xen/xen-pciback/pciback_ops.c	2011-09-16 17:40:58.000000000 +0200
@@ -6,14 +6,18 @@
 #include <linux/module.h>
 #include <linux/wait.h>
 #include <linux/bitops.h>
+#ifndef CONFIG_XEN
 #include <xen/events.h>
+#else
+#include <xen/evtchn.h>
+#endif
 #include <linux/sched.h>
 #include "pciback.h"
 
-#define DRV_NAME	"xen-pciback"
 int verbose_request;
 module_param(verbose_request, int, 0644);
 
+#ifndef CONFIG_XEN
 static irqreturn_t xen_pcibk_guest_interrupt(int irq, void *dev_id);
 
 /* Ensure a device is has the fake IRQ handler "turned on/off" and is
@@ -93,6 +97,7 @@ out:
 		enable ? (dev_data->isr_on ? "enabled" : "failed to enable") :
 			(dev_data->isr_on ? "failed to disable" : "disabled"));
 }
+#endif
 
 /* Ensure a device is "turned off" and ready to be exported.
  * (Also see xen_pcibk_config_reset to ensure virtual configuration space is
@@ -102,7 +107,9 @@ void xen_pcibk_reset_device(struct pci_d
 {
 	u16 cmd;
 
+#ifndef CONFIG_XEN
 	xen_pcibk_control_isr(dev, 1 /* reset device */);
+#endif
 
 	/* Disable devices (but not bridges) */
 	if (dev->hdr_type == PCI_HEADER_TYPE_NORMAL) {
@@ -118,6 +125,9 @@ void xen_pcibk_reset_device(struct pci_d
 
 		pci_write_config_word(dev, PCI_COMMAND, 0);
 
+#ifdef CONFIG_XEN
+		atomic_set(&dev->enable_cnt, 0);
+#endif
 		dev->is_busmaster = 0;
 	} else {
 		pci_read_config_word(dev, PCI_COMMAND, &cmd);
@@ -135,7 +145,9 @@ static
 int xen_pcibk_enable_msi(struct xen_pcibk_device *pdev,
 			 struct pci_dev *dev, struct xen_pci_op *op)
 {
+#ifndef CONFIG_XEN
 	struct xen_pcibk_dev_data *dev_data;
+#endif
 	int otherend = pdev->xdev->otherend_id;
 	int status;
 
@@ -154,14 +166,20 @@ int xen_pcibk_enable_msi(struct xen_pcib
 	/* The value the guest needs is actually the IDT vector, not the
 	 * the local domain's IRQ number. */
 
+#ifndef CONFIG_XEN
 	op->value = dev->irq ? xen_pirq_from_irq(dev->irq) : 0;
+#else
+	op->value = dev->irq;
+#endif
 	if (unlikely(verbose_request))
 		printk(KERN_DEBUG DRV_NAME ": %s: MSI: %d\n", pci_name(dev),
 			op->value);
 
+#ifndef CONFIG_XEN
 	dev_data = pci_get_drvdata(dev);
 	if (dev_data)
 		dev_data->ack_intr = 0;
+#endif
 
 	return 0;
 }
@@ -170,20 +188,28 @@ static
 int xen_pcibk_disable_msi(struct xen_pcibk_device *pdev,
 			  struct pci_dev *dev, struct xen_pci_op *op)
 {
+#ifndef CONFIG_XEN
 	struct xen_pcibk_dev_data *dev_data;
+#endif
 
 	if (unlikely(verbose_request))
 		printk(KERN_DEBUG DRV_NAME ": %s: disable MSI\n",
 		       pci_name(dev));
 	pci_disable_msi(dev);
 
+#ifndef CONFIG_XEN
 	op->value = dev->irq ? xen_pirq_from_irq(dev->irq) : 0;
+#else
+	op->value = dev->irq;
+#endif
 	if (unlikely(verbose_request))
 		printk(KERN_DEBUG DRV_NAME ": %s: MSI: %d\n", pci_name(dev),
 			op->value);
+#ifndef CONFIG_XEN
 	dev_data = pci_get_drvdata(dev);
 	if (dev_data)
 		dev_data->ack_intr = 1;
+#endif
 	return 0;
 }
 
@@ -191,7 +217,9 @@ static
 int xen_pcibk_enable_msix(struct xen_pcibk_device *pdev,
 			  struct pci_dev *dev, struct xen_pci_op *op)
 {
+#ifndef CONFIG_XEN
 	struct xen_pcibk_dev_data *dev_data;
+#endif
 	int i, result;
 	struct msix_entry *entries;
 
@@ -215,9 +243,13 @@ int xen_pcibk_enable_msix(struct xen_pci
 	if (result == 0) {
 		for (i = 0; i < op->value; i++) {
 			op->msix_entries[i].entry = entries[i].entry;
+#ifndef CONFIG_XEN
 			if (entries[i].vector)
 				op->msix_entries[i].vector =
 					xen_pirq_from_irq(entries[i].vector);
+#else
+			op->msix_entries[i].vector = entries[i].vector;
+#endif
 				if (unlikely(verbose_request))
 					printk(KERN_DEBUG DRV_NAME ": %s: " \
 						"MSI-X[%d]: %d\n",
@@ -231,9 +263,11 @@ int xen_pcibk_enable_msix(struct xen_pci
 	kfree(entries);
 
 	op->value = result;
+#ifndef CONFIG_XEN
 	dev_data = pci_get_drvdata(dev);
 	if (dev_data)
 		dev_data->ack_intr = 0;
+#endif
 
 	return result;
 }
@@ -242,12 +276,16 @@ static
 int xen_pcibk_disable_msix(struct xen_pcibk_device *pdev,
 			   struct pci_dev *dev, struct xen_pci_op *op)
 {
+#ifndef CONFIG_XEN
 	struct xen_pcibk_dev_data *dev_data;
+#endif
+
 	if (unlikely(verbose_request))
 		printk(KERN_DEBUG DRV_NAME ": %s: disable MSI-X\n",
 			pci_name(dev));
 	pci_disable_msix(dev);
 
+#ifndef CONFIG_XEN
 	/*
 	 * SR-IOV devices (which don't have any legacy IRQ) have
 	 * an undefined IRQ value of zero.
@@ -259,6 +297,9 @@ int xen_pcibk_disable_msix(struct xen_pc
 	dev_data = pci_get_drvdata(dev);
 	if (dev_data)
 		dev_data->ack_intr = 1;
+#else
+	op->value = dev->irq;
+#endif
 	return 0;
 }
 #endif
@@ -303,9 +344,14 @@ void xen_pcibk_do_op(struct work_struct 
 	if (dev == NULL)
 		op->err = XEN_PCI_ERR_dev_not_found;
 	else {
+#ifndef CONFIG_XEN
 		dev_data = pci_get_drvdata(dev);
 		if (dev_data)
 			test_intx = dev_data->enable_intx;
+#else
+		(void)dev_data;
+		(void)test_intx;
+#endif
 		switch (op->cmd) {
 		case XEN_PCI_OP_conf_read:
 			op->err = xen_pcibk_config_read(dev,
@@ -334,11 +380,13 @@ void xen_pcibk_do_op(struct work_struct 
 			break;
 		}
 	}
+#ifndef CONFIG_XEN
 	if (!op->err && dev && dev_data) {
 		/* Transition detected */
 		if ((dev_data->enable_intx != test_intx))
 			xen_pcibk_control_isr(dev, 0 /* no reset */);
 	}
+#endif
 	/* Tell the driver domain that we're done. */
 	wmb();
 	clear_bit(_XEN_PCIF_active, (unsigned long *)&pdev->sh_info->flags);
@@ -363,6 +411,8 @@ irqreturn_t xen_pcibk_handle_event(int i
 
 	return IRQ_HANDLED;
 }
+
+#ifndef CONFIG_XEN
 static irqreturn_t xen_pcibk_guest_interrupt(int irq, void *dev_id)
 {
 	struct pci_dev *dev = (struct pci_dev *)dev_id;
@@ -382,3 +432,4 @@ static irqreturn_t xen_pcibk_guest_inter
 	}
 	return IRQ_NONE;
 }
+#endif
--- head-2011-11-03.orig/drivers/xen/xen-pciback/slot.c	2011-01-31 17:56:27.000000000 +0100
+++ head-2011-11-03/drivers/xen/xen-pciback/slot.c	2011-09-19 14:36:47.000000000 +0200
@@ -6,9 +6,6 @@
  *   Author: Tristan Gingold <tristan.gingold@bull.net>, from vpci.c
  */
 
-#include <linux/list.h>
-#include <linux/slab.h>
-#include <linux/pci.h>
 #include <linux/spinlock.h>
 #include "pciback.h"
 
@@ -23,9 +20,10 @@ struct slot_dev_data {
 	spinlock_t lock;
 };
 
-struct pci_dev *pciback_get_pci_dev(struct pciback_device *pdev,
-				    unsigned int domain, unsigned int bus,
-				    unsigned int devfn)
+static struct pci_dev *_xen_pcibk_get_pci_dev(struct xen_pcibk_device *pdev,
+					      unsigned int domain,
+					      unsigned int bus,
+					      unsigned int devfn)
 {
 	struct pci_dev *dev = NULL;
 	struct slot_dev_data *slot_dev = pdev->pci_dev_data;
@@ -44,8 +42,9 @@ struct pci_dev *pciback_get_pci_dev(stru
 	return dev;
 }
 
-int pciback_add_pci_dev(struct pciback_device *pdev, struct pci_dev *dev,
-			int devid, publish_pci_dev_cb publish_cb)
+static int _xen_pcibk_add_pci_dev(struct xen_pcibk_device *pdev,
+				  struct pci_dev *dev, int devid,
+				  publish_pci_dev_cb publish_cb)
 {
 	int err = 0, slot, bus;
 	struct slot_dev_data *slot_dev = pdev->pci_dev_data;
@@ -87,7 +86,8 @@ int pciback_add_pci_dev(struct pciback_d
 	return err;
 }
 
-void pciback_release_pci_dev(struct pciback_device *pdev, struct pci_dev *dev)
+static void _xen_pcibk_release_pci_dev(struct xen_pcibk_device *pdev,
+				       struct pci_dev *dev)
 {
 	int slot, bus;
 	struct slot_dev_data *slot_dev = pdev->pci_dev_data;
@@ -112,7 +112,7 @@ void pciback_release_pci_dev(struct pcib
 		pcistub_put_pci_dev(found_dev);
 }
 
-int pciback_init_devices(struct pciback_device *pdev)
+static int _xen_pcibk_init_devices(struct xen_pcibk_device *pdev)
 {
 	int slot, bus;
 	struct slot_dev_data *slot_dev;
@@ -132,14 +132,14 @@ int pciback_init_devices(struct pciback_
 	return 0;
 }
 
-int pciback_publish_pci_roots(struct pciback_device *pdev,
-			      publish_pci_root_cb publish_cb)
+static int _xen_pcibk_publish_pci_roots(struct xen_pcibk_device *pdev,
+					publish_pci_root_cb publish_cb)
 {
 	/* The Virtual PCI bus has only one root */
 	return publish_cb(pdev, 0, 0);
 }
 
-void pciback_release_devices(struct pciback_device *pdev)
+static void _xen_pcibk_release_devices(struct xen_pcibk_device *pdev)
 {
 	int slot, bus;
 	struct slot_dev_data *slot_dev = pdev->pci_dev_data;
@@ -156,8 +156,10 @@ void pciback_release_devices(struct pcib
 	pdev->pci_dev_data = NULL;
 }
 
-int pciback_get_pcifront_dev(struct pci_dev *pcidev, struct pciback_device *pdev, 
-		unsigned int *domain, unsigned int *bus, unsigned int *devfn)
+static int _xen_pcibk_get_pcifront_dev(struct pci_dev *pcidev,
+				       struct xen_pcibk_device *pdev,
+				       unsigned int *domain,
+				       unsigned int *bus, unsigned int *devfn)
 {
 	int slot, busnr;
 	struct slot_dev_data *slot_dev = pdev->pci_dev_data;
@@ -185,3 +187,14 @@ out:
 	return found;
 
 }
+
+const struct xen_pcibk_backend xen_pcibk_slot_backend = {
+	.name		= "slot",
+	.init		= _xen_pcibk_init_devices,
+	.free		= _xen_pcibk_release_devices,
+	.find		= _xen_pcibk_get_pcifront_dev,
+	.publish	= _xen_pcibk_publish_pci_roots,
+	.release	= _xen_pcibk_release_pci_dev,
+	.add		= _xen_pcibk_add_pci_dev,
+	.get		= _xen_pcibk_get_pci_dev,
+};
--- head-2011-11-03.orig/drivers/xen/xen-pciback/vpci.c	2011-11-03 13:58:09.000000000 +0100
+++ head-2011-11-03/drivers/xen/xen-pciback/vpci.c	2011-09-16 17:23:49.000000000 +0200
@@ -12,7 +12,6 @@
 #include "pciback.h"
 
 #define PCI_SLOT_MAX 32
-#define DRV_NAME	"xen-pciback"
 
 struct vpci_dev_data {
 	/* Access to dev_list must be protected by lock */
@@ -150,9 +149,9 @@ static void __xen_pcibk_release_pci_dev(
 	spin_lock_irqsave(&vpci_dev->lock, flags);
 
 	for (slot = 0; slot < PCI_SLOT_MAX; slot++) {
-		struct pci_dev_entry *e, *tmp;
-		list_for_each_entry_safe(e, tmp, &vpci_dev->dev_list[slot],
-					 list) {
+		struct pci_dev_entry *e;
+
+		list_for_each_entry(e, &vpci_dev->dev_list[slot], list) {
 			if (e->dev == dev) {
 				list_del(&e->list);
 				found_dev = e->dev;
@@ -247,7 +246,7 @@ static int __xen_pcibk_get_pcifront_dev(
 	return found;
 }
 
-struct xen_pcibk_backend xen_pcibk_vpci_backend = {
+const struct xen_pcibk_backend xen_pcibk_vpci_backend = {
 	.name		= "vpci",
 	.init		= __xen_pcibk_init_devices,
 	.free		= __xen_pcibk_release_devices,
--- head-2011-11-03.orig/drivers/xen/xen-pciback/xenbus.c	2011-11-03 13:58:09.000000000 +0100
+++ head-2011-11-03/drivers/xen/xen-pciback/xenbus.c	2011-09-23 09:56:59.000000000 +0200
@@ -9,28 +9,75 @@
 #include <linux/vmalloc.h>
 #include <linux/workqueue.h>
 #include <xen/xenbus.h>
+#ifndef CONFIG_XEN
 #include <xen/events.h>
 #include <asm/xen/pci.h>
+#else
+#include <xen/evtchn.h>
+#endif
 #include "pciback.h"
 
-#define	DRV_NAME	"xen-pciback"
 #define INVALID_EVTCHN_IRQ  (-1)
 struct workqueue_struct *xen_pcibk_wq;
 
-static int __read_mostly passthrough;
-module_param(passthrough, bool, S_IRUGO);
-MODULE_PARM_DESC(passthrough,
-	"Option to specify how to export PCI topology to guest:\n"\
-	" 0 - (default) Hide the true PCI topology and makes the frontend\n"\
-	"   there is a single PCI bus with only the exported devices on it.\n"\
-	"   For example, a device at 03:05.0 will be re-assigned to 00:00.0\n"\
-	"   while second device at 02:1a.1 will be re-assigned to 00:01.1.\n"\
-	" 1 - Passthrough provides a real view of the PCI topology to the\n"\
-	"   frontend (for example, a device at 06:01.b will still appear at\n"\
-	"   06:01.b to the frontend). This is similar to how Xen 2.0.x\n"\
-	"   exposed PCI devices to its driver domains. This may be required\n"\
-	"   for drivers which depend on finding their hardward in certain\n"\
-	"   bus/slot locations.");
+static char __read_mostly mode[16] = CONFIG_XEN_PCIDEV_BACKEND_DEFAULT;
+module_param_string(mode, mode, sizeof(mode), S_IRUGO);
+MODULE_PARM_DESC(mode,
+	"Option to specify how to export PCI topology to guest:\n"
+#ifdef CONFIG_XEN_PCIDEV_BACKEND_VPCI
+	" vpci"
+# ifdef CONFIG_XEN_PCIDEV_BACKEND_DEFAULT_VPCI
+	" (default)"
+# endif
+	"\n"
+	"   Hides the true PCI topology and makes the frontend think there\n"
+	"   is a single PCI bus with only the exported devices on it.\n"
+	"   For example, a device at 03:05.0 will be re-assigned to 00:00.0\n"
+	"   while second device at 02:1a.1 will be re-assigned to 00:01.1.\n"
+#endif
+#ifdef CONFIG_XEN_PCIDEV_BACKEND_PASSTHROUGH
+	" passthrough"
+# ifdef CONFIG_XEN_PCIDEV_BACKEND_DEFAULT_PASSTHROUGH
+	" (default)"
+# endif
+	"\n"
+	"   Passthrough provides a real view of the PCI topology to the\n"
+	"   frontend (for example, a device at 06:01.b will still appear at\n"
+	"   06:01.b to the frontend). This is similar to how Xen 2.0.x\n"
+	"   exposed PCI devices to its driver domains. This may be required\n"
+	"   for drivers which depend on finding their hardware in certain\n"
+	"   bus/slot locations.\n"
+#endif
+#ifdef CONFIG_XEN_PCIDEV_BACKEND_SLOT
+	" slot\n"
+# ifdef CONFIG_XEN_PCIDEV_BACKEND_DEFAULT_SLOT
+	" (default)"
+# endif
+	"   Hides the true PCI topology and makes the frontend think there\n"
+	"   is a single PCI bus with only the exported devices on it.\n"
+	"   Contrary to the virtual PCI backend, each function becomes a\n"
+	"   new slot.\n"
+	"   For example, a device at 03:05.2 will be re-assigned to 00:00.0.\n"
+	"   A second device at 02:1a.1 will be re-assigned to 00:01.0.\n"
+#endif
+#ifdef CONFIG_XEN_PCIDEV_BACKEND_CONTROLLER
+	" controller\n"
+# ifdef CONFIG_XEN_PCIDEV_BACKEND_DEFAULT_CONTROLLER
+	" (default)"
+# endif
+	"   Virtualizes the PCI bus topology by providing a virtual bus\n"
+	"   per PCI root device.  Devices which are physically under\n"
+	"   the same root bus will appear on the same virtual bus.  For\n"
+	"   systems with complex I/O addressing, this is the only backend\n"
+	"   which supports extended I/O port spaces and MMIO translation\n"
+	"   offsets.  This backend also supports slot virtualization.\n"
+	"   For example, a device at 0000:01:02.1 will be re-assigned to\n"
+	"   0000:00:00.0.  A second device at 0000:02:05.0 (behind a P2P\n"
+	"   bridge on bus 0000:01) will be re-assigned to 0000:00:01.0.  A\n"
+	"   third device at 0000:16:05.0 (under a different PCI root bus)\n"
+	"   will be re-assigned to 0000:01:00.0.\n"
+#endif
+	);
 
 static struct xen_pcibk_device *alloc_pdev(struct xenbus_device *xdev)
 {
@@ -44,8 +91,11 @@ static struct xen_pcibk_device *alloc_pd
 	pdev->xdev = xdev;
 	dev_set_drvdata(&xdev->dev, pdev);
 
-	spin_lock_init(&pdev->dev_lock);
+	mutex_init(&pdev->dev_lock);
 
+#ifdef CONFIG_XEN
+	pdev->sh_area = NULL;
+#endif
 	pdev->sh_info = NULL;
 	pdev->evtchn_irq = INVALID_EVTCHN_IRQ;
 	pdev->be_watching = 0;
@@ -62,14 +112,12 @@ out:
 
 static void xen_pcibk_disconnect(struct xen_pcibk_device *pdev)
 {
-	spin_lock(&pdev->dev_lock);
-
+	mutex_lock(&pdev->dev_lock);
 	/* Ensure the guest can't trigger our handler before removing devices */
 	if (pdev->evtchn_irq != INVALID_EVTCHN_IRQ) {
 		unbind_from_irqhandler(pdev->evtchn_irq, pdev);
 		pdev->evtchn_irq = INVALID_EVTCHN_IRQ;
 	}
-	spin_unlock(&pdev->dev_lock);
 
 	/* If the driver domain started an op, make sure we complete it
 	 * before releasing the shared memory */
@@ -77,13 +125,15 @@ static void xen_pcibk_disconnect(struct 
 	/* Note, the workqueue does not use spinlocks at all.*/
 	flush_workqueue(xen_pcibk_wq);
 
-	spin_lock(&pdev->dev_lock);
 	if (pdev->sh_info != NULL) {
+#ifndef CONFIG_XEN
 		xenbus_unmap_ring_vfree(pdev->xdev, pdev->sh_info);
+#else
+		xenbus_unmap_ring_vfree(pdev->xdev, pdev->sh_area);
+#endif
 		pdev->sh_info = NULL;
 	}
-	spin_unlock(&pdev->dev_lock);
-
+	mutex_unlock(&pdev->dev_lock);
 }
 
 static void free_pdev(struct xen_pcibk_device *pdev)
@@ -107,22 +157,35 @@ static int xen_pcibk_do_attach(struct xe
 			     int remote_evtchn)
 {
 	int err = 0;
+#ifndef CONFIG_XEN
 	void *vaddr;
+#else
+	struct vm_struct *area;
+#endif
 
 	dev_dbg(&pdev->xdev->dev,
 		"Attaching to frontend resources - gnt_ref=%d evtchn=%d\n",
 		gnt_ref, remote_evtchn);
 
+#ifndef CONFIG_XEN
 	err = xenbus_map_ring_valloc(pdev->xdev, gnt_ref, &vaddr);
 	if (err < 0) {
+#else
+	area = xenbus_map_ring_valloc(pdev->xdev, gnt_ref);
+	if (IS_ERR(area)) {
+		err = PTR_ERR(area);
+#endif
 		xenbus_dev_fatal(pdev->xdev, err,
 				"Error mapping other domain page in ours.");
 		goto out;
 	}
 
-	spin_lock(&pdev->dev_lock);
+#ifndef CONFIG_XEN
 	pdev->sh_info = vaddr;
-	spin_unlock(&pdev->dev_lock);
+#else
+	pdev->sh_area = area;
+	pdev->sh_info = area->addr;
+#endif
 
 	err = bind_interdomain_evtchn_to_irqhandler(
 		pdev->xdev->otherend_id, remote_evtchn, xen_pcibk_handle_event,
@@ -132,10 +195,7 @@ static int xen_pcibk_do_attach(struct xe
 				 "Error binding event channel to IRQ");
 		goto out;
 	}
-
-	spin_lock(&pdev->dev_lock);
 	pdev->evtchn_irq = err;
-	spin_unlock(&pdev->dev_lock);
 	err = 0;
 
 	dev_dbg(&pdev->xdev->dev, "Attached!\n");
@@ -149,6 +209,7 @@ static int xen_pcibk_attach(struct xen_p
 	int gnt_ref, remote_evtchn;
 	char *magic = NULL;
 
+	mutex_lock(&pdev->dev_lock);
 
 	/* Make sure we only do this setup once */
 	if (xenbus_read_driver_state(pdev->xdev->nodename) !=
@@ -176,7 +237,7 @@ static int xen_pcibk_attach(struct xen_p
 	if (magic == NULL || strcmp(magic, XEN_PCI_MAGIC) != 0) {
 		xenbus_dev_fatal(pdev->xdev, -EFAULT,
 				 "version mismatch (%s/%s) with pcifront - "
-				 "halting xen_pcibk",
+				 "halting " DRV_NAME,
 				 magic, XEN_PCI_MAGIC);
 		goto out;
 	}
@@ -194,6 +255,7 @@ static int xen_pcibk_attach(struct xen_p
 
 	dev_dbg(&pdev->xdev->dev, "Connected? %d\n", err);
 out:
+	mutex_unlock(&pdev->dev_lock);
 
 	kfree(magic);
 
@@ -248,6 +310,7 @@ static int xen_pcibk_export_device(struc
 	if (err)
 		goto out;
 
+#ifndef CONFIG_XEN
 	dev_dbg(&dev->dev, "registering for %d\n", pdev->xdev->otherend_id);
 	if (xen_register_device_domain_owner(dev,
 					     pdev->xdev->otherend_id) != 0) {
@@ -256,6 +319,7 @@ static int xen_pcibk_export_device(struc
 		xen_unregister_device_domain_owner(dev);
 		xen_register_device_domain_owner(dev, pdev->xdev->otherend_id);
 	}
+#endif
 
 	/* TODO: It'd be nice to export a bridge and have all of its children
 	 * get exported with it. This may be best done in xend (which will
@@ -287,8 +351,10 @@ static int xen_pcibk_remove_device(struc
 		goto out;
 	}
 
+#ifndef CONFIG_XEN
 	dev_dbg(&dev->dev, "unregistering for %d\n", pdev->xdev->otherend_id);
 	xen_unregister_device_domain_owner(dev);
+#endif
 
 	xen_pcibk_release_pci_dev(pdev, dev);
 
@@ -369,6 +435,7 @@ static int xen_pcibk_reconfigure(struct 
 
 	dev_dbg(&pdev->xdev->dev, "Reconfiguring device ...\n");
 
+	mutex_lock(&pdev->dev_lock);
 	/* Make sure we only reconfigure once */
 	if (xenbus_read_driver_state(pdev->xdev->nodename) !=
 	    XenbusStateReconfiguring)
@@ -506,6 +573,7 @@ static int xen_pcibk_reconfigure(struct 
 	}
 
 out:
+	mutex_unlock(&pdev->dev_lock);
 	return 0;
 }
 
@@ -562,6 +630,7 @@ static int xen_pcibk_setup_backend(struc
 	char dev_str[64];
 	char state_str[64];
 
+	mutex_lock(&pdev->dev_lock);
 	/* It's possible we could get the call to setup twice, so make sure
 	 * we're not already connected.
 	 */
@@ -642,6 +711,7 @@ static int xen_pcibk_setup_backend(struc
 				 "Error switching to initialised state!");
 
 out:
+	mutex_unlock(&pdev->dev_lock);
 	if (!err)
 		/* see if pcifront is already configured (if not, we'll wait) */
 		xen_pcibk_attach(pdev);
@@ -717,26 +787,38 @@ static const struct xenbus_device_id xen
 
 static struct xenbus_driver xenbus_xen_pcibk_driver = {
 	.name			= DRV_NAME,
-	.owner			= THIS_MODULE,
 	.ids			= xenpci_ids,
 	.probe			= xen_pcibk_xenbus_probe,
 	.remove			= xen_pcibk_xenbus_remove,
 	.otherend_changed	= xen_pcibk_frontend_changed,
 };
 
-struct xen_pcibk_backend *xen_pcibk_backend;
+const struct xen_pcibk_backend *__read_mostly xen_pcibk_backend;
+static const struct xen_pcibk_backend *__initdata xen_pcibk_backends[] = {
+	&xen_pcibk_vpci_backend,
+	&xen_pcibk_passthrough_backend,
+	&xen_pcibk_slot_backend,
+	&xen_pcibk_controller_backend,
+};
 
 int __init xen_pcibk_xenbus_register(void)
 {
+	unsigned int i;
+
 	xen_pcibk_wq = create_workqueue("xen_pciback_workqueue");
 	if (!xen_pcibk_wq) {
 		printk(KERN_ERR "%s: create"
 			"xen_pciback_workqueue failed\n", __func__);
 		return -EFAULT;
 	}
-	xen_pcibk_backend = &xen_pcibk_vpci_backend;
-	if (passthrough)
-		xen_pcibk_backend = &xen_pcibk_passthrough_backend;
+	for (i = 0; i < ARRAY_SIZE(xen_pcibk_backends); ++i) {
+		if (!xen_pcibk_backends[i])
+			continue;
+		if (strcmp(xen_pcibk_backends[i]->name, mode) == 0) {
+			xen_pcibk_backend = xen_pcibk_backends[i];
+			break;
+		}
+	}
 	pr_info(DRV_NAME ": backend is %s\n", xen_pcibk_backend->name);
 	return xenbus_register_backend(&xenbus_xen_pcibk_driver);
 }
--- head-2011-11-03.orig/drivers/xen/xenbus/xenbus_client.c	2011-02-01 15:04:27.000000000 +0100
+++ head-2011-11-03/drivers/xen/xenbus/xenbus_client.c	2011-09-12 12:00:32.000000000 +0200
@@ -431,7 +431,7 @@ int xenbus_free_evtchn(struct xenbus_dev
 EXPORT_SYMBOL_GPL(xenbus_free_evtchn);
 
 
-#if 0 /* !defined(CONFIG_XEN) && !defined(MODULE) */
+#if !defined(CONFIG_XEN) && !defined(MODULE)
 /**
  * xenbus_map_ring_valloc
  * @dev: xenbus device
--- head-2011-11-03.orig/drivers/xen/xenbus/xenbus_probe.c	2011-06-10 12:08:06.000000000 +0200
+++ head-2011-11-03/drivers/xen/xenbus/xenbus_probe.c	2011-09-09 09:52:35.000000000 +0200
@@ -465,35 +465,41 @@ static void xenbus_dev_release(struct de
 		kfree(to_xenbus_device(dev));
 }
 
-static ssize_t xendev_show_nodename(struct device *dev,
+static ssize_t nodename_show(struct device *dev,
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,13)
-				    struct device_attribute *attr,
+			     struct device_attribute *attr,
 #endif
-				    char *buf)
+			     char *buf)
 {
 	return sprintf(buf, "%s\n", to_xenbus_device(dev)->nodename);
 }
-static DEVICE_ATTR(nodename, S_IRUSR | S_IRGRP | S_IROTH, xendev_show_nodename, NULL);
 
-static ssize_t xendev_show_devtype(struct device *dev,
+static ssize_t devtype_show(struct device *dev,
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,13)
-				   struct device_attribute *attr,
+			    struct device_attribute *attr,
 #endif
-				   char *buf)
+			    char *buf)
 {
 	return sprintf(buf, "%s\n", to_xenbus_device(dev)->devicetype);
 }
-static DEVICE_ATTR(devtype, S_IRUSR | S_IRGRP | S_IROTH, xendev_show_devtype, NULL);
 
-static ssize_t xendev_show_modalias(struct device *dev,
+static ssize_t modalias_show(struct device *dev,
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,13)
-				    struct device_attribute *attr,
+			     struct device_attribute *attr,
 #endif
-				    char *buf)
+			     char *buf)
 {
-	return sprintf(buf, "xen:%s\n", to_xenbus_device(dev)->devicetype);
+	return sprintf(buf, "%s:%s\n", dev->bus->name,
+		       to_xenbus_device(dev)->devicetype);
 }
-static DEVICE_ATTR(modalias, S_IRUSR | S_IRGRP | S_IROTH, xendev_show_modalias, NULL);
+
+struct device_attribute xenbus_dev_attrs[] = {
+	__ATTR_RO(nodename),
+	__ATTR_RO(devtype),
+	__ATTR_RO(modalias),
+	__ATTR_NULL
+};
+PARAVIRT_EXPORT_SYMBOL(xenbus_dev_attrs);
 
 int xenbus_probe_node(struct xen_bus_type *bus,
 		      const char *type,
@@ -558,25 +564,7 @@ int xenbus_probe_node(struct xen_bus_typ
 	if (err)
 		goto fail;
 
-	err = device_create_file(&xendev->dev, &dev_attr_nodename);
-	if (err)
-		goto fail_unregister;
-
-	err = device_create_file(&xendev->dev, &dev_attr_devtype);
-	if (err)
-		goto fail_remove_nodename;
-
-	err = device_create_file(&xendev->dev, &dev_attr_modalias);
-	if (err)
-		goto fail_remove_devtype;
-
 	return 0;
-fail_remove_devtype:
-	device_remove_file(&xendev->dev, &dev_attr_devtype);
-fail_remove_nodename:
-	device_remove_file(&xendev->dev, &dev_attr_nodename);
-fail_unregister:
-	device_unregister(&xendev->dev);
 fail:
 	kfree(xendev);
 	return err;
@@ -645,12 +633,6 @@ static int xenbus_uevent_frontend(struct
 }
 #endif
 
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,29)
-static struct device_attribute xenbus_dev_attrs[] = {
-	__ATTR_NULL
-};
-#endif
-
 /* Bus type for frontend drivers. */
 static struct xen_bus_type xenbus_frontend = {
 	.root = "device",
--- head-2011-11-03.orig/drivers/xen/xenbus/xenbus_probe.h	2011-04-13 15:17:16.000000000 +0200
+++ head-2011-11-03/drivers/xen/xenbus/xenbus_probe.h	2011-09-09 09:49:02.000000000 +0200
@@ -78,6 +78,8 @@ struct xen_bus_type
 	struct bus_type bus;
 };
 
+extern struct device_attribute xenbus_dev_attrs[];
+
 extern int xenbus_match(struct device *_dev, struct device_driver *_drv);
 extern int xenbus_dev_probe(struct device *_dev);
 extern int xenbus_dev_remove(struct device *_dev);
--- head-2011-11-03.orig/drivers/xen/xenbus/xenbus_probe_backend.c	2011-04-04 15:08:12.000000000 +0200
+++ head-2011-11-03/drivers/xen/xenbus/xenbus_probe_backend.c	2011-09-09 09:51:45.000000000 +0200
@@ -119,6 +119,9 @@ static int xenbus_uevent_backend(struct 
 	if (xdev == NULL)
 		return -ENODEV;
 
+	if (add_uevent_var(env, "MODALIAS=xen-backend:%s", xdev->devicetype))
+		return -ENOMEM;
+
 	/* stuff we want to pass to /sbin/hotplug */
 	if (add_uevent_var(env, "XENBUS_TYPE=%s", xdev->devicetype))
 		return -ENOMEM;
@@ -197,10 +200,6 @@ static void frontend_changed(struct xenb
 }
 #endif
 
-static struct device_attribute xenbus_backend_dev_attrs[] = {
-	__ATTR_NULL
-};
-
 static struct xen_bus_type xenbus_backend = {
 	.root = "backend",
 	.levels = 3,		/* backend/type/<frontend>/<id> */
@@ -223,7 +222,7 @@ static struct xen_bus_type xenbus_backen
 #if !defined(CONFIG_XEN) && !defined(HAVE_XEN_PLATFORM_COMPAT_H)
 		.shutdown	= xenbus_dev_shutdown,
 #endif
-		.dev_attrs	= xenbus_backend_dev_attrs,
+		.dev_attrs	= xenbus_dev_attrs,
 	},
 };
 
--- head-2011-11-03.orig/include/xen/balloon.h	2011-04-13 17:01:31.000000000 +0200
+++ head-2011-11-03/include/xen/balloon.h	2011-09-09 09:54:19.000000000 +0200
@@ -72,6 +72,10 @@ struct balloon_stats {
 	unsigned long max_schedule_delay;
 	unsigned long retry_count;
 	unsigned long max_retry_count;
+#ifdef CONFIG_XEN_BALLOON_MEMORY_HOTPLUG
+	unsigned long hotplug_pages;
+	unsigned long balloon_hotplug;
+#endif
 };
 
 extern struct balloon_stats balloon_stats;
@@ -81,6 +85,16 @@ void balloon_set_new_target(unsigned lon
 int alloc_xenballooned_pages(int nr_pages, struct page** pages);
 void free_xenballooned_pages(int nr_pages, struct page** pages);
 
+struct sys_device;
+#ifdef CONFIG_XEN_SELFBALLOONING
+extern int register_xen_selfballooning(struct sys_device *sysdev);
+#else
+static inline int register_xen_selfballooning(struct sys_device *sysdev)
+{
+	return -ENOSYS;
+}
+#endif
+
 #endif /* CONFIG_PARAVIRT_XEN */
 
 #endif /* __XEN_BALLOON_H__ */
--- head-2011-11-03.orig/include/xen/interface/xen.h	2011-08-09 10:41:09.000000000 +0200
+++ head-2011-11-03/include/xen/interface/xen.h	2011-09-09 09:56:19.000000000 +0200
@@ -689,7 +689,7 @@ typedef struct dom0_vga_console_info {
             uint8_t  green_pos, green_size;
             uint8_t  blue_pos, blue_size;
             uint8_t  rsvd_pos, rsvd_size;
-#if __XEN_INTERFACE_VERSION__ >= 0x00030206
+#if __XEN_INTERFACE_VERSION__ >= 0x00030206 || (defined(CONFIG_PARAVIRT_XEN) && !defined(HAVE_XEN_PLATFORM_COMPAT_H))
             /* VESA capabilities (offset 0xa, VESA command 0x4f00). */
             uint32_t gbl_caps;
             /* Mode attributes (offset 0x0, VESA command 0x4f01). */
--- head-2011-11-03.orig/drivers/xen/blkback/xenbus.c	2011-09-07 12:37:53.000000000 +0200
+++ head-2011-11-03/drivers/xen/blkback/xenbus.c	2011-09-23 10:14:13.000000000 +0200
@@ -401,11 +401,11 @@ static void frontend_changed(struct xenb
 		break;
 
 	case XenbusStateClosing:
-		blkif_disconnect(be->blkif);
 		xenbus_switch_state(dev, XenbusStateClosing);
 		break;
 
 	case XenbusStateClosed:
+		blkif_disconnect(be->blkif);
 		xenbus_switch_state(dev, XenbusStateClosed);
 		if (xenbus_dev_is_online(dev))
 			break;
