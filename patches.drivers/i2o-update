diff -urNp linux-2.6.5/drivers/message/i2o/Kconfig linux-2.6.5.SUSE/drivers/message/i2o/Kconfig
--- linux-2.6.5/drivers/message/i2o/Kconfig	2004-04-04 05:36:15.000000000 +0200
+++ linux-2.6.5.SUSE/drivers/message/i2o/Kconfig	2004-05-06 16:59:07.000000000 +0200
@@ -3,7 +3,7 @@ menu "I2O device support"
 
 config I2O
 	tristate "I2O support"
-	depends on PCI && !64BIT
+	depends on PCI
 	---help---
 	  The Intelligent Input/Output (I2O) architecture allows hardware
 	  drivers to be split into two parts: an operating system specific
@@ -20,19 +20,20 @@ config I2O
 	  drivers and OSM's with the following questions.
 
 	  To compile this support as a module, choose M here: the
-	  modules will be called i2o_core and i2o_config.
+	  modules will be called i2o_core.
 
 	  If unsure, say N.
 
-config I2O_PCI
-	tristate "I2O PCI support"
+config I2O_CONFIG
+	tristate "I2O Configuration support"
 	depends on PCI && I2O
 	help
-	  Say Y for support of PCI bus I2O interface adapters. Currently this
-	  is the only variety supported, so you should say Y.
+	  Say Y for support of the configuration interface for the I2O adapters.
+	  If you have a RAID controller from Adaptec and you want to use the
+	  raidutils to manage your RAID array, you have to say Y here.
 
 	  To compile this support as a module, choose M here: the
-	  module will be called i2o_pci.
+	  module will be called i2o_config.
 
 config I2O_BLOCK
 	tristate "I2O Block OSM"
diff -urNp linux-2.6.5/drivers/message/i2o/Makefile linux-2.6.5.SUSE/drivers/message/i2o/Makefile
--- linux-2.6.5/drivers/message/i2o/Makefile	2004-04-04 05:37:37.000000000 +0200
+++ linux-2.6.5.SUSE/drivers/message/i2o/Makefile	2004-05-06 16:59:07.000000000 +0200
@@ -5,7 +5,8 @@
 # In the future, some of these should be built conditionally.
 #
 
-obj-$(CONFIG_I2O)	+= i2o_core.o i2o_config.o
+obj-$(CONFIG_I2O)	+= i2o_core.o
+obj-$(CONFIG_I2O_CONFIG)+= i2o_config.o
 obj-$(CONFIG_I2O_BLOCK)	+= i2o_block.o
 obj-$(CONFIG_I2O_SCSI)	+= i2o_scsi.o
 obj-$(CONFIG_I2O_PROC)	+= i2o_proc.o
diff -urNp linux-2.6.5/drivers/message/i2o/i2o_block.c linux-2.6.5.SUSE/drivers/message/i2o/i2o_block.c
--- linux-2.6.5/drivers/message/i2o/i2o_block.c	2004-04-04 05:37:37.000000000 +0200
+++ linux-2.6.5.SUSE/drivers/message/i2o/i2o_block.c	2004-05-06 16:59:07.000000000 +0200
@@ -83,7 +83,6 @@
 #include <asm/semaphore.h>
 #include <linux/completion.h>
 #include <asm/io.h>
-#include <asm/atomic.h>
 #include <linux/smp_lock.h>
 #include <linux/wait.h>
 
@@ -111,16 +110,12 @@
 				 I2O_EVT_IND_BSA_SCSI_SMART )
 
 
-#define I2O_LOCK(unit)	(i2ob_dev[(unit)].req_queue->queue_lock)
-
 /*
  *	Some of these can be made smaller later
  */
 
-static int i2ob_media_change_flag[MAX_I2OB];
-static u32 i2ob_max_sectors[MAX_I2OB<<4];
-
 static int i2ob_context;
+static struct block_device_operations i2ob_fops;
 
 /*
  * I2O Block device descriptor 
@@ -143,6 +138,9 @@ struct i2ob_device
 	int wcache;
 	int power;
 	int index;
+	int media_change_flag;
+	u32 max_sectors;
+	struct gendisk *gd;
 };
 
 /*
@@ -162,16 +160,16 @@ struct i2ob_request
 };
 
 /*
- * Per IOP requst queue information
+ * Per IOP request queue information
  *
- * We have a separate requeust_queue_t per IOP so that a heavilly
+ * We have a separate request_queue_t per IOP so that a heavilly
  * loaded I2O block device on an IOP does not starve block devices
  * across all I2O controllers.
  * 
  */
 struct i2ob_iop_queue
 {
-	atomic_t queue_depth;
+	unsigned int queue_depth;
 	struct i2ob_request request_queue[MAX_I2OB_DEPTH];
 	struct i2ob_request *i2ob_qhead;
 	request_queue_t *req_queue;
@@ -183,9 +181,8 @@ static struct i2ob_iop_queue *i2ob_queue
  *	Each I2O disk is one of these.
  */
 
-static struct i2ob_device i2ob_dev[MAX_I2OB<<4];
+static struct i2ob_device i2ob_dev[MAX_I2OB];
 static int i2ob_dev_count = 0;
-static struct gendisk *i2ob_disk[MAX_I2OB];
 
 /*
  * Mutex and spin lock for event handling synchronization
@@ -312,7 +309,6 @@ static int i2ob_send(u32 m, struct i2ob_
 	/* 
 	 * Mask out partitions from now on
 	 */
-	unit &= 0xF0;
 		
 	/* This can be optimised later - just want to be sure its right for
 	   starters */
@@ -402,7 +398,7 @@ static int i2ob_send(u32 m, struct i2ob_
 	}
 
 	i2o_post_message(c,m);
-	atomic_inc(&i2ob_queues[c->unit]->queue_depth);
+	i2ob_queues[c->unit]->queue_depth ++;
 
 	return 0;
 }
@@ -453,8 +449,8 @@ static void i2o_block_reply(struct i2o_h
 	struct i2ob_request *ireq = NULL;
 	u8 st;
 	u32 *m = (u32 *)msg;
-	u8 unit = (m[2]>>8)&0xF0;	/* low 4 bits are partition */
-	struct i2ob_device *dev = &i2ob_dev[(unit&0xF0)];
+	u8 unit = m[2]>>8;
+	struct i2ob_device *dev = &i2ob_dev[unit];
 
 	/*
 	 * FAILed message
@@ -475,10 +471,10 @@ static void i2o_block_reply(struct i2o_h
 		ireq=&i2ob_queues[c->unit]->request_queue[m[3]];
 		ireq->req->errors++;
 
-		spin_lock_irqsave(I2O_LOCK(c->unit), flags);
+		spin_lock_irqsave(dev->req_queue->queue_lock, flags);
 		i2ob_unhook_request(ireq, c->unit);
 		i2ob_end_request(ireq->req);
-		spin_unlock_irqrestore(I2O_LOCK(c->unit), flags);
+		spin_unlock_irqrestore(dev->req_queue->queue_lock, flags);
 	
 		/* Now flush the message by making it a NOP */
 		m[0]&=0x00FFFFFF;
@@ -509,10 +505,10 @@ static void i2o_block_reply(struct i2o_h
 		ireq=&i2ob_queues[c->unit]->request_queue[m[3]];
 		ireq->req->errors++;
 		printk(KERN_WARNING "I2O Block: Data transfer to deleted device!\n");
-		spin_lock_irqsave(I2O_LOCK(c->unit), flags);
+		spin_lock_irqsave(dev->req_queue->queue_lock, flags);
 		i2ob_unhook_request(ireq, c->unit);
 		i2ob_end_request(ireq->req);
-		spin_unlock_irqrestore(I2O_LOCK(c->unit), flags);
+		spin_unlock_irqrestore(dev->req_queue->queue_lock, flags);
 		return;
 	}	
 
@@ -576,17 +572,17 @@ static void i2o_block_reply(struct i2o_h
 	 */
 	
 	i2ob_free_sglist(dev, ireq);
-	spin_lock_irqsave(I2O_LOCK(c->unit), flags);
+	spin_lock_irqsave(dev->req_queue->queue_lock, flags);
 	i2ob_unhook_request(ireq, c->unit);
 	i2ob_end_request(ireq->req);
-	atomic_dec(&i2ob_queues[c->unit]->queue_depth);
+	i2ob_queues[c->unit]->queue_depth --;
 	
 	/*
 	 *	We may be able to do more I/O
 	 */
 	 
-	i2ob_request(dev->req_queue);
-	spin_unlock_irqrestore(I2O_LOCK(c->unit), flags);
+	i2ob_request(dev->gd->queue);
+	spin_unlock_irqrestore(dev->req_queue->queue_lock, flags);
 }
 
 /* 
@@ -598,8 +594,8 @@ static int i2ob_evt(void *dummy)
 {
 	unsigned int evt;
 	unsigned long flags;
+	struct i2ob_device *dev;
 	int unit;
-	int i;
 	//The only event that has data is the SCSI_SMART event.
 	struct i2o_reply {
 		u32 header[4];
@@ -638,6 +634,7 @@ static int i2ob_evt(void *dummy)
 		unit = le32_to_cpu(evt_local->header[3]);
 		evt = le32_to_cpu(evt_local->evt_indicator);
 
+		dev = &i2ob_dev[unit];
 		switch(evt)
 		{
 			/*
@@ -648,10 +645,9 @@ static int i2ob_evt(void *dummy)
 			 */
 			case I2O_EVT_IND_BSA_VOLUME_LOAD:
 			{
-				struct gendisk *p = i2ob_disk[unit>>4];
-				i2ob_install_device(i2ob_dev[unit].i2odev->controller, 
-					i2ob_dev[unit].i2odev, unit);
-				add_disk(p);
+				i2ob_install_device(dev->i2odev->controller, 
+					dev->i2odev, unit);
+				add_disk(dev->gd);
 				break;
 			}
 
@@ -663,17 +659,18 @@ static int i2ob_evt(void *dummy)
 			 */
 			case I2O_EVT_IND_BSA_VOLUME_UNLOAD:
 			{
-				struct gendisk *p = i2ob_disk[unit>>4];
+				struct gendisk *p = dev->gd;
+				blk_queue_max_sectors(dev->gd->queue, 0);
 				del_gendisk(p);
-				for(i = unit; i <= unit+15; i++)
-					blk_queue_max_sectors(i2ob_dev[i].req_queue, 0);
-				i2ob_media_change_flag[unit] = 1;
+				put_disk(p);
+				dev->gd = NULL;
+				dev->media_change_flag = 1;
 				break;
 			}
 
 			case I2O_EVT_IND_BSA_VOLUME_UNLOAD_REQ:
 				printk(KERN_WARNING "%s: Attempt to eject locked media\n", 
-					i2ob_dev[unit].i2odev->dev_name);
+					dev->i2odev->dev_name);
 				break;
 
 			/*
@@ -691,12 +688,12 @@ static int i2ob_evt(void *dummy)
 			{
 				u64 size;
 
-	  			if(i2ob_query_device(&i2ob_dev[unit], 0x0004, 0, &size, 8) !=0 )
-					i2ob_query_device(&i2ob_dev[unit], 0x0000, 4, &size, 8);
+	  			if(i2ob_query_device(dev, 0x0004, 0, &size, 8) !=0 )
+					i2ob_query_device(dev, 0x0000, 4, &size, 8);
 
-				spin_lock_irqsave(I2O_LOCK(unit), flags);	
-				set_capacity(i2ob_disk[unit>>4], size>>9);
-				spin_unlock_irqrestore(I2O_LOCK(unit), flags);	
+				spin_lock_irqsave(dev->req_queue->queue_lock, flags);	
+				set_capacity(dev->gd, size>>9);
+				spin_unlock_irqrestore(dev->req_queue->queue_lock, flags);	
 				break;
 			}
 
@@ -708,7 +705,7 @@ static int i2ob_evt(void *dummy)
 			case I2O_EVT_IND_BSA_SCSI_SMART:
 			{
 				char buf[16];
-				printk(KERN_INFO "I2O Block: %s received a SCSI SMART Event\n",i2ob_dev[unit].i2odev->dev_name);
+				printk(KERN_INFO "I2O Block: %s received a SCSI SMART Event\n",dev->i2odev->dev_name);
 				evt_local->data[16]='\0';
 				sprintf(buf,"%s",&evt_local->data[0]);
 				printk(KERN_INFO "      Disk Serial#:%s\n",buf);
@@ -735,12 +732,12 @@ static int i2ob_evt(void *dummy)
 				 * hit the fan big time. The card seems to recover but loses
 				 * the pending writes. Deeply ungood except for testing fsck
 				 */
-				if(i2ob_dev[unit].i2odev->controller->promise)
+				if(dev->i2odev->controller->promise)
 					panic("I2O controller firmware failed. Reboot and force a filesystem check.\n");
 			default:
 				printk(KERN_INFO "%s: Received event 0x%X we didn't register for\n"
 					KERN_INFO "   Blame the I2O card manufacturer 8)\n", 
-					i2ob_dev[unit].i2odev->dev_name, evt);
+					dev->i2odev->dev_name, evt);
 				break;
 		}
 	};
@@ -765,14 +762,6 @@ static void i2ob_request(request_queue_t
 	u32 m;
 	
 	while ((req = elv_next_request(q)) != NULL) {
-		/*
-		 *	On an IRQ completion if there is an inactive
-		 *	request on the queue head it means it isnt yet
-		 *	ready to dispatch.
-		 */
-		if(req->rq_status == RQ_INACTIVE)
-			return;
-
 		dev = req->rq_disk->private_data;
 
 		/* 
@@ -780,7 +769,7 @@ static void i2ob_request(request_queue_t
 		 *	generic IOP commit control. Certainly it's not right 
 		 *	its global!  
 		 */
-		if(atomic_read(&i2ob_queues[dev->unit]->queue_depth) >= dev->depth)
+		if(i2ob_queues[dev->unit]->queue_depth >= dev->depth)
 			break;
 		
 		/* Get a message */
@@ -788,7 +777,7 @@ static void i2ob_request(request_queue_t
 
 		if(m==0xFFFFFFFF)
 		{
-			if(atomic_read(&i2ob_queues[dev->unit]->queue_depth) == 0)
+			if(i2ob_queues[dev->unit]->queue_depth == 0)
 				printk(KERN_ERR "i2o_block: message queue and request queue empty!!\n");
 			break;
 		}
@@ -797,13 +786,12 @@ static void i2ob_request(request_queue_t
 		 */
 		req->errors = 0;
 		blkdev_dequeue_request(req);	
-		req->waiting = NULL;
 		
 		ireq = i2ob_queues[dev->unit]->i2ob_qhead;
 		i2ob_queues[dev->unit]->i2ob_qhead = ireq->next;
 		ireq->req = req;
 
-		i2ob_send(m, dev, ireq, (dev->unit&0xF0));
+		i2ob_send(m, dev, ireq, dev->index);
 	}
 }
 
@@ -1065,7 +1053,10 @@ static int i2ob_install_device(struct i2
 	u16 power;
 	u32 flags, status;
 	struct i2ob_device *dev=&i2ob_dev[unit];
-	int i;
+	struct gendisk *disk;
+	request_queue_t *q;
+	int segments;
+
 
 	/*
 	 * For logging purposes...
@@ -1079,21 +1070,35 @@ static int i2ob_install_device(struct i2
 	 * before any I/O can be performed. If it fails, this
 	 * device is useless.
 	 */
-	if(!i2ob_queues[unit]) {
-		if(i2ob_init_iop(unit))
+	if(!i2ob_queues[c->unit]) {
+		if(i2ob_init_iop(c->unit))
 			return 1;
 	}
 
+	q = i2ob_queues[c->unit]->req_queue;
+
 	/*
 	 * This will save one level of lookup/indirection in critical
 	 * code so that we can directly get the queue ptr from the
 	 * device instead of having to go the IOP data structure.
 	 */
-	dev->req_queue = i2ob_queues[unit]->req_queue;
+	dev->req_queue = q;
 
+	/*
+	 * Allocate a gendisk structure and initialize it
+	 */
+	disk = alloc_disk(16);
+	if (!disk)
+		return 1;
+
+	dev->gd = disk;
 	/* initialize gendik structure */
-	i2ob_disk[unit>>4]->private_data = dev;
-	i2ob_disk[unit>>4]->queue = dev->req_queue;
+	disk->major = MAJOR_NR;
+	disk->first_minor = unit<<4;
+	disk->queue = q;
+	disk->fops = &i2ob_fops;
+	sprintf(disk->disk_name, "i2o/hd%c", 'a' + unit);
+	disk->private_data = dev;
 
 	/*
 	 *	Ask for the current media data. If that isn't supported
@@ -1110,53 +1115,49 @@ static int i2ob_install_device(struct i2
 		power = 0;
 	i2ob_query_device(dev, 0x0000, 5, &flags, 4);
 	i2ob_query_device(dev, 0x0000, 6, &status, 4);
-	set_capacity(i2ob_disk[unit>>4], size>>9);
+	set_capacity(disk, size>>9);
 
 	/*
 	 * Max number of Scatter-Gather Elements
 	 */	
 
-	i2ob_dev[unit].power = power;	/* Save power state in device proper */
-	i2ob_dev[unit].flags = flags;
+	dev->power = power;	/* Save power state in device proper */
+	dev->flags = flags;
 
-	for(i=unit;i<=unit+15;i++)
-	{
-		request_queue_t *q = i2ob_dev[unit].req_queue;
-		int segments = (d->controller->status_block->inbound_frame_size - 7) / 2;
+	segments = (d->controller->status_block->inbound_frame_size - 7) / 2;
 
-		if(segments > 16)
-			segments = 16;
-					
-		i2ob_dev[i].power = power;	/* Save power state */
-		i2ob_dev[unit].flags = flags;	/* Keep the type info */
+	if(segments > 16)
+		segments = 16;
+				
+	dev->power = power;	/* Save power state */
+	dev->flags = flags;	/* Keep the type info */
 		
-		blk_queue_max_sectors(q, 96);	/* 256 might be nicer but many controllers 
+	blk_queue_max_sectors(q, 96);	/* 256 might be nicer but many controllers 
 						   explode on 65536 or higher */
-		blk_queue_max_phys_segments(q, segments);
-		blk_queue_max_hw_segments(q, segments);
+	blk_queue_max_phys_segments(q, segments);
+	blk_queue_max_hw_segments(q, segments);
 		
-		i2ob_dev[i].rcache = CACHE_SMARTFETCH;
-		i2ob_dev[i].wcache = CACHE_WRITETHROUGH;
+	dev->rcache = CACHE_SMARTFETCH;
+	dev->wcache = CACHE_WRITETHROUGH;
 		
-		if(d->controller->battery == 0)
-			i2ob_dev[i].wcache = CACHE_WRITETHROUGH;
+	if(d->controller->battery == 0)
+		dev->wcache = CACHE_WRITETHROUGH;
 
-		if(d->controller->promise)
-			i2ob_dev[i].wcache = CACHE_WRITETHROUGH;
+	if(d->controller->promise)
+		dev->wcache = CACHE_WRITETHROUGH;
 
-		if(d->controller->short_req)
-		{
-			blk_queue_max_sectors(q, 8);
-			blk_queue_max_phys_segments(q, 8);
-			blk_queue_max_hw_segments(q, 8);
-		}
+	if(d->controller->short_req)
+	{
+		blk_queue_max_sectors(q, 8);
+		blk_queue_max_phys_segments(q, 8);
+		blk_queue_max_hw_segments(q, 8);
 	}
 
-	strcpy(d->dev_name, i2ob_disk[unit>>4]->disk_name);
-	strcpy(i2ob_disk[unit>>4]->devfs_name, i2ob_disk[unit>>4]->disk_name);
+	strcpy(d->dev_name, disk->disk_name);
+	strcpy(disk->devfs_name, disk->disk_name);
 
 	printk(KERN_INFO "%s: Max segments %d, queue depth %d, byte limit %d.\n",
-		 d->dev_name, i2ob_dev[unit].max_segments, i2ob_dev[unit].depth, i2ob_max_sectors[unit]<<9);
+		 d->dev_name, dev->max_segments, dev->depth, dev->max_sectors<<9);
 
 	i2ob_query_device(dev, 0x0000, 0, &type, 1);
 
@@ -1197,7 +1198,7 @@ static int i2ob_install_device(struct i2
 	}
 	printk(".\n");
 	printk(KERN_INFO "%s: Maximum sectors/read set to %d.\n", 
-		d->dev_name, i2ob_max_sectors[unit]);
+		d->dev_name, dev->max_sectors);
 
 	/*
 	 * Register for the events we're interested in and that the
@@ -1233,7 +1234,7 @@ static int i2ob_init_iop(unsigned int un
 	/* Queue is MAX_I2OB + 1... */
 	i2ob_queues[unit]->request_queue[i].next = NULL;
 	i2ob_queues[unit]->i2ob_qhead = &i2ob_queues[unit]->request_queue[0];
-	atomic_set(&i2ob_queues[unit]->queue_depth, 0);
+	i2ob_queues[unit]->queue_depth = 0;
 
 	i2ob_queues[unit]->lock = SPIN_LOCK_UNLOCKED;
 	i2ob_queues[unit]->req_queue = blk_init_queue(i2ob_request, &i2ob_queues[unit]->lock);
@@ -1257,7 +1258,6 @@ static void i2ob_scan(int bios)
 
 	struct i2o_device *d, *b=NULL;
 	struct i2o_controller *c;
-	struct i2ob_device *dev;
 		
 	for(i=0; i< MAX_I2O_CONTROLLERS; i++)
 	{
@@ -1313,44 +1313,12 @@ static void i2ob_scan(int bios)
 					continue; /*Already claimed on pass 1 */
 			}
 
-			if(i2o_claim_device(d, &i2o_block_handler))
-			{
-				printk(KERN_WARNING "i2o_block: Controller %d, TID %d\n", c->unit,
-					d->lct_data.tid);
-				printk(KERN_WARNING "\t%sevice refused claim! Skipping installation\n", bios?"Boot d":"D");
-				continue;
-			}
-
-			i2o_release_device(d, &i2o_block_handler);
-
-			if(scan_unit<MAX_I2OB<<4)
-			{
- 				/*
-				 * Get the device and fill in the
-				 * Tid and controller.
-				 */
-				dev=&i2ob_dev[scan_unit];
-				dev->i2odev = d; 
-				dev->controller = c;
-				dev->unit = c->unit;
-				dev->tid = d->lct_data.tid;
-
-				if(i2ob_install_device(c,d,scan_unit))
-					printk(KERN_WARNING "Could not install I2O block device\n");
-				else
-				{
-					add_disk(i2ob_disk[scan_unit>>4]);
-					scan_unit+=16;
-					i2ob_dev_count++;
-
-					/* We want to know when device goes away */
-					i2o_device_notify_on(d, &i2o_block_handler);
-				}
-			}
+			if(scan_unit<MAX_I2OB)
+				i2ob_new_device(c, d);
 			else
 			{
 				if(!warned++)
-					printk(KERN_WARNING "i2o_block: too many device, registering only %d.\n", scan_unit>>4);
+					printk(KERN_WARNING "i2o_block: too many device, registering only %d.\n", scan_unit);
 			}
 		}
 		i2o_unlock_controller(c);
@@ -1399,12 +1367,12 @@ void i2ob_new_device(struct i2o_controll
 	printk(KERN_INFO "   Controller %d Tid %d\n",c->unit, d->lct_data.tid);
 
 	/* Check for available space */
-	if(i2ob_dev_count>=MAX_I2OB<<4)
+	if(i2ob_dev_count>=MAX_I2OB)
 	{
 		printk(KERN_ERR "i2o_block: No more devices allowed!\n");
 		return;
 	}
-	for(unit = 0; unit < (MAX_I2OB<<4); unit += 16)
+	for(unit = 0; unit < MAX_I2OB; unit ++)
 	{
 		if(!i2ob_dev[unit].i2odev)
 			break;
@@ -1420,18 +1388,20 @@ void i2ob_new_device(struct i2o_controll
 	dev->i2odev = d; 
 	dev->controller = c;
 	dev->tid = d->lct_data.tid;
+	dev->unit = c->unit;
 
-	if(i2ob_install_device(c,d,unit))
+	if(i2ob_install_device(c,d,unit)) {
+		i2o_release_device(d, &i2o_block_handler);
 		printk(KERN_ERR "i2o_block: Could not install new device\n");
+	}
 	else	
 	{
-		add_disk(i2ob_disk[unit>>4]);
+		i2o_release_device(d, &i2o_block_handler);
+		add_disk(dev->gd);
 		i2ob_dev_count++;
 		i2o_device_notify_on(d, &i2o_block_handler);
 	}
 
-	i2o_release_device(d, &i2o_block_handler);
- 
 	return;
 }
 
@@ -1443,64 +1413,58 @@ void i2ob_new_device(struct i2o_controll
 void i2ob_del_device(struct i2o_controller *c, struct i2o_device *d)
 {	
 	int unit = 0;
-	int i = 0;
 	unsigned long flags;
+	struct i2ob_device *dev;
 
-	spin_lock_irqsave(I2O_LOCK(c->unit), flags);
-
-	/*
-	 * Need to do this...we somtimes get two events from the IRTOS
-	 * in a row and that causes lots of problems.
-	 */
-	i2o_device_notify_off(d, &i2o_block_handler);
-
-	printk(KERN_INFO "I2O Block Device Deleted\n");
-
-	for(unit = 0; unit < MAX_I2OB<<4; unit += 16)
+	for(unit = 0; unit < MAX_I2OB; unit ++)
 	{
-		if(i2ob_dev[unit].i2odev == d)
+		dev = &i2ob_dev[unit];
+		if(dev->i2odev == d)
 		{
 			printk(KERN_INFO "  /dev/%s: Controller %d Tid %d\n", 
 				d->dev_name, c->unit, d->lct_data.tid);
 			break;
 		}
 	}
-	if(unit >= MAX_I2OB<<4)
+
+	printk(KERN_INFO "I2O Block Device Deleted\n");
+
+	if(unit >= MAX_I2OB)
 	{
 		printk(KERN_ERR "i2ob_del_device called, but not in dev table!\n");
-		spin_unlock_irqrestore(I2O_LOCK(c->unit), flags);
 		return;
 	}
 
+	spin_lock_irqsave(dev->req_queue->queue_lock, flags);
+
+	/*
+	 * Need to do this...we somtimes get two events from the IRTOS
+	 * in a row and that causes lots of problems.
+	 */
+	i2o_device_notify_off(d, &i2o_block_handler);
+
 	/* 
 	 * This will force errors when i2ob_get_queue() is called
 	 * by the kenrel.
 	 */
-	del_gendisk(i2ob_disk[unit>>4]);
-	i2ob_dev[unit].req_queue = NULL;
-	for(i = unit; i <= unit+15; i++)
-	{
-		i2ob_dev[i].i2odev = NULL;
-		blk_queue_max_sectors(i2ob_dev[i].req_queue, 0);
-	}
-	spin_unlock_irqrestore(I2O_LOCK(c->unit), flags);
-
-	/*
-	 * Decrease usage count for module
-	 */	
-
-	while(i2ob_dev[unit].refcnt--)
-		MOD_DEC_USE_COUNT;
-
-	i2ob_dev[unit].refcnt = 0;
-	
-	i2ob_dev[i].tid = 0;
+	if(dev->gd) {
+		struct gendisk *gd = dev->gd;
+		gd->queue = NULL;
+		del_gendisk(gd);
+		put_disk(gd);
+		dev->gd = NULL;
+	}
+	spin_unlock_irqrestore(dev->req_queue->queue_lock, flags);
+	dev->req_queue = NULL;
+	dev->i2odev = NULL;
+	dev->refcnt = 0;
+	dev->tid = 0;
 
 	/* 
 	 * Do we need this?
 	 * The media didn't really change...the device is just gone
 	 */
-	i2ob_media_change_flag[unit] = 1;
+	dev->media_change_flag = 1;
 
 	i2ob_dev_count--;	
 }
@@ -1511,10 +1475,9 @@ void i2ob_del_device(struct i2o_controll
 static int i2ob_media_change(struct gendisk *disk)
 {
 	struct i2ob_device *p = disk->private_data;
-	int i = p->index;
-	if(i2ob_media_change_flag[i])
+	if(p->media_change_flag)
 	{
-		i2ob_media_change_flag[i]=0;
+		p->media_change_flag=0;
 		return 1;
 	}
 	return 0;
@@ -1523,7 +1486,7 @@ static int i2ob_media_change(struct gend
 static int i2ob_revalidate(struct gendisk *disk)
 {
 	struct i2ob_device *p = disk->private_data;
-	return i2ob_install_device(p->controller, p->i2odev, p->index<<4);
+	return i2ob_install_device(p->controller, p->i2odev, p->index);
 }
 
 /*
@@ -1536,7 +1499,7 @@ static void i2ob_reboot_event(void)
 	
 	for(i=0;i<MAX_I2OB;i++)
 	{
-		struct i2ob_device *dev=&i2ob_dev[(i<<4)];
+		struct i2ob_device *dev=&i2ob_dev[i];
 		
 		if(dev->refcnt!=0)
 		{
@@ -1598,51 +1561,36 @@ static int i2o_block_init(void)
 	if (register_blkdev(MAJOR_NR, "i2o_block"))
 		return -EIO;
 
-	for (i = 0; i < MAX_I2OB; i++) {
-		struct gendisk *disk = alloc_disk(16);
-		if (!disk)
-			goto oom;
-		i2ob_dev[i<<4].index = i;
-		disk->queue = i2ob_dev[i<<4].req_queue;
-		i2ob_disk[i] = disk;
-	}
 #ifdef MODULE
 	printk(KERN_INFO "i2o_block: registered device at major %d\n", MAJOR_NR);
 #endif
 
 	/*
+	 *	Set up the queue
+	 */
+	for(i = 0; i < MAX_I2O_CONTROLLERS; i++)
+		i2ob_queues[i] = NULL;
+
+	/*
 	 *	Now fill in the boiler plate
 	 */
 	 
-	for (i = 0; i < MAX_I2OB << 4; i++) {
-		i2ob_dev[i].refcnt = 0;
-		i2ob_dev[i].flags = 0;
-		i2ob_dev[i].controller = NULL;
-		i2ob_dev[i].i2odev = NULL;
-		i2ob_dev[i].tid = 0;
-		i2ob_dev[i].head = NULL;
-		i2ob_dev[i].tail = NULL;
-		i2ob_dev[i].depth = MAX_I2OB_DEPTH;
-		i2ob_max_sectors[i] = 2;
-	}
-	
 	for (i = 0; i < MAX_I2OB; i++) {
-		struct gendisk *disk = i2ob_disk[i];
-		disk->major = MAJOR_NR;
-		disk->first_minor = i<<4;
-		disk->fops = &i2ob_fops;
-		sprintf(disk->disk_name, "i2o/hd%c", 'a' + i);
+		struct i2ob_device *dev = &i2ob_dev[i];
+		dev->index = i;
+		dev->refcnt = 0;
+		dev->flags = 0;
+		dev->controller = NULL;
+		dev->i2odev = NULL;
+		dev->tid = 0;
+		dev->head = NULL;
+		dev->tail = NULL;
+		dev->depth = MAX_I2OB_DEPTH;
+		dev->max_sectors = 2;
+		dev->gd = NULL;
 	}
 	
 	/*
-	 *	Set up the queue
-	 */
-	for(i = 0; i < MAX_I2O_CONTROLLERS; i++)
-	{
-		i2ob_queues[i] = NULL;
-	}
-
-	/*
 	 *	Register the OSM handler as we will need this to probe for
 	 *	drives, geometry and other goodies.
 	 */
@@ -1671,9 +1619,6 @@ static int i2o_block_init(void)
 
 	return 0;
 
-oom:
-	while (i--)
-		put_disk(i2ob_disk[i]);
 	unregister_blkdev(MAJOR_NR, "i2o_block");
 	return -ENOMEM;
 }
@@ -1701,11 +1646,8 @@ static void i2o_block_exit(void)
 	if(i2ob_dev_count) {
 		struct i2o_device *d;
 		for(i = 0; i < MAX_I2OB; i++)
-		if((d=i2ob_dev[i<<4].i2odev)) {
-			i2o_device_notify_off(d, &i2o_block_handler);
-			i2o_event_register(d->controller, d->lct_data.tid, 
-				i2ob_context, i<<4, 0);
-		}
+			if((d = i2ob_dev[i].i2odev))
+				i2ob_del_device(d->controller, d);
 	}
 	
 	/*
@@ -1725,15 +1667,21 @@ static void i2o_block_exit(void)
 	 */
 
 	i2o_remove_handler(&i2o_block_handler);
-		 
-	for (i = 0; i < MAX_I2OB; i++)
-		put_disk(i2ob_disk[i]);
 
 	/*
 	 *	Return the block device
 	 */
 	if (unregister_blkdev(MAJOR_NR, "i2o_block") != 0)
 		printk("i2o_block: cleanup_module failed\n");
+
+	/*
+	 *	release request queue
+	 */
+	for (i = 0; i < MAX_I2O_CONTROLLERS; i ++)
+		if(i2ob_queues[i]) {
+			blk_cleanup_queue(i2ob_queues[i]->req_queue);
+			kfree(i2ob_queues[i]);
+		}
 }
 
 MODULE_AUTHOR("Red Hat");
diff -urNp linux-2.6.5/drivers/message/i2o/i2o_config.c linux-2.6.5.SUSE/drivers/message/i2o/i2o_config.c
--- linux-2.6.5/drivers/message/i2o/i2o_config.c	2004-04-04 05:38:14.000000000 +0200
+++ linux-2.6.5.SUSE/drivers/message/i2o/i2o_config.c	2004-05-06 16:59:07.000000000 +0200
@@ -5,21 +5,24 @@
  *	
  * Written by Alan Cox, Building Number Three Ltd
  *
- * Modified 04/20/1999 by Deepak Saxena
- *   - Added basic ioctl() support
- * Modified 06/07/1999 by Deepak Saxena
- *   - Added software download ioctl (still testing)
- * Modified 09/10/1999 by Auvo Häkkinen
- *   - Changes to i2o_cfg_reply(), ioctl_parms()
- *   - Added ioct_validate()
- * Modified 09/30/1999 by Taneli Vähäkangas
- *   - Fixed ioctl_swdl()
- * Modified 10/04/1999 by Taneli Vähäkangas
- *   - Changed ioctl_swdl(), implemented ioctl_swul() and ioctl_swdel()
- * Modified 11/18/1999 by Deepak Saxena
- *   - Added event managmenet support
- *
- * 2.4 rewrite ported to 2.5 - Alan Cox <alan@redhat.com>
+ * Fixes/additions:
+ *	Deepak Saxena (04/20/1999):
+ *		Added basic ioctl() support
+ *	Deepak Saxena (06/07/1999):
+ *		Added software download ioctl (still testing)
+ *	Auvo Häkkinen (09/10/1999):
+ *		Changes to i2o_cfg_reply(), ioctl_parms()
+ *		Added ioct_validate()
+ *	Taneli Vähäkangas (09/30/1999):
+ *		Fixed ioctl_swdl()
+ *	Taneli Vähäkangas (10/04/1999):
+ *		Changed ioctl_swdl(), implemented ioctl_swul() and ioctl_swdel()
+ *	Deepak Saxena (11/18/1999):
+ *		Added event managmenet support
+ *	Alan Cox <alan@redhat.com>:
+ *		2.4 rewrite ported to 2.5
+ *	Markus Lidel <Markus.Lidel@shadowconnect.com>:
+ *		Added pass-thru support for Adaptec's raidutils
  *
  * This program is free software; you can redistribute it and/or
  * modify it under the terms of the GNU General Public License
@@ -49,6 +52,11 @@ struct wait_queue *i2o_wait_queue;
 
 #define MODINC(x,y) ((x) = ((x) + 1) % (y))
 
+struct sg_simple_element {
+	u32  flag_count;
+	u32 addr_bus;
+};
+
 struct i2o_cfg_info
 {
 	struct file* fp;
@@ -75,6 +83,7 @@ static int ioctl_swdel(unsigned long);
 static int ioctl_validate(unsigned long); 
 static int ioctl_evt_reg(unsigned long, struct file *);
 static int ioctl_evt_get(unsigned long, struct file *);
+static int ioctl_passthru(unsigned long);
 static int cfg_fasync(int, struct file*, int);
 
 /*
@@ -256,6 +265,10 @@ static int cfg_ioctl(struct inode *inode
 			ret = ioctl_evt_get(arg, fp);
 			break;
 
+		case I2OPASSTHRU:
+			ret = ioctl_passthru(arg);
+			break;
+
 		default:
 			ret = -EINVAL;
 	}
@@ -827,6 +840,157 @@ static int ioctl_evt_get(unsigned long a
 	return 0;
 }
 
+static int ioctl_passthru(unsigned long arg)
+{
+	struct i2o_cmd_passthru *cmd = (struct i2o_cmd_passthru *) arg;
+	struct i2o_controller *c;
+	u32 msg[MSG_FRAME_SIZE];
+	u32 *user_msg = (u32*)cmd->msg;
+	u32 *reply = NULL;
+	u32 *user_reply = NULL;
+	u32 size = 0;
+	u32 reply_size = 0;
+	u32 rcode = 0;
+	ulong sg_list[SG_TABLESIZE];
+	u32 sg_offset = 0;
+	u32 sg_count = 0;
+	int sg_index = 0;
+	u32 i = 0;
+	ulong p = 0;
+
+	c = i2o_find_controller(cmd->iop);
+	if(!c)
+                return -ENXIO;
+
+	memset(&msg, 0, MSG_FRAME_SIZE*4);
+	if(get_user(size, &user_msg[0]))
+		return -EFAULT;
+	size = size>>16;
+
+	user_reply = &user_msg[size];
+	if(size > MSG_FRAME_SIZE)
+		return -EFAULT;
+	size *= 4; // Convert to bytes
+                                              
+	/* Copy in the user's I2O command */
+	if(copy_from_user((void*)msg, (void*)user_msg, size))
+		return -EFAULT;
+	get_user(reply_size, &user_reply[0]);
+	reply_size = reply_size>>16;
+	reply = kmalloc(REPLY_FRAME_SIZE*4, GFP_KERNEL);
+	if(!reply) {
+		printk(KERN_WARNING"%s: Could not allocate reply buffer\n",c->name);
+		return -ENOMEM;
+	}
+	memset(reply, 0, REPLY_FRAME_SIZE*4);
+	sg_offset = (msg[0]>>4)&0x0f;
+	msg[2] = (u32)i2o_cfg_context;
+	msg[3] = (u32)reply;
+
+	memset(sg_list,0, sizeof(sg_list[0])*SG_TABLESIZE);
+	if(sg_offset) {
+		// TODO 64bit fix
+		struct sg_simple_element *sg = (struct sg_simple_element*) (msg+sg_offset);
+		sg_count = (size - sg_offset*4) / sizeof(struct sg_simple_element);
+		if (sg_count > SG_TABLESIZE) {
+			printk(KERN_DEBUG"%s:IOCTL SG List too large (%u)\n", c->name,sg_count);
+			kfree (reply);
+			return -EINVAL;
+		}
+
+		for(i = 0; i < sg_count; i++) {
+			int sg_size;
+
+			if (!(sg[i].flag_count & 0x10000000 /*I2O_SGL_FLAGS_SIMPLE_ADDRESS_ELEMENT*/)) {
+				printk(KERN_DEBUG"%s:Bad SG element %d - not simple (%x)\n",c->name,i,  sg[i].flag_count);
+				rcode = -EINVAL;
+				goto cleanup;
+			}
+			sg_size = sg[i].flag_count & 0xffffff;
+			/* Allocate memory for the transfer */
+			p = (ulong)kmalloc(sg_size, GFP_KERNEL);
+			if (!p) {
+				printk(KERN_DEBUG"%s: Could not allocate SG buffer - size = %d buffer number %d of %d\n", c->name,sg_size,i,sg_count);
+				rcode = -ENOMEM;
+				goto cleanup;
+			}
+			sg_list[sg_index++] = p; // sglist indexed with input frame, not our internal frame.
+			/* Copy in the user's SG buffer if necessary */
+			if(sg[i].flag_count & 0x04000000 /*I2O_SGL_FLAGS_DIR*/) {
+				// TODO 64bit fix
+			        if (copy_from_user((void*)p,(void*)sg[i].addr_bus, sg_size)) {
+					printk(KERN_DEBUG"%s: Could not copy SG buf %d FROM user\n",c->name,i);
+					rcode = -EFAULT;
+					goto cleanup;
+				}
+			}
+			//TODO 64bit fix
+			sg[i].addr_bus = (u32)virt_to_bus((void*)p);
+		}
+	}
+
+	rcode = i2o_post_wait(c, msg, size, 60);
+	if(rcode)
+		goto cleanup;
+
+	if(sg_offset) {
+		/* Copy back the Scatter Gather buffers back to user space */
+		u32 j;
+		// TODO 64bit fix
+		struct sg_simple_element* sg;
+		int sg_size;
+										                                                                                
+		// re-acquire the original message to handle correctly the sg copy operation
+		memset(&msg, 0, MSG_FRAME_SIZE*4);
+		// get user msg size in u32s
+		if (get_user(size, &user_msg[0])) {
+			rcode = -EFAULT;
+			goto cleanup;
+		}
+		size = size>>16;
+		size *= 4;
+		/* Copy in the user's I2O command */
+		if (copy_from_user ((void*)msg, (void*)user_msg, size)) {
+			rcode = -EFAULT;
+			goto cleanup;
+		}
+		sg_count = (size - sg_offset*4) / sizeof(struct sg_simple_element);
+
+		 // TODO 64bit fix
+		sg = (struct sg_simple_element*)(msg + sg_offset);
+		for (j = 0; j < sg_count; j++) {
+			/* Copy out the SG list to user's buffer if necessary */
+			if (!(sg[j].flag_count & 0x4000000 /*I2O_SGL_FLAGS_DIR*/)) {
+				sg_size = sg[j].flag_count & 0xffffff;
+				// TODO 64bit fix
+				if (copy_to_user((void*)sg[j].addr_bus,(void*)sg_list[j], sg_size)) {
+					printk(KERN_WARNING"%s: Could not copy %lx TO user %x\n",c->name, sg_list[j], sg[j].addr_bus);
+					rcode = -EFAULT;
+					goto cleanup;
+				}
+			}
+		}
+	}
+	
+	/* Copy back the reply to user space */
+        if (reply_size) {
+		// we wrote our own values for context - now restore the user supplied ones
+		if(copy_from_user(reply+2, user_msg+2, sizeof(u32)*2)) {
+			printk(KERN_WARNING"%s: Could not copy message context FROM user\n",c->name);
+			rcode = -EFAULT;
+		}
+		if(copy_to_user(user_reply, reply, reply_size)) {
+			printk(KERN_WARNING"%s: Could not copy reply TO user\n",c->name);
+			rcode = -EFAULT;
+		}
+	}
+
+cleanup:
+	kfree(reply);
+	i2o_unlock_controller(c);
+	return rcode;
+}		
+
 static int cfg_open(struct inode *inode, struct file *file)
 {
 	struct i2o_cfg_info *tmp = 
diff -urNp linux-2.6.5/drivers/message/i2o/i2o_core.c linux-2.6.5.SUSE/drivers/message/i2o/i2o_core.c
--- linux-2.6.5/drivers/message/i2o/i2o_core.c	2004-04-04 05:37:36.000000000 +0200
+++ linux-2.6.5.SUSE/drivers/message/i2o/i2o_core.c	2004-05-06 16:59:07.000000000 +0200
@@ -213,6 +213,135 @@ static struct notifier_block i2o_reboot_
 
 static int verbose;
 
+#if BITS_PER_LONG == 64
+/**
+ *      i2o_context_list_add -	append an ptr to the context list and return a
+ *				matching context id.
+ *	@ptr: pointer to add to the context list
+ *	@c: controller to which the context list belong
+ *	returns context id, which could be used in the transaction context
+ *	field.
+ *
+ *	Because the context field in I2O is only 32-bit large, on 64-bit the
+ *	pointer is to large to fit in the context field. The i2o_context_list
+ *	functiones map pointers to context fields.
+ */
+u32 i2o_context_list_add(void *ptr, struct i2o_controller *c) {
+	u32 context = 1;
+	struct i2o_context_list_element **entry = &c->context_list;
+	struct i2o_context_list_element *element;
+	unsigned long flags;
+
+	spin_lock_irqsave(&c->context_list_lock, flags);
+	while(*entry && ((*entry)->flags & I2O_CONTEXT_LIST_USED)) {
+		if((*entry)->context >= context)
+			context = (*entry)->context + 1;
+		entry = &((*entry)->next);
+	}
+
+	if(!*entry) {
+		if(unlikely(!context)) {
+			spin_unlock_irqrestore(&c->context_list_lock, flags);
+			printk(KERN_EMERG "i2o_core: context list overflow\n");
+			return 0;
+		}
+
+		element = kmalloc(sizeof(struct i2o_context_list_element), GFP_KERNEL);
+		if(!element) {
+			printk(KERN_EMERG "i2o_core: could not allocate memory for context list element\n");
+			return 0;
+		}
+		element->context = context;
+		element->next = NULL;
+		*entry = element;
+	} else
+		element = *entry;
+
+	element->ptr = ptr;
+	element->flags = I2O_CONTEXT_LIST_USED;
+
+	spin_unlock_irqrestore(&c->context_list_lock, flags);
+	dprintk(KERN_DEBUG "i2o_core: add context to list %p -> %d\n", ptr, context);
+	return context;
+}
+
+/**
+ *      i2o_context_list_remove - remove a ptr from the context list and return
+ *				  the matching context id.
+ *	@ptr: pointer to be removed from the context list
+ *	@c: controller to which the context list belong
+ *	returns context id, which could be used in the transaction context
+ *	field.
+ */
+u32 i2o_context_list_remove(void *ptr, struct i2o_controller *c) {
+	struct i2o_context_list_element **entry = &c->context_list;
+	struct i2o_context_list_element *element;
+	u32 context;
+	unsigned long flags;
+
+	spin_lock_irqsave(&c->context_list_lock, flags);
+	while(*entry && ((*entry)->ptr != ptr))
+		entry = &((*entry)->next);
+
+	if(unlikely(!*entry)) {
+		spin_unlock_irqrestore(&c->context_list_lock, flags);
+		printk(KERN_WARNING "i2o_core: could not remove nonexistent ptr %p\n", ptr);
+		return 0;
+	}
+
+	element = *entry;
+
+	context = element->context;
+	element->ptr = NULL;
+	element->flags |= I2O_CONTEXT_LIST_DELETED;
+
+	spin_unlock_irqrestore(&c->context_list_lock, flags);
+	dprintk(KERN_DEBUG "i2o_core: markt as deleted in context list %p -> %d\n", ptr, context);
+	return context;
+}
+
+/**
+ *      i2o_context_list_get -	get a ptr from the context list and remove it
+ *				from the list.
+ *	@context: context id to which the pointer belong
+ *	@c: controller to which the context list belong
+ *	returns pointer to the matching context id
+ */
+void *i2o_context_list_get(u32 context, struct i2o_controller *c) {
+	struct i2o_context_list_element **entry = &c->context_list;
+	struct i2o_context_list_element *element;
+	void *ptr;
+	int count = 0;
+	unsigned long flags;
+
+	spin_lock_irqsave(&c->context_list_lock, flags);
+	while(*entry && ((*entry)->context != context)) {
+		entry = &((*entry)->next);
+		count ++;
+	}
+
+	if(unlikely(!*entry)) {
+		spin_unlock_irqrestore(&c->context_list_lock, flags);
+		printk(KERN_WARNING "i2o_core: context id %d not found\n", context);
+		return NULL;
+	}
+
+	element = *entry;
+	ptr = element->ptr;
+	if(count >= I2O_CONTEXT_LIST_MIN_LENGTH) {
+		*entry = (*entry)->next;
+		kfree(element);
+	} else {
+		element->ptr = NULL;
+		element->flags &= !I2O_CONTEXT_LIST_USED;
+	}
+
+	spin_unlock_irqrestore(&c->context_list_lock, flags);
+	dprintk(KERN_DEBUG "i2o_core: get ptr from context list %d -> %p\n", context, ptr);
+	return ptr;
+}
+#endif
+
 /*
  * I2O Core reply handler
  */
@@ -3551,6 +3680,10 @@ int __init i2o_pci_install(struct pci_de
 	c->short_req = 0;
 	c->pdev = dev;
 
+#if BITS_PER_LONG == 64
+	c->context_list_lock = SPIN_LOCK_UNLOCKED;
+#endif
+
 	c->irq_mask = mem+0x34;
 	c->post_port = mem+0x40;
 	c->reply_port = mem+0x44;
@@ -3788,3 +3921,6 @@ EXPORT_SYMBOL(i2o_event_ack);
 EXPORT_SYMBOL(i2o_report_status);
 EXPORT_SYMBOL(i2o_dump_message);
 EXPORT_SYMBOL(i2o_get_class_name);
+EXPORT_SYMBOL(i2o_context_list_add);
+EXPORT_SYMBOL(i2o_context_list_get);
+EXPORT_SYMBOL(i2o_context_list_remove);
diff -urNp linux-2.6.5/drivers/message/i2o/i2o_scsi.c linux-2.6.5.SUSE/drivers/message/i2o/i2o_scsi.c
--- linux-2.6.5/drivers/message/i2o/i2o_scsi.c	2004-04-04 05:37:41.000000000 +0200
+++ linux-2.6.5.SUSE/drivers/message/i2o/i2o_scsi.c	2004-05-06 16:59:07.000000000 +0200
@@ -62,9 +62,6 @@
 #include "../../scsi/scsi.h"
 #include "../../scsi/hosts.h"
 
-#if BITS_PER_LONG == 64
-#error FIXME: driver does not support 64-bit platforms
-#endif
 
 
 #define VERSION_STRING        "Version 0.1.2"
@@ -233,7 +230,10 @@ static void i2o_scsi_reply(struct i2o_ha
 		{
 			spin_unlock_irqrestore(&retry_lock, flags);
 			/* Create a scsi error for this */
-			current_command = (Scsi_Cmnd *)m[3];
+			current_command = (Scsi_Cmnd *)i2o_context_list_get(m[3], c);
+			if(!current_command)
+				return;
+
 			lock = current_command->device->host->host_lock;
 			printk("Aborted %ld\n", current_command->serial_number);
 
@@ -276,16 +276,15 @@ static void i2o_scsi_reply(struct i2o_ha
 		printk(KERN_INFO "i2o_scsi: bus reset completed.\n");
 		return;
 	}
-	/*
- 	 *	FIXME: 64bit breakage
-	 */
 
-	current_command = (Scsi_Cmnd *)m[3];
+	current_command = (Scsi_Cmnd *)i2o_context_list_get(m[3], c);
 	
 	/*
 	 *	Is this a control request coming back - eg an abort ?
 	 */
 	 
+	atomic_dec(&queue_depth);
+
 	if(current_command==NULL)
 	{
 		if(st)
@@ -296,8 +295,6 @@ static void i2o_scsi_reply(struct i2o_ha
 	
 	dprintk(KERN_INFO "Completed %ld\n", current_command->serial_number);
 	
-	atomic_dec(&queue_depth);
-	
 	if(st == 0x06)
 	{
 		if(le32_to_cpu(m[5]) < current_command->underflow)
@@ -647,9 +644,7 @@ static int i2o_scsi_queuecommand(Scsi_Cm
 	if(tid == -1)
 	{
 		SCpnt->result = DID_NO_CONNECT << 16;
-		spin_lock_irqsave(host->host_lock, flags);
 		done(SCpnt);
-		spin_unlock_irqrestore(host->host_lock, flags);
 		return 0;
 	}
 	
@@ -699,8 +694,7 @@ static int i2o_scsi_queuecommand(Scsi_Cm
 	
 	i2o_raw_writel(I2O_CMD_SCSI_EXEC<<24|HOST_TID<<12|tid, &msg[1]);
 	i2o_raw_writel(scsi_context, &msg[2]);	/* So the I2O layer passes to us */
-	/* Sorry 64bit folks. FIXME */
-	i2o_raw_writel((u32)SCpnt, &msg[3]);	/* We want the SCSI control block back */
+	i2o_raw_writel(i2o_context_list_add(SCpnt, c), &msg[3]);	/* We want the SCSI control block back */
 
 	/* LSI_920_PCI_QUIRK
 	 *
@@ -883,7 +877,7 @@ static int i2o_scsi_queuecommand(Scsi_Cm
  *	@SCpnt: command to abort
  *
  *	Ask the I2O controller to abort a command. This is an asynchrnous
- *	process and oru callback handler will see the command complete
+ *	process and our callback handler will see the command complete
  *	with an aborted message if it succeeds. 
  *
  *	Locks: no locks are held or needed
@@ -894,10 +888,9 @@ int i2o_scsi_abort(Scsi_Cmnd * SCpnt)
 	struct i2o_controller *c;
 	struct Scsi_Host *host;
 	struct i2o_scsi_host *hostdata;
-	unsigned long msg;
-	u32 m;
+	u32 msg[5];
 	int tid;
-	unsigned long timeout;
+	int status = FAILED;
 	
 	printk(KERN_WARNING "i2o_scsi: Aborting command block.\n");
 	
@@ -907,37 +900,22 @@ int i2o_scsi_abort(Scsi_Cmnd * SCpnt)
 	if(tid==-1)
 	{
 		printk(KERN_ERR "i2o_scsi: Impossible command to abort!\n");
-		return FAILED;
+		return status;
 	}
 	c = hostdata->controller;
 
 	spin_unlock_irq(host->host_lock);
 		
-	timeout = jiffies+2*HZ;
-	do
-	{
-		m = le32_to_cpu(I2O_POST_READ32(c));
-		if(m != 0xFFFFFFFF)
-			break;
-		set_current_state(TASK_UNINTERRUPTIBLE);
-		schedule_timeout(1);
-		mb();
-	}
-	while(time_before(jiffies, timeout));
-	
-	msg = c->mem_offset + m;
-	
-	i2o_raw_writel(FIVE_WORD_MSG_SIZE, msg);
-	i2o_raw_writel(I2O_CMD_SCSI_ABORT<<24|HOST_TID<<12|tid, msg+4);
-	i2o_raw_writel(scsi_context, msg+8);
-	i2o_raw_writel(0, msg+12);	/* Not needed for an abort */
-	i2o_raw_writel((u32)SCpnt, msg+16);	
-	wmb();
-	i2o_post_message(c,m);
-	wmb();
-	
+	msg[0] = FIVE_WORD_MSG_SIZE;
+	msg[1] = I2O_CMD_SCSI_ABORT<<24|HOST_TID<<12|tid;
+	msg[2] = scsi_context;
+	msg[3] = 0;
+	msg[4] = i2o_context_list_remove(SCpnt, c);
+	if(i2o_post_wait(c, msg, sizeof(msg), 240))
+		status = SUCCESS;
+
 	spin_lock_irq(host->host_lock);
-	return SUCCESS;
+	return status;
 }
 
 /**
diff -urNp linux-2.6.5/include/linux/i2o-dev.h linux-2.6.5.SUSE/include/linux/i2o-dev.h
--- linux-2.6.5/include/linux/i2o-dev.h	2004-04-04 05:36:24.000000000 +0200
+++ linux-2.6.5.SUSE/include/linux/i2o-dev.h	2004-05-06 16:59:07.000000000 +0200
@@ -41,6 +41,14 @@
 #define I2OHTML 		_IOWR(I2O_MAGIC_NUMBER,9,struct i2o_html)
 #define I2OEVTREG		_IOW(I2O_MAGIC_NUMBER,10,struct i2o_evt_id)
 #define I2OEVTGET		_IOR(I2O_MAGIC_NUMBER,11,struct i2o_evt_info)
+#define I2OPASSTHRU		_IOR(I2O_MAGIC_NUMBER,12,struct i2o_cmd_passthru)
+
+struct i2o_cmd_passthru
+{
+	void *msg;		/* message */
+	int iop;		/* number of the I2O controller, to which the
+				   message should go to */
+};
 
 struct i2o_cmd_hrtlct
 {
diff -urNp linux-2.6.5/include/linux/i2o.h linux-2.6.5.SUSE/include/linux/i2o.h
--- linux-2.6.5/include/linux/i2o.h	2004-04-04 05:36:27.000000000 +0200
+++ linux-2.6.5.SUSE/include/linux/i2o.h	2004-05-06 16:59:07.000000000 +0200
@@ -76,6 +76,16 @@ struct i2o_device
 };
 
 /*
+ * context queue entry, used for 32-bit context on 64-bit systems
+ */
+struct i2o_context_list_element {
+	struct i2o_context_list_element *next;
+	u32 context;
+	void *ptr;
+	unsigned int flags;
+};
+
+/*
  * Each I2O controller has one of these objects
  */
 struct i2o_controller
@@ -133,6 +143,11 @@ struct i2o_controller
 
 	void *page_frame;			/* Message buffers */
 	dma_addr_t page_frame_map;		/* Cache map */
+#if BITS_PER_LONG == 64
+	spinlock_t context_list_lock;		/* lock for context_list */
+	struct i2o_context_list_element *context_list; /* list of context id's
+						    and pointers */
+#endif
 };
 
 /*
@@ -322,6 +337,27 @@ extern int i2o_activate_controller(struc
 extern void i2o_run_queue(struct i2o_controller *);
 extern int i2o_delete_controller(struct i2o_controller *);
 
+#if BITS_PER_LONG == 64
+extern u32 i2o_context_list_add(void *, struct i2o_controller *);
+extern void *i2o_context_list_get(u32, struct i2o_controller *);
+extern u32 i2o_context_list_remove(void *, struct i2o_controller *);
+#else
+static inline u32 i2o_context_list_add(void *ptr, struct i2o_controller *c)
+{
+	return (u32)ptr;
+}
+
+static inline void *i2o_context_list_get(u32 context, struct i2o_controller *c)
+{
+	return (void *)context;
+}
+
+static inline u32 i2o_context_list_remove(void *ptr, struct i2o_controller *c)
+{
+	return (u32)ptr;
+}
+#endif
+
 /*
  *	Cache strategies
  */
@@ -640,6 +676,8 @@ extern int i2o_delete_controller(struct 
 #define HOST_TID		1
 
 #define MSG_FRAME_SIZE		64	/* i2o_scsi assumes >= 32 */
+#define REPLY_FRAME_SIZE	17
+#define SG_TABLESIZE		30
 #define NMBR_MSG_FRAMES		128
 
 #define MSG_POOL_SIZE		(MSG_FRAME_SIZE*NMBR_MSG_FRAMES*sizeof(u32))
@@ -647,5 +685,9 @@ extern int i2o_delete_controller(struct 
 #define I2O_POST_WAIT_OK	0
 #define I2O_POST_WAIT_TIMEOUT	-ETIMEDOUT
 
+#define I2O_CONTEXT_LIST_MIN_LENGTH	15
+#define I2O_CONTEXT_LIST_USED		0x01
+#define I2O_CONTEXT_LIST_DELETED	0x02
+
 #endif /* __KERNEL__ */
 #endif /* _I2O_H */
