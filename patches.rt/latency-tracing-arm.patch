 arch/arm/boot/compressed/head.S |   12 ++++
 arch/arm/kernel/entry-common.S  |  109 ++++++++++++++++++++++++++++++++++++++++
 arch/arm/kernel/fiq.c           |    4 -
 arch/arm/kernel/irq.c           |    5 +
 arch/arm/kernel/traps.c         |    1 
 arch/arm/mm/copypage-v4mc.c     |    4 -
 arch/arm/mm/copypage-xscale.c   |    4 -
 arch/arm/mm/fault.c             |   14 ++---
 include/asm-arm/pgalloc.h       |    4 -
 include/asm-arm/timex.h         |   10 +++
 include/asm-arm/unistd.h        |    4 +
 11 files changed, 154 insertions(+), 17 deletions(-)

Index: linux-2.6.22/arch/arm/boot/compressed/head.S
===================================================================
--- linux-2.6.22.orig/arch/arm/boot/compressed/head.S	2007-07-24 08:56:34.000000000 +0200
+++ linux-2.6.22/arch/arm/boot/compressed/head.S	2007-07-24 08:57:07.000000000 +0200
@@ -836,6 +836,18 @@ memdump:	mov	r12, r0
 		mov	pc, r10
 #endif
 
+#ifdef CONFIG_MCOUNT
+/* CONFIG_MCOUNT causes boot header to be built with -pg requiring this
+ * trampoline
+ */
+		.text
+                .align 0
+                .type mcount %function
+                .global mcount
+mcount:
+		mov pc, lr	@ just return
+#endif
+
 		.ltorg
 reloc_end:
 
Index: linux-2.6.22/arch/arm/kernel/entry-common.S
===================================================================
--- linux-2.6.22.orig/arch/arm/kernel/entry-common.S	2007-07-24 08:56:34.000000000 +0200
+++ linux-2.6.22/arch/arm/kernel/entry-common.S	2007-07-24 08:57:07.000000000 +0200
@@ -3,6 +3,8 @@
  *
  *  Copyright (C) 2000 Russell King
  *
+ * FUNCTION_TRACE/mcount support (C) 2005 Timesys john.cooper@timesys.com
+ *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License version 2 as
  * published by the Free Software Foundation.
@@ -395,5 +397,112 @@ ENTRY(sys_oabi_call_table)
 #undef ABI
 #undef OBSOLETE
 
+#ifdef CONFIG_FRAME_POINTER
+
+#ifdef CONFIG_MCOUNT
+/*
+ * At the point where we are in mcount() we maintain the
+ * frame of the prologue code and keep the call to mcount()
+ * out of the stack frame list:
+
+        saved pc          <---\     caller of instrumented routine
+        saved lr              |
+        ip/prev_sp            |
+        fp        -----^      |
+         :                    |
+                              |
+     -> saved pc              |     instrumented routine
+    |   saved lr              |
+    |   ip/prev_sp            |
+    |   fp           ---------/
+    |     :
+    |
+    |                             mcount
+    |	saved pc
+    |	saved lr
+    |	ip/prev sp
+     --	fp
+        r3
+        r2
+        r1
+   sp-> r0
+         :
+ */
+
+	.text
+	.align 0
+	.type mcount %function
+	.global mcount
+
+/* gcc -pg generated FUNCTION_PROLOGUE references mcount()
+ * and has already created the stack frame invocation for
+ * the routine we have been called to instrument. We create
+ * a complete frame nevertheless, as we want to use the same
+ * call to mcount() from c code.
+ */
+mcount:
+
+	ldr	ip, =mcount_enabled	@ leave early, if disabled
+	ldr	ip, [ip]
+	cmp	ip, #0
+	moveq	pc,lr
+
+	mov	ip,  sp
+	stmdb   sp!, {r0 - r3, fp, ip, lr, pc}	@ create stack frame
+
+	ldr	r1, [fp, #-4]		@ get lr (the return address
+					@ of the caller of the
+					@ instrumented function)
+	mov	r0, lr			@ get lr - (the return address
+					@ of the instrumented function)
+
+	sub	fp, ip, #4		@ point fp at this frame
+
+	bl	__trace
+1:
+	ldmdb   fp, {r0 - r3, fp, sp, pc}	@ pop entry frame and return
+
+#endif
+
+/* ARM replacement for unsupported gcc __builtin_return_address(n)
+ * where 0 < n.  n == 0 is supported here as well.
+ *
+ * Walk up the stack frame until the desired frame is found or a NULL
+ * fp is encountered, return NULL in the latter case.
+ *
+ * Note: it is possible under code optimization for the stack invocation
+ * of an ancestor function (level N) to be removed before calling a
+ * descendant function (level N+1).  No easy means is available to deduce
+ * this scenario with the result being [for example] caller_addr(0) when
+ * called from level N+1 returning level N-1 rather than the expected
+ * level N.  This optimization issue appears isolated to the case of
+ * a call to a level N+1 routine made at the tail end of a level N
+ * routine -- the level N frame is deleted and a simple branch is made
+ * to the level N+1 routine.
+ */
+
+	.text
+	.align 0
+	.type arm_return_addr %function
+	.global arm_return_addr
+
+arm_return_addr:
+	mov	ip, r0
+	mov	r0, fp
+3:
+	cmp	r0, #0
+	beq	1f		@ frame list hit end, bail
+	cmp	ip, #0
+	beq	2f		@ reached desired frame
+	ldr	r0, [r0, #-12]  @ else continue, get next fp
+	sub	ip, ip, #1
+	b	 3b
+2:
+	ldr	r0, [r0, #-4]   @ get target return address
+1:
+	mov	pc, lr
+
+#endif
+
 #endif
 
Index: linux-2.6.22/arch/arm/kernel/fiq.c
===================================================================
--- linux-2.6.22.orig/arch/arm/kernel/fiq.c	2007-07-24 08:56:34.000000000 +0200
+++ linux-2.6.22/arch/arm/kernel/fiq.c	2007-07-24 08:57:07.000000000 +0200
@@ -89,7 +89,7 @@ void set_fiq_handler(void *start, unsign
  * disable irqs for the duration.  Note - these functions are almost
  * entirely coded in assembly.
  */
-void __attribute__((naked)) set_fiq_regs(struct pt_regs *regs)
+void notrace __attribute__((naked)) set_fiq_regs(struct pt_regs *regs)
 {
 	register unsigned long tmp;
 	asm volatile (
@@ -107,7 +107,7 @@ void __attribute__((naked)) set_fiq_regs
 	: "r" (&regs->ARM_r8), "I" (PSR_I_BIT | PSR_F_BIT | FIQ_MODE));
 }
 
-void __attribute__((naked)) get_fiq_regs(struct pt_regs *regs)
+void notrace __attribute__((naked)) get_fiq_regs(struct pt_regs *regs)
 {
 	register unsigned long tmp;
 	asm volatile (
Index: linux-2.6.22/arch/arm/kernel/irq.c
===================================================================
--- linux-2.6.22.orig/arch/arm/kernel/irq.c	2007-07-24 08:56:34.000000000 +0200
+++ linux-2.6.22/arch/arm/kernel/irq.c	2007-07-24 08:57:07.000000000 +0200
@@ -108,11 +108,14 @@ static struct irq_desc bad_irq_desc = {
  * come via this function.  Instead, they should provide their
  * own 'handler'
  */
-asmlinkage void __exception asm_do_IRQ(unsigned int irq, struct pt_regs *regs)
+asmlinkage void __exception notrace asm_do_IRQ(unsigned int irq,
+					       struct pt_regs *regs)
 {
 	struct pt_regs *old_regs = set_irq_regs(regs);
 	struct irq_desc *desc = irq_desc + irq;
 
+	trace_special(instruction_pointer(regs), irq, 0);
+
 	/*
 	 * Some hardware gives randomly wrong interrupts.  Rather
 	 * than crashing, do something sensible.
Index: linux-2.6.22/arch/arm/kernel/traps.c
===================================================================
--- linux-2.6.22.orig/arch/arm/kernel/traps.c	2007-07-24 08:56:34.000000000 +0200
+++ linux-2.6.22/arch/arm/kernel/traps.c	2007-07-24 08:57:07.000000000 +0200
@@ -182,6 +182,7 @@ static void dump_backtrace(struct pt_reg
 void dump_stack(void)
 {
 	__backtrace();
+	print_traces(current);
 }
 
 EXPORT_SYMBOL(dump_stack);
Index: linux-2.6.22/arch/arm/mm/copypage-v4mc.c
===================================================================
--- linux-2.6.22.orig/arch/arm/mm/copypage-v4mc.c	2007-07-24 08:56:34.000000000 +0200
+++ linux-2.6.22/arch/arm/mm/copypage-v4mc.c	2007-07-24 08:57:07.000000000 +0200
@@ -44,7 +44,7 @@ static DEFINE_SPINLOCK(minicache_lock);
  * instruction.  If your processor does not supply this, you have to write your
  * own copy_user_page that does the right thing.
  */
-static void __attribute__((naked))
+static void notrace __attribute__((naked))
 mc_copy_user_page(void *from, void *to)
 {
 	asm volatile(
@@ -88,7 +88,7 @@ void v4_mc_copy_user_page(void *kto, con
 /*
  * ARMv4 optimised clear_user_page
  */
-void __attribute__((naked))
+void notrace __attribute__((naked))
 v4_mc_clear_user_page(void *kaddr, unsigned long vaddr)
 {
 	asm volatile(
Index: linux-2.6.22/arch/arm/mm/copypage-xscale.c
===================================================================
--- linux-2.6.22.orig/arch/arm/mm/copypage-xscale.c	2007-07-24 08:56:34.000000000 +0200
+++ linux-2.6.22/arch/arm/mm/copypage-xscale.c	2007-07-24 08:57:07.000000000 +0200
@@ -42,7 +42,7 @@ static DEFINE_SPINLOCK(minicache_lock);
  * Dcache aliasing issue.  The writes will be forwarded to the write buffer,
  * and merged as appropriate.
  */
-static void __attribute__((naked))
+static void notrace __attribute__((naked))
 mc_copy_user_page(void *from, void *to)
 {
 	/*
@@ -110,7 +110,7 @@ void xscale_mc_copy_user_page(void *kto,
 /*
  * XScale optimised clear_user_page
  */
-void __attribute__((naked))
+void notrace __attribute__((naked))
 xscale_mc_clear_user_page(void *kaddr, unsigned long vaddr)
 {
 	asm volatile(
Index: linux-2.6.22/arch/arm/mm/fault.c
===================================================================
--- linux-2.6.22.orig/arch/arm/mm/fault.c	2007-07-24 08:56:34.000000000 +0200
+++ linux-2.6.22/arch/arm/mm/fault.c	2007-07-24 08:57:07.000000000 +0200
@@ -215,7 +215,7 @@ out:
 	return fault;
 }
 
-static int
+static notrace int
 do_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 {
 	struct task_struct *tsk;
@@ -315,7 +315,7 @@ no_context:
  * interrupt or a critical region, and should only copy the information
  * from the master page table, nothing more.
  */
-static int
+static notrace int
 do_translation_fault(unsigned long addr, unsigned int fsr,
 		     struct pt_regs *regs)
 {
@@ -358,7 +358,7 @@ bad_area:
  * Some section permission faults need to be handled gracefully.
  * They can happen due to a __{get,put}_user during an oops.
  */
-static int
+static notrace int
 do_sect_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 {
 	do_bad_area(addr, fsr, regs);
@@ -368,7 +368,7 @@ do_sect_fault(unsigned long addr, unsign
 /*
  * This abort handler always returns "fault".
  */
-static int
+static notrace int
 do_bad(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 {
 	return 1;
@@ -423,7 +423,7 @@ static struct fsr_info {
 	{ do_bad,		SIGBUS,  0,		"unknown 31"			   }
 };
 
-void __init
+void __init notrace
 hook_fault_code(int nr, int (*fn)(unsigned long, unsigned int, struct pt_regs *),
 		int sig, const char *name)
 {
@@ -437,7 +437,7 @@ hook_fault_code(int nr, int (*fn)(unsign
 /*
  * Dispatch a data abort to the relevant handler.
  */
-asmlinkage void __exception
+asmlinkage void __exception notrace
 do_DataAbort(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
 {
 	const struct fsr_info *inf = fsr_info + (fsr & 15) + ((fsr & (1 << 10)) >> 6);
@@ -456,7 +456,7 @@ do_DataAbort(unsigned long addr, unsigne
 	arm_notify_die("", regs, &info, fsr, 0);
 }
 
-asmlinkage void __exception
+asmlinkage void __exception notrace
 do_PrefetchAbort(unsigned long addr, struct pt_regs *regs)
 {
 	do_translation_fault(addr, 0, regs);
Index: linux-2.6.22/include/asm-arm/pgalloc.h
===================================================================
--- linux-2.6.22.orig/include/asm-arm/pgalloc.h	2007-07-24 08:56:34.000000000 +0200
+++ linux-2.6.22/include/asm-arm/pgalloc.h	2007-07-24 08:57:07.000000000 +0200
@@ -109,7 +109,7 @@ static inline void __pmd_populate(pmd_t 
  *
  * Ensure that we always set both PMD entries.
  */
-static inline void
+static inline void notrace
 pmd_populate_kernel(struct mm_struct *mm, pmd_t *pmdp, pte_t *ptep)
 {
 	unsigned long pte_ptr = (unsigned long)ptep;
@@ -122,7 +122,7 @@ pmd_populate_kernel(struct mm_struct *mm
 	__pmd_populate(pmdp, __pa(pte_ptr) | _PAGE_KERNEL_TABLE);
 }
 
-static inline void
+static inline void notrace
 pmd_populate(struct mm_struct *mm, pmd_t *pmdp, struct page *ptep)
 {
 	__pmd_populate(pmdp, page_to_pfn(ptep) << PAGE_SHIFT | _PAGE_USER_TABLE);
Index: linux-2.6.22/include/asm-arm/timex.h
===================================================================
--- linux-2.6.22.orig/include/asm-arm/timex.h	2007-07-24 08:56:34.000000000 +0200
+++ linux-2.6.22/include/asm-arm/timex.h	2007-07-24 08:57:07.000000000 +0200
@@ -16,9 +16,17 @@
 
 typedef unsigned long cycles_t;
 
+#ifndef mach_read_cycles
+ #define mach_read_cycles() (0)
+#ifdef CONFIG_LATENCY_TIMING
+ #define mach_cycles_to_usecs(d) (d)
+ #define mach_usecs_to_cycles(d) (d)
+#endif
+#endif
+
 static inline cycles_t get_cycles (void)
 {
-	return 0;
+	return mach_read_cycles();
 }
 
 #endif
Index: linux-2.6.22/include/asm-arm/unistd.h
===================================================================
--- linux-2.6.22.orig/include/asm-arm/unistd.h	2007-07-24 08:56:34.000000000 +0200
+++ linux-2.6.22/include/asm-arm/unistd.h	2007-07-24 08:57:07.000000000 +0200
@@ -379,6 +379,10 @@
 #define __NR_timerfd			(__NR_SYSCALL_BASE+350)
 #define __NR_eventfd			(__NR_SYSCALL_BASE+351)
 
+#ifndef __ASSEMBLY__
+#define NR_syscalls			(__NR_eventfd + 1 - __NR_SYSCALL_BASE)
+#endif
+
 /*
  * The following SWIs are ARM private.
  */
