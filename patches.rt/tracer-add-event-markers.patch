Subject: Linux-RT 2.6.27-RT
From: http://www.kernel.org/pub/linux/kernel/projects/rt/
Acked-by: Tony Jones <tonyj@suse.de>
Add markers to various events

This patch adds markers to various events in the kernel.
(interrupts, task activation and hrtimers)

Signed-off-by: Steven Rostedt <srostedt@redhat.com>
---
 arch/x86/kernel/apic_32.c  |    2 ++
 arch/x86/kernel/irq_32.c   |    3 +++
 arch/x86/kernel/irq_64.c   |    3 +++
 arch/x86/kernel/traps_32.c |    3 +++
 arch/x86/kernel/traps_64.c |    3 +++
 arch/x86/mm/fault.c        |    3 +++
 include/linux/ftrace.h     |   32 ++++++++++++++++++++++++++++++++
 kernel/hrtimer.c           |    6 ++++++
 kernel/sched.c             |    7 +++++++
 9 files changed, 62 insertions(+), 0 deletions(-)

diff --git a/arch/x86/kernel/apic_32.c b/arch/x86/kernel/apic_32.c
index f88bd0d..6825abc 100644
--- a/arch/x86/kernel/apic_32.c
+++ b/arch/x86/kernel/apic_32.c
@@ -28,6 +28,7 @@
 #include <linux/acpi_pmtmr.h>
 #include <linux/module.h>
 #include <linux/dmi.h>
+#include <linux/ftrace.h>
 
 #include <asm/atomic.h>
 #include <asm/smp.h>
@@ -619,6 +620,7 @@ void smp_apic_timer_interrupt(struct pt_regs *regs)
 {
 	struct pt_regs *old_regs = set_irq_regs(regs);
 
+	trace_event_irq(-1, user_mode(regs), regs->ip);
 	/*
 	 * NOTE! We'd better ACK the irq immediately,
 	 * because timer handling can be slow.
diff --git a/arch/x86/kernel/irq_32.c b/arch/x86/kernel/irq_32.c
index 1cf8c1f..b0a1a77 100644
--- a/arch/x86/kernel/irq_32.c
+++ b/arch/x86/kernel/irq_32.c
@@ -16,6 +16,8 @@
 #include <linux/cpu.h>
 #include <linux/delay.h>
 
+#include <linux/ftrace.h>
+
 #include <asm/apic.h>
 #include <asm/uaccess.h>
 
@@ -234,6 +236,7 @@ unsigned int do_IRQ(struct pt_regs *regs)
 
 	old_regs = set_irq_regs(regs);
 	irq_enter();
+	trace_event_irq(irq, user_mode(regs), regs->ip);
 
 	overflow = check_stack_overflow();
 
diff --git a/arch/x86/kernel/irq_64.c b/arch/x86/kernel/irq_64.c
index 1f78b23..f985282 100644
--- a/arch/x86/kernel/irq_64.c
+++ b/arch/x86/kernel/irq_64.c
@@ -13,6 +13,7 @@
 #include <linux/seq_file.h>
 #include <linux/module.h>
 #include <linux/delay.h>
+#include <linux/ftrace.h>
 #include <asm/uaccess.h>
 #include <asm/io_apic.h>
 #include <asm/idle.h>
@@ -197,6 +198,8 @@ asmlinkage unsigned int do_IRQ(struct pt_regs *regs)
 	irq_enter();
 	irq = __get_cpu_var(vector_irq)[vector];
 
+	trace_event_irq(irq, user_mode(regs), regs->ip);
+
 #ifdef CONFIG_DEBUG_STACKOVERFLOW
 	stack_overflow_check(regs);
 #endif
diff --git a/arch/x86/kernel/traps_32.c b/arch/x86/kernel/traps_32.c
index 03df8e4..2c6a9c0 100644
--- a/arch/x86/kernel/traps_32.c
+++ b/arch/x86/kernel/traps_32.c
@@ -32,6 +32,7 @@
 #include <linux/bug.h>
 #include <linux/nmi.h>
 #include <linux/mm.h>
+#include <linux/ftrace.h>
 
 #ifdef CONFIG_EISA
 #include <linux/ioport.h>
@@ -825,6 +826,8 @@ notrace __kprobes void do_nmi(struct pt_regs *regs, long error_code)
 
 	nmi_enter();
 
+	trace_event_irq(-1, user_mode(regs), regs->ip);
+
 	cpu = smp_processor_id();
 
 	++nmi_count(cpu);
diff --git a/arch/x86/kernel/traps_64.c b/arch/x86/kernel/traps_64.c
index 513caac..f5dedbe 100644
--- a/arch/x86/kernel/traps_64.c
+++ b/arch/x86/kernel/traps_64.c
@@ -17,6 +17,7 @@
 #include <linux/kprobes.h>
 #include <linux/uaccess.h>
 #include <linux/utsname.h>
+#include <linux/ftrace.h>
 #include <linux/kdebug.h>
 #include <linux/kernel.h>
 #include <linux/module.h>
@@ -801,6 +802,8 @@ asmlinkage notrace __kprobes void default_do_nmi(struct pt_regs *regs)
 
 	cpu = smp_processor_id();
 
+	trace_event_irq(-1, user_mode(regs), regs->ip);
+
 	/* Only the BSP gets external NMIs from the system. */
 	if (!cpu)
 		reason = get_nmi_reason();
diff --git a/arch/x86/mm/fault.c b/arch/x86/mm/fault.c
index 455f3fe..c113684 100644
--- a/arch/x86/mm/fault.c
+++ b/arch/x86/mm/fault.c
@@ -26,6 +26,7 @@
 #include <linux/kprobes.h>
 #include <linux/uaccess.h>
 #include <linux/kdebug.h>
+#include <linux/ftrace.h>
 
 #include <asm/system.h>
 #include <asm/desc.h>
@@ -605,6 +606,8 @@ void __kprobes do_page_fault(struct pt_regs *regs, unsigned long error_code)
 	/* get the address */
 	address = read_cr2();
 
+	trace_event_fault(regs->ip, error_code, address);
+
 	si_code = SEGV_MAPERR;
 
 	if (notify_page_fault(regs))
diff --git a/include/linux/ftrace.h b/include/linux/ftrace.h
index bb38406..47343f1 100644
--- a/include/linux/ftrace.h
+++ b/include/linux/ftrace.h
@@ -3,7 +3,9 @@
 
 #ifdef CONFIG_FTRACE
 
+#include <linux/tracepoint.h>
 #include <linux/linkage.h>
+#include <linux/ktime.h>
 #include <linux/fs.h>
 
 extern int ftrace_enabled;
@@ -162,4 +164,34 @@ static inline void
 ftrace_special(unsigned long arg1, unsigned long arg2, unsigned long arg3) { }
 #endif
 
+struct hrtimer;
+
+DEFINE_TRACE(event_irq,
+	TPPROTO(int irq, int user, unsigned long ip),
+		TPARGS(irq, user, ip));
+
+DEFINE_TRACE(event_fault,
+	TPPROTO(unsigned long ip, unsigned long error, unsigned long addr),
+		TPARGS(ip, error, addr));
+
+DEFINE_TRACE(event_timer_set,
+	TPPROTO(ktime_t *expires, struct hrtimer *timer),
+	     TPARGS(expires, timer));
+
+DEFINE_TRACE(event_timer_triggered,
+	TPPROTO(ktime_t *expires, struct hrtimer *timer),
+	     TPARGS(expires, timer));
+
+DEFINE_TRACE(event_timestamp,
+	TPPROTO(ktime_t *time),
+	     TPARGS(time));
+
+DEFINE_TRACE(event_task_activate,
+	TPPROTO(struct task_struct *p, int cpu),
+	     TPARGS(p, cpu));
+
+DEFINE_TRACE(event_task_deactivate,
+	TPPROTO(struct task_struct *p, int cpu),
+	     TPARGS(p, cpu));
+
 #endif /* _LINUX_FTRACE_H */
diff --git a/kernel/hrtimer.c b/kernel/hrtimer.c
index b8e4dce..b3b19e4 100644
--- a/kernel/hrtimer.c
+++ b/kernel/hrtimer.c
@@ -44,6 +44,7 @@
 #include <linux/seq_file.h>
 #include <linux/err.h>
 #include <linux/debugobjects.h>
+#include <linux/ftrace.h>
 
 #include <asm/uaccess.h>
 
@@ -837,6 +838,8 @@ static void enqueue_hrtimer(struct hrtimer *timer,
 
 	debug_hrtimer_activate(timer);
 
+	trace_event_timer_set(&timer->expires, timer);
+
 	/*
 	 * Find the right place in the rbtree:
 	 */
@@ -1290,6 +1293,7 @@ void hrtimer_interrupt(struct clock_event_device *dev)
 
  retry:
 	now = ktime_get();
+	trace_event_timestamp(&now);
 
 	expires_next.tv64 = KTIME_MAX;
 
@@ -1318,6 +1322,8 @@ void hrtimer_interrupt(struct clock_event_device *dev)
 				break;
 			}
 
+			trace_event_timer_triggered(&timer->expires, timer);
+
 			/* Move softirq callbacks to the pending list */
 			if (timer->cb_mode == HRTIMER_CB_SOFTIRQ) {
 				__remove_hrtimer(timer, base,
diff --git a/kernel/sched.c b/kernel/sched.c
index 8810514..f9ed5d5 100644
--- a/kernel/sched.c
+++ b/kernel/sched.c
@@ -86,6 +86,11 @@
 #define PRIO_TO_NICE(prio)	((prio) - MAX_RT_PRIO - 20)
 #define TASK_NICE(p)		PRIO_TO_NICE((p)->static_prio)
 
+#define __PRIO(prio) \
+	((prio) <= 99 ? 199 - (prio) : (prio) - 120)
+
+#define PRIO(p) __PRIO((p)->prio)
+
 /*
  * 'User priority' is the nice value converted to something we
  * can work with better when scaling various scheduler parameters,
@@ -1712,6 +1717,7 @@ static void activate_task(struct rq *rq, struct task_struct *p, int wakeup)
 	if (task_contributes_to_load(p))
 		rq->nr_uninterruptible--;
 
+	trace_event_task_activate(p, cpu_of(rq));
 	enqueue_task(rq, p, wakeup);
 	inc_nr_running(rq);
 }
@@ -1724,6 +1730,7 @@ static void deactivate_task(struct rq *rq, struct task_struct *p, int sleep)
 	if (task_contributes_to_load(p))
 		rq->nr_uninterruptible++;
 
+	trace_event_task_deactivate(p, cpu_of(rq));
 	dequeue_task(rq, p, sleep);
 	dec_nr_running(rq);
 }
