Subject: Linux-RT 2.6.25.4-RT
From: http://www.kernel.org/pub/linux/kernel/projects/rt/
Acked-by: Sven-Thorsten Dietrich <sdietrich@suse.de>
Date: Tue, 27 May 2008 03:21:25 +0200
From: Carsten Emde <c.emde@osadl.org>
To: Steven Rostedt <rostedt@goodmis.org>
Cc: Thomas Gleixner <tglx@linutronix.de>
Subject: trace_hist.c: divide-by-zero problem (2)
Parts/Attachments:
   1 Shown    20 lines  Text
   2 Shown    86 lines  Text
----------------------------------------

Steven,

do we really need to continuously calculate the average latency and
spend lots of time in the division function? I don't think so. It is
probably sufficient to calculate the average latency only when we
display it.

What do you think?


        Carsten.



The division function of a 64-bit divisor divided by a 64-bit dividend
to calculate the average latency may be time-consuming on a 32-bit
system. We, therefore, no longer calculate the average whenever a new
latency value is added but only when we display the histogram data.

Signed-off-by: Carsten Emde <C.Emde@osadl.org>


---
 kernel/trace/trace_hist.c |   21 ++++++++-------------
 1 file changed, 8 insertions(+), 13 deletions(-)

Index: linux-2.6.25.4-rt4/kernel/trace/trace_hist.c
===================================================================
--- linux-2.6.25.4-rt4.orig/kernel/trace/trace_hist.c	2008-05-29 09:46:08.000000000 -0400
+++ linux-2.6.25.4-rt4/kernel/trace/trace_hist.c	2008-05-29 09:46:08.000000000 -0400
@@ -17,7 +17,6 @@
 #include <linux/debugfs.h>
 #include <linux/seq_file.h>
 #include <linux/percpu.h>
-#include <linux/spinlock.h>
 #include <linux/marker.h>
 #include <asm/atomic.h>
 #include <asm/div64.h>
@@ -68,15 +67,10 @@ static DEFINE_PER_CPU(struct hist_data, 
 static char *wakeup_latency_hist_dir = "wakeup_latency";
 #endif
 
-static inline u64 u64_div(u64 x, u64 y)
-{
-	do_div(x, y);
-	return x;
-}
-
 void notrace latency_hist(int latency_type, int cpu, unsigned long latency)
 {
 	struct hist_data *my_hist;
+	unsigned long long total_samples;
 
 	if ((cpu < 0) || (cpu >= NR_CPUS) || (latency_type < INTERRUPT_LATENCY)
 			|| (latency_type > WAKEUP_LATENCY) || (latency < 0))
@@ -123,10 +117,11 @@ void notrace latency_hist(int latency_ty
 	else if (latency > my_hist->max_lat)
 		my_hist->max_lat = latency;
 
-	my_hist->total_samples++;
+	total_samples = my_hist->total_samples++;
 	my_hist->accumulate_lat += latency;
-	my_hist->avg_lat = (unsigned long) u64_div(my_hist->accumulate_lat,
-						  my_hist->total_samples);
+	if (likely(total_samples))
+		my_hist->avg_lat = (unsigned long)
+		    div64_64(my_hist->accumulate_lat, total_samples);
 	return;
 }
 
@@ -220,11 +215,11 @@ static void hist_reset(struct hist_data 
 	atomic_dec(&hist->hist_mode);
 
 	memset(hist->hist_array, 0, sizeof(hist->hist_array));
-	hist->beyond_hist_bound_samples = 0UL;
+	hist->beyond_hist_bound_samples = 0ULL;
 	hist->min_lat = 0xFFFFFFFFUL;
 	hist->max_lat = 0UL;
-	hist->total_samples = 0UL;
-	hist->accumulate_lat = 0UL;
+	hist->total_samples = 0ULL;
+	hist->accumulate_lat = 0ULL;
 	hist->avg_lat = 0UL;
 
 	atomic_inc(&hist->hist_mode);
