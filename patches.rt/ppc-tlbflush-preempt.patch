Subject: Linux-RT 2.6.27-RT
From: http://www.kernel.org/pub/linux/kernel/projects/rt/
Acked-by: Tony Jones <tonyj@suse.de>
From estarkov@ru.mvista.com Mon Mar 24 17:41:35 2008
Date: Wed, 12 Mar 2008 18:37:42 +0300
From: Egor Starkov <estarkov@ru.mvista.com>
To: mingo@elte.hu
Subject: Memory corruption fixes
Resent-Date: Wed, 12 Mar 2008 17:06:59 +0100
Resent-Date: Wed, 12 Mar 2008 12:10:04 -0400
Resent-From: Ingo Molnar <mingo@elte.hu>
Resent-To: Steven Rostedt <rostedt@goodmis.org>

Hi Ingo,

I have found out that functions __flush_tlb_pending and hpte_need_flush 
must be called from within some kind of spinlock/non-preempt region. Fix 
"flush_hash_page_fix.patch" is attached.

Also debug version of function add_preempt_count can be called
on early stage of boot when current is not set and is 0.
So we can have memory corruption. I had it as stack pointer
exception after "Freeing unused kernel memory" message. Fix 
"preempt_debug_trace_fix.patch" is attached.

Egor Starkov

    [ Part 2: "Attached Text" ]

Signed-off-by: Egor Starkov <estarkov@ru.mvista.com>
Description:
	Functions __flush_tlb_pending and hpte_need_flush must
	be called from within some kind of spinlock/non-preempt region

---
 arch/powerpc/include/asm/pgtable-ppc64.h |    9 ++++++++-
 arch/powerpc/include/asm/tlbflush.h      |   20 ++++++++++++++++++--
 2 files changed, 26 insertions(+), 3 deletions(-)

diff --git a/arch/powerpc/include/asm/pgtable-ppc64.h b/arch/powerpc/include/asm/pgtable-ppc64.h
index 4597c49..6cd819d 100644
--- a/arch/powerpc/include/asm/pgtable-ppc64.h
+++ b/arch/powerpc/include/asm/pgtable-ppc64.h
@@ -288,8 +288,15 @@ static inline unsigned long pte_update(struct mm_struct *mm,
 	: "r" (ptep), "r" (clr), "m" (*ptep), "i" (_PAGE_BUSY)
 	: "cc" );
 
-	if (old & _PAGE_HASHPTE)
+	if (old & _PAGE_HASHPTE) {
+#ifdef CONFIG_PREEMPT_RT
+		preempt_disable();
+#endif
 		hpte_need_flush(mm, addr, ptep, old, huge);
+#ifdef CONFIG_PREEMPT_RT
+		preempt_enable();
+#endif
+	}
 	return old;
 }
 
diff --git a/arch/powerpc/include/asm/tlbflush.h b/arch/powerpc/include/asm/tlbflush.h
index 56fd44d..0067f0e 100644
--- a/arch/powerpc/include/asm/tlbflush.h
+++ b/arch/powerpc/include/asm/tlbflush.h
@@ -109,7 +109,15 @@ extern void hpte_need_flush(struct mm_struct *mm, unsigned long addr,
 
 static inline void arch_enter_lazy_mmu_mode(void)
 {
-	struct ppc64_tlb_batch *batch = &get_cpu_var(ppc64_tlb_batch);
+	struct ppc64_tlb_batch *batch;
+#ifdef CONFIG_PREEMPT_RT
+	preempt_disable();
+#endif
+	batch = &get_cpu_var(ppc64_tlb_batch);
+
+#ifdef CONFIG_PREEMPT_RT
+	preempt_enable();
+#endif
 
 	batch->active = 1;
 	put_cpu_var(ppc64_tlb_batch);
@@ -117,7 +125,12 @@ static inline void arch_enter_lazy_mmu_mode(void)
 
 static inline void arch_leave_lazy_mmu_mode(void)
 {
-	struct ppc64_tlb_batch *batch = &get_cpu_var(ppc64_tlb_batch);
+	struct ppc64_tlb_batch *batch;
+
+#ifdef CONFIG_PREEMPT_RT
+	preempt_disable();
+#endif
+	batch = &get_cpu_var(ppc64_tlb_batch);
 
 	if (batch->active) {
 		if (batch->index) {
@@ -125,6 +138,9 @@ static inline void arch_leave_lazy_mmu_mode(void)
 		}
 		batch->active = 0;
 	}
+#ifdef CONFIG_PREEMPT_RT
+	preempt_enable();
+#endif
 	put_cpu_var(ppc64_tlb_batch);
 }
 
