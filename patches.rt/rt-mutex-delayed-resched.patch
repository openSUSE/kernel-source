---
 drivers/acpi/processor_idle.c |    6 +++---
 include/linux/preempt.h       |   16 ++++++++++++++++
 include/linux/sched.h         |   23 ++++++++++++++++++++++-
 kernel/sched.c                |   10 +++++++---
 4 files changed, 48 insertions(+), 7 deletions(-)

Index: linux-2.6.22/drivers/acpi/processor_idle.c
===================================================================
--- linux-2.6.22.orig/drivers/acpi/processor_idle.c	2007-07-24 08:57:08.000000000 +0200
+++ linux-2.6.22/drivers/acpi/processor_idle.c	2007-07-24 08:57:18.000000000 +0200
@@ -884,7 +884,7 @@ static int acpi_idle_enter_c1(struct cpu
 	 * NEED_RESCHED:
 	 */
 	smp_mb();
-	if (!need_resched())
+	if (!need_resched() || !need_resched_delayed())
 		safe_halt();
 	current_thread_info()->status |= TS_POLLING;
 
@@ -920,7 +920,7 @@ static int acpi_idle_enter_c2(struct cpu
 	 */
 	smp_mb();
 
-	if (unlikely(need_resched())) {
+	if (unlikely(need_resched() || need_resched_delayed())) {
 		current_thread_info()->status |= TS_POLLING;
 		local_irq_enable();
 		return 0;
@@ -978,7 +978,7 @@ static int acpi_idle_enter_c3(struct cpu
 	 */
 	smp_mb();
 
-	if (unlikely(need_resched())) {
+	if (unlikely(need_resched() || need_resched_delayed())) {
 		current_thread_info()->status |= TS_POLLING;
 		local_irq_enable();
 		return 0;
Index: linux-2.6.22/include/linux/preempt.h
===================================================================
--- linux-2.6.22.orig/include/linux/preempt.h	2007-07-24 08:57:17.000000000 +0200
+++ linux-2.6.22/include/linux/preempt.h	2007-07-24 08:57:18.000000000 +0200
@@ -67,6 +67,21 @@ do { \
 		preempt_schedule(); \
 } while (0)
 
+
+/*
+ * If the architecture doens't have TIF_NEED_RESCHED_DELAYED
+ * help it out and define it back to TIF_NEED_RESCHED
+ */
+#ifndef TIF_NEED_RESCHED_DELAYED
+# define TIF_NEED_RESCHED_DELAYED TIF_NEED_RESCHED
+#endif
+
+#define preempt_check_resched_delayed() \
+do { \
+	if (unlikely(test_thread_flag(TIF_NEED_RESCHED_DELAYED))) \
+		preempt_schedule(); \
+} while (0)
+
 #define preempt_enable() \
 do { \
 	__preempt_enable_no_resched(); \
@@ -81,6 +96,7 @@ do { \
 #define __preempt_enable_no_resched()	do { } while (0)
 #define preempt_enable()		do { } while (0)
 #define preempt_check_resched()		do { } while (0)
+#define preempt_check_resched_delayed()	do { } while (0)
 
 #define preempt_schedule_irq()		do { } while (0)
 
Index: linux-2.6.22/include/linux/sched.h
===================================================================
--- linux-2.6.22.orig/include/linux/sched.h	2007-07-24 08:57:14.000000000 +0200
+++ linux-2.6.22/include/linux/sched.h	2007-07-24 08:57:18.000000000 +0200
@@ -1821,11 +1821,32 @@ static inline int signal_pending(struct 
 	return unlikely(test_tsk_thread_flag(p,TIF_SIGPENDING));
 }
   
-static inline int need_resched(void)
+static inline int _need_resched(void)
 {
 	return unlikely(test_thread_flag(TIF_NEED_RESCHED));
 }
 
+static inline int need_resched(void)
+{
+	touch_critical_timing();
+	return _need_resched();
+}
+
+static inline void set_tsk_need_resched_delayed(struct task_struct *tsk)
+{
+	set_tsk_thread_flag(tsk,TIF_NEED_RESCHED_DELAYED);
+}
+
+static inline void clear_tsk_need_resched_delayed(struct task_struct *tsk)
+{
+	clear_tsk_thread_flag(tsk,TIF_NEED_RESCHED_DELAYED);
+}
+
+static inline int need_resched_delayed(void)
+{
+	return unlikely(test_thread_flag(TIF_NEED_RESCHED_DELAYED));
+}
+
 /*
  * cond_resched() and cond_resched_lock(): latency reduction via
  * explicit rescheduling in places that are safe. The return
Index: linux-2.6.22/kernel/sched.c
===================================================================
--- linux-2.6.22.orig/kernel/sched.c	2007-07-24 08:57:17.000000000 +0200
+++ linux-2.6.22/kernel/sched.c	2007-07-24 08:57:18.000000000 +0200
@@ -3331,6 +3331,7 @@ need_resched_nonpreemptible:
 
 	spin_lock_irq(&rq->lock);
 	clear_tsk_need_resched(prev);
+	clear_tsk_need_resched_delayed(prev);
 
 	if (prev->state && !(preempt_count() & PREEMPT_ACTIVE)) {
 		if (unlikely((prev->state & TASK_INTERRUPTIBLE) &&
@@ -3368,7 +3369,8 @@ need_resched_nonpreemptible:
 		goto need_resched_nonpreemptible;
 	}
 	__preempt_enable_no_resched();
-	if (unlikely(test_thread_flag(TIF_NEED_RESCHED)))
+	if (unlikely(test_thread_flag(TIF_NEED_RESCHED) ||
+		     test_thread_flag(TIF_NEED_RESCHED_DELAYED)))
 		goto need_resched;
 }
 EXPORT_SYMBOL(schedule);
@@ -3412,7 +3414,8 @@ need_resched:
 
 	/* we could miss a preemption opportunity between schedule and now */
 	barrier();
-	if (unlikely(test_thread_flag(TIF_NEED_RESCHED)))
+	if (unlikely(test_thread_flag(TIF_NEED_RESCHED) ||
+			test_thread_flag(TIF_NEED_RESCHED_DELAYED)))
 		goto need_resched;
 }
 EXPORT_SYMBOL(preempt_schedule);
@@ -3454,7 +3457,8 @@ need_resched:
 
 	/* we could miss a preemption opportunity between schedule and now */
 	barrier();
-	if (unlikely(test_thread_flag(TIF_NEED_RESCHED)))
+	if (unlikely(test_thread_flag(TIF_NEED_RESCHED) ||
+		     test_thread_flag(TIF_NEED_RESCHED_DELAYED)))
 		goto need_resched;
 }
 
