diff -purN linux-post-2.6.4rc2-20040307/Documentation/cdrom/ide-cd linux-post-2.6.4rc2-20040309/Documentation/cdrom/ide-cd
--- linux-post-2.6.4rc2-20040307/Documentation/cdrom/ide-cd	2002-02-05 17:40:36.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/Documentation/cdrom/ide-cd	2004-03-07 07:17:11.000000000 +0000
@@ -74,7 +74,7 @@ This driver provides the following featu
 3. The CDROM drive should be connected to the host on an IDE
    interface.  Each interface on a system is defined by an I/O port
    address and an IRQ number, the standard assignments being
-   0x170 and 14 for the primary interface and 0x1f0 and 15 for the
+   0x1f0 and 14 for the primary interface and 0x170 and 15 for the
    secondary interface.  Each interface can control up to two devices,
    where each device can be a hard drive, a CDROM drive, a floppy drive, 
    or a tape drive.  The two devices on an interface are called `master'
@@ -268,8 +268,8 @@ b. Timeout/IRQ errors.
 
   - Double-check your hardware configuration to make sure that the IRQ
     number of your IDE interface matches what the driver expects.
-    (The usual assignments are 14 for the primary (0x170) interface
-    and 15 for the secondary (0x1f0) interface.)  Also be sure that
+    (The usual assignments are 14 for the primary (0x1f0) interface
+    and 15 for the secondary (0x170) interface.)  Also be sure that
     you don't have some other hardware which might be conflicting with
     the IRQ you're using.  Also check the BIOS setup for your system;
     some have the ability to disable individual IRQ levels, and I've
diff -purN linux-post-2.6.4rc2-20040307/arch/alpha/kernel/ptrace.c linux-post-2.6.4rc2-20040309/arch/alpha/kernel/ptrace.c
--- linux-post-2.6.4rc2-20040307/arch/alpha/kernel/ptrace.c	2003-05-21 17:51:52.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/arch/alpha/kernel/ptrace.c	2004-03-07 07:16:12.000000000 +0000
@@ -369,8 +369,8 @@ do_sys_ptrace(long request, long pid, lo
 		/* Mark single stepping.  */
 		child->thread_info->bpt_nsaved = -1;
 		clear_tsk_thread_flag(child, TIF_SYSCALL_TRACE);
-		wake_up_process(child);
 		child->exit_code = data;
+		wake_up_process(child);
 		/* give it a chance to run. */
 		ret = 0;
 		goto out;
diff -purN linux-post-2.6.4rc2-20040307/arch/i386/kernel/cpu/centaur.c linux-post-2.6.4rc2-20040309/arch/i386/kernel/cpu/centaur.c
--- linux-post-2.6.4rc2-20040307/arch/i386/kernel/cpu/centaur.c	2003-03-13 23:47:14.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/arch/i386/kernel/cpu/centaur.c	2004-01-31 04:25:15.000000000 +0000
@@ -246,7 +246,15 @@ static void __init winchip2_protect_mcr(
 	lo&=~0x1C0;	/* blank bits 8-6 */
 	wrmsr(MSR_IDT_MCR_CTRL, lo, hi);
 }
-#endif
+#endif /* CONFIG_X86_OOSTORE */
+
+#define ACE_PRESENT	(1 << 6)
+#define ACE_ENABLED	(1 << 7)
+#define ACE_FCR		(1 << 28)	/* MSR_VIA_FCR */
+
+#define RNG_PRESENT	(1 << 2)
+#define RNG_ENABLED	(1 << 3)
+#define RNG_ENABLE	(1 << 6)	/* MSR_VIA_RNG */
 
 static void __init init_c3(struct cpuinfo_x86 *c)
 {
@@ -254,6 +262,24 @@ static void __init init_c3(struct cpuinf
 
 	/* Test for Centaur Extended Feature Flags presence */
 	if (cpuid_eax(0xC0000000) >= 0xC0000001) {
+		u32 tmp = cpuid_edx(0xC0000001);
+
+		/* enable ACE unit, if present and disabled */
+		if ((tmp & (ACE_PRESENT | ACE_ENABLED)) == ACE_PRESENT) {
+			rdmsr (MSR_VIA_FCR, lo, hi);
+			lo |= ACE_FCR;		/* enable ACE unit */
+			wrmsr (MSR_VIA_FCR, lo, hi);
+			printk(KERN_INFO "CPU: Enabled ACE h/w crypto\n");
+		}
+
+		/* enable RNG unit, if present and disabled */
+		if ((tmp & (RNG_PRESENT | RNG_ENABLED)) == RNG_PRESENT) {
+			rdmsr (MSR_VIA_RNG, lo, hi);
+			lo |= RNG_ENABLE;	/* enable RNG unit */
+			wrmsr (MSR_VIA_RNG, lo, hi);
+			printk(KERN_INFO "CPU: Enabled h/w RNG\n");
+		}
+
 		/* store Centaur Extended Feature Flags as
 		 * word 5 of the CPU capability bit array
 		 */
diff -purN linux-post-2.6.4rc2-20040307/arch/i386/kernel/cpu/proc.c linux-post-2.6.4rc2-20040309/arch/i386/kernel/cpu/proc.c
--- linux-post-2.6.4rc2-20040307/arch/i386/kernel/cpu/proc.c	2003-08-19 02:46:23.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/arch/i386/kernel/cpu/proc.c	2004-01-31 04:25:15.000000000 +0000
@@ -50,7 +50,7 @@ static int show_cpuinfo(struct seq_file 
 		NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL,
 
 		/* VIA/Cyrix/Centaur-defined */
-		NULL, NULL, "xstore", NULL, NULL, NULL, NULL, NULL,
+		NULL, NULL, "rng", "rng_en", NULL, NULL, "ace", "ace_en",
 		NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL,
 		NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL,
 		NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL,
diff -purN linux-post-2.6.4rc2-20040307/arch/i386/kernel/io_apic.c linux-post-2.6.4rc2-20040309/arch/i386/kernel/io_apic.c
--- linux-post-2.6.4rc2-20040307/arch/i386/kernel/io_apic.c	2004-02-19 06:54:10.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/arch/i386/kernel/io_apic.c	2004-03-08 14:21:21.000000000 +0000
@@ -694,7 +694,7 @@ static inline void move_irq(int irq) { }
 #endif /* CONFIG_IRQBALANCE */
 
 #ifndef CONFIG_SMP
-void send_IPI_self(int vector)
+void fastcall send_IPI_self(int vector)
 {
 	unsigned int cfg;
 
diff -purN linux-post-2.6.4rc2-20040307/arch/i386/kernel/process.c linux-post-2.6.4rc2-20040309/arch/i386/kernel/process.c
--- linux-post-2.6.4rc2-20040307/arch/i386/kernel/process.c	2004-02-26 11:26:02.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/arch/i386/kernel/process.c	2004-03-07 07:04:57.000000000 +0000
@@ -493,7 +493,7 @@ int dump_task_regs(struct task_struct *t
  * the task-switch, and shows up in ret_from_fork in entry.S,
  * for example.
  */
-struct task_struct * __switch_to(struct task_struct *prev_p, struct task_struct *next_p)
+struct task_struct fastcall * __switch_to(struct task_struct *prev_p, struct task_struct *next_p)
 {
 	struct thread_struct *prev = &prev_p->thread,
 				 *next = &next_p->thread;
diff -purN linux-post-2.6.4rc2-20040307/arch/i386/kernel/signal.c linux-post-2.6.4rc2-20040309/arch/i386/kernel/signal.c
--- linux-post-2.6.4rc2-20040307/arch/i386/kernel/signal.c	2003-11-16 00:25:54.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/arch/i386/kernel/signal.c	2004-03-07 07:04:57.000000000 +0000
@@ -551,7 +551,7 @@ handle_signal(unsigned long sig, siginfo
  * want to handle. Thus you cannot kill init even with a SIGKILL even by
  * mistake.
  */
-int do_signal(struct pt_regs *regs, sigset_t *oldset)
+int fastcall do_signal(struct pt_regs *regs, sigset_t *oldset)
 {
 	siginfo_t info;
 	int signr;
diff -purN linux-post-2.6.4rc2-20040307/arch/i386/kernel/smp.c linux-post-2.6.4rc2-20040309/arch/i386/kernel/smp.c
--- linux-post-2.6.4rc2-20040307/arch/i386/kernel/smp.c	2003-08-19 02:46:23.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/arch/i386/kernel/smp.c	2004-03-07 07:05:01.000000000 +0000
@@ -150,7 +150,7 @@ inline void __send_IPI_shortcut(unsigned
 	apic_write_around(APIC_ICR, cfg);
 }
 
-void send_IPI_self(int vector)
+void fastcall send_IPI_self(int vector)
 {
 	__send_IPI_shortcut(APIC_DEST_SELF, vector);
 }
diff -purN linux-post-2.6.4rc2-20040307/arch/i386/kernel/vm86.c linux-post-2.6.4rc2-20040309/arch/i386/kernel/vm86.c
--- linux-post-2.6.4rc2-20040307/arch/i386/kernel/vm86.c	2003-12-29 21:37:31.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/arch/i386/kernel/vm86.c	2004-03-07 07:04:57.000000000 +0000
@@ -95,7 +95,7 @@
 #define VM86_REGS_SIZE2 (sizeof(struct kernel_vm86_regs) - VM86_REGS_SIZE1)
 
 struct pt_regs * FASTCALL(save_v86_state(struct kernel_vm86_regs * regs));
-struct pt_regs * save_v86_state(struct kernel_vm86_regs * regs)
+struct pt_regs * fastcall save_v86_state(struct kernel_vm86_regs * regs)
 {
 	struct tss_struct *tss;
 	struct pt_regs *ret;
diff -purN linux-post-2.6.4rc2-20040307/arch/mips/kernel/ioctl32.c linux-post-2.6.4rc2-20040309/arch/mips/kernel/ioctl32.c
--- linux-post-2.6.4rc2-20040307/arch/mips/kernel/ioctl32.c	2004-02-25 10:31:12.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/arch/mips/kernel/ioctl32.c	2004-03-07 07:04:56.000000000 +0000
@@ -1277,20 +1277,6 @@ COMPATIBLE_IOCTL(SBPROF_ZBSTOP)
 COMPATIBLE_IOCTL(SBPROF_ZBWAITFULL)
 #endif /* CONFIG_SIBYTE_TBPROF */
 
-#if defined(CONFIG_BLK_DEV_DM) || defined(CONFIG_BLK_DEV_DM_MODULE)
-COMPATIBLE_IOCTL(DM_VERSION)
-COMPATIBLE_IOCTL(DM_REMOVE_ALL)
-COMPATIBLE_IOCTL(DM_DEV_CREATE)
-COMPATIBLE_IOCTL(DM_DEV_REMOVE)
-COMPATIBLE_IOCTL(DM_DEV_RELOAD)
-COMPATIBLE_IOCTL(DM_DEV_SUSPEND)
-COMPATIBLE_IOCTL(DM_DEV_RENAME)
-COMPATIBLE_IOCTL(DM_DEV_DEPS)
-COMPATIBLE_IOCTL(DM_DEV_STATUS)
-COMPATIBLE_IOCTL(DM_TARGET_STATUS)
-COMPATIBLE_IOCTL(DM_TARGET_WAIT)
-#endif /* CONFIG_BLK_DEV_DM */
-
 COMPATIBLE_IOCTL(MTIOCTOP)			/* mtio.h ioctls  */
 HANDLE_IOCTL(MTIOCGET32, mt_ioctl_trans)
 HANDLE_IOCTL(MTIOCPOS32, mt_ioctl_trans)
diff -purN linux-post-2.6.4rc2-20040307/arch/ppc64/Kconfig linux-post-2.6.4rc2-20040309/arch/ppc64/Kconfig
--- linux-post-2.6.4rc2-20040307/arch/ppc64/Kconfig	2004-02-27 07:24:31.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/arch/ppc64/Kconfig	2004-03-07 07:05:28.000000000 +0000
@@ -300,10 +300,6 @@ config VIOCD
 	  If you are running Linux on an IBM iSeries system and you want to
 	  read a CD drive owned by OS/400, say Y here.
 
-config VIOCD_AZTECH
-	bool "iSeries Virtual CD Aztech emulation"
-	depends on VIOCD
-
 config VIOTAPE
 	tristate "iSeries Virtual Tape Support"
 	help
diff -purN linux-post-2.6.4rc2-20040307/arch/ppc64/kernel/iSeries_iommu.c linux-post-2.6.4rc2-20040309/arch/ppc64/kernel/iSeries_iommu.c
--- linux-post-2.6.4rc2-20040307/arch/ppc64/kernel/iSeries_iommu.c	2004-02-27 18:28:03.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/arch/ppc64/kernel/iSeries_iommu.c	2004-03-07 07:05:28.000000000 +0000
@@ -43,6 +43,7 @@
 #include <asm/iommu.h>
 #include <asm/pci-bridge.h>
 #include <asm/iSeries/iSeries_pci.h>
+#include <asm/iSeries/vio.h>
 
 #include <asm/machdep.h>
 
@@ -58,11 +59,6 @@ static struct iSeries_Device_Node vio_de
 static struct pci_dev _veth_dev = { .sysdata = &veth_dev_node };
 static struct pci_dev _vio_dev  = { .sysdata = &vio_dev_node, .dev.bus = &pci_bus_type  };
 
-/*
- * I wonder what the deal is with these.  Nobody uses them.  Why do they
- * exist? Why do we export them to modules? Why is this comment here, and
- * why didn't I just delete them?
- */
 struct pci_dev *iSeries_veth_dev = &_veth_dev;
 struct device *iSeries_vio_dev = &_vio_dev.dev;
 
diff -purN linux-post-2.6.4rc2-20040307/arch/ppc64/kernel/mf.c linux-post-2.6.4rc2-20040309/arch/ppc64/kernel/mf.c
--- linux-post-2.6.4rc2-20040307/arch/ppc64/kernel/mf.c	2004-01-19 06:28:27.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/arch/ppc64/kernel/mf.c	2004-03-07 07:05:28.000000000 +0000
@@ -38,10 +38,9 @@
 #include <asm/iSeries/ItSpCommArea.h>
 #include <asm/iSeries/iSeries_proc.h>
 #include <asm/uaccess.h>
-#include <linux/pci.h>
+#include <linux/dma-mapping.h>
 #include <linux/bcd.h>
-
-extern struct pci_dev *iSeries_vio_dev;
+#include <asm/iSeries/vio.h>
 
 /*
  * This is the structure layout for the Machine Facilites LPAR event
@@ -791,7 +790,8 @@ void mf_setCmdLine(const char *cmdline, 
 {
 	struct VspCmdData myVspCmd;
 	dma_addr_t dma_addr = 0;
-	char *page = pci_alloc_consistent(iSeries_vio_dev, size, &dma_addr);
+	char *page = dma_alloc_coherent(iSeries_vio_dev, size, &dma_addr,
+			GFP_ATOMIC);
 
 	if (page == NULL) {
 		printk(KERN_ERR "mf.c: couldn't allocate memory to set command line\n");
@@ -809,7 +809,7 @@ void mf_setCmdLine(const char *cmdline, 
 	mb();
 	(void)signal_vsp_instruction(&myVspCmd);
 
-	pci_free_consistent(iSeries_vio_dev, size, page, dma_addr);
+	dma_free_coherent(iSeries_vio_dev, size, page, dma_addr);
 }
 
 int mf_getCmdLine(char *cmdline, int *size, u64 side)
@@ -819,8 +819,8 @@ int mf_getCmdLine(char *cmdline, int *si
 	int len = *size;
 	dma_addr_t dma_addr;
 
-	dma_addr = pci_map_single(iSeries_vio_dev, cmdline, len,
-			PCI_DMA_FROMDEVICE);
+	dma_addr = dma_map_single(iSeries_vio_dev, cmdline, len,
+			DMA_FROM_DEVICE);
 	memset(cmdline, 0, len);
 	memset(&myVspCmd, 0, sizeof(myVspCmd));
 	myVspCmd.cmd = 33;
@@ -840,7 +840,7 @@ int mf_getCmdLine(char *cmdline, int *si
 #endif
 	}
 
-	pci_unmap_single(iSeries_vio_dev, dma_addr, *size, PCI_DMA_FROMDEVICE);
+	dma_unmap_single(iSeries_vio_dev, dma_addr, *size, DMA_FROM_DEVICE);
 
 	return len;
 }
@@ -851,7 +851,8 @@ int mf_setVmlinuxChunk(const char *buffe
 	struct VspCmdData myVspCmd;
 	int rc;
 	dma_addr_t dma_addr = 0;
-	char *page = pci_alloc_consistent(iSeries_vio_dev, size, &dma_addr);
+	char *page = dma_alloc_coherent(iSeries_vio_dev, size, &dma_addr,
+			GFP_ATOMIC);
 
 	if (page == NULL) {
 		printk(KERN_ERR "mf.c: couldn't allocate memory to set vmlinux chunk\n");
@@ -876,7 +877,7 @@ int mf_setVmlinuxChunk(const char *buffe
 			rc = -ENOMEM;
 	}
 
-	pci_free_consistent(iSeries_vio_dev, size, page, dma_addr);
+	dma_free_coherent(iSeries_vio_dev, size, page, dma_addr);
 
 	return rc;
 }
@@ -888,8 +889,8 @@ int mf_getVmlinuxChunk(char *buffer, int
 	int len = *size;
 	dma_addr_t dma_addr;
 
-	dma_addr = pci_map_single(iSeries_vio_dev, buffer, len,
-			PCI_DMA_FROMDEVICE);
+	dma_addr = dma_map_single(iSeries_vio_dev, buffer, len,
+			DMA_FROM_DEVICE);
 	memset(buffer, 0, len);
 	memset(&myVspCmd, 0, sizeof(myVspCmd));
 	myVspCmd.cmd = 32;
@@ -907,7 +908,7 @@ int mf_getVmlinuxChunk(char *buffer, int
 			rc = -ENOMEM;
 	}
 
-	pci_unmap_single(iSeries_vio_dev, dma_addr, len, PCI_DMA_FROMDEVICE);
+	dma_unmap_single(iSeries_vio_dev, dma_addr, len, DMA_FROM_DEVICE);
 
 	return rc;
 }
diff -purN linux-post-2.6.4rc2-20040307/arch/ppc64/kernel/stab.c linux-post-2.6.4rc2-20040309/arch/ppc64/kernel/stab.c
--- linux-post-2.6.4rc2-20040307/arch/ppc64/kernel/stab.c	2004-02-27 22:59:30.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/arch/ppc64/kernel/stab.c	2004-03-07 07:05:29.000000000 +0000
@@ -184,13 +184,13 @@ int ste_allocate(unsigned long ea)
 	/* Kernel or user address? */
 	if (REGION_ID(ea) >= KERNEL_REGION_ID) {
 		vsid = get_kernel_vsid(ea);
-		context = REGION_ID(ea);
+		context = KERNEL_CONTEXT(ea);
 	} else {
 		if (!current->mm)
 			return 1;
 
 		context = current->mm->context;
-		vsid = get_vsid(context, ea);
+		vsid = get_vsid(context.id, ea);
 	}
 
 	esid = GET_ESID(ea);
@@ -223,7 +223,7 @@ static void preload_stab(struct task_str
 
 	if (!IS_VALID_EA(pc) || (REGION_ID(pc) >= KERNEL_REGION_ID))
 		return;
-	vsid = get_vsid(mm->context, pc);
+	vsid = get_vsid(mm->context.id, pc);
 	__ste_allocate(pc_esid, vsid);
 
 	if (pc_esid == stack_esid)
@@ -231,7 +231,7 @@ static void preload_stab(struct task_str
 
 	if (!IS_VALID_EA(stack) || (REGION_ID(stack) >= KERNEL_REGION_ID))
 		return;
-	vsid = get_vsid(mm->context, stack);
+	vsid = get_vsid(mm->context.id, stack);
 	__ste_allocate(stack_esid, vsid);
 
 	if (pc_esid == unmapped_base_esid || stack_esid == unmapped_base_esid)
@@ -240,7 +240,7 @@ static void preload_stab(struct task_str
 	if (!IS_VALID_EA(unmapped_base) ||
 	    (REGION_ID(unmapped_base) >= KERNEL_REGION_ID))
 		return;
-	vsid = get_vsid(mm->context, unmapped_base);
+	vsid = get_vsid(mm->context.id, unmapped_base);
 	__ste_allocate(unmapped_base_esid, vsid);
 
 	/* Order update */
@@ -406,14 +406,14 @@ int slb_allocate(unsigned long ea)
 
 	/* Kernel or user address? */
 	if (REGION_ID(ea) >= KERNEL_REGION_ID) {
-		context = REGION_ID(ea);
+		context = KERNEL_CONTEXT(ea);
 		vsid = get_kernel_vsid(ea);
 	} else {
 		if (unlikely(!current->mm))
 			return 1;
 
 		context = current->mm->context;
-		vsid = get_vsid(context, ea);
+		vsid = get_vsid(context.id, ea);
 	}
 
 	esid = GET_ESID(ea);
@@ -444,7 +444,7 @@ static void preload_slb(struct task_stru
 
 	if (!IS_VALID_EA(pc) || (REGION_ID(pc) >= KERNEL_REGION_ID))
 		return;
-	vsid = get_vsid(mm->context, pc);
+	vsid = get_vsid(mm->context.id, pc);
 	__slb_allocate(pc_esid, vsid, mm->context);
 
 	if (pc_esid == stack_esid)
@@ -452,7 +452,7 @@ static void preload_slb(struct task_stru
 
 	if (!IS_VALID_EA(stack) || (REGION_ID(stack) >= KERNEL_REGION_ID))
 		return;
-	vsid = get_vsid(mm->context, stack);
+	vsid = get_vsid(mm->context.id, stack);
 	__slb_allocate(stack_esid, vsid, mm->context);
 
 	if (pc_esid == unmapped_base_esid || stack_esid == unmapped_base_esid)
@@ -461,7 +461,7 @@ static void preload_slb(struct task_stru
 	if (!IS_VALID_EA(unmapped_base) ||
 	    (REGION_ID(unmapped_base) >= KERNEL_REGION_ID))
 		return;
-	vsid = get_vsid(mm->context, unmapped_base);
+	vsid = get_vsid(mm->context.id, unmapped_base);
 	__slb_allocate(unmapped_base_esid, vsid, mm->context);
 }
 
diff -purN linux-post-2.6.4rc2-20040307/arch/ppc64/kernel/viopath.c linux-post-2.6.4rc2-20040309/arch/ppc64/kernel/viopath.c
--- linux-post-2.6.4rc2-20040307/arch/ppc64/kernel/viopath.c	2004-02-27 05:25:15.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/arch/ppc64/kernel/viopath.c	2004-03-07 07:05:28.000000000 +0000
@@ -35,7 +35,6 @@
 #include <linux/vmalloc.h>
 #include <linux/string.h>
 #include <linux/proc_fs.h>
-#include <linux/device.h>
 #include <linux/dma-mapping.h>
 #include <linux/wait.h>
 
@@ -49,8 +48,6 @@
 #include <asm/iSeries/iSeries_proc.h>
 #include <asm/iSeries/vio.h>
 
-extern struct device *iSeries_vio_dev;
-
 /* Status of the path to each other partition in the system.
  * This is overkill, since we will only ever establish connections
  * to our hosting partition and the primary partition on the system.
diff -purN linux-post-2.6.4rc2-20040307/arch/ppc64/mm/hash_utils.c linux-post-2.6.4rc2-20040309/arch/ppc64/mm/hash_utils.c
--- linux-post-2.6.4rc2-20040307/arch/ppc64/mm/hash_utils.c	2004-02-27 12:16:07.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/arch/ppc64/mm/hash_utils.c	2004-03-07 07:05:29.000000000 +0000
@@ -265,7 +265,7 @@ int hash_page(unsigned long ea, unsigned
 		if (mm == NULL)
 			return 1;
 
-		vsid = get_vsid(mm->context, ea);
+		vsid = get_vsid(mm->context.id, ea);
 		break;
 	case IO_REGION_ID:
 		mm = &ioremap_mm;
diff -purN linux-post-2.6.4rc2-20040307/arch/ppc64/mm/hugetlbpage.c linux-post-2.6.4rc2-20040309/arch/ppc64/mm/hugetlbpage.c
--- linux-post-2.6.4rc2-20040307/arch/ppc64/mm/hugetlbpage.c	2004-01-31 08:15:33.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/arch/ppc64/mm/hugetlbpage.c	2004-03-07 07:05:29.000000000 +0000
@@ -244,7 +244,7 @@ static int open_32bit_htlbpage_range(str
 	struct vm_area_struct *vma;
 	unsigned long addr;
 
-	if (mm->context & CONTEXT_LOW_HPAGES)
+	if (mm->context.low_hpages)
 		return 0; /* The window is already open */
 	
 	/* Check no VMAs are in the region */
@@ -281,7 +281,7 @@ static int open_32bit_htlbpage_range(str
 
 	/* FIXME: do we need to scan for PTEs too? */
 
-	mm->context |= CONTEXT_LOW_HPAGES;
+	mm->context.low_hpages = 1;
 
 	/* the context change must make it to memory before the slbia,
 	 * so that further SLB misses do the right thing. */
@@ -589,7 +589,6 @@ full_search:
 	}
 }
 
-
 unsigned long hugetlb_get_unmapped_area(struct file *file, unsigned long addr,
 					unsigned long len, unsigned long pgoff,
 					unsigned long flags)
@@ -778,7 +777,7 @@ static void flush_hash_hugepage(mm_conte
 	BUG_ON(hugepte_bad(pte));
 	BUG_ON(!in_hugepage_area(context, ea));
 
-	vsid = get_vsid(context, ea);
+	vsid = get_vsid(context.id, ea);
 
 	va = (vsid << 28) | (ea & 0x0fffffff);
 	vpn = va >> LARGE_PAGE_SHIFT;
diff -purN linux-post-2.6.4rc2-20040307/arch/ppc64/mm/init.c linux-post-2.6.4rc2-20040309/arch/ppc64/mm/init.c
--- linux-post-2.6.4rc2-20040307/arch/ppc64/mm/init.c	2004-02-27 12:16:07.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/arch/ppc64/mm/init.c	2004-03-07 07:05:29.000000000 +0000
@@ -794,7 +794,7 @@ void update_mmu_cache(struct vm_area_str
 	if (!ptep)
 		return;
 
-	vsid = get_vsid(vma->vm_mm->context, ea);
+	vsid = get_vsid(vma->vm_mm->context.id, ea);
 
 	tmp = cpumask_of_cpu(smp_processor_id());
 	if (cpus_equal(vma->vm_mm->cpu_vm_mask, tmp))
diff -purN linux-post-2.6.4rc2-20040307/arch/ppc64/mm/tlb.c linux-post-2.6.4rc2-20040309/arch/ppc64/mm/tlb.c
--- linux-post-2.6.4rc2-20040307/arch/ppc64/mm/tlb.c	2004-02-27 12:40:06.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/arch/ppc64/mm/tlb.c	2004-03-07 07:05:29.000000000 +0000
@@ -62,7 +62,7 @@ void hpte_update(pte_t *ptep, unsigned l
 	addr = ptep_to_address(ptep);
 
 	if (REGION_ID(addr) == USER_REGION_ID)
-		context = mm->context;
+		context = mm->context.id;
 	i = batch->index;
 
 	/*
diff -purN linux-post-2.6.4rc2-20040307/arch/ppc64/xmon/xmon.c linux-post-2.6.4rc2-20040309/arch/ppc64/xmon/xmon.c
--- linux-post-2.6.4rc2-20040307/arch/ppc64/xmon/xmon.c	2004-02-27 05:25:16.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/arch/ppc64/xmon/xmon.c	2004-03-07 07:05:27.000000000 +0000
@@ -344,7 +344,7 @@ xmon(struct pt_regs *excp)
 #endif /* CONFIG_SMP */
 	set_msrd(msr);		/* restore interrupt enable */
 
-	return 0;
+	return 1;
 }
 
 int
diff -purN linux-post-2.6.4rc2-20040307/arch/sparc/kernel/sys_sunos.c linux-post-2.6.4rc2-20040309/arch/sparc/kernel/sys_sunos.c
--- linux-post-2.6.4rc2-20040307/arch/sparc/kernel/sys_sunos.c	2004-02-25 10:31:13.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/arch/sparc/kernel/sys_sunos.c	2004-03-05 22:45:19.000000000 +0000
@@ -682,8 +682,8 @@ static int get_default (int value, int d
 
 static int sunos_nfs_mount(char *dir_name, int linux_flags, void *data)
 {
-	int  server_fd;
-	char *the_name;
+	int  server_fd, err;
+	char *the_name, *mount_page;
 	struct nfs_mount_data linux_nfs_mount;
 	struct sunos_nfs_mount_args sunos_mount;
 
@@ -736,7 +736,16 @@ static int sunos_nfs_mount(char *dir_nam
 		sizeof(linux_nfs_mount.hostname));
 	putname (the_name);
 	
-	return do_mount ("", dir_name, "nfs", linux_flags, &linux_nfs_mount);
+	mount_page = (char *) get_zeroed_page(GFP_KERNEL);
+	if (!mount_page)
+		return -ENOMEM;
+
+	memcpy(mount_page, &linux_nfs_mount, sizeof(linux_nfs_mount));
+
+	err = do_mount("", dir_name, "nfs", linux_flags, mount_page);
+
+	free_page((unsigned long) mount_page);
+	return err;
 }
 
 asmlinkage int
diff -purN linux-post-2.6.4rc2-20040307/arch/sparc/mm/srmmu.c linux-post-2.6.4rc2-20040309/arch/sparc/mm/srmmu.c
--- linux-post-2.6.4rc2-20040307/arch/sparc/mm/srmmu.c	2004-03-05 05:57:03.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/arch/sparc/mm/srmmu.c	2004-03-06 17:39:23.000000000 +0000
@@ -632,7 +632,8 @@ struct thread_info *srmmu_alloc_thread_i
 	ret = (struct thread_info *)__get_free_pages(GFP_KERNEL,
 						     THREAD_INFO_ORDER);
 #ifdef CONFIG_DEBUG_STACK_USAGE
-	memset(ret, 0, PAGE_SIZE << THREAD_INFO_ORDER);
+	if (ret)
+		memset(ret, 0, PAGE_SIZE << THREAD_INFO_ORDER);
 #endif /* DEBUG_STACK_USAGE */
 
 	return ret;
diff -purN linux-post-2.6.4rc2-20040307/arch/sparc64/kernel/ioctl32.c linux-post-2.6.4rc2-20040309/arch/sparc64/kernel/ioctl32.c
--- linux-post-2.6.4rc2-20040307/arch/sparc64/kernel/ioctl32.c	2004-02-25 10:31:13.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/arch/sparc64/kernel/ioctl32.c	2004-03-07 07:04:56.000000000 +0000
@@ -1117,34 +1117,6 @@ COMPATIBLE_IOCTL(BNEPCONNADD)
 COMPATIBLE_IOCTL(BNEPCONNDEL)
 COMPATIBLE_IOCTL(BNEPGETCONNLIST)
 COMPATIBLE_IOCTL(BNEPGETCONNINFO)
-/* device-mapper */
-#if defined(CONFIG_DM_IOCTL_V4)
-COMPATIBLE_IOCTL(DM_VERSION)
-COMPATIBLE_IOCTL(DM_REMOVE_ALL)
-COMPATIBLE_IOCTL(DM_LIST_DEVICES)
-COMPATIBLE_IOCTL(DM_DEV_CREATE)
-COMPATIBLE_IOCTL(DM_DEV_REMOVE)
-COMPATIBLE_IOCTL(DM_DEV_RENAME)
-COMPATIBLE_IOCTL(DM_DEV_SUSPEND)
-COMPATIBLE_IOCTL(DM_DEV_STATUS)
-COMPATIBLE_IOCTL(DM_DEV_WAIT)
-COMPATIBLE_IOCTL(DM_TABLE_LOAD)
-COMPATIBLE_IOCTL(DM_TABLE_CLEAR)
-COMPATIBLE_IOCTL(DM_TABLE_DEPS)
-COMPATIBLE_IOCTL(DM_TABLE_STATUS)
-#else
-COMPATIBLE_IOCTL(DM_VERSION)
-COMPATIBLE_IOCTL(DM_REMOVE_ALL)
-COMPATIBLE_IOCTL(DM_DEV_CREATE)
-COMPATIBLE_IOCTL(DM_DEV_REMOVE)
-COMPATIBLE_IOCTL(DM_DEV_RELOAD)
-COMPATIBLE_IOCTL(DM_DEV_SUSPEND)
-COMPATIBLE_IOCTL(DM_DEV_RENAME)
-COMPATIBLE_IOCTL(DM_DEV_DEPS)
-COMPATIBLE_IOCTL(DM_DEV_STATUS)
-COMPATIBLE_IOCTL(DM_TARGET_STATUS)
-COMPATIBLE_IOCTL(DM_TARGET_WAIT)
-#endif
 /* And these ioctls need translation */
 /* NCPFS */
 HANDLE_IOCTL(NCP_IOC_NCPREQUEST_32, do_ncp_ncprequest)
diff -purN linux-post-2.6.4rc2-20040307/arch/sparc64/kernel/smp.c linux-post-2.6.4rc2-20040309/arch/sparc64/kernel/smp.c
--- linux-post-2.6.4rc2-20040307/arch/sparc64/kernel/smp.c	2004-01-20 14:49:30.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/arch/sparc64/kernel/smp.c	2004-02-25 00:11:02.000000000 +0000
@@ -46,7 +46,6 @@ extern void calibrate_delay(void);
 static unsigned char boot_cpu_id;
 
 cpumask_t cpu_online_map = CPU_MASK_NONE;
-atomic_t sparc64_num_cpus_possible = ATOMIC_INIT(0);
 cpumask_t phys_cpu_present_map = CPU_MASK_NONE;
 static cpumask_t smp_commenced_mask;
 static cpumask_t cpu_callout_map;
@@ -1236,20 +1235,17 @@ void __init smp_prepare_cpus(unsigned in
 
 	instance = 0;
 	while (!cpu_find_by_instance(instance, NULL, &mid)) {
-		if (mid < max_cpus) {
+		if (mid < max_cpus)
 			cpu_set(mid, phys_cpu_present_map);
-			atomic_inc(&sparc64_num_cpus_possible);
-		}
 		instance++;
 	}
 
-	if (atomic_read(&sparc64_num_cpus_possible) > max_cpus) {
+	if (num_possible_cpus() > max_cpus) {
 		instance = 0;
 		while (!cpu_find_by_instance(instance, NULL, &mid)) {
 			if (mid != boot_cpu_id) {
 				cpu_clear(mid, phys_cpu_present_map);
-				atomic_dec(&sparc64_num_cpus_possible);
-				if (atomic_read(&sparc64_num_cpus_possible) <= max_cpus)
+				if (num_possible_cpus() <= max_cpus)
 					break;
 			}
 			instance++;
diff -purN linux-post-2.6.4rc2-20040307/arch/sparc64/kernel/sparc64_ksyms.c linux-post-2.6.4rc2-20040309/arch/sparc64/kernel/sparc64_ksyms.c
--- linux-post-2.6.4rc2-20040307/arch/sparc64/kernel/sparc64_ksyms.c	2004-02-25 10:35:06.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/arch/sparc64/kernel/sparc64_ksyms.c	2004-02-25 00:08:44.000000000 +0000
@@ -145,7 +145,6 @@ EXPORT_SYMBOL_NOVERS(mcount);
 /* CPU online map and active count.  */
 EXPORT_SYMBOL(cpu_online_map);
 EXPORT_SYMBOL(phys_cpu_present_map);
-EXPORT_SYMBOL(sparc64_num_cpus_possible);
 
 /* Spinlock debugging library, optional. */
 #ifdef CONFIG_DEBUG_SPINLOCK
diff -purN linux-post-2.6.4rc2-20040307/arch/sparc64/kernel/sys_sunos32.c linux-post-2.6.4rc2-20040309/arch/sparc64/kernel/sys_sunos32.c
--- linux-post-2.6.4rc2-20040307/arch/sparc64/kernel/sys_sunos32.c	2004-02-25 10:31:13.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/arch/sparc64/kernel/sys_sunos32.c	2004-03-05 22:45:19.000000000 +0000
@@ -650,8 +650,8 @@ static int get_default (int value, int d
 /* XXXXXXXXXXXXXXXXXXXX */
 static int sunos_nfs_mount(char *dir_name, int linux_flags, void *data)
 {
-	int  server_fd;
-	char *the_name;
+	int  server_fd, err;
+	char *the_name, *mount_page;
 	struct nfs_mount_data linux_nfs_mount;
 	struct sunos_nfs_mount_args sunos_mount;
 
@@ -704,7 +704,16 @@ static int sunos_nfs_mount(char *dir_nam
 		sizeof(linux_nfs_mount.hostname));
 	putname (the_name);
 	
-	return do_mount ("", dir_name, "nfs", linux_flags, &linux_nfs_mount);
+	mount_page = (char *) get_zeroed_page(GFP_KERNEL);
+	if (!mount_page)
+		return -ENOMEM;
+
+	memcpy(mount_page, &linux_nfs_mount, sizeof(linux_nfs_mount));
+
+	err = do_mount("", dir_name, "nfs", linux_flags, mount_page);
+
+	free_page((unsigned long) mount_page);
+	return err;
 }
 
 /* XXXXXXXXXXXXXXXXXXXX */
diff -purN linux-post-2.6.4rc2-20040307/crypto/arc4.c linux-post-2.6.4rc2-20040309/crypto/arc4.c
--- linux-post-2.6.4rc2-20040307/crypto/arc4.c	2004-03-04 08:14:38.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/crypto/arc4.c	2004-03-07 10:22:38.000000000 +0000
@@ -59,10 +59,11 @@ static void arc4_crypt(void *ctx_arg, u8
 	u8 *const S = ctx->S;
 	u8 x = ctx->x;
 	u8 y = ctx->y;
+	u8 a, b;
 
-	u8 a = S[x];
+	a = S[x];
 	y = (y + a) & 0xff;
-	u8 b = S[y];
+	b = S[y];
 	S[x] = b;
 	S[y] = a;
 	x = (x + 1) & 0xff;
diff -purN linux-post-2.6.4rc2-20040307/drivers/block/Kconfig linux-post-2.6.4rc2-20040309/drivers/block/Kconfig
--- linux-post-2.6.4rc2-20040307/drivers/block/Kconfig	2004-02-23 05:24:10.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/block/Kconfig	2004-03-07 07:12:57.000000000 +0000
@@ -321,6 +321,7 @@ config BLK_DEV_RAM_SIZE
 
 config BLK_DEV_INITRD
 	bool "Initial RAM disk (initrd) support"
+	depends on BLK_DEV_RAM && BLK_DEV_RAM!=m
 	help
 	  The initial RAM disk is a RAM disk that is loaded by the boot loader
 	  (loadlin or lilo) and that is mounted as root before the normal boot
diff -purN linux-post-2.6.4rc2-20040307/drivers/block/floppy.c linux-post-2.6.4rc2-20040309/drivers/block/floppy.c
--- linux-post-2.6.4rc2-20040307/drivers/block/floppy.c	2004-02-04 05:34:23.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/block/floppy.c	2004-03-07 07:22:15.000000000 +0000
@@ -4242,6 +4242,15 @@ int __init floppy_init(void)
 		disks[i] = alloc_disk(1);
 		if (!disks[i])
 			goto Enomem;
+
+		disks[i]->major = FLOPPY_MAJOR;
+		disks[i]->first_minor = TOMINOR(i);
+		disks[i]->fops = &floppy_fops;
+		sprintf(disks[i]->disk_name, "fd%d", i);
+
+		init_timer(&motor_off_timer[i]);
+		motor_off_timer[i].data = i;
+		motor_off_timer[i].function = motor_off_callback;
 	}
 
 	devfs_mk_dir ("floppy");
@@ -4255,13 +4264,6 @@ int __init floppy_init(void)
 		goto fail_queue;
 	}
 
-	for (i=0; i<N_DRIVE; i++) {
-		disks[i]->major = FLOPPY_MAJOR;
-		disks[i]->first_minor = TOMINOR(i);
-		disks[i]->fops = &floppy_fops;
-		sprintf(disks[i]->disk_name, "fd%d", i);
-	}
-
 	blk_register_region(MKDEV(FLOPPY_MAJOR, 0), 256, THIS_MODULE,
 				floppy_find, NULL, NULL);
 
@@ -4366,9 +4368,6 @@ int __init floppy_init(void)
 	}
 	
 	for (drive = 0; drive < N_DRIVE; drive++) {
-		init_timer(&motor_off_timer[drive]);
-		motor_off_timer[drive].data = drive;
-		motor_off_timer[drive].function = motor_off_callback;
 		if (!(allowed_drive_mask & (1 << drive)))
 			continue;
 		if (fdc_state[FDC(drive)].version == FDC_NONE)
diff -purN linux-post-2.6.4rc2-20040307/drivers/block/ll_rw_blk.c linux-post-2.6.4rc2-20040309/drivers/block/ll_rw_blk.c
--- linux-post-2.6.4rc2-20040307/drivers/block/ll_rw_blk.c	2004-02-01 18:09:12.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/block/ll_rw_blk.c	2004-03-08 20:41:21.000000000 +0000
@@ -1188,13 +1188,23 @@ static void blk_unplug_timeout(unsigned 
  * Description:
  *   blk_start_queue() will clear the stop flag on the queue, and call
  *   the request_fn for the queue if it was in a stopped state when
- *   entered. Also see blk_stop_queue(). Must not be called from driver
- *   request function due to recursion issues. Queue lock must be held.
+ *   entered. Also see blk_stop_queue(). Queue lock must be held.
  **/
 void blk_start_queue(request_queue_t *q)
 {
 	clear_bit(QUEUE_FLAG_STOPPED, &q->queue_flags);
-	schedule_work(&q->unplug_work);
+
+	/*
+	 * one level of recursion is ok and is much faster than kicking
+	 * the unplug handling
+	 */
+	if (!test_and_set_bit(QUEUE_FLAG_REENTER, &q->queue_flags)) {
+		q->request_fn(q);
+		clear_bit(QUEUE_FLAG_REENTER, &q->queue_flags);
+	} else {
+		blk_plug_device(q);
+		schedule_work(&q->unplug_work);
+	}
 }
 
 EXPORT_SYMBOL(blk_start_queue);
@@ -1737,9 +1747,9 @@ void blk_insert_request(request_queue_t 
 	/*
 	 * If command is tagged, release the tag
 	 */
-	if(reinsert) {
+	if (reinsert)
 		blk_requeue_request(q, rq);
-	} else {
+	else {
 		int where = ELEVATOR_INSERT_BACK;
 
 		if (at_head)
@@ -1751,7 +1761,10 @@ void blk_insert_request(request_queue_t 
 		drive_stat_acct(rq, rq->nr_sectors, 1);
 		__elv_add_request(q, rq, where, 0);
 	}
-	q->request_fn(q);
+	if (blk_queue_plugged(q))
+		__generic_unplug_device(q);
+	else
+		q->request_fn(q);
 	spin_unlock_irqrestore(q->queue_lock, flags);
 }
 
diff -purN linux-post-2.6.4rc2-20040307/drivers/block/viodasd.c linux-post-2.6.4rc2-20040309/drivers/block/viodasd.c
--- linux-post-2.6.4rc2-20040307/drivers/block/viodasd.c	2004-03-02 03:01:22.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/block/viodasd.c	2004-03-08 06:47:43.000000000 +0000
@@ -38,7 +38,6 @@
 #include <linux/errno.h>
 #include <linux/init.h>
 #include <linux/string.h>
-#include <linux/device.h>
 #include <linux/dma-mapping.h>
 #include <linux/completion.h>
 
@@ -77,8 +76,6 @@ static spinlock_t	viodasd_spinlock = SPI
 
 #define DEVICE_NO(cell)	((struct viodasd_device *)(cell) - &viodasd_devices[0])
 
-extern struct device *iSeries_vio_dev;
-
 struct open_data {
 	u64	disk_size;
 	u16	max_disk;
diff -purN linux-post-2.6.4rc2-20040307/drivers/cdrom/Makefile linux-post-2.6.4rc2-20040309/drivers/cdrom/Makefile
--- linux-post-2.6.4rc2-20040307/drivers/cdrom/Makefile	2003-02-03 22:19:36.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/cdrom/Makefile	2004-03-07 07:05:28.000000000 +0000
@@ -20,3 +20,4 @@ obj-$(CONFIG_OPTCD)		+= optcd.o
 obj-$(CONFIG_SBPCD)		+= sbpcd.o      cdrom.o
 obj-$(CONFIG_SJCD)		+= sjcd.o
 obj-$(CONFIG_CDU535)		+= sonycd535.o
+obj-$(CONFIG_VIOCD)		+= viocd.o      cdrom.o
diff -purN linux-post-2.6.4rc2-20040307/drivers/cdrom/viocd.c linux-post-2.6.4rc2-20040309/drivers/cdrom/viocd.c
--- linux-post-2.6.4rc2-20040307/drivers/cdrom/viocd.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/cdrom/viocd.c	2004-03-07 07:05:28.000000000 +0000
@@ -0,0 +1,656 @@
+/* -*- linux-c -*-
+ *  drivers/cdrom/viocd.c
+ *
+ *  iSeries Virtual CD Rom
+ *
+ *  Authors: Dave Boutcher <boutcher@us.ibm.com>
+ *           Ryan Arnold <ryanarn@us.ibm.com>
+ *           Colin Devilbiss <devilbis@us.ibm.com>
+ *           Stephen Rothwell <sfr@au1.ibm.com>
+ *
+ * (C) Copyright 2000-2004 IBM Corporation
+ *
+ * This program is free software;  you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation; either version 2 of the
+ * License, or (at your option) anyu later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software Foundation,
+ * Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
+ *
+ * This routine provides access to CD ROM drives owned and managed by an
+ * OS/400 partition running on the same box as this Linux partition.
+ *
+ * All operations are performed by sending messages back and forth to
+ * the OS/400 partition.
+ */
+
+#include <linux/major.h>
+#include <linux/blkdev.h>
+#include <linux/cdrom.h>
+#include <linux/errno.h>
+#include <linux/init.h>
+#include <linux/dma-mapping.h>
+#include <linux/module.h>
+#include <linux/completion.h>
+
+#include <asm/bug.h>
+
+#include <asm/scatterlist.h>
+#include <asm/iSeries/HvTypes.h>
+#include <asm/iSeries/HvLpEvent.h>
+#include <asm/iSeries/vio.h>
+
+#define VIOCD_DEVICE			"iseries/vcd"
+#define VIOCD_DEVICE_DEVFS		"iseries/vcd"
+
+#define VIOCD_VERS "1.06"
+
+#define VIOCD_KERN_WARNING		KERN_WARNING "viocd: "
+#define VIOCD_KERN_INFO			KERN_INFO "viocd: "
+
+struct viocdlpevent {
+	struct HvLpEvent	event;
+	u32			reserved;
+	u16			version;
+	u16			sub_result;
+	u16			disk;
+	u16			flags;
+	u32			token;
+	u64			offset;		/* On open, max number of disks */
+	u64			len;		/* On open, size of the disk */
+	u32			block_size;	/* Only set on open */
+	u32			media_size;	/* Only set on open */
+};
+
+enum viocdsubtype {
+	viocdopen = 0x0001,
+	viocdclose = 0x0002,
+	viocdread = 0x0003,
+	viocdwrite = 0x0004,
+	viocdlockdoor = 0x0005,
+	viocdgetinfo = 0x0006,
+	viocdcheck = 0x0007
+};
+
+/*
+ * Should probably make this a module parameter....sigh
+ */
+#define VIOCD_MAX_CD 8
+
+static const struct vio_error_entry viocd_err_table[] = {
+	{0x0201, EINVAL, "Invalid Range"},
+	{0x0202, EINVAL, "Invalid Token"},
+	{0x0203, EIO, "DMA Error"},
+	{0x0204, EIO, "Use Error"},
+	{0x0205, EIO, "Release Error"},
+	{0x0206, EINVAL, "Invalid CD"},
+	{0x020C, EROFS, "Read Only Device"},
+	{0x020D, ENOMEDIUM, "Changed or Missing Volume (or Varied Off?)"},
+	{0x020E, EIO, "Optical System Error (Varied Off?)"},
+	{0x02FF, EIO, "Internal Error"},
+	{0x3010, EIO, "Changed Volume"},
+	{0xC100, EIO, "Optical System Error"},
+	{0x0000, 0, NULL},
+};
+
+/*
+ * This is the structure we use to exchange info between driver and interrupt
+ * handler
+ */
+struct viocd_waitevent {
+	struct completion	com;
+	int			rc;
+	u16			sub_result;
+	int			changed;
+};
+
+/* this is a lookup table for the true capabilities of a device */
+struct capability_entry {
+	char	*type;
+	int	capability;
+};
+
+static struct capability_entry capability_table[] __initdata = {
+	{ "6330", CDC_LOCK | CDC_DVD_RAM },
+	{ "6321", CDC_LOCK },
+	{ "632B", 0 },
+	{ NULL  , CDC_LOCK },
+};
+
+/* These are our internal structures for keeping track of devices */
+static int viocd_numdev;
+
+struct cdrom_info {
+	char	rsrcname[10];
+	char	type[4];
+	char	model[3];
+};
+static struct cdrom_info viocd_unitinfo[VIOCD_MAX_CD];
+
+struct disk_info {
+	struct gendisk			*viocd_disk;
+	struct cdrom_device_info	viocd_info;
+};
+static struct disk_info viocd_diskinfo[VIOCD_MAX_CD];
+
+#define DEVICE_NR(di)	((di) - &viocd_diskinfo[0])
+#define VIOCDI		viocd_diskinfo[deviceno].viocd_info
+
+static request_queue_t *viocd_queue;
+static spinlock_t viocd_reqlock;
+
+#define MAX_CD_REQ	1
+
+static int viocd_blk_open(struct inode *inode, struct file *file)
+{
+	struct disk_info *di = inode->i_bdev->bd_disk->private_data;
+	return cdrom_open(&di->viocd_info, inode, file);
+}
+
+static int viocd_blk_release(struct inode *inode, struct file *file)
+{
+	struct disk_info *di = inode->i_bdev->bd_disk->private_data;
+	return cdrom_release(&di->viocd_info, file);
+}
+
+static int viocd_blk_ioctl(struct inode *inode, struct file *file,
+		unsigned cmd, unsigned long arg)
+{
+	struct disk_info *di = inode->i_bdev->bd_disk->private_data;
+	return cdrom_ioctl(&di->viocd_info, inode, cmd, arg);
+}
+
+static int viocd_blk_media_changed(struct gendisk *disk)
+{
+	struct disk_info *di = disk->private_data;
+	return cdrom_media_changed(&di->viocd_info);
+}
+
+struct block_device_operations viocd_fops = {
+	.owner =		THIS_MODULE,
+	.open =			viocd_blk_open,
+	.release =		viocd_blk_release,
+	.ioctl =		viocd_blk_ioctl,
+	.media_changed =	viocd_blk_media_changed,
+};
+
+/* Get info on CD devices from OS/400 */
+static void __init get_viocd_info(void)
+{
+	dma_addr_t dmaaddr;
+	HvLpEvent_Rc hvrc;
+	int i;
+	struct viocd_waitevent we;
+
+	dmaaddr = dma_map_single(iSeries_vio_dev, viocd_unitinfo,
+			sizeof(viocd_unitinfo), DMA_FROM_DEVICE);
+	if (dmaaddr == (dma_addr_t)-1) {
+		printk(VIOCD_KERN_WARNING "error allocating tce\n");
+		return;
+	}
+
+	init_completion(&we.com);
+
+	hvrc = HvCallEvent_signalLpEventFast(viopath_hostLp,
+			HvLpEvent_Type_VirtualIo,
+			viomajorsubtype_cdio | viocdgetinfo,
+			HvLpEvent_AckInd_DoAck, HvLpEvent_AckType_ImmediateAck,
+			viopath_sourceinst(viopath_hostLp),
+			viopath_targetinst(viopath_hostLp),
+			(u64)&we, VIOVERSION << 16, dmaaddr, 0,
+			sizeof(viocd_unitinfo), 0);
+	if (hvrc != HvLpEvent_Rc_Good) {
+		printk(VIOCD_KERN_WARNING "cdrom error sending event. rc %d\n",
+				(int)hvrc);
+		return;
+	}
+
+	wait_for_completion(&we.com);
+
+	dma_unmap_single(iSeries_vio_dev, dmaaddr, sizeof(viocd_unitinfo),
+			DMA_FROM_DEVICE);
+
+	if (we.rc) {
+		const struct vio_error_entry *err =
+			vio_lookup_rc(viocd_err_table, we.sub_result);
+		printk(VIOCD_KERN_WARNING "bad rc %d:0x%04X on getinfo: %s\n",
+				we.rc, we.sub_result, err->msg);
+		return;
+	}
+
+	for (i = 0; (i < VIOCD_MAX_CD) && viocd_unitinfo[i].rsrcname[0]; i++)
+		viocd_numdev++;
+}
+
+static int viocd_open(struct cdrom_device_info *cdi, int purpose)
+{
+        struct disk_info *diskinfo = cdi->handle;
+	int device_no = DEVICE_NR(diskinfo);
+	HvLpEvent_Rc hvrc;
+	struct viocd_waitevent we;
+
+	init_completion(&we.com);
+	hvrc = HvCallEvent_signalLpEventFast(viopath_hostLp,
+			HvLpEvent_Type_VirtualIo,
+			viomajorsubtype_cdio | viocdopen,
+			HvLpEvent_AckInd_DoAck, HvLpEvent_AckType_ImmediateAck,
+			viopath_sourceinst(viopath_hostLp),
+			viopath_targetinst(viopath_hostLp),
+			(u64)&we, VIOVERSION << 16, ((u64)device_no << 48),
+			0, 0, 0);
+	if (hvrc != 0) {
+		printk(VIOCD_KERN_WARNING
+				"bad rc on HvCallEvent_signalLpEventFast %d\n",
+				(int)hvrc);
+		return -EIO;
+	}
+
+	wait_for_completion(&we.com);
+
+	if (we.rc) {
+		const struct vio_error_entry *err =
+			vio_lookup_rc(viocd_err_table, we.sub_result);
+		printk(VIOCD_KERN_WARNING "bad rc %d:0x%04X on open: %s\n",
+				we.rc, we.sub_result, err->msg);
+		return -err->errno;
+	}
+
+	return 0;
+}
+
+static void viocd_release(struct cdrom_device_info *cdi)
+{
+	int device_no = DEVICE_NR((struct disk_info *)cdi->handle);
+	HvLpEvent_Rc hvrc;
+
+	hvrc = HvCallEvent_signalLpEventFast(viopath_hostLp,
+			HvLpEvent_Type_VirtualIo,
+			viomajorsubtype_cdio | viocdclose,
+			HvLpEvent_AckInd_NoAck, HvLpEvent_AckType_ImmediateAck,
+			viopath_sourceinst(viopath_hostLp),
+			viopath_targetinst(viopath_hostLp), 0,
+			VIOVERSION << 16, ((u64)device_no << 48), 0, 0, 0);
+	if (hvrc != 0)
+		printk(VIOCD_KERN_WARNING
+				"bad rc on HvCallEvent_signalLpEventFast %d\n",
+				(int)hvrc);
+}
+
+/* Send a read or write request to OS/400 */
+static int send_request(struct request *req)
+{
+	HvLpEvent_Rc hvrc;
+	struct disk_info *diskinfo = req->rq_disk->private_data;
+	u64 len;
+	dma_addr_t dmaaddr;
+	struct scatterlist sg;
+
+	BUG_ON(req->nr_phys_segments > 1);
+	BUG_ON(rq_data_dir(req) != READ);
+
+        if (blk_rq_map_sg(req->q, req, &sg) == 0) {
+		printk(VIOCD_KERN_WARNING
+				"error setting up scatter/gather list\n");
+		return -1;
+	}
+
+	if (dma_map_sg(iSeries_vio_dev, &sg, 1, DMA_FROM_DEVICE) == 0) {
+		printk(VIOCD_KERN_WARNING "error allocating sg tce\n");
+		return -1;
+	}
+	dmaaddr = sg_dma_address(&sg);
+	len = sg_dma_len(&sg);
+	if (dmaaddr == (dma_addr_t)-1) {
+		printk(VIOCD_KERN_WARNING "error allocating tce\n");
+		return -1;
+	}
+
+	hvrc = HvCallEvent_signalLpEventFast(viopath_hostLp,
+			HvLpEvent_Type_VirtualIo,
+			viomajorsubtype_cdio | viocdread,
+			HvLpEvent_AckInd_DoAck,
+			HvLpEvent_AckType_ImmediateAck,
+			viopath_sourceinst(viopath_hostLp),
+			viopath_targetinst(viopath_hostLp),
+			(u64)req, VIOVERSION << 16,
+			((u64)DEVICE_NR(diskinfo) << 48) | dmaaddr,
+			(u64)req->sector * 512, len, 0);
+	if (hvrc != HvLpEvent_Rc_Good) {
+		printk(VIOCD_KERN_WARNING "hv error on op %d\n", (int)hvrc);
+		return -1;
+	}
+
+	return 0;
+}
+
+
+static int rwreq;
+
+static void do_viocd_request(request_queue_t *q)
+{
+	struct request *req;
+
+	while ((rwreq == 0) && ((req = elv_next_request(q)) != NULL)) {
+		/* check for any kind of error */
+		if (send_request(req) < 0) {
+			printk(VIOCD_KERN_WARNING
+					"unable to send message to OS/400!");
+			end_request(req, 0);
+		} else
+			rwreq++;
+	}
+}
+
+static int viocd_media_changed(struct cdrom_device_info *cdi, int disc_nr)
+{
+	struct viocd_waitevent we;
+	HvLpEvent_Rc hvrc;
+	int device_no = DEVICE_NR((struct disk_info *)cdi->handle);
+
+	init_completion(&we.com);
+
+	/* Send the open event to OS/400 */
+	hvrc = HvCallEvent_signalLpEventFast(viopath_hostLp,
+			HvLpEvent_Type_VirtualIo,
+			viomajorsubtype_cdio | viocdcheck,
+			HvLpEvent_AckInd_DoAck, HvLpEvent_AckType_ImmediateAck,
+			viopath_sourceinst(viopath_hostLp),
+			viopath_targetinst(viopath_hostLp),
+			(u64)&we, VIOVERSION << 16, ((u64)device_no << 48),
+			0, 0, 0);
+	if (hvrc != 0) {
+		printk(VIOCD_KERN_WARNING "bad rc on HvCallEvent_signalLpEventFast %d\n",
+				(int)hvrc);
+		return -EIO;
+	}
+
+	wait_for_completion(&we.com);
+
+	/* Check the return code.  If bad, assume no change */
+	if (we.rc) {
+		const struct vio_error_entry *err =
+			vio_lookup_rc(viocd_err_table, we.sub_result);
+		printk(VIOCD_KERN_WARNING
+				"bad rc %d:0x%04X on check_change: %s; Assuming no change\n",
+				we.rc, we.sub_result, err->msg);
+		return 0;
+	}
+
+	return we.changed;
+}
+
+static int viocd_lock_door(struct cdrom_device_info *cdi, int locking)
+{
+	HvLpEvent_Rc hvrc;
+	u64 device_no = DEVICE_NR((struct disk_info *)cdi->handle);
+	/* NOTE: flags is 1 or 0 so it won't overwrite the device_no */
+	u64 flags = !!locking;
+	struct viocd_waitevent we;
+
+	init_completion(&we.com);
+
+	/* Send the lockdoor event to OS/400 */
+	hvrc = HvCallEvent_signalLpEventFast(viopath_hostLp,
+			HvLpEvent_Type_VirtualIo,
+			viomajorsubtype_cdio | viocdlockdoor,
+			HvLpEvent_AckInd_DoAck, HvLpEvent_AckType_ImmediateAck,
+			viopath_sourceinst(viopath_hostLp),
+			viopath_targetinst(viopath_hostLp),
+			(u64)&we, VIOVERSION << 16,
+			(device_no << 48) | (flags << 32), 0, 0, 0);
+	if (hvrc != 0) {
+		printk(VIOCD_KERN_WARNING "bad rc on HvCallEvent_signalLpEventFast %d\n",
+				(int)hvrc);
+		return -EIO;
+	}
+
+	wait_for_completion(&we.com);
+
+	if (we.rc != 0)
+		return -EIO;
+	return 0;
+}
+
+/* This routine handles incoming CD LP events */
+static void vio_handle_cd_event(struct HvLpEvent *event)
+{
+	struct viocdlpevent *bevent;
+	struct viocd_waitevent *pwe;
+	struct disk_info *di;
+	unsigned long flags;
+	struct request *req;
+
+
+	if (event == NULL)
+		/* Notification that a partition went away! */
+		return;
+	/* First, we should NEVER get an int here...only acks */
+	if (event->xFlags.xFunction == HvLpEvent_Function_Int) {
+		printk(VIOCD_KERN_WARNING
+				"Yikes! got an int in viocd event handler!\n");
+		if (event->xFlags.xAckInd == HvLpEvent_AckInd_DoAck) {
+			event->xRc = HvLpEvent_Rc_InvalidSubtype;
+			HvCallEvent_ackLpEvent(event);
+		}
+	}
+
+	bevent = (struct viocdlpevent *)event;
+
+	switch (event->xSubtype & VIOMINOR_SUBTYPE_MASK) {
+	case viocdopen:
+		if (event->xRc == 0) {
+			di = &viocd_diskinfo[bevent->disk];
+			blk_queue_hardsect_size(viocd_queue,
+					bevent->block_size);
+			set_capacity(di->viocd_disk,
+					bevent->media_size *
+					bevent->block_size / 512);
+		}
+		/* FALLTHROUGH !! */
+	case viocdgetinfo:
+	case viocdlockdoor:
+		pwe = (struct viocd_waitevent *)event->xCorrelationToken;
+return_complete:
+		pwe->rc = event->xRc;
+		pwe->sub_result = bevent->sub_result;
+		complete(&pwe->com);
+		break;
+
+	case viocdcheck:
+		pwe = (struct viocd_waitevent *)event->xCorrelationToken;
+		pwe->changed = bevent->flags;
+		goto return_complete;
+
+	case viocdclose:
+		break;
+
+	case viocdread:
+		/*
+		 * Since this is running in interrupt mode, we need to
+		 * make sure we're not stepping on any global I/O operations
+		 */
+		spin_lock_irqsave(&viocd_reqlock, flags);
+		dma_unmap_single(iSeries_vio_dev, bevent->token, bevent->len,
+				DMA_FROM_DEVICE);
+		req = (struct request *)bevent->event.xCorrelationToken;
+		rwreq--;
+
+		if (event->xRc != HvLpEvent_Rc_Good) {
+			const struct vio_error_entry *err =
+				vio_lookup_rc(viocd_err_table,
+						bevent->sub_result);
+			printk(VIOCD_KERN_WARNING "request %p failed "
+					"with rc %d:0x%04X: %s\n",
+					req, event->xRc,
+					bevent->sub_result, err->msg);
+			end_request(req, 0);
+		} else
+			end_request(req, 1);
+
+		/* restart handling of incoming requests */
+		spin_unlock_irqrestore(&viocd_reqlock, flags);
+		blk_run_queue(viocd_queue);
+		break;
+
+	default:
+		printk(VIOCD_KERN_WARNING
+				"message with invalid subtype %0x04X!\n",
+				event->xSubtype & VIOMINOR_SUBTYPE_MASK);
+		if (event->xFlags.xAckInd == HvLpEvent_AckInd_DoAck) {
+			event->xRc = HvLpEvent_Rc_InvalidSubtype;
+			HvCallEvent_ackLpEvent(event);
+		}
+	}
+}
+
+static struct cdrom_device_ops viocd_dops = {
+	.open = viocd_open,
+	.release = viocd_release,
+	.media_changed = viocd_media_changed,
+	.lock_door = viocd_lock_door,
+	.capability = CDC_CLOSE_TRAY | CDC_OPEN_TRAY | CDC_LOCK | CDC_SELECT_SPEED | CDC_SELECT_DISC | CDC_MULTI_SESSION | CDC_MCN | CDC_MEDIA_CHANGED | CDC_PLAY_AUDIO | CDC_RESET | CDC_IOCTLS | CDC_DRIVE_STATUS | CDC_GENERIC_PACKET | CDC_CD_R | CDC_CD_RW | CDC_DVD | CDC_DVD_R | CDC_DVD_RAM
+};
+
+static int __init find_capability(const char *type)
+{
+	struct capability_entry *entry;
+
+	for(entry = capability_table; entry->type; ++entry)
+		if(!strncmp(entry->type, type, 4))
+			break;
+	return entry->capability;
+}
+
+static int __init viocd_init(void)
+{
+	struct gendisk *gendisk;
+	int deviceno;
+	int ret = 0;
+
+	if (viopath_hostLp == HvLpIndexInvalid) {
+		vio_set_hostlp();
+		/* If we don't have a host, bail out */
+		if (viopath_hostLp == HvLpIndexInvalid)
+			return -ENODEV;
+	}
+
+	printk(VIOCD_KERN_INFO "vers " VIOCD_VERS ", hosting partition %d\n",
+			viopath_hostLp);
+
+	if (register_blkdev(VIOCD_MAJOR, VIOCD_DEVICE) != 0) {
+		printk(VIOCD_KERN_WARNING
+				"Unable to get major %d for %s\n",
+				VIOCD_MAJOR, VIOCD_DEVICE);
+		return -EIO;
+	}
+
+	ret = viopath_open(viopath_hostLp, viomajorsubtype_cdio,
+			MAX_CD_REQ + 2);
+	if (ret) {
+		printk(VIOCD_KERN_WARNING
+				"error opening path to host partition %d\n",
+				viopath_hostLp);
+		goto out_unregister;
+	}
+
+	/* Initialize our request handler */
+	vio_setHandler(viomajorsubtype_cdio, vio_handle_cd_event);
+
+	get_viocd_info();
+	if (viocd_numdev == 0)
+		goto out_undo_vio;
+
+	ret = -ENOMEM;
+	spin_lock_init(&viocd_reqlock);
+	viocd_queue = blk_init_queue(do_viocd_request, &viocd_reqlock);
+	if (viocd_queue == NULL)
+		goto out_unregister;
+	blk_queue_max_hw_segments(viocd_queue, 1);
+	blk_queue_max_phys_segments(viocd_queue, 1);
+	blk_queue_max_sectors(viocd_queue, 4096 / 512);
+
+	/* initialize units */
+	for (deviceno = 0; deviceno < viocd_numdev; deviceno++) {
+		struct disk_info *d = &viocd_diskinfo[deviceno];
+		struct cdrom_device_info *c = &d->viocd_info;
+		struct cdrom_info *ci = &viocd_unitinfo[deviceno];
+
+		c->ops = &viocd_dops;
+		c->speed = 4;
+		c->capacity = 1;
+		c->handle = d;
+		c->mask = ~find_capability(ci->type);
+		sprintf(c->name, VIOCD_DEVICE "%c", 'a' + deviceno);
+
+		if (register_cdrom(c) != 0) {
+			printk(VIOCD_KERN_WARNING
+					"Cannot register viocd CD-ROM %s!\n",
+					c->name);
+			continue;
+		}
+		printk(VIOCD_KERN_INFO "cd %s is iSeries resource %10.10s "
+				"type %4.4s, model %3.3s\n",
+				c->name, ci->rsrcname, ci->type, ci->model);
+		gendisk = alloc_disk(1);
+		if (gendisk == NULL) {
+			printk(VIOCD_KERN_WARNING
+					"Cannot create gendisk for %s!\n",
+					c->name);
+			unregister_cdrom(&VIOCDI);
+			continue;
+		}
+		gendisk->major = VIOCD_MAJOR;
+		gendisk->first_minor = deviceno;
+		strncpy(gendisk->disk_name, c->name,
+				sizeof(gendisk->disk_name));
+		snprintf(gendisk->devfs_name, sizeof(gendisk->devfs_name),
+				VIOCD_DEVICE_DEVFS "%d", deviceno);
+		gendisk->queue = viocd_queue;
+		gendisk->fops = &viocd_fops;
+		gendisk->flags = GENHD_FL_CD;
+		set_capacity(gendisk, 0);
+		gendisk->private_data = d;
+		d->viocd_disk = gendisk;
+		add_disk(gendisk);
+	}
+
+	return 0;
+
+out_undo_vio:
+	vio_clearHandler(viomajorsubtype_cdio);
+	viopath_close(viopath_hostLp, viomajorsubtype_cdio, MAX_CD_REQ + 2);
+out_unregister:
+	unregister_blkdev(VIOCD_MAJOR, VIOCD_DEVICE);
+	return ret;
+}
+
+static void __exit viocd_exit(void)
+{
+	int deviceno;
+
+	for (deviceno = 0; deviceno < viocd_numdev; deviceno++) {
+		struct disk_info *d = &viocd_diskinfo[deviceno];
+		if (unregister_cdrom(&d->viocd_info) != 0)
+			printk(VIOCD_KERN_WARNING
+					"Cannot unregister viocd CD-ROM %s!\n",
+					d->viocd_info.name);
+		del_gendisk(d->viocd_disk);
+		put_disk(d->viocd_disk);
+	}
+	blk_cleanup_queue(viocd_queue);
+
+	viopath_close(viopath_hostLp, viomajorsubtype_cdio, MAX_CD_REQ + 2);
+	vio_clearHandler(viomajorsubtype_cdio);
+	unregister_blkdev(VIOCD_MAJOR, VIOCD_DEVICE);
+}
+
+module_init(viocd_init);
+module_exit(viocd_exit);
+MODULE_LICENSE("GPL");
diff -purN linux-post-2.6.4rc2-20040307/drivers/char/hw_random.c linux-post-2.6.4rc2-20040309/drivers/char/hw_random.c
--- linux-post-2.6.4rc2-20040307/drivers/char/hw_random.c	2003-09-09 20:45:16.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/char/hw_random.c	2004-01-31 04:25:15.000000000 +0000
@@ -454,11 +454,7 @@ static int __init via_init(struct pci_de
 
 static void via_cleanup(void)
 {
-	u32 lo, hi;
-
-	rdmsr(MSR_VIA_RNG, lo, hi);
-	lo &= ~VIA_RNG_ENABLE;
-	wrmsr(MSR_VIA_RNG, lo, hi);
+	/* do nothing */
 }
 
 
diff -purN linux-post-2.6.4rc2-20040307/drivers/char/rio/rioctrl.c linux-post-2.6.4rc2-20040309/drivers/char/rio/rioctrl.c
--- linux-post-2.6.4rc2-20040307/drivers/char/rio/rioctrl.c	2003-03-18 16:58:11.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/char/rio/rioctrl.c	2004-03-07 07:12:56.000000000 +0000
@@ -522,7 +522,7 @@ RIO_DEBUG_CTRL, 				if (su)
 					else {
 		 				rio_dprintk (RIO_DEBUG_CTRL, "p->RIOBindTab full! - Rta %x not added\n",
 		  					(int) arg);
-		 				return 1;
+		 				return -ENOMEM;
 					}
 					return 0;
 				}
@@ -1593,12 +1593,12 @@ RIO_DEBUG_CTRL, 				if (su)
 			case RIO_NO_MESG:
 				if ( su )
 					 p->RIONoMessage = 1;
-				return su ? 0 : EPERM;
+				return su ? 0 : -EPERM;
 
 			case RIO_MESG:
 				if ( su )
 					p->RIONoMessage = 0;
-				return su ? 0 : EPERM;
+				return su ? 0 : -EPERM;
 
 			case RIO_WHAT_MESG:
 				if ( copyout( (caddr_t)&p->RIONoMessage, (int)arg, 
diff -purN linux-post-2.6.4rc2-20040307/drivers/i2c/busses/i2c-elv.c linux-post-2.6.4rc2-20040309/drivers/i2c/busses/i2c-elv.c
--- linux-post-2.6.4rc2-20040307/drivers/i2c/busses/i2c-elv.c	2004-02-20 06:21:19.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/i2c/busses/i2c-elv.c	2004-03-07 07:17:43.000000000 +0000
@@ -152,7 +152,7 @@ static int __init i2c_bitelv_init(void)
 			return -ENODEV;
 		}
 	}
-	pr_debug("i2c-elv: found device at %#x.\n",base);
+	pr_debug("i2c-elv: found device at %#lx.\n",base);
 	return 0;
 }
 
diff -purN linux-post-2.6.4rc2-20040307/drivers/i2c/busses/i2c-velleman.c linux-post-2.6.4rc2-20040309/drivers/i2c/busses/i2c-velleman.c
--- linux-post-2.6.4rc2-20040307/drivers/i2c/busses/i2c-velleman.c	2004-02-20 05:29:11.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/i2c/busses/i2c-velleman.c	2004-03-07 07:17:43.000000000 +0000
@@ -138,7 +138,7 @@ static int __init i2c_bitvelle_init(void
 			return -ENODEV;
 		}
 	}
-	pr_debug("i2c-velleman: found device at %#x.\n",base);
+	pr_debug("i2c-velleman: found device at %#lx.\n",base);
 	return 0;
 }
 
diff -purN linux-post-2.6.4rc2-20040307/drivers/ide/Kconfig linux-post-2.6.4rc2-20040309/drivers/ide/Kconfig
--- linux-post-2.6.4rc2-20040307/drivers/ide/Kconfig	2004-02-05 19:38:13.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/ide/Kconfig	2004-03-08 20:38:35.000000000 +0000
@@ -699,8 +699,8 @@ config BLK_DEV_PDC202XX_OLD
 
 config PDC202XX_BURST
 	bool "Special UDMA Feature"
-	depends on BLK_DEV_PDC202XX_OLD=y
-	---help---
+	depends on BLK_DEV_PDC202XX_OLD
+	help
 	  This option causes the pdc202xx driver to enable UDMA modes on the
 	  PDC202xx even when the PDC202xx BIOS has not done so.
 
@@ -720,7 +720,7 @@ config BLK_DEV_PDC202XX_NEW
 # FIXME - probably wants to be one for old and for new
 config PDC202XX_FORCE
 	bool "Enable controller even if disabled by BIOS"
-	depends on BLK_DEV_PDC202XX_NEW=y
+	depends on BLK_DEV_PDC202XX_NEW
 	help
 	  Enable the PDC202xx controller even if it has been disabled in the BIOS setup.
 
diff -purN linux-post-2.6.4rc2-20040307/drivers/md/Kconfig linux-post-2.6.4rc2-20040309/drivers/md/Kconfig
--- linux-post-2.6.4rc2-20040307/drivers/md/Kconfig	2004-02-19 03:43:14.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/md/Kconfig	2004-03-07 07:04:56.000000000 +0000
@@ -162,14 +162,6 @@ config BLK_DEV_DM
 
 	  If unsure, say N.
 
-config DM_IOCTL_V4
-	bool "ioctl interface version 4"
-	depends on BLK_DEV_DM
-	default y
-	---help---
-	  Recent tools use a new version of the ioctl interface, only
-          select this option if you intend using such tools.
-
 config DM_CRYPT
 	tristate "Crypt target support"
 	depends on BLK_DEV_DM && EXPERIMENTAL
diff -purN linux-post-2.6.4rc2-20040307/drivers/md/dm-ioctl-v1.c linux-post-2.6.4rc2-20040309/drivers/md/dm-ioctl-v1.c
--- linux-post-2.6.4rc2-20040307/drivers/md/dm-ioctl-v1.c	2003-12-29 21:38:35.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/md/dm-ioctl-v1.c	1970-01-01 00:00:00.000000000 +0000
@@ -1,1159 +0,0 @@
-/*
- * Copyright (C) 2001, 2002 Sistina Software (UK) Limited.
- *
- * This file is released under the GPL.
- */
-
-#include "dm.h"
-
-#include <linux/module.h>
-#include <linux/vmalloc.h>
-#include <linux/miscdevice.h>
-#include <linux/dm-ioctl.h>
-#include <linux/init.h>
-#include <linux/wait.h>
-#include <linux/slab.h>
-#include <linux/devfs_fs_kernel.h>
-
-#include <asm/uaccess.h>
-
-#define DM_DRIVER_EMAIL "dm@uk.sistina.com"
-
-/*-----------------------------------------------------------------
- * The ioctl interface needs to be able to look up devices by
- * name or uuid.
- *---------------------------------------------------------------*/
-struct hash_cell {
-	struct list_head name_list;
-	struct list_head uuid_list;
-
-	char *name;
-	char *uuid;
-	struct mapped_device *md;
-};
-
-#define NUM_BUCKETS 64
-#define MASK_BUCKETS (NUM_BUCKETS - 1)
-static struct list_head _name_buckets[NUM_BUCKETS];
-static struct list_head _uuid_buckets[NUM_BUCKETS];
-
-void dm_hash_remove_all(void);
-
-/*
- * Guards access to all three tables.
- */
-static DECLARE_RWSEM(_hash_lock);
-
-static void init_buckets(struct list_head *buckets)
-{
-	unsigned int i;
-
-	for (i = 0; i < NUM_BUCKETS; i++)
-		INIT_LIST_HEAD(buckets + i);
-}
-
-int dm_hash_init(void)
-{
-	init_buckets(_name_buckets);
-	init_buckets(_uuid_buckets);
-	devfs_mk_dir(DM_DIR);
-	return 0;
-}
-
-void dm_hash_exit(void)
-{
-	dm_hash_remove_all();
-	devfs_remove(DM_DIR);
-}
-
-/*-----------------------------------------------------------------
- * Hash function:
- * We're not really concerned with the str hash function being
- * fast since it's only used by the ioctl interface.
- *---------------------------------------------------------------*/
-static unsigned int hash_str(const char *str)
-{
-	const unsigned int hash_mult = 2654435387U;
-	unsigned int h = 0;
-
-	while (*str)
-		h = (h + (unsigned int) *str++) * hash_mult;
-
-	return h & MASK_BUCKETS;
-}
-
-/*-----------------------------------------------------------------
- * Code for looking up a device by name
- *---------------------------------------------------------------*/
-static struct hash_cell *__get_name_cell(const char *str)
-{
-	struct list_head *tmp;
-	struct hash_cell *hc;
-	unsigned int h = hash_str(str);
-
-	list_for_each (tmp, _name_buckets + h) {
-		hc = list_entry(tmp, struct hash_cell, name_list);
-		if (!strcmp(hc->name, str))
-			return hc;
-	}
-
-	return NULL;
-}
-
-static struct hash_cell *__get_uuid_cell(const char *str)
-{
-	struct list_head *tmp;
-	struct hash_cell *hc;
-	unsigned int h = hash_str(str);
-
-	list_for_each (tmp, _uuid_buckets + h) {
-		hc = list_entry(tmp, struct hash_cell, uuid_list);
-		if (!strcmp(hc->uuid, str))
-			return hc;
-	}
-
-	return NULL;
-}
-
-/*-----------------------------------------------------------------
- * Inserting, removing and renaming a device.
- *---------------------------------------------------------------*/
-static inline char *kstrdup(const char *str)
-{
-	char *r = kmalloc(strlen(str) + 1, GFP_KERNEL);
-	if (r)
-		strcpy(r, str);
-	return r;
-}
-
-static struct hash_cell *alloc_cell(const char *name, const char *uuid,
-				    struct mapped_device *md)
-{
-	struct hash_cell *hc;
-
-	hc = kmalloc(sizeof(*hc), GFP_KERNEL);
-	if (!hc)
-		return NULL;
-
-	hc->name = kstrdup(name);
-	if (!hc->name) {
-		kfree(hc);
-		return NULL;
-	}
-
-	if (!uuid)
-		hc->uuid = NULL;
-
-	else {
-		hc->uuid = kstrdup(uuid);
-		if (!hc->uuid) {
-			kfree(hc->name);
-			kfree(hc);
-			return NULL;
-		}
-	}
-
-	INIT_LIST_HEAD(&hc->name_list);
-	INIT_LIST_HEAD(&hc->uuid_list);
-	hc->md = md;
-	return hc;
-}
-
-static void free_cell(struct hash_cell *hc)
-{
-	if (hc) {
-		kfree(hc->name);
-		kfree(hc->uuid);
-		kfree(hc);
-	}
-}
-
-/*
- * devfs stuff.
- */
-static int register_with_devfs(struct hash_cell *hc)
-{
-	struct gendisk *disk = dm_disk(hc->md);
-
-	devfs_mk_bdev(MKDEV(disk->major, disk->first_minor),
-		       S_IFBLK | S_IRUSR | S_IWUSR | S_IRGRP,
-		       DM_DIR "/%s", hc->name);
-	return 0;
-}
-
-static int unregister_with_devfs(struct hash_cell *hc)
-{
-	devfs_remove(DM_DIR"/%s", hc->name);
-	return 0;
-}
-
-/*
- * The kdev_t and uuid of a device can never change once it is
- * initially inserted.
- */
-int dm_hash_insert(const char *name, const char *uuid, struct mapped_device *md)
-{
-	struct hash_cell *cell;
-
-	/*
-	 * Allocate the new cells.
-	 */
-	cell = alloc_cell(name, uuid, md);
-	if (!cell)
-		return -ENOMEM;
-
-	/*
-	 * Insert the cell into all three hash tables.
-	 */
-	down_write(&_hash_lock);
-	if (__get_name_cell(name))
-		goto bad;
-
-	list_add(&cell->name_list, _name_buckets + hash_str(name));
-
-	if (uuid) {
-		if (__get_uuid_cell(uuid)) {
-			list_del(&cell->name_list);
-			goto bad;
-		}
-		list_add(&cell->uuid_list, _uuid_buckets + hash_str(uuid));
-	}
-	register_with_devfs(cell);
-	dm_get(md);
-	up_write(&_hash_lock);
-
-	return 0;
-
- bad:
-	up_write(&_hash_lock);
-	free_cell(cell);
-	return -EBUSY;
-}
-
-void __hash_remove(struct hash_cell *hc)
-{
-	/* remove from the dev hash */
-	list_del(&hc->uuid_list);
-	list_del(&hc->name_list);
-	unregister_with_devfs(hc);
-	dm_put(hc->md);
-	free_cell(hc);
-}
-
-void dm_hash_remove_all(void)
-{
-	int i;
-	struct hash_cell *hc;
-	struct list_head *tmp, *n;
-
-	down_write(&_hash_lock);
-	for (i = 0; i < NUM_BUCKETS; i++) {
-		list_for_each_safe (tmp, n, _name_buckets + i) {
-			hc = list_entry(tmp, struct hash_cell, name_list);
-			__hash_remove(hc);
-		}
-	}
-	up_write(&_hash_lock);
-}
-
-int dm_hash_rename(const char *old, const char *new)
-{
-	char *new_name, *old_name;
-	struct hash_cell *hc;
-
-	/*
-	 * duplicate new.
-	 */
-	new_name = kstrdup(new);
-	if (!new_name)
-		return -ENOMEM;
-
-	down_write(&_hash_lock);
-
-	/*
-	 * Is new free ?
-	 */
-	hc = __get_name_cell(new);
-	if (hc) {
-		DMWARN("asked to rename to an already existing name %s -> %s",
-		       old, new);
-		up_write(&_hash_lock);
-		kfree(new_name);
-		return -EBUSY;
-	}
-
-	/*
-	 * Is there such a device as 'old' ?
-	 */
-	hc = __get_name_cell(old);
-	if (!hc) {
-		DMWARN("asked to rename a non existent device %s -> %s",
-		       old, new);
-		up_write(&_hash_lock);
-		kfree(new_name);
-		return -ENXIO;
-	}
-
-	/*
-	 * rename and move the name cell.
-	 */
-	unregister_with_devfs(hc);
-
-	list_del(&hc->name_list);
-	old_name = hc->name;
-	hc->name = new_name;
-	list_add(&hc->name_list, _name_buckets + hash_str(new_name));
-
-	/* rename the device node in devfs */
-	register_with_devfs(hc);
-
-	up_write(&_hash_lock);
-	kfree(old_name);
-	return 0;
-}
-
-
-/*-----------------------------------------------------------------
- * Implementation of the ioctl commands
- *---------------------------------------------------------------*/
-
-/*
- * All the ioctl commands get dispatched to functions with this
- * prototype.
- */
-typedef int (*ioctl_fn)(struct dm_ioctl *param, struct dm_ioctl *user);
-
-/*
- * Check a string doesn't overrun the chunk of
- * memory we copied from userland.
- */
-static int valid_str(char *str, void *begin, void *end)
-{
-	while (((void *) str >= begin) && ((void *) str < end))
-		if (!*str++)
-			return 0;
-
-	return -EINVAL;
-}
-
-static int next_target(struct dm_target_spec *last, uint32_t next,
-		       void *begin, void *end,
-		       struct dm_target_spec **spec, char **params)
-{
-	*spec = (struct dm_target_spec *)
-	    ((unsigned char *) last + next);
-	*params = (char *) (*spec + 1);
-
-	if (*spec < (last + 1) || ((void *) *spec > end))
-		return -EINVAL;
-
-	return valid_str(*params, begin, end);
-}
-
-static int populate_table(struct dm_table *table, struct dm_ioctl *args)
-{
-	int r, first = 1;
-	unsigned int i = 0;
-	struct dm_target_spec *spec;
-	char *params;
-	void *begin, *end;
-
-	if (!args->target_count) {
-		DMWARN("populate_table: no targets specified");
-		return -EINVAL;
-	}
-
-	begin = (void *) args;
-	end = begin + args->data_size;
-
-	for (i = 0; i < args->target_count; i++) {
-
-		if (first)
-			r = next_target((struct dm_target_spec *) args,
-					args->data_start,
-					begin, end, &spec, &params);
-		else
-			r = next_target(spec, spec->next, begin, end,
-					&spec, &params);
-
-		if (r) {
-			DMWARN("unable to find target");
-			return -EINVAL;
-		}
-
-		r = dm_table_add_target(table, spec->target_type,
-					(sector_t) spec->sector_start,
-					(sector_t) spec->length,
-					params);
-		if (r) {
-			DMWARN("internal error adding target to table");
-			return -EINVAL;
-		}
-
-		first = 0;
-	}
-
-	return dm_table_complete(table);
-}
-
-/*
- * Round up the ptr to the next 'align' boundary.  Obviously
- * 'align' must be a power of 2.
- */
-static inline void *align_ptr(void *ptr, unsigned int align)
-{
-	align--;
-	return (void *) (((unsigned long) (ptr + align)) & ~align);
-}
-
-/*
- * Copies a dm_ioctl and an optional additional payload to
- * userland.
- */
-static int results_to_user(struct dm_ioctl *user, struct dm_ioctl *param,
-			   void *data, uint32_t len)
-{
-	int r;
-	void *ptr = NULL;
-
-	if (data) {
-		ptr = align_ptr(user + 1, sizeof(unsigned long));
-		param->data_start = ptr - (void *) user;
-	}
-
-	/*
-	 * The version number has already been filled in, so we
-	 * just copy later fields.
-	 */
-	r = copy_to_user(&user->data_size, &param->data_size,
-			 sizeof(*param) - sizeof(param->version));
-	if (r)
-		return -EFAULT;
-
-	if (data) {
-		if (param->data_start + len > param->data_size)
-			return -ENOSPC;
-
-		if (copy_to_user(ptr, data, len))
-			r = -EFAULT;
-	}
-
-	return r;
-}
-
-/*
- * Fills in a dm_ioctl structure, ready for sending back to
- * userland.
- */
-static int __info(struct mapped_device *md, struct dm_ioctl *param)
-{
-	struct dm_table *table;
-	struct block_device *bdev;
-	struct gendisk *disk = dm_disk(md);
-
-	param->flags = DM_EXISTS_FLAG;
-	if (dm_suspended(md))
-		param->flags |= DM_SUSPEND_FLAG;
-
-	bdev = bdget_disk(disk, 0);
-	if (!bdev)
-		return -ENXIO;
-
-	param->dev = old_encode_dev(bdev->bd_dev);
-	param->open_count = bdev->bd_openers;
-	bdput(bdev);
-
-	if (disk->policy)
-		param->flags |= DM_READONLY_FLAG;
-
-	table = dm_get_table(md);
-	param->target_count = dm_table_get_num_targets(table);
-	dm_table_put(table);
-
-	return 0;
-}
-
-/*
- * Always use UUID for lookups if it's present, otherwise use name.
- */
-static inline struct mapped_device *find_device(struct dm_ioctl *param)
-{
-	struct hash_cell *hc;
-	struct mapped_device *md = NULL;
-
-	down_read(&_hash_lock);
-	hc = *param->uuid ? __get_uuid_cell(param->uuid) :
-		__get_name_cell(param->name);
-	if (hc) {
-		md = hc->md;
-
-		/*
-		 * Sneakily write in both the name and the uuid
-		 * while we have the cell.
-		 */
-		strlcpy(param->name, hc->name, sizeof(param->name));
-		if (hc->uuid)
-			strlcpy(param->uuid, hc->uuid, sizeof(param->uuid));
-		else
-			param->uuid[0] = '\0';
-
-		dm_get(md);
-	}
-	up_read(&_hash_lock);
-
-	return md;
-}
-
-#define ALIGNMENT sizeof(int)
-static void *_align(void *ptr, unsigned int a)
-{
-	register unsigned long align = --a;
-
-	return (void *) (((unsigned long) ptr + align) & ~align);
-}
-
-/*
- * Copies device info back to user space, used by
- * the create and info ioctls.
- */
-static int info(struct dm_ioctl *param, struct dm_ioctl *user)
-{
-	struct mapped_device *md;
-
-	param->flags = 0;
-
-	md = find_device(param);
-	if (!md)
-		/*
-		 * Device not found - returns cleared exists flag.
-		 */
-		goto out;
-
-	__info(md, param);
-	dm_put(md);
-
-      out:
-	return results_to_user(user, param, NULL, 0);
-}
-
-static inline int get_mode(struct dm_ioctl *param)
-{
-	int mode = FMODE_READ | FMODE_WRITE;
-
-	if (param->flags & DM_READONLY_FLAG)
-		mode = FMODE_READ;
-
-	return mode;
-}
-
-static int check_name(const char *name)
-{
-	if (name[0] == '/') {
-		DMWARN("invalid device name");
-		return -EINVAL;
-	}
-
-	return 0;
-}
-
-static int create(struct dm_ioctl *param, struct dm_ioctl *user)
-{
-	int r;
-	struct dm_table *t;
-	struct mapped_device *md;
-
-	r = check_name(param->name);
-	if (r)
-		return r;
-
-	r = dm_table_create(&t, get_mode(param), param->target_count);
-	if (r)
-		return r;
-
-	r = populate_table(t, param);
-	if (r) {
-		dm_table_put(t);
-		return r;
-	}
-
-	if (param->flags & DM_PERSISTENT_DEV_FLAG)
-		r = dm_create_with_minor(MINOR(old_decode_dev(param->dev)), &md);
-	else
-		r = dm_create(&md);
-
-	if (r) {
-		dm_table_put(t);
-		return r;
-	}
-
-	/* suspend the device */
-	r = dm_suspend(md);
-	if (r) {
-		DMWARN("suspend failed");
-		dm_table_put(t);
-		dm_put(md);
-		return r;
-	}
-	/* swap in the table */
-	r = dm_swap_table(md, t);
-	if (r) {
-		DMWARN("table swap failed");
-		dm_table_put(t);
-		dm_put(md);
-		return r;
-	}
-
-	/* resume the device */
-	r = dm_resume(md);
-	if (r) {
-		DMWARN("resume failed");
-		dm_table_put(t);
-		dm_put(md);
-		return r;
-	}
-
-	dm_table_put(t);	/* md will have grabbed its own reference */
-
-	set_disk_ro(dm_disk(md), (param->flags & DM_READONLY_FLAG) ? 1 : 0);
-	r = dm_hash_insert(param->name, *param->uuid ? param->uuid : NULL, md);
-	dm_put(md);
-
-	return r ? r : info(param, user);
-}
-
-/*
- * Build up the status struct for each target
- */
-static int __status(struct mapped_device *md, struct dm_ioctl *param,
-		    char *outbuf, size_t *len)
-{
-	unsigned int i, num_targets;
-	struct dm_target_spec *spec;
-	char *outptr;
-	status_type_t type;
-	struct dm_table *table = dm_get_table(md);
-
-	if (param->flags & DM_STATUS_TABLE_FLAG)
-		type = STATUSTYPE_TABLE;
-	else
-		type = STATUSTYPE_INFO;
-
-	outptr = outbuf;
-
-	/* Get all the target info */
-	num_targets = dm_table_get_num_targets(table);
-	for (i = 0; i < num_targets; i++) {
-		struct dm_target *ti = dm_table_get_target(table, i);
-
-		if (outptr - outbuf +
-		    sizeof(struct dm_target_spec) > param->data_size) {
-			dm_table_put(table);
-			return -ENOMEM;
-		}
-
-		spec = (struct dm_target_spec *) outptr;
-
-		spec->status = 0;
-		spec->sector_start = ti->begin;
-		spec->length = ti->len;
-		strlcpy(spec->target_type, ti->type->name,
-			sizeof(spec->target_type));
-
-		outptr += sizeof(struct dm_target_spec);
-
-		/* Get the status/table string from the target driver */
-		if (ti->type->status)
-			ti->type->status(ti, type, outptr,
-					 outbuf + param->data_size - outptr);
-		else
-			outptr[0] = '\0';
-
-		outptr += strlen(outptr) + 1;
-		_align(outptr, ALIGNMENT);
-		spec->next = outptr - outbuf;
-	}
-
-	param->target_count = num_targets;
-	*len = outptr - outbuf;
-	dm_table_put(table);
-
-	return 0;
-}
-
-/*
- * Return the status of a device as a text string for each
- * target.
- */
-static int get_status(struct dm_ioctl *param, struct dm_ioctl *user)
-{
-	struct mapped_device *md;
-	size_t len = 0;
-	int ret;
-	char *outbuf = NULL;
-
-	md = find_device(param);
-	if (!md)
-		/*
-		 * Device not found - returns cleared exists flag.
-		 */
-		goto out;
-
-	/* We haven't a clue how long the resultant data will be so
-	   just allocate as much as userland has allowed us and make sure
-	   we don't overun it */
-	outbuf = kmalloc(param->data_size, GFP_KERNEL);
-	if (!outbuf)
-		goto out;
-	/*
-	 * Get the status of all targets
-	 */
-	__status(md, param, outbuf, &len);
-
-	/*
-	 * Setup the basic dm_ioctl structure.
-	 */
-	__info(md, param);
-
-      out:
-	if (md)
-		dm_put(md);
-
-	ret = results_to_user(user, param, outbuf, len);
-
-	if (outbuf)
-		kfree(outbuf);
-
-	return ret;
-}
-
-/*
- * Wait for a device to report an event
- */
-static int wait_device_event(struct dm_ioctl *param, struct dm_ioctl *user)
-{
-	struct mapped_device *md;
-	DECLARE_WAITQUEUE(wq, current);
-
-	md = find_device(param);
-	if (!md)
-		/*
-		 * Device not found - returns cleared exists flag.
-		 */
-		goto out;
-
-	/*
-	 * Setup the basic dm_ioctl structure.
-	 */
-	__info(md, param);
-
-	/*
-	 * Wait for a notification event
-	 */
-	set_current_state(TASK_INTERRUPTIBLE);
- 	if (!dm_add_wait_queue(md, &wq, dm_get_event_nr(md))) {
- 		schedule();
- 		dm_remove_wait_queue(md, &wq);
- 	}
-  	set_current_state(TASK_RUNNING);
- 	dm_put(md);
-
-      out:
-	return results_to_user(user, param, NULL, 0);
-}
-
-/*
- * Retrieves a list of devices used by a particular dm device.
- */
-static int dep(struct dm_ioctl *param, struct dm_ioctl *user)
-{
-	int r;
-	unsigned int count;
-	struct mapped_device *md;
-	struct list_head *tmp;
-	size_t len = 0;
-	struct dm_target_deps *deps = NULL;
-	struct dm_table *table;
-
-	md = find_device(param);
-	if (!md)
-		goto out;
-	table = dm_get_table(md);
-
-	/*
-	 * Setup the basic dm_ioctl structure.
-	 */
-	__info(md, param);
-
-	/*
-	 * Count the devices.
-	 */
-	count = 0;
-	list_for_each(tmp, dm_table_get_devices(table))
-	    count++;
-
-	/*
-	 * Allocate a kernel space version of the dm_target_status
-	 * struct.
-	 */
-	if (array_too_big(sizeof(*deps), sizeof(*deps->dev), count)) {
-		dm_table_put(table);
-		dm_put(md);
-		return -ENOMEM;
-	}
-
-	len = sizeof(*deps) + (sizeof(*deps->dev) * count);
-	deps = kmalloc(len, GFP_KERNEL);
-	if (!deps) {
-		dm_table_put(table);
-		dm_put(md);
-		return -ENOMEM;
-	}
-
-	/*
-	 * Fill in the devices.
-	 */
-	deps->count = count;
-	count = 0;
-	list_for_each(tmp, dm_table_get_devices(table)) {
-		struct dm_dev *dd = list_entry(tmp, struct dm_dev, list);
-		deps->dev[count++] = old_encode_dev(dd->bdev->bd_dev);
-	}
-	dm_table_put(table);
-	dm_put(md);
-
-      out:
-	r = results_to_user(user, param, deps, len);
-
-	kfree(deps);
-	return r;
-}
-
-static int remove(struct dm_ioctl *param, struct dm_ioctl *user)
-{
-	struct hash_cell *hc;
-
-	down_write(&_hash_lock);
-	hc = *param->uuid ? __get_uuid_cell(param->uuid) :
-		__get_name_cell(param->name);
-	if (!hc) {
-		DMWARN("device doesn't appear to be in the dev hash table.");
-		up_write(&_hash_lock);
-		return -EINVAL;
-	}
-
-	/*
-	 * You may ask the interface to drop its reference to an
-	 * in use device.  This is no different to unlinking a
-	 * file that someone still has open.  The device will not
-	 * actually be destroyed until the last opener closes it.
-	 * The name and uuid of the device (both are interface
-	 * properties) will be available for reuse immediately.
-	 *
-	 * You don't want to drop a _suspended_ device from the
-	 * interface, since that will leave you with no way of
-	 * resuming it.
-	 */
-	if (dm_suspended(hc->md)) {
-		DMWARN("refusing to remove a suspended device.");
-		up_write(&_hash_lock);
-		return -EPERM;
-	}
-
-	__hash_remove(hc);
-	up_write(&_hash_lock);
-	return 0;
-}
-
-static int remove_all(struct dm_ioctl *param, struct dm_ioctl *user)
-{
-	dm_hash_remove_all();
-	return 0;
-}
-
-static int suspend(struct dm_ioctl *param, struct dm_ioctl *user)
-{
-	int r;
-	struct mapped_device *md;
-
-	md = find_device(param);
-	if (!md)
-		return -ENXIO;
-
-	if (param->flags & DM_SUSPEND_FLAG)
-		r = dm_suspend(md);
-	else
-		r = dm_resume(md);
-
-	dm_put(md);
-	return r;
-}
-
-static int reload(struct dm_ioctl *param, struct dm_ioctl *user)
-{
-	int r;
-	struct mapped_device *md;
-	struct dm_table *t;
-
-	r = dm_table_create(&t, get_mode(param), param->target_count);
-	if (r)
-		return r;
-
-	r = populate_table(t, param);
-	if (r) {
-		dm_table_put(t);
-		return r;
-	}
-
-	md = find_device(param);
-	if (!md) {
-		dm_table_put(t);
-		return -ENXIO;
-	}
-
-	r = dm_swap_table(md, t);
-	if (r) {
-		dm_put(md);
-		dm_table_put(t);
-		return r;
-	}
-	dm_table_put(t);	/* md will have taken its own reference */
-
-	set_disk_ro(dm_disk(md), (param->flags & DM_READONLY_FLAG) ? 1 : 0);
-	dm_put(md);
-
-	r = info(param, user);
-	return r;
-}
-
-static int rename(struct dm_ioctl *param, struct dm_ioctl *user)
-{
-	int r;
-	char *new_name = (char *) param + param->data_start;
-
-	if (valid_str(new_name, (void *) param,
-		      (void *) param + param->data_size)) {
-		DMWARN("Invalid new logical volume name supplied.");
-		return -EINVAL;
-	}
-
-	r = check_name(new_name);
-	if (r)
-		return r;
-
-	return dm_hash_rename(param->name, new_name);
-}
-
-
-/*-----------------------------------------------------------------
- * Implementation of open/close/ioctl on the special char
- * device.
- *---------------------------------------------------------------*/
-static ioctl_fn lookup_ioctl(unsigned int cmd)
-{
-	static struct {
-		int cmd;
-		ioctl_fn fn;
-	} _ioctls[] = {
-		{DM_VERSION_CMD, NULL},	/* version is dealt with elsewhere */
-		{DM_REMOVE_ALL_CMD, remove_all},
-		{DM_DEV_CREATE_CMD, create},
-		{DM_DEV_REMOVE_CMD, remove},
-		{DM_DEV_RELOAD_CMD, reload},
-		{DM_DEV_RENAME_CMD, rename},
-		{DM_DEV_SUSPEND_CMD, suspend},
-		{DM_DEV_DEPS_CMD, dep},
-		{DM_DEV_STATUS_CMD, info},
-		{DM_TARGET_STATUS_CMD, get_status},
-		{DM_TARGET_WAIT_CMD, wait_device_event},
-	};
-
-	return (cmd >= ARRAY_SIZE(_ioctls)) ? NULL : _ioctls[cmd].fn;
-}
-
-/*
- * As well as checking the version compatibility this always
- * copies the kernel interface version out.
- */
-static int check_version(unsigned int cmd, struct dm_ioctl *user)
-{
-	uint32_t version[3];
-	int r = 0;
-
-	if (copy_from_user(version, user->version, sizeof(version)))
-		return -EFAULT;
-
-	if ((DM_VERSION_MAJOR != version[0]) ||
-	    (DM_VERSION_MINOR < version[1])) {
-		DMWARN("ioctl interface mismatch: "
-		       "kernel(%u.%u.%u), user(%u.%u.%u), cmd(%d)",
-		       DM_VERSION_MAJOR, DM_VERSION_MINOR,
-		       DM_VERSION_PATCHLEVEL,
-		       version[0], version[1], version[2], cmd);
-		r = -EINVAL;
-	}
-
-	/*
-	 * Fill in the kernel version.
-	 */
-	version[0] = DM_VERSION_MAJOR;
-	version[1] = DM_VERSION_MINOR;
-	version[2] = DM_VERSION_PATCHLEVEL;
-	if (copy_to_user(user->version, version, sizeof(version)))
-		return -EFAULT;
-
-	return r;
-}
-
-static void free_params(struct dm_ioctl *param)
-{
-	vfree(param);
-}
-
-static int copy_params(struct dm_ioctl *user, struct dm_ioctl **param)
-{
-	struct dm_ioctl tmp, *dmi;
-
-	if (copy_from_user(&tmp, user, sizeof(tmp)))
-		return -EFAULT;
-
-	if (tmp.data_size < sizeof(tmp))
-		return -EINVAL;
-
-	dmi = (struct dm_ioctl *) vmalloc(tmp.data_size);
-	if (!dmi)
-		return -ENOMEM;
-
-	if (copy_from_user(dmi, user, tmp.data_size)) {
-		vfree(dmi);
-		return -EFAULT;
-	}
-
-	*param = dmi;
-	return 0;
-}
-
-static int validate_params(uint cmd, struct dm_ioctl *param)
-{
-	/* Ignores parameters */
-	if (cmd == DM_REMOVE_ALL_CMD)
-		return 0;
-
-	/* Unless creating, either name of uuid but not both */
-	if (cmd != DM_DEV_CREATE_CMD) {
-		if ((!*param->uuid && !*param->name) ||
-		    (*param->uuid && *param->name)) {
-			DMWARN("one of name or uuid must be supplied");
-			return -EINVAL;
-		}
-	}
-
-	/* Ensure strings are terminated */
-	param->name[DM_NAME_LEN - 1] = '\0';
-	param->uuid[DM_UUID_LEN - 1] = '\0';
-
-	return 0;
-}
-
-static int ctl_ioctl(struct inode *inode, struct file *file,
-		     uint command, ulong u)
-{
-	int r = 0;
-	unsigned int cmd;
-	struct dm_ioctl *param;
-	struct dm_ioctl *user = (struct dm_ioctl *) u;
-	ioctl_fn fn = NULL;
-
-	/* only root can play with this */
-	if (!capable(CAP_SYS_ADMIN))
-		return -EACCES;
-
-	if (_IOC_TYPE(command) != DM_IOCTL)
-		return -ENOTTY;
-
-	cmd = _IOC_NR(command);
-
-	/*
-	 * Check the interface version passed in.  This also
-	 * writes out the kernels interface version.
-	 */
-	r = check_version(cmd, user);
-	if (r)
-		return r;
-
-	/*
-	 * Nothing more to do for the version command.
-	 */
-	if (cmd == DM_VERSION_CMD)
-		return 0;
-
-	fn = lookup_ioctl(cmd);
-	if (!fn) {
-		DMWARN("dm_ctl_ioctl: unknown command 0x%x", command);
-		return -ENOTTY;
-	}
-
-	/*
-	 * Copy the parameters into kernel space.
-	 */
-	r = copy_params(user, &param);
-	if (r)
-		return r;
-
-	r = validate_params(cmd, param);
-	if (r) {
-		free_params(param);
-		return r;
-	}
-
-	r = fn(param, user);
-	free_params(param);
-	return r;
-}
-
-static struct file_operations _ctl_fops = {
-	.ioctl	 = ctl_ioctl,
-	.owner	 = THIS_MODULE,
-};
-
-static struct miscdevice _dm_misc = {
-	.minor		= MISC_DYNAMIC_MINOR,
-	.name		= DM_NAME,
-	.devfs_name	= "mapper/control",
-	.fops		= &_ctl_fops
-};
-
-/*
- * Create misc character device and link to DM_DIR/control.
- */
-int __init dm_interface_init(void)
-{
-	int r;
-
-	r = dm_hash_init();
-	if (r)
-		return r;
-
-	r = misc_register(&_dm_misc);
-	if (r) {
-		DMERR("misc_register failed for control device");
-		dm_hash_exit();
-		return r;
-	}
-
-	DMINFO("%d.%d.%d%s initialised: %s", DM_VERSION_MAJOR,
-	       DM_VERSION_MINOR, DM_VERSION_PATCHLEVEL, DM_VERSION_EXTRA,
-	       DM_DRIVER_EMAIL);
-	return 0;
-
-	if (misc_deregister(&_dm_misc) < 0)
-		DMERR("misc_deregister failed for control device");
-	dm_hash_exit();
-	return r;
-}
-
-void dm_interface_exit(void)
-{
-	if (misc_deregister(&_dm_misc) < 0)
-		DMERR("misc_deregister failed for control device");
-	dm_hash_exit();
-}
diff -purN linux-post-2.6.4rc2-20040307/drivers/md/dm-ioctl-v4.c linux-post-2.6.4rc2-20040309/drivers/md/dm-ioctl-v4.c
--- linux-post-2.6.4rc2-20040307/drivers/md/dm-ioctl-v4.c	2003-12-29 21:38:35.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/md/dm-ioctl-v4.c	1970-01-01 00:00:00.000000000 +0000
@@ -1,1264 +0,0 @@
-/*
- * Copyright (C) 2001, 2002 Sistina Software (UK) Limited.
- *
- * This file is released under the GPL.
- */
-
-#include "dm.h"
-
-#include <linux/module.h>
-#include <linux/vmalloc.h>
-#include <linux/miscdevice.h>
-#include <linux/init.h>
-#include <linux/wait.h>
-#include <linux/slab.h>
-#include <linux/devfs_fs_kernel.h>
-#include <linux/dm-ioctl.h>
-
-#include <asm/uaccess.h>
-
-#define DM_DRIVER_EMAIL "dm@uk.sistina.com"
-
-/*-----------------------------------------------------------------
- * The ioctl interface needs to be able to look up devices by
- * name or uuid.
- *---------------------------------------------------------------*/
-struct hash_cell {
-	struct list_head name_list;
-	struct list_head uuid_list;
-
-	char *name;
-	char *uuid;
-	struct mapped_device *md;
-	struct dm_table *new_map;
-};
-
-#define NUM_BUCKETS 64
-#define MASK_BUCKETS (NUM_BUCKETS - 1)
-static struct list_head _name_buckets[NUM_BUCKETS];
-static struct list_head _uuid_buckets[NUM_BUCKETS];
-
-void dm_hash_remove_all(void);
-
-/*
- * Guards access to both hash tables.
- */
-static DECLARE_RWSEM(_hash_lock);
-
-static void init_buckets(struct list_head *buckets)
-{
-	unsigned int i;
-
-	for (i = 0; i < NUM_BUCKETS; i++)
-		INIT_LIST_HEAD(buckets + i);
-}
-
-int dm_hash_init(void)
-{
-	init_buckets(_name_buckets);
-	init_buckets(_uuid_buckets);
-	devfs_mk_dir(DM_DIR);
-	return 0;
-}
-
-void dm_hash_exit(void)
-{
-	dm_hash_remove_all();
-	devfs_remove(DM_DIR);
-}
-
-/*-----------------------------------------------------------------
- * Hash function:
- * We're not really concerned with the str hash function being
- * fast since it's only used by the ioctl interface.
- *---------------------------------------------------------------*/
-static unsigned int hash_str(const char *str)
-{
-	const unsigned int hash_mult = 2654435387U;
-	unsigned int h = 0;
-
-	while (*str)
-		h = (h + (unsigned int) *str++) * hash_mult;
-
-	return h & MASK_BUCKETS;
-}
-
-/*-----------------------------------------------------------------
- * Code for looking up a device by name
- *---------------------------------------------------------------*/
-static struct hash_cell *__get_name_cell(const char *str)
-{
-	struct list_head *tmp;
-	struct hash_cell *hc;
-	unsigned int h = hash_str(str);
-
-	list_for_each (tmp, _name_buckets + h) {
-		hc = list_entry(tmp, struct hash_cell, name_list);
-		if (!strcmp(hc->name, str))
-			return hc;
-	}
-
-	return NULL;
-}
-
-static struct hash_cell *__get_uuid_cell(const char *str)
-{
-	struct list_head *tmp;
-	struct hash_cell *hc;
-	unsigned int h = hash_str(str);
-
-	list_for_each (tmp, _uuid_buckets + h) {
-		hc = list_entry(tmp, struct hash_cell, uuid_list);
-		if (!strcmp(hc->uuid, str))
-			return hc;
-	}
-
-	return NULL;
-}
-
-/*-----------------------------------------------------------------
- * Inserting, removing and renaming a device.
- *---------------------------------------------------------------*/
-static inline char *kstrdup(const char *str)
-{
-	char *r = kmalloc(strlen(str) + 1, GFP_KERNEL);
-	if (r)
-		strcpy(r, str);
-	return r;
-}
-
-static struct hash_cell *alloc_cell(const char *name, const char *uuid,
-				    struct mapped_device *md)
-{
-	struct hash_cell *hc;
-
-	hc = kmalloc(sizeof(*hc), GFP_KERNEL);
-	if (!hc)
-		return NULL;
-
-	hc->name = kstrdup(name);
-	if (!hc->name) {
-		kfree(hc);
-		return NULL;
-	}
-
-	if (!uuid)
-		hc->uuid = NULL;
-
-	else {
-		hc->uuid = kstrdup(uuid);
-		if (!hc->uuid) {
-			kfree(hc->name);
-			kfree(hc);
-			return NULL;
-		}
-	}
-
-	INIT_LIST_HEAD(&hc->name_list);
-	INIT_LIST_HEAD(&hc->uuid_list);
-	hc->md = md;
-	hc->new_map = NULL;
-	return hc;
-}
-
-static void free_cell(struct hash_cell *hc)
-{
-	if (hc) {
-		kfree(hc->name);
-		kfree(hc->uuid);
-		kfree(hc);
-	}
-}
-
-/*
- * devfs stuff.
- */
-static int register_with_devfs(struct hash_cell *hc)
-{
-	struct gendisk *disk = dm_disk(hc->md);
-
-	devfs_mk_bdev(MKDEV(disk->major, disk->first_minor),
-		      S_IFBLK | S_IRUSR | S_IWUSR | S_IRGRP,
-		      DM_DIR "/%s", hc->name);
-	return 0;
-}
-
-static int unregister_with_devfs(struct hash_cell *hc)
-{
-	devfs_remove(DM_DIR"/%s", hc->name);
-	return 0;
-}
-
-/*
- * The kdev_t and uuid of a device can never change once it is
- * initially inserted.
- */
-int dm_hash_insert(const char *name, const char *uuid, struct mapped_device *md)
-{
-	struct hash_cell *cell;
-
-	/*
-	 * Allocate the new cells.
-	 */
-	cell = alloc_cell(name, uuid, md);
-	if (!cell)
-		return -ENOMEM;
-
-	/*
-	 * Insert the cell into both hash tables.
-	 */
-	down_write(&_hash_lock);
-	if (__get_name_cell(name))
-		goto bad;
-
-	list_add(&cell->name_list, _name_buckets + hash_str(name));
-
-	if (uuid) {
-		if (__get_uuid_cell(uuid)) {
-			list_del(&cell->name_list);
-			goto bad;
-		}
-		list_add(&cell->uuid_list, _uuid_buckets + hash_str(uuid));
-	}
-	register_with_devfs(cell);
-	dm_get(md);
-	up_write(&_hash_lock);
-
-	return 0;
-
- bad:
-	up_write(&_hash_lock);
-	free_cell(cell);
-	return -EBUSY;
-}
-
-void __hash_remove(struct hash_cell *hc)
-{
-	/* remove from the dev hash */
-	list_del(&hc->uuid_list);
-	list_del(&hc->name_list);
-	unregister_with_devfs(hc);
-	dm_put(hc->md);
-	if (hc->new_map)
-		dm_table_put(hc->new_map);
-	free_cell(hc);
-}
-
-void dm_hash_remove_all(void)
-{
-	int i;
-	struct hash_cell *hc;
-	struct list_head *tmp, *n;
-
-	down_write(&_hash_lock);
-	for (i = 0; i < NUM_BUCKETS; i++) {
-		list_for_each_safe (tmp, n, _name_buckets + i) {
-			hc = list_entry(tmp, struct hash_cell, name_list);
-			__hash_remove(hc);
-		}
-	}
-	up_write(&_hash_lock);
-}
-
-int dm_hash_rename(const char *old, const char *new)
-{
-	char *new_name, *old_name;
-	struct hash_cell *hc;
-
-	/*
-	 * duplicate new.
-	 */
-	new_name = kstrdup(new);
-	if (!new_name)
-		return -ENOMEM;
-
-	down_write(&_hash_lock);
-
-	/*
-	 * Is new free ?
-	 */
-	hc = __get_name_cell(new);
-	if (hc) {
-		DMWARN("asked to rename to an already existing name %s -> %s",
-		       old, new);
-		up_write(&_hash_lock);
-		kfree(new_name);
-		return -EBUSY;
-	}
-
-	/*
-	 * Is there such a device as 'old' ?
-	 */
-	hc = __get_name_cell(old);
-	if (!hc) {
-		DMWARN("asked to rename a non existent device %s -> %s",
-		       old, new);
-		up_write(&_hash_lock);
-		kfree(new_name);
-		return -ENXIO;
-	}
-
-	/*
-	 * rename and move the name cell.
-	 */
-	unregister_with_devfs(hc);
-
-	list_del(&hc->name_list);
-	old_name = hc->name;
-	hc->name = new_name;
-	list_add(&hc->name_list, _name_buckets + hash_str(new_name));
-
-	/* rename the device node in devfs */
-	register_with_devfs(hc);
-
-	up_write(&_hash_lock);
-	kfree(old_name);
-	return 0;
-}
-
-/*-----------------------------------------------------------------
- * Implementation of the ioctl commands
- *---------------------------------------------------------------*/
-/*
- * All the ioctl commands get dispatched to functions with this
- * prototype.
- */
-typedef int (*ioctl_fn)(struct dm_ioctl *param, size_t param_size);
-
-static int remove_all(struct dm_ioctl *param, size_t param_size)
-{
-	dm_hash_remove_all();
-	param->data_size = 0;
-	return 0;
-}
-
-/*
- * Round up the ptr to an 8-byte boundary.
- */
-#define ALIGN_MASK 7
-static inline void *align_ptr(void *ptr)
-{
-	return (void *) (((size_t) (ptr + ALIGN_MASK)) & ~ALIGN_MASK);
-}
-
-/*
- * Retrieves the data payload buffer from an already allocated
- * struct dm_ioctl.
- */
-static void *get_result_buffer(struct dm_ioctl *param, size_t param_size,
-			       size_t *len)
-{
-	param->data_start = align_ptr(param + 1) - (void *) param;
-
-	if (param->data_start < param_size)
-		*len = param_size - param->data_start;
-	else
-		*len = 0;
-
-	return ((void *) param) + param->data_start;
-}
-
-static int list_devices(struct dm_ioctl *param, size_t param_size)
-{
-	unsigned int i;
-	struct hash_cell *hc;
-	size_t len, needed = 0;
-	struct gendisk *disk;
-	struct dm_name_list *nl, *old_nl = NULL;
-
-	down_write(&_hash_lock);
-
-	/*
-	 * Loop through all the devices working out how much
-	 * space we need.
-	 */
-	for (i = 0; i < NUM_BUCKETS; i++) {
-		list_for_each_entry (hc, _name_buckets + i, name_list) {
-			needed += sizeof(struct dm_name_list);
-			needed += strlen(hc->name);
-			needed += ALIGN_MASK;
-		}
-	}
-
-	/*
-	 * Grab our output buffer.
-	 */
-	nl = get_result_buffer(param, param_size, &len);
-	if (len < needed) {
-		param->flags |= DM_BUFFER_FULL_FLAG;
-		goto out;
-	}
-	param->data_size = param->data_start + needed;
-
-	nl->dev = 0;	/* Flags no data */
-
-	/*
-	 * Now loop through filling out the names.
-	 */
-	for (i = 0; i < NUM_BUCKETS; i++) {
-		list_for_each_entry (hc, _name_buckets + i, name_list) {
-			if (old_nl)
-				old_nl->next = (uint32_t) ((void *) nl -
-							   (void *) old_nl);
-			disk = dm_disk(hc->md);
-			nl->dev = huge_encode_dev(MKDEV(disk->major, disk->first_minor));
-			nl->next = 0;
-			strcpy(nl->name, hc->name);
-
-			old_nl = nl;
-			nl = align_ptr(((void *) ++nl) + strlen(hc->name) + 1);
-		}
-	}
-
- out:
-	up_write(&_hash_lock);
-	return 0;
-}
-
-static int check_name(const char *name)
-{
-	if (strchr(name, '/')) {
-		DMWARN("invalid device name");
-		return -EINVAL;
-	}
-
-	return 0;
-}
-
-/*
- * Fills in a dm_ioctl structure, ready for sending back to
- * userland.
- */
-static int __dev_status(struct mapped_device *md, struct dm_ioctl *param)
-{
-	struct gendisk *disk = dm_disk(md);
-	struct dm_table *table;
-	struct block_device *bdev;
-
-	param->flags &= ~(DM_SUSPEND_FLAG | DM_READONLY_FLAG |
-			  DM_ACTIVE_PRESENT_FLAG);
-
-	if (dm_suspended(md))
-		param->flags |= DM_SUSPEND_FLAG;
-
-	bdev = bdget_disk(disk, 0);
-	if (!bdev)
-		return -ENXIO;
-
-	param->dev = huge_encode_dev(MKDEV(disk->major, disk->first_minor));
-
-	/*
-	 * Yes, this will be out of date by the time it gets back
-	 * to userland, but it is still very useful ofr
-	 * debugging.
-	 */
-	param->open_count = bdev->bd_openers;
-	bdput(bdev);
-
-	if (disk->policy)
-		param->flags |= DM_READONLY_FLAG;
-
-	param->event_nr = dm_get_event_nr(md);
-
-	table = dm_get_table(md);
-	if (table) {
-		param->flags |= DM_ACTIVE_PRESENT_FLAG;
-		param->target_count = dm_table_get_num_targets(table);
-		dm_table_put(table);
-	} else
-		param->target_count = 0;
-
-	return 0;
-}
-
-static int dev_create(struct dm_ioctl *param, size_t param_size)
-{
-	int r;
-	struct mapped_device *md;
-
-	r = check_name(param->name);
-	if (r)
-		return r;
-
-	if (param->flags & DM_PERSISTENT_DEV_FLAG)
-		r = dm_create_with_minor(MINOR(huge_decode_dev(param->dev)), &md);
-	else
-		r = dm_create(&md);
-
-	if (r)
-		return r;
-
-	r = dm_hash_insert(param->name, *param->uuid ? param->uuid : NULL, md);
-	if (r) {
-		dm_put(md);
-		return r;
-	}
-
-	param->flags &= ~DM_INACTIVE_PRESENT_FLAG;
-
-	r = __dev_status(md, param);
-	dm_put(md);
-
-	return r;
-}
-
-/*
- * Always use UUID for lookups if it's present, otherwise use name.
- */
-static inline struct hash_cell *__find_device_hash_cell(struct dm_ioctl *param)
-{
-	return *param->uuid ?
-	    __get_uuid_cell(param->uuid) : __get_name_cell(param->name);
-}
-
-static inline struct mapped_device *find_device(struct dm_ioctl *param)
-{
-	struct hash_cell *hc;
-	struct mapped_device *md = NULL;
-
-	down_read(&_hash_lock);
-	hc = __find_device_hash_cell(param);
-	if (hc) {
-		md = hc->md;
-
-		/*
-		 * Sneakily write in both the name and the uuid
-		 * while we have the cell.
-		 */
-		strncpy(param->name, hc->name, sizeof(param->name));
-		if (hc->uuid)
-			strncpy(param->uuid, hc->uuid, sizeof(param->uuid)-1);
-		else
-			param->uuid[0] = '\0';
-
-		if (hc->new_map)
-			param->flags |= DM_INACTIVE_PRESENT_FLAG;
-		else
-			param->flags &= ~DM_INACTIVE_PRESENT_FLAG;
-
-		dm_get(md);
-	}
-	up_read(&_hash_lock);
-
-	return md;
-}
-
-static int dev_remove(struct dm_ioctl *param, size_t param_size)
-{
-	struct hash_cell *hc;
-
-	down_write(&_hash_lock);
-	hc = __find_device_hash_cell(param);
-
-	if (!hc) {
-		DMWARN("device doesn't appear to be in the dev hash table.");
-		up_write(&_hash_lock);
-		return -ENXIO;
-	}
-
-	__hash_remove(hc);
-	up_write(&_hash_lock);
-	param->data_size = 0;
-	return 0;
-}
-
-/*
- * Check a string doesn't overrun the chunk of
- * memory we copied from userland.
- */
-static int invalid_str(char *str, void *end)
-{
-	while ((void *) str < end)
-		if (!*str++)
-			return 0;
-
-	return -EINVAL;
-}
-
-static int dev_rename(struct dm_ioctl *param, size_t param_size)
-{
-	int r;
-	char *new_name = (char *) param + param->data_start;
-
-	if (new_name < (char *) (param + 1) ||
-	    invalid_str(new_name, (void *) param + param_size)) {
-		DMWARN("Invalid new logical volume name supplied.");
-		return -EINVAL;
-	}
-
-	r = check_name(new_name);
-	if (r)
-		return r;
-
-	param->data_size = 0;
-	return dm_hash_rename(param->name, new_name);
-}
-
-static int do_suspend(struct dm_ioctl *param)
-{
-	int r = 0;
-	struct mapped_device *md;
-
-	md = find_device(param);
-	if (!md)
-		return -ENXIO;
-
-	if (!dm_suspended(md))
-		r = dm_suspend(md);
-
-	if (!r)
-		r = __dev_status(md, param);
-
-	dm_put(md);
-	return r;
-}
-
-static int do_resume(struct dm_ioctl *param)
-{
-	int r = 0;
-	struct hash_cell *hc;
-	struct mapped_device *md;
-	struct dm_table *new_map;
-
-	down_write(&_hash_lock);
-
-	hc = __find_device_hash_cell(param);
-	if (!hc) {
-		DMWARN("device doesn't appear to be in the dev hash table.");
-		up_write(&_hash_lock);
-		return -ENXIO;
-	}
-
-	md = hc->md;
-	dm_get(md);
-
-	new_map = hc->new_map;
-	hc->new_map = NULL;
-	param->flags &= ~DM_INACTIVE_PRESENT_FLAG;
-
-	up_write(&_hash_lock);
-
-	/* Do we need to load a new map ? */
-	if (new_map) {
-		/* Suspend if it isn't already suspended */
-		if (!dm_suspended(md))
-			dm_suspend(md);
-
-		r = dm_swap_table(md, new_map);
-		if (r) {
-			dm_put(md);
-			dm_table_put(new_map);
-			return r;
-		}
-
-		if (dm_table_get_mode(new_map) & FMODE_WRITE)
-			set_disk_ro(dm_disk(md), 0);
-		else
-			set_disk_ro(dm_disk(md), 1);
-
-		dm_table_put(new_map);
-	}
-
-	if (dm_suspended(md))
-		r = dm_resume(md);
-
-	if (!r)
-		r = __dev_status(md, param);
-
-	dm_put(md);
-	return r;
-}
-
-/*
- * Set or unset the suspension state of a device.
- * If the device already is in the requested state we just return its status.
- */
-static int dev_suspend(struct dm_ioctl *param, size_t param_size)
-{
-	if (param->flags & DM_SUSPEND_FLAG)
-		return do_suspend(param);
-
-	return do_resume(param);
-}
-
-/*
- * Copies device info back to user space, used by
- * the create and info ioctls.
- */
-static int dev_status(struct dm_ioctl *param, size_t param_size)
-{
-	int r;
-	struct mapped_device *md;
-
-	md = find_device(param);
-	if (!md)
-		return -ENXIO;
-
-	r = __dev_status(md, param);
-	dm_put(md);
-	return r;
-}
-
-/*
- * Build up the status struct for each target
- */
-static void retrieve_status(struct dm_table *table,
-			    struct dm_ioctl *param, size_t param_size)
-{
-	unsigned int i, num_targets;
-	struct dm_target_spec *spec;
-	char *outbuf, *outptr;
-	status_type_t type;
-	size_t remaining, len, used = 0;
-
-	outptr = outbuf = get_result_buffer(param, param_size, &len);
-
-	if (param->flags & DM_STATUS_TABLE_FLAG)
-		type = STATUSTYPE_TABLE;
-	else
-		type = STATUSTYPE_INFO;
-
-	/* Get all the target info */
-	num_targets = dm_table_get_num_targets(table);
-	for (i = 0; i < num_targets; i++) {
-		struct dm_target *ti = dm_table_get_target(table, i);
-
-		remaining = len - (outptr - outbuf);
-		if (remaining < sizeof(struct dm_target_spec)) {
-			param->flags |= DM_BUFFER_FULL_FLAG;
-			break;
-		}
-
-		spec = (struct dm_target_spec *) outptr;
-
-		spec->status = 0;
-		spec->sector_start = ti->begin;
-		spec->length = ti->len;
-		strncpy(spec->target_type, ti->type->name,
-			sizeof(spec->target_type));
-
-		outptr += sizeof(struct dm_target_spec);
-		remaining = len - (outptr - outbuf);
-
-		/* Get the status/table string from the target driver */
-		if (ti->type->status) {
-			if (ti->type->status(ti, type, outptr, remaining)) {
-				param->flags |= DM_BUFFER_FULL_FLAG;
-				break;
-			}
-		} else
-			outptr[0] = '\0';
-
-		outptr += strlen(outptr) + 1;
-		used = param->data_start + (outptr - outbuf);
-
-		align_ptr(outptr);
-		spec->next = outptr - outbuf;
-	}
-
-	if (used)
-		param->data_size = used;
-
-	param->target_count = num_targets;
-}
-
-/*
- * Wait for a device to report an event
- */
-static int dev_wait(struct dm_ioctl *param, size_t param_size)
-{
-	int r;
-	struct mapped_device *md;
-	struct dm_table *table;
-	DECLARE_WAITQUEUE(wq, current);
-
-	md = find_device(param);
-	if (!md)
-		return -ENXIO;
-
-	/*
-	 * Wait for a notification event
-	 */
-	set_current_state(TASK_INTERRUPTIBLE);
-	if (!dm_add_wait_queue(md, &wq, param->event_nr)) {
-		schedule();
-		dm_remove_wait_queue(md, &wq);
-	}
- 	set_current_state(TASK_RUNNING);
-
-	/*
-	 * The userland program is going to want to know what
-	 * changed to trigger the event, so we may as well tell
-	 * him and save an ioctl.
-	 */
-	r = __dev_status(md, param);
-	if (r)
-		goto out;
-
-	table = dm_get_table(md);
-	if (table) {
-		retrieve_status(table, param, param_size);
-		dm_table_put(table);
-	}
-
- out:
-	dm_put(md);
-	return r;
-}
-
-static inline int get_mode(struct dm_ioctl *param)
-{
-	int mode = FMODE_READ | FMODE_WRITE;
-
-	if (param->flags & DM_READONLY_FLAG)
-		mode = FMODE_READ;
-
-	return mode;
-}
-
-static int next_target(struct dm_target_spec *last, uint32_t next, void *end,
-		       struct dm_target_spec **spec, char **target_params)
-{
-	*spec = (struct dm_target_spec *) ((unsigned char *) last + next);
-	*target_params = (char *) (*spec + 1);
-
-	if (*spec < (last + 1))
-		return -EINVAL;
-
-	return invalid_str(*target_params, end);
-}
-
-static int populate_table(struct dm_table *table,
-			  struct dm_ioctl *param, size_t param_size)
-{
-	int r;
-	unsigned int i = 0;
-	struct dm_target_spec *spec = (struct dm_target_spec *) param;
-	uint32_t next = param->data_start;
-	void *end = (void *) param + param_size;
-	char *target_params;
-
-	if (!param->target_count) {
-		DMWARN("populate_table: no targets specified");
-		return -EINVAL;
-	}
-
-	for (i = 0; i < param->target_count; i++) {
-
-		r = next_target(spec, next, end, &spec, &target_params);
-		if (r) {
-			DMWARN("unable to find target");
-			return r;
-		}
-
-		r = dm_table_add_target(table, spec->target_type,
-					(sector_t) spec->sector_start,
-					(sector_t) spec->length,
-					target_params);
-		if (r) {
-			DMWARN("error adding target to table");
-			return r;
-		}
-
-		next = spec->next;
-	}
-
-	return dm_table_complete(table);
-}
-
-static int table_load(struct dm_ioctl *param, size_t param_size)
-{
-	int r;
-	struct hash_cell *hc;
-	struct dm_table *t;
-
-	r = dm_table_create(&t, get_mode(param), param->target_count);
-	if (r)
-		return r;
-
-	r = populate_table(t, param, param_size);
-	if (r) {
-		dm_table_put(t);
-		return r;
-	}
-
-	down_write(&_hash_lock);
-	hc = __find_device_hash_cell(param);
-	if (!hc) {
-		DMWARN("device doesn't appear to be in the dev hash table.");
-		up_write(&_hash_lock);
-		return -ENXIO;
-	}
-
-	if (hc->new_map)
-		dm_table_put(hc->new_map);
-	hc->new_map = t;
-	param->flags |= DM_INACTIVE_PRESENT_FLAG;
-
-	r = __dev_status(hc->md, param);
-	up_write(&_hash_lock);
-	return r;
-}
-
-static int table_clear(struct dm_ioctl *param, size_t param_size)
-{
-	int r;
-	struct hash_cell *hc;
-
-	down_write(&_hash_lock);
-
-	hc = __find_device_hash_cell(param);
-	if (!hc) {
-		DMWARN("device doesn't appear to be in the dev hash table.");
-		up_write(&_hash_lock);
-		return -ENXIO;
-	}
-
-	if (hc->new_map) {
-		dm_table_put(hc->new_map);
-		hc->new_map = NULL;
-	}
-
-	param->flags &= ~DM_INACTIVE_PRESENT_FLAG;
-
-	r = __dev_status(hc->md, param);
-	up_write(&_hash_lock);
-	return r;
-}
-
-/*
- * Retrieves a list of devices used by a particular dm device.
- */
-static void retrieve_deps(struct dm_table *table,
-			  struct dm_ioctl *param, size_t param_size)
-{
-	unsigned int count = 0;
-	struct list_head *tmp;
-	size_t len, needed;
-	struct dm_target_deps *deps;
-
-	deps = get_result_buffer(param, param_size, &len);
-
-	/*
-	 * Count the devices.
-	 */
-	list_for_each(tmp, dm_table_get_devices(table))
-		count++;
-
-	/*
-	 * Check we have enough space.
-	 */
-	needed = sizeof(*deps) + (sizeof(*deps->dev) * count);
-	if (len < needed) {
-		param->flags |= DM_BUFFER_FULL_FLAG;
-		return;
-	}
-
-	/*
-	 * Fill in the devices.
-	 */
-	deps->count = count;
-	count = 0;
-	list_for_each(tmp, dm_table_get_devices(table)) {
-		struct dm_dev *dd = list_entry(tmp, struct dm_dev, list);
-		deps->dev[count++] = huge_encode_dev(dd->bdev->bd_dev);
-	}
-
-	param->data_size = param->data_start + needed;
-}
-
-static int table_deps(struct dm_ioctl *param, size_t param_size)
-{
-	int r = 0;
-	struct mapped_device *md;
-	struct dm_table *table;
-
-	md = find_device(param);
-	if (!md)
-		return -ENXIO;
-
-	r = __dev_status(md, param);
-	if (r)
-		goto out;
-
-	table = dm_get_table(md);
-	if (table) {
-		retrieve_deps(table, param, param_size);
-		dm_table_put(table);
-	}
-
- out:
-	dm_put(md);
-	return r;
-}
-
-/*
- * Return the status of a device as a text string for each
- * target.
- */
-static int table_status(struct dm_ioctl *param, size_t param_size)
-{
-	int r;
-	struct mapped_device *md;
-	struct dm_table *table;
-
-	md = find_device(param);
-	if (!md)
-		return -ENXIO;
-
-	r = __dev_status(md, param);
-	if (r)
-		goto out;
-
-	table = dm_get_table(md);
-	if (table) {
-		retrieve_status(table, param, param_size);
-		dm_table_put(table);
-	}
-
- out:
-	dm_put(md);
-	return r;
-}
-
-/*-----------------------------------------------------------------
- * Implementation of open/close/ioctl on the special char
- * device.
- *---------------------------------------------------------------*/
-static ioctl_fn lookup_ioctl(unsigned int cmd)
-{
-	static struct {
-		int cmd;
-		ioctl_fn fn;
-	} _ioctls[] = {
-		{DM_VERSION_CMD, NULL},	/* version is dealt with elsewhere */
-		{DM_REMOVE_ALL_CMD, remove_all},
-		{DM_LIST_DEVICES_CMD, list_devices},
-
-		{DM_DEV_CREATE_CMD, dev_create},
-		{DM_DEV_REMOVE_CMD, dev_remove},
-		{DM_DEV_RENAME_CMD, dev_rename},
-		{DM_DEV_SUSPEND_CMD, dev_suspend},
-		{DM_DEV_STATUS_CMD, dev_status},
-		{DM_DEV_WAIT_CMD, dev_wait},
-
-		{DM_TABLE_LOAD_CMD, table_load},
-		{DM_TABLE_CLEAR_CMD, table_clear},
-		{DM_TABLE_DEPS_CMD, table_deps},
-		{DM_TABLE_STATUS_CMD, table_status}
-	};
-
-	return (cmd >= ARRAY_SIZE(_ioctls)) ? NULL : _ioctls[cmd].fn;
-}
-
-/*
- * As well as checking the version compatibility this always
- * copies the kernel interface version out.
- */
-static int check_version(unsigned int cmd, struct dm_ioctl *user)
-{
-	uint32_t version[3];
-	int r = 0;
-
-	if (copy_from_user(version, user->version, sizeof(version)))
-		return -EFAULT;
-
-	if ((DM_VERSION_MAJOR != version[0]) ||
-	    (DM_VERSION_MINOR < version[1])) {
-		DMWARN("ioctl interface mismatch: "
-		       "kernel(%u.%u.%u), user(%u.%u.%u), cmd(%d)",
-		       DM_VERSION_MAJOR, DM_VERSION_MINOR,
-		       DM_VERSION_PATCHLEVEL,
-		       version[0], version[1], version[2], cmd);
-		r = -EINVAL;
-	}
-
-	/*
-	 * Fill in the kernel version.
-	 */
-	version[0] = DM_VERSION_MAJOR;
-	version[1] = DM_VERSION_MINOR;
-	version[2] = DM_VERSION_PATCHLEVEL;
-	if (copy_to_user(user->version, version, sizeof(version)))
-		return -EFAULT;
-
-	return r;
-}
-
-static void free_params(struct dm_ioctl *param)
-{
-	vfree(param);
-}
-
-static int copy_params(struct dm_ioctl *user, struct dm_ioctl **param)
-{
-	struct dm_ioctl tmp, *dmi;
-
-	if (copy_from_user(&tmp, user, sizeof(tmp)))
-		return -EFAULT;
-
-	if (tmp.data_size < sizeof(tmp))
-		return -EINVAL;
-
-	dmi = (struct dm_ioctl *) vmalloc(tmp.data_size);
-	if (!dmi)
-		return -ENOMEM;
-
-	if (copy_from_user(dmi, user, tmp.data_size)) {
-		vfree(dmi);
-		return -EFAULT;
-	}
-
-	*param = dmi;
-	return 0;
-}
-
-static int validate_params(uint cmd, struct dm_ioctl *param)
-{
-	/* Always clear this flag */
-	param->flags &= ~DM_BUFFER_FULL_FLAG;
-
-	/* Ignores parameters */
-	if (cmd == DM_REMOVE_ALL_CMD || cmd == DM_LIST_DEVICES_CMD)
-		return 0;
-
-	/* Unless creating, either name or uuid but not both */
-	if (cmd != DM_DEV_CREATE_CMD) {
-		if ((!*param->uuid && !*param->name) ||
-		    (*param->uuid && *param->name)) {
-			DMWARN("one of name or uuid must be supplied, cmd(%u)",
-			       cmd);
-			return -EINVAL;
-		}
-	}
-
-	/* Ensure strings are terminated */
-	param->name[DM_NAME_LEN - 1] = '\0';
-	param->uuid[DM_UUID_LEN - 1] = '\0';
-
-	return 0;
-}
-
-static int ctl_ioctl(struct inode *inode, struct file *file,
-		     uint command, ulong u)
-{
-	int r = 0;
-	unsigned int cmd;
-	struct dm_ioctl *param;
-	struct dm_ioctl *user = (struct dm_ioctl *) u;
-	ioctl_fn fn = NULL;
-	size_t param_size;
-
-	/* only root can play with this */
-	if (!capable(CAP_SYS_ADMIN))
-		return -EACCES;
-
-	if (_IOC_TYPE(command) != DM_IOCTL)
-		return -ENOTTY;
-
-	cmd = _IOC_NR(command);
-
-	/*
-	 * Check the interface version passed in.  This also
-	 * writes out the kernel's interface version.
-	 */
-	r = check_version(cmd, user);
-	if (r)
-		return r;
-
-	/*
-	 * Nothing more to do for the version command.
-	 */
-	if (cmd == DM_VERSION_CMD)
-		return 0;
-
-	fn = lookup_ioctl(cmd);
-	if (!fn) {
-		DMWARN("dm_ctl_ioctl: unknown command 0x%x", command);
-		return -ENOTTY;
-	}
-
-	/*
-	 * Trying to avoid low memory issues when a device is
-	 * suspended.
-	 */
-	current->flags |= PF_MEMALLOC;
-
-	/*
-	 * Copy the parameters into kernel space.
-	 */
-	r = copy_params(user, &param);
-	if (r) {
-		current->flags &= ~PF_MEMALLOC;
-		return r;
-	}
-
-	/*
-	 * FIXME: eventually we will remove the PF_MEMALLOC flag
-	 * here.  However the tools still do nasty things like
-	 * 'load' while a device is suspended.
-	 */
-
-	r = validate_params(cmd, param);
-	if (r)
-		goto out;
-
-	param_size = param->data_size;
-	param->data_size = sizeof(*param);
-	r = fn(param, param_size);
-
-	/*
-	 * Copy the results back to userland.
-	 */
-	if (!r && copy_to_user(user, param, param->data_size))
-		r = -EFAULT;
-
- out:
-	free_params(param);
-	current->flags &= ~PF_MEMALLOC;
-	return r;
-}
-
-static struct file_operations _ctl_fops = {
-	.ioctl	 = ctl_ioctl,
-	.owner	 = THIS_MODULE,
-};
-
-static struct miscdevice _dm_misc = {
-	.minor 		= MISC_DYNAMIC_MINOR,
-	.name  		= DM_NAME,
-	.devfs_name 	= "mapper/control",
-	.fops  		= &_ctl_fops
-};
-
-/*
- * Create misc character device and link to DM_DIR/control.
- */
-int __init dm_interface_init(void)
-{
-	int r;
-
-	r = dm_hash_init();
-	if (r)
-		return r;
-
-	r = misc_register(&_dm_misc);
-	if (r) {
-		DMERR("misc_register failed for control device");
-		dm_hash_exit();
-		return r;
-	}
-
-	DMINFO("%d.%d.%d%s initialised: %s", DM_VERSION_MAJOR,
-	       DM_VERSION_MINOR, DM_VERSION_PATCHLEVEL, DM_VERSION_EXTRA,
-	       DM_DRIVER_EMAIL);
-	return 0;
-}
-
-void dm_interface_exit(void)
-{
-	if (misc_deregister(&_dm_misc) < 0)
-		DMERR("misc_deregister failed for control device");
-
-	dm_hash_exit();
-}
diff -purN linux-post-2.6.4rc2-20040307/drivers/md/dm-ioctl.c linux-post-2.6.4rc2-20040309/drivers/md/dm-ioctl.c
--- linux-post-2.6.4rc2-20040307/drivers/md/dm-ioctl.c	2003-07-18 05:30:58.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/md/dm-ioctl.c	2004-03-07 07:04:56.000000000 +0000
@@ -1,13 +1,1264 @@
 /*
- * Copyright (C) 2003 Sistina Software (UK) Limited.
+ * Copyright (C) 2001, 2002 Sistina Software (UK) Limited.
  *
  * This file is released under the GPL.
  */
 
+#include "dm.h"
+
+#include <linux/module.h>
+#include <linux/vmalloc.h>
+#include <linux/miscdevice.h>
+#include <linux/init.h>
+#include <linux/wait.h>
+#include <linux/slab.h>
+#include <linux/devfs_fs_kernel.h>
 #include <linux/dm-ioctl.h>
 
-#ifdef CONFIG_DM_IOCTL_V4
-#include "dm-ioctl-v4.c"
-#else
-#include "dm-ioctl-v1.c"
-#endif
+#include <asm/uaccess.h>
+
+#define DM_DRIVER_EMAIL "dm@uk.sistina.com"
+
+/*-----------------------------------------------------------------
+ * The ioctl interface needs to be able to look up devices by
+ * name or uuid.
+ *---------------------------------------------------------------*/
+struct hash_cell {
+	struct list_head name_list;
+	struct list_head uuid_list;
+
+	char *name;
+	char *uuid;
+	struct mapped_device *md;
+	struct dm_table *new_map;
+};
+
+#define NUM_BUCKETS 64
+#define MASK_BUCKETS (NUM_BUCKETS - 1)
+static struct list_head _name_buckets[NUM_BUCKETS];
+static struct list_head _uuid_buckets[NUM_BUCKETS];
+
+void dm_hash_remove_all(void);
+
+/*
+ * Guards access to both hash tables.
+ */
+static DECLARE_RWSEM(_hash_lock);
+
+static void init_buckets(struct list_head *buckets)
+{
+	unsigned int i;
+
+	for (i = 0; i < NUM_BUCKETS; i++)
+		INIT_LIST_HEAD(buckets + i);
+}
+
+int dm_hash_init(void)
+{
+	init_buckets(_name_buckets);
+	init_buckets(_uuid_buckets);
+	devfs_mk_dir(DM_DIR);
+	return 0;
+}
+
+void dm_hash_exit(void)
+{
+	dm_hash_remove_all();
+	devfs_remove(DM_DIR);
+}
+
+/*-----------------------------------------------------------------
+ * Hash function:
+ * We're not really concerned with the str hash function being
+ * fast since it's only used by the ioctl interface.
+ *---------------------------------------------------------------*/
+static unsigned int hash_str(const char *str)
+{
+	const unsigned int hash_mult = 2654435387U;
+	unsigned int h = 0;
+
+	while (*str)
+		h = (h + (unsigned int) *str++) * hash_mult;
+
+	return h & MASK_BUCKETS;
+}
+
+/*-----------------------------------------------------------------
+ * Code for looking up a device by name
+ *---------------------------------------------------------------*/
+static struct hash_cell *__get_name_cell(const char *str)
+{
+	struct list_head *tmp;
+	struct hash_cell *hc;
+	unsigned int h = hash_str(str);
+
+	list_for_each (tmp, _name_buckets + h) {
+		hc = list_entry(tmp, struct hash_cell, name_list);
+		if (!strcmp(hc->name, str))
+			return hc;
+	}
+
+	return NULL;
+}
+
+static struct hash_cell *__get_uuid_cell(const char *str)
+{
+	struct list_head *tmp;
+	struct hash_cell *hc;
+	unsigned int h = hash_str(str);
+
+	list_for_each (tmp, _uuid_buckets + h) {
+		hc = list_entry(tmp, struct hash_cell, uuid_list);
+		if (!strcmp(hc->uuid, str))
+			return hc;
+	}
+
+	return NULL;
+}
+
+/*-----------------------------------------------------------------
+ * Inserting, removing and renaming a device.
+ *---------------------------------------------------------------*/
+static inline char *kstrdup(const char *str)
+{
+	char *r = kmalloc(strlen(str) + 1, GFP_KERNEL);
+	if (r)
+		strcpy(r, str);
+	return r;
+}
+
+static struct hash_cell *alloc_cell(const char *name, const char *uuid,
+				    struct mapped_device *md)
+{
+	struct hash_cell *hc;
+
+	hc = kmalloc(sizeof(*hc), GFP_KERNEL);
+	if (!hc)
+		return NULL;
+
+	hc->name = kstrdup(name);
+	if (!hc->name) {
+		kfree(hc);
+		return NULL;
+	}
+
+	if (!uuid)
+		hc->uuid = NULL;
+
+	else {
+		hc->uuid = kstrdup(uuid);
+		if (!hc->uuid) {
+			kfree(hc->name);
+			kfree(hc);
+			return NULL;
+		}
+	}
+
+	INIT_LIST_HEAD(&hc->name_list);
+	INIT_LIST_HEAD(&hc->uuid_list);
+	hc->md = md;
+	hc->new_map = NULL;
+	return hc;
+}
+
+static void free_cell(struct hash_cell *hc)
+{
+	if (hc) {
+		kfree(hc->name);
+		kfree(hc->uuid);
+		kfree(hc);
+	}
+}
+
+/*
+ * devfs stuff.
+ */
+static int register_with_devfs(struct hash_cell *hc)
+{
+	struct gendisk *disk = dm_disk(hc->md);
+
+	devfs_mk_bdev(MKDEV(disk->major, disk->first_minor),
+		      S_IFBLK | S_IRUSR | S_IWUSR | S_IRGRP,
+		      DM_DIR "/%s", hc->name);
+	return 0;
+}
+
+static int unregister_with_devfs(struct hash_cell *hc)
+{
+	devfs_remove(DM_DIR"/%s", hc->name);
+	return 0;
+}
+
+/*
+ * The kdev_t and uuid of a device can never change once it is
+ * initially inserted.
+ */
+int dm_hash_insert(const char *name, const char *uuid, struct mapped_device *md)
+{
+	struct hash_cell *cell;
+
+	/*
+	 * Allocate the new cells.
+	 */
+	cell = alloc_cell(name, uuid, md);
+	if (!cell)
+		return -ENOMEM;
+
+	/*
+	 * Insert the cell into both hash tables.
+	 */
+	down_write(&_hash_lock);
+	if (__get_name_cell(name))
+		goto bad;
+
+	list_add(&cell->name_list, _name_buckets + hash_str(name));
+
+	if (uuid) {
+		if (__get_uuid_cell(uuid)) {
+			list_del(&cell->name_list);
+			goto bad;
+		}
+		list_add(&cell->uuid_list, _uuid_buckets + hash_str(uuid));
+	}
+	register_with_devfs(cell);
+	dm_get(md);
+	up_write(&_hash_lock);
+
+	return 0;
+
+ bad:
+	up_write(&_hash_lock);
+	free_cell(cell);
+	return -EBUSY;
+}
+
+void __hash_remove(struct hash_cell *hc)
+{
+	/* remove from the dev hash */
+	list_del(&hc->uuid_list);
+	list_del(&hc->name_list);
+	unregister_with_devfs(hc);
+	dm_put(hc->md);
+	if (hc->new_map)
+		dm_table_put(hc->new_map);
+	free_cell(hc);
+}
+
+void dm_hash_remove_all(void)
+{
+	int i;
+	struct hash_cell *hc;
+	struct list_head *tmp, *n;
+
+	down_write(&_hash_lock);
+	for (i = 0; i < NUM_BUCKETS; i++) {
+		list_for_each_safe (tmp, n, _name_buckets + i) {
+			hc = list_entry(tmp, struct hash_cell, name_list);
+			__hash_remove(hc);
+		}
+	}
+	up_write(&_hash_lock);
+}
+
+int dm_hash_rename(const char *old, const char *new)
+{
+	char *new_name, *old_name;
+	struct hash_cell *hc;
+
+	/*
+	 * duplicate new.
+	 */
+	new_name = kstrdup(new);
+	if (!new_name)
+		return -ENOMEM;
+
+	down_write(&_hash_lock);
+
+	/*
+	 * Is new free ?
+	 */
+	hc = __get_name_cell(new);
+	if (hc) {
+		DMWARN("asked to rename to an already existing name %s -> %s",
+		       old, new);
+		up_write(&_hash_lock);
+		kfree(new_name);
+		return -EBUSY;
+	}
+
+	/*
+	 * Is there such a device as 'old' ?
+	 */
+	hc = __get_name_cell(old);
+	if (!hc) {
+		DMWARN("asked to rename a non existent device %s -> %s",
+		       old, new);
+		up_write(&_hash_lock);
+		kfree(new_name);
+		return -ENXIO;
+	}
+
+	/*
+	 * rename and move the name cell.
+	 */
+	unregister_with_devfs(hc);
+
+	list_del(&hc->name_list);
+	old_name = hc->name;
+	hc->name = new_name;
+	list_add(&hc->name_list, _name_buckets + hash_str(new_name));
+
+	/* rename the device node in devfs */
+	register_with_devfs(hc);
+
+	up_write(&_hash_lock);
+	kfree(old_name);
+	return 0;
+}
+
+/*-----------------------------------------------------------------
+ * Implementation of the ioctl commands
+ *---------------------------------------------------------------*/
+/*
+ * All the ioctl commands get dispatched to functions with this
+ * prototype.
+ */
+typedef int (*ioctl_fn)(struct dm_ioctl *param, size_t param_size);
+
+static int remove_all(struct dm_ioctl *param, size_t param_size)
+{
+	dm_hash_remove_all();
+	param->data_size = 0;
+	return 0;
+}
+
+/*
+ * Round up the ptr to an 8-byte boundary.
+ */
+#define ALIGN_MASK 7
+static inline void *align_ptr(void *ptr)
+{
+	return (void *) (((size_t) (ptr + ALIGN_MASK)) & ~ALIGN_MASK);
+}
+
+/*
+ * Retrieves the data payload buffer from an already allocated
+ * struct dm_ioctl.
+ */
+static void *get_result_buffer(struct dm_ioctl *param, size_t param_size,
+			       size_t *len)
+{
+	param->data_start = align_ptr(param + 1) - (void *) param;
+
+	if (param->data_start < param_size)
+		*len = param_size - param->data_start;
+	else
+		*len = 0;
+
+	return ((void *) param) + param->data_start;
+}
+
+static int list_devices(struct dm_ioctl *param, size_t param_size)
+{
+	unsigned int i;
+	struct hash_cell *hc;
+	size_t len, needed = 0;
+	struct gendisk *disk;
+	struct dm_name_list *nl, *old_nl = NULL;
+
+	down_write(&_hash_lock);
+
+	/*
+	 * Loop through all the devices working out how much
+	 * space we need.
+	 */
+	for (i = 0; i < NUM_BUCKETS; i++) {
+		list_for_each_entry (hc, _name_buckets + i, name_list) {
+			needed += sizeof(struct dm_name_list);
+			needed += strlen(hc->name);
+			needed += ALIGN_MASK;
+		}
+	}
+
+	/*
+	 * Grab our output buffer.
+	 */
+	nl = get_result_buffer(param, param_size, &len);
+	if (len < needed) {
+		param->flags |= DM_BUFFER_FULL_FLAG;
+		goto out;
+	}
+	param->data_size = param->data_start + needed;
+
+	nl->dev = 0;	/* Flags no data */
+
+	/*
+	 * Now loop through filling out the names.
+	 */
+	for (i = 0; i < NUM_BUCKETS; i++) {
+		list_for_each_entry (hc, _name_buckets + i, name_list) {
+			if (old_nl)
+				old_nl->next = (uint32_t) ((void *) nl -
+							   (void *) old_nl);
+			disk = dm_disk(hc->md);
+			nl->dev = huge_encode_dev(MKDEV(disk->major, disk->first_minor));
+			nl->next = 0;
+			strcpy(nl->name, hc->name);
+
+			old_nl = nl;
+			nl = align_ptr(((void *) ++nl) + strlen(hc->name) + 1);
+		}
+	}
+
+ out:
+	up_write(&_hash_lock);
+	return 0;
+}
+
+static int check_name(const char *name)
+{
+	if (strchr(name, '/')) {
+		DMWARN("invalid device name");
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+/*
+ * Fills in a dm_ioctl structure, ready for sending back to
+ * userland.
+ */
+static int __dev_status(struct mapped_device *md, struct dm_ioctl *param)
+{
+	struct gendisk *disk = dm_disk(md);
+	struct dm_table *table;
+	struct block_device *bdev;
+
+	param->flags &= ~(DM_SUSPEND_FLAG | DM_READONLY_FLAG |
+			  DM_ACTIVE_PRESENT_FLAG);
+
+	if (dm_suspended(md))
+		param->flags |= DM_SUSPEND_FLAG;
+
+	bdev = bdget_disk(disk, 0);
+	if (!bdev)
+		return -ENXIO;
+
+	param->dev = huge_encode_dev(MKDEV(disk->major, disk->first_minor));
+
+	/*
+	 * Yes, this will be out of date by the time it gets back
+	 * to userland, but it is still very useful ofr
+	 * debugging.
+	 */
+	param->open_count = bdev->bd_openers;
+	bdput(bdev);
+
+	if (disk->policy)
+		param->flags |= DM_READONLY_FLAG;
+
+	param->event_nr = dm_get_event_nr(md);
+
+	table = dm_get_table(md);
+	if (table) {
+		param->flags |= DM_ACTIVE_PRESENT_FLAG;
+		param->target_count = dm_table_get_num_targets(table);
+		dm_table_put(table);
+	} else
+		param->target_count = 0;
+
+	return 0;
+}
+
+static int dev_create(struct dm_ioctl *param, size_t param_size)
+{
+	int r;
+	struct mapped_device *md;
+
+	r = check_name(param->name);
+	if (r)
+		return r;
+
+	if (param->flags & DM_PERSISTENT_DEV_FLAG)
+		r = dm_create_with_minor(MINOR(huge_decode_dev(param->dev)), &md);
+	else
+		r = dm_create(&md);
+
+	if (r)
+		return r;
+
+	r = dm_hash_insert(param->name, *param->uuid ? param->uuid : NULL, md);
+	if (r) {
+		dm_put(md);
+		return r;
+	}
+
+	param->flags &= ~DM_INACTIVE_PRESENT_FLAG;
+
+	r = __dev_status(md, param);
+	dm_put(md);
+
+	return r;
+}
+
+/*
+ * Always use UUID for lookups if it's present, otherwise use name.
+ */
+static inline struct hash_cell *__find_device_hash_cell(struct dm_ioctl *param)
+{
+	return *param->uuid ?
+	    __get_uuid_cell(param->uuid) : __get_name_cell(param->name);
+}
+
+static inline struct mapped_device *find_device(struct dm_ioctl *param)
+{
+	struct hash_cell *hc;
+	struct mapped_device *md = NULL;
+
+	down_read(&_hash_lock);
+	hc = __find_device_hash_cell(param);
+	if (hc) {
+		md = hc->md;
+
+		/*
+		 * Sneakily write in both the name and the uuid
+		 * while we have the cell.
+		 */
+		strncpy(param->name, hc->name, sizeof(param->name));
+		if (hc->uuid)
+			strncpy(param->uuid, hc->uuid, sizeof(param->uuid)-1);
+		else
+			param->uuid[0] = '\0';
+
+		if (hc->new_map)
+			param->flags |= DM_INACTIVE_PRESENT_FLAG;
+		else
+			param->flags &= ~DM_INACTIVE_PRESENT_FLAG;
+
+		dm_get(md);
+	}
+	up_read(&_hash_lock);
+
+	return md;
+}
+
+static int dev_remove(struct dm_ioctl *param, size_t param_size)
+{
+	struct hash_cell *hc;
+
+	down_write(&_hash_lock);
+	hc = __find_device_hash_cell(param);
+
+	if (!hc) {
+		DMWARN("device doesn't appear to be in the dev hash table.");
+		up_write(&_hash_lock);
+		return -ENXIO;
+	}
+
+	__hash_remove(hc);
+	up_write(&_hash_lock);
+	param->data_size = 0;
+	return 0;
+}
+
+/*
+ * Check a string doesn't overrun the chunk of
+ * memory we copied from userland.
+ */
+static int invalid_str(char *str, void *end)
+{
+	while ((void *) str < end)
+		if (!*str++)
+			return 0;
+
+	return -EINVAL;
+}
+
+static int dev_rename(struct dm_ioctl *param, size_t param_size)
+{
+	int r;
+	char *new_name = (char *) param + param->data_start;
+
+	if (new_name < (char *) (param + 1) ||
+	    invalid_str(new_name, (void *) param + param_size)) {
+		DMWARN("Invalid new logical volume name supplied.");
+		return -EINVAL;
+	}
+
+	r = check_name(new_name);
+	if (r)
+		return r;
+
+	param->data_size = 0;
+	return dm_hash_rename(param->name, new_name);
+}
+
+static int do_suspend(struct dm_ioctl *param)
+{
+	int r = 0;
+	struct mapped_device *md;
+
+	md = find_device(param);
+	if (!md)
+		return -ENXIO;
+
+	if (!dm_suspended(md))
+		r = dm_suspend(md);
+
+	if (!r)
+		r = __dev_status(md, param);
+
+	dm_put(md);
+	return r;
+}
+
+static int do_resume(struct dm_ioctl *param)
+{
+	int r = 0;
+	struct hash_cell *hc;
+	struct mapped_device *md;
+	struct dm_table *new_map;
+
+	down_write(&_hash_lock);
+
+	hc = __find_device_hash_cell(param);
+	if (!hc) {
+		DMWARN("device doesn't appear to be in the dev hash table.");
+		up_write(&_hash_lock);
+		return -ENXIO;
+	}
+
+	md = hc->md;
+	dm_get(md);
+
+	new_map = hc->new_map;
+	hc->new_map = NULL;
+	param->flags &= ~DM_INACTIVE_PRESENT_FLAG;
+
+	up_write(&_hash_lock);
+
+	/* Do we need to load a new map ? */
+	if (new_map) {
+		/* Suspend if it isn't already suspended */
+		if (!dm_suspended(md))
+			dm_suspend(md);
+
+		r = dm_swap_table(md, new_map);
+		if (r) {
+			dm_put(md);
+			dm_table_put(new_map);
+			return r;
+		}
+
+		if (dm_table_get_mode(new_map) & FMODE_WRITE)
+			set_disk_ro(dm_disk(md), 0);
+		else
+			set_disk_ro(dm_disk(md), 1);
+
+		dm_table_put(new_map);
+	}
+
+	if (dm_suspended(md))
+		r = dm_resume(md);
+
+	if (!r)
+		r = __dev_status(md, param);
+
+	dm_put(md);
+	return r;
+}
+
+/*
+ * Set or unset the suspension state of a device.
+ * If the device already is in the requested state we just return its status.
+ */
+static int dev_suspend(struct dm_ioctl *param, size_t param_size)
+{
+	if (param->flags & DM_SUSPEND_FLAG)
+		return do_suspend(param);
+
+	return do_resume(param);
+}
+
+/*
+ * Copies device info back to user space, used by
+ * the create and info ioctls.
+ */
+static int dev_status(struct dm_ioctl *param, size_t param_size)
+{
+	int r;
+	struct mapped_device *md;
+
+	md = find_device(param);
+	if (!md)
+		return -ENXIO;
+
+	r = __dev_status(md, param);
+	dm_put(md);
+	return r;
+}
+
+/*
+ * Build up the status struct for each target
+ */
+static void retrieve_status(struct dm_table *table,
+			    struct dm_ioctl *param, size_t param_size)
+{
+	unsigned int i, num_targets;
+	struct dm_target_spec *spec;
+	char *outbuf, *outptr;
+	status_type_t type;
+	size_t remaining, len, used = 0;
+
+	outptr = outbuf = get_result_buffer(param, param_size, &len);
+
+	if (param->flags & DM_STATUS_TABLE_FLAG)
+		type = STATUSTYPE_TABLE;
+	else
+		type = STATUSTYPE_INFO;
+
+	/* Get all the target info */
+	num_targets = dm_table_get_num_targets(table);
+	for (i = 0; i < num_targets; i++) {
+		struct dm_target *ti = dm_table_get_target(table, i);
+
+		remaining = len - (outptr - outbuf);
+		if (remaining < sizeof(struct dm_target_spec)) {
+			param->flags |= DM_BUFFER_FULL_FLAG;
+			break;
+		}
+
+		spec = (struct dm_target_spec *) outptr;
+
+		spec->status = 0;
+		spec->sector_start = ti->begin;
+		spec->length = ti->len;
+		strncpy(spec->target_type, ti->type->name,
+			sizeof(spec->target_type));
+
+		outptr += sizeof(struct dm_target_spec);
+		remaining = len - (outptr - outbuf);
+
+		/* Get the status/table string from the target driver */
+		if (ti->type->status) {
+			if (ti->type->status(ti, type, outptr, remaining)) {
+				param->flags |= DM_BUFFER_FULL_FLAG;
+				break;
+			}
+		} else
+			outptr[0] = '\0';
+
+		outptr += strlen(outptr) + 1;
+		used = param->data_start + (outptr - outbuf);
+
+		align_ptr(outptr);
+		spec->next = outptr - outbuf;
+	}
+
+	if (used)
+		param->data_size = used;
+
+	param->target_count = num_targets;
+}
+
+/*
+ * Wait for a device to report an event
+ */
+static int dev_wait(struct dm_ioctl *param, size_t param_size)
+{
+	int r;
+	struct mapped_device *md;
+	struct dm_table *table;
+	DECLARE_WAITQUEUE(wq, current);
+
+	md = find_device(param);
+	if (!md)
+		return -ENXIO;
+
+	/*
+	 * Wait for a notification event
+	 */
+	set_current_state(TASK_INTERRUPTIBLE);
+	if (!dm_add_wait_queue(md, &wq, param->event_nr)) {
+		schedule();
+		dm_remove_wait_queue(md, &wq);
+	}
+ 	set_current_state(TASK_RUNNING);
+
+	/*
+	 * The userland program is going to want to know what
+	 * changed to trigger the event, so we may as well tell
+	 * him and save an ioctl.
+	 */
+	r = __dev_status(md, param);
+	if (r)
+		goto out;
+
+	table = dm_get_table(md);
+	if (table) {
+		retrieve_status(table, param, param_size);
+		dm_table_put(table);
+	}
+
+ out:
+	dm_put(md);
+	return r;
+}
+
+static inline int get_mode(struct dm_ioctl *param)
+{
+	int mode = FMODE_READ | FMODE_WRITE;
+
+	if (param->flags & DM_READONLY_FLAG)
+		mode = FMODE_READ;
+
+	return mode;
+}
+
+static int next_target(struct dm_target_spec *last, uint32_t next, void *end,
+		       struct dm_target_spec **spec, char **target_params)
+{
+	*spec = (struct dm_target_spec *) ((unsigned char *) last + next);
+	*target_params = (char *) (*spec + 1);
+
+	if (*spec < (last + 1))
+		return -EINVAL;
+
+	return invalid_str(*target_params, end);
+}
+
+static int populate_table(struct dm_table *table,
+			  struct dm_ioctl *param, size_t param_size)
+{
+	int r;
+	unsigned int i = 0;
+	struct dm_target_spec *spec = (struct dm_target_spec *) param;
+	uint32_t next = param->data_start;
+	void *end = (void *) param + param_size;
+	char *target_params;
+
+	if (!param->target_count) {
+		DMWARN("populate_table: no targets specified");
+		return -EINVAL;
+	}
+
+	for (i = 0; i < param->target_count; i++) {
+
+		r = next_target(spec, next, end, &spec, &target_params);
+		if (r) {
+			DMWARN("unable to find target");
+			return r;
+		}
+
+		r = dm_table_add_target(table, spec->target_type,
+					(sector_t) spec->sector_start,
+					(sector_t) spec->length,
+					target_params);
+		if (r) {
+			DMWARN("error adding target to table");
+			return r;
+		}
+
+		next = spec->next;
+	}
+
+	return dm_table_complete(table);
+}
+
+static int table_load(struct dm_ioctl *param, size_t param_size)
+{
+	int r;
+	struct hash_cell *hc;
+	struct dm_table *t;
+
+	r = dm_table_create(&t, get_mode(param), param->target_count);
+	if (r)
+		return r;
+
+	r = populate_table(t, param, param_size);
+	if (r) {
+		dm_table_put(t);
+		return r;
+	}
+
+	down_write(&_hash_lock);
+	hc = __find_device_hash_cell(param);
+	if (!hc) {
+		DMWARN("device doesn't appear to be in the dev hash table.");
+		up_write(&_hash_lock);
+		return -ENXIO;
+	}
+
+	if (hc->new_map)
+		dm_table_put(hc->new_map);
+	hc->new_map = t;
+	param->flags |= DM_INACTIVE_PRESENT_FLAG;
+
+	r = __dev_status(hc->md, param);
+	up_write(&_hash_lock);
+	return r;
+}
+
+static int table_clear(struct dm_ioctl *param, size_t param_size)
+{
+	int r;
+	struct hash_cell *hc;
+
+	down_write(&_hash_lock);
+
+	hc = __find_device_hash_cell(param);
+	if (!hc) {
+		DMWARN("device doesn't appear to be in the dev hash table.");
+		up_write(&_hash_lock);
+		return -ENXIO;
+	}
+
+	if (hc->new_map) {
+		dm_table_put(hc->new_map);
+		hc->new_map = NULL;
+	}
+
+	param->flags &= ~DM_INACTIVE_PRESENT_FLAG;
+
+	r = __dev_status(hc->md, param);
+	up_write(&_hash_lock);
+	return r;
+}
+
+/*
+ * Retrieves a list of devices used by a particular dm device.
+ */
+static void retrieve_deps(struct dm_table *table,
+			  struct dm_ioctl *param, size_t param_size)
+{
+	unsigned int count = 0;
+	struct list_head *tmp;
+	size_t len, needed;
+	struct dm_target_deps *deps;
+
+	deps = get_result_buffer(param, param_size, &len);
+
+	/*
+	 * Count the devices.
+	 */
+	list_for_each(tmp, dm_table_get_devices(table))
+		count++;
+
+	/*
+	 * Check we have enough space.
+	 */
+	needed = sizeof(*deps) + (sizeof(*deps->dev) * count);
+	if (len < needed) {
+		param->flags |= DM_BUFFER_FULL_FLAG;
+		return;
+	}
+
+	/*
+	 * Fill in the devices.
+	 */
+	deps->count = count;
+	count = 0;
+	list_for_each(tmp, dm_table_get_devices(table)) {
+		struct dm_dev *dd = list_entry(tmp, struct dm_dev, list);
+		deps->dev[count++] = huge_encode_dev(dd->bdev->bd_dev);
+	}
+
+	param->data_size = param->data_start + needed;
+}
+
+static int table_deps(struct dm_ioctl *param, size_t param_size)
+{
+	int r = 0;
+	struct mapped_device *md;
+	struct dm_table *table;
+
+	md = find_device(param);
+	if (!md)
+		return -ENXIO;
+
+	r = __dev_status(md, param);
+	if (r)
+		goto out;
+
+	table = dm_get_table(md);
+	if (table) {
+		retrieve_deps(table, param, param_size);
+		dm_table_put(table);
+	}
+
+ out:
+	dm_put(md);
+	return r;
+}
+
+/*
+ * Return the status of a device as a text string for each
+ * target.
+ */
+static int table_status(struct dm_ioctl *param, size_t param_size)
+{
+	int r;
+	struct mapped_device *md;
+	struct dm_table *table;
+
+	md = find_device(param);
+	if (!md)
+		return -ENXIO;
+
+	r = __dev_status(md, param);
+	if (r)
+		goto out;
+
+	table = dm_get_table(md);
+	if (table) {
+		retrieve_status(table, param, param_size);
+		dm_table_put(table);
+	}
+
+ out:
+	dm_put(md);
+	return r;
+}
+
+/*-----------------------------------------------------------------
+ * Implementation of open/close/ioctl on the special char
+ * device.
+ *---------------------------------------------------------------*/
+static ioctl_fn lookup_ioctl(unsigned int cmd)
+{
+	static struct {
+		int cmd;
+		ioctl_fn fn;
+	} _ioctls[] = {
+		{DM_VERSION_CMD, NULL},	/* version is dealt with elsewhere */
+		{DM_REMOVE_ALL_CMD, remove_all},
+		{DM_LIST_DEVICES_CMD, list_devices},
+
+		{DM_DEV_CREATE_CMD, dev_create},
+		{DM_DEV_REMOVE_CMD, dev_remove},
+		{DM_DEV_RENAME_CMD, dev_rename},
+		{DM_DEV_SUSPEND_CMD, dev_suspend},
+		{DM_DEV_STATUS_CMD, dev_status},
+		{DM_DEV_WAIT_CMD, dev_wait},
+
+		{DM_TABLE_LOAD_CMD, table_load},
+		{DM_TABLE_CLEAR_CMD, table_clear},
+		{DM_TABLE_DEPS_CMD, table_deps},
+		{DM_TABLE_STATUS_CMD, table_status}
+	};
+
+	return (cmd >= ARRAY_SIZE(_ioctls)) ? NULL : _ioctls[cmd].fn;
+}
+
+/*
+ * As well as checking the version compatibility this always
+ * copies the kernel interface version out.
+ */
+static int check_version(unsigned int cmd, struct dm_ioctl *user)
+{
+	uint32_t version[3];
+	int r = 0;
+
+	if (copy_from_user(version, user->version, sizeof(version)))
+		return -EFAULT;
+
+	if ((DM_VERSION_MAJOR != version[0]) ||
+	    (DM_VERSION_MINOR < version[1])) {
+		DMWARN("ioctl interface mismatch: "
+		       "kernel(%u.%u.%u), user(%u.%u.%u), cmd(%d)",
+		       DM_VERSION_MAJOR, DM_VERSION_MINOR,
+		       DM_VERSION_PATCHLEVEL,
+		       version[0], version[1], version[2], cmd);
+		r = -EINVAL;
+	}
+
+	/*
+	 * Fill in the kernel version.
+	 */
+	version[0] = DM_VERSION_MAJOR;
+	version[1] = DM_VERSION_MINOR;
+	version[2] = DM_VERSION_PATCHLEVEL;
+	if (copy_to_user(user->version, version, sizeof(version)))
+		return -EFAULT;
+
+	return r;
+}
+
+static void free_params(struct dm_ioctl *param)
+{
+	vfree(param);
+}
+
+static int copy_params(struct dm_ioctl *user, struct dm_ioctl **param)
+{
+	struct dm_ioctl tmp, *dmi;
+
+	if (copy_from_user(&tmp, user, sizeof(tmp)))
+		return -EFAULT;
+
+	if (tmp.data_size < sizeof(tmp))
+		return -EINVAL;
+
+	dmi = (struct dm_ioctl *) vmalloc(tmp.data_size);
+	if (!dmi)
+		return -ENOMEM;
+
+	if (copy_from_user(dmi, user, tmp.data_size)) {
+		vfree(dmi);
+		return -EFAULT;
+	}
+
+	*param = dmi;
+	return 0;
+}
+
+static int validate_params(uint cmd, struct dm_ioctl *param)
+{
+	/* Always clear this flag */
+	param->flags &= ~DM_BUFFER_FULL_FLAG;
+
+	/* Ignores parameters */
+	if (cmd == DM_REMOVE_ALL_CMD || cmd == DM_LIST_DEVICES_CMD)
+		return 0;
+
+	/* Unless creating, either name or uuid but not both */
+	if (cmd != DM_DEV_CREATE_CMD) {
+		if ((!*param->uuid && !*param->name) ||
+		    (*param->uuid && *param->name)) {
+			DMWARN("one of name or uuid must be supplied, cmd(%u)",
+			       cmd);
+			return -EINVAL;
+		}
+	}
+
+	/* Ensure strings are terminated */
+	param->name[DM_NAME_LEN - 1] = '\0';
+	param->uuid[DM_UUID_LEN - 1] = '\0';
+
+	return 0;
+}
+
+static int ctl_ioctl(struct inode *inode, struct file *file,
+		     uint command, ulong u)
+{
+	int r = 0;
+	unsigned int cmd;
+	struct dm_ioctl *param;
+	struct dm_ioctl *user = (struct dm_ioctl *) u;
+	ioctl_fn fn = NULL;
+	size_t param_size;
+
+	/* only root can play with this */
+	if (!capable(CAP_SYS_ADMIN))
+		return -EACCES;
+
+	if (_IOC_TYPE(command) != DM_IOCTL)
+		return -ENOTTY;
+
+	cmd = _IOC_NR(command);
+
+	/*
+	 * Check the interface version passed in.  This also
+	 * writes out the kernel's interface version.
+	 */
+	r = check_version(cmd, user);
+	if (r)
+		return r;
+
+	/*
+	 * Nothing more to do for the version command.
+	 */
+	if (cmd == DM_VERSION_CMD)
+		return 0;
+
+	fn = lookup_ioctl(cmd);
+	if (!fn) {
+		DMWARN("dm_ctl_ioctl: unknown command 0x%x", command);
+		return -ENOTTY;
+	}
+
+	/*
+	 * Trying to avoid low memory issues when a device is
+	 * suspended.
+	 */
+	current->flags |= PF_MEMALLOC;
+
+	/*
+	 * Copy the parameters into kernel space.
+	 */
+	r = copy_params(user, &param);
+	if (r) {
+		current->flags &= ~PF_MEMALLOC;
+		return r;
+	}
+
+	/*
+	 * FIXME: eventually we will remove the PF_MEMALLOC flag
+	 * here.  However the tools still do nasty things like
+	 * 'load' while a device is suspended.
+	 */
+
+	r = validate_params(cmd, param);
+	if (r)
+		goto out;
+
+	param_size = param->data_size;
+	param->data_size = sizeof(*param);
+	r = fn(param, param_size);
+
+	/*
+	 * Copy the results back to userland.
+	 */
+	if (!r && copy_to_user(user, param, param->data_size))
+		r = -EFAULT;
+
+ out:
+	free_params(param);
+	current->flags &= ~PF_MEMALLOC;
+	return r;
+}
+
+static struct file_operations _ctl_fops = {
+	.ioctl	 = ctl_ioctl,
+	.owner	 = THIS_MODULE,
+};
+
+static struct miscdevice _dm_misc = {
+	.minor 		= MISC_DYNAMIC_MINOR,
+	.name  		= DM_NAME,
+	.devfs_name 	= "mapper/control",
+	.fops  		= &_ctl_fops
+};
+
+/*
+ * Create misc character device and link to DM_DIR/control.
+ */
+int __init dm_interface_init(void)
+{
+	int r;
+
+	r = dm_hash_init();
+	if (r)
+		return r;
+
+	r = misc_register(&_dm_misc);
+	if (r) {
+		DMERR("misc_register failed for control device");
+		dm_hash_exit();
+		return r;
+	}
+
+	DMINFO("%d.%d.%d%s initialised: %s", DM_VERSION_MAJOR,
+	       DM_VERSION_MINOR, DM_VERSION_PATCHLEVEL, DM_VERSION_EXTRA,
+	       DM_DRIVER_EMAIL);
+	return 0;
+}
+
+void dm_interface_exit(void)
+{
+	if (misc_deregister(&_dm_misc) < 0)
+		DMERR("misc_deregister failed for control device");
+
+	dm_hash_exit();
+}
diff -purN linux-post-2.6.4rc2-20040307/drivers/media/video/v4l1-compat.c linux-post-2.6.4rc2-20040309/drivers/media/video/v4l1-compat.c
--- linux-post-2.6.4rc2-20040307/drivers/media/video/v4l1-compat.c	2004-01-19 06:36:25.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/media/video/v4l1-compat.c	2004-03-07 07:16:10.000000000 +0000
@@ -503,10 +503,11 @@ v4l_compat_translate_ioctl(struct inode 
 		int *on = arg;
 
 		if (0 == *on) {
+			enum v4l2_buf_type type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
 			/* dirty hack time.  But v4l1 has no STREAMOFF
 			 * equivalent in the API, and this one at
 			 * least comes close ... */
-			drv(inode, file, VIDIOC_STREAMOFF, NULL);
+			drv(inode, file, VIDIOC_STREAMOFF, &type);
 		}
 		err = drv(inode, file, VIDIOC_OVERLAY, arg);
 		if (err < 0)
@@ -857,6 +858,7 @@ v4l_compat_translate_ioctl(struct inode 
 	case VIDIOCMCAPTURE: /*  capture a frame  */
 	{
 		struct video_mmap	*mm = arg;
+		enum v4l2_buf_type	type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
 
 		fmt2 = kmalloc(sizeof(*fmt2),GFP_KERNEL);
 		memset(&buf2,0,sizeof(buf2));
@@ -897,7 +899,7 @@ v4l_compat_translate_ioctl(struct inode 
 			dprintk("VIDIOCMCAPTURE / VIDIOC_QBUF: %d\n",err);
 			break;
 		}
-		err = drv(inode, file, VIDIOC_STREAMON, NULL);
+		err = drv(inode, file, VIDIOC_STREAMON, &type);
 		if (err < 0)
 			dprintk("VIDIOCMCAPTURE / VIDIOC_STREAMON: %d\n",err);
 		break;
diff -purN linux-post-2.6.4rc2-20040307/drivers/message/i2o/Kconfig linux-post-2.6.4rc2-20040309/drivers/message/i2o/Kconfig
--- linux-post-2.6.4rc2-20040307/drivers/message/i2o/Kconfig	2004-01-21 14:51:11.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/message/i2o/Kconfig	2004-03-07 07:16:10.000000000 +0000
@@ -39,7 +39,10 @@ config I2O_BLOCK
 	depends on I2O
 	help
 	  Include support for the I2O Block OSM. The Block OSM presents disk
-	  and other structured block devices to the operating system.
+	  and other structured block devices to the operating system. If you
+	  are using an RAID controller, you could access the array only by
+	  the Block OSM driver. But it is possible to access the single disks
+	  by the SCSI OSM driver, for example to monitor the disks.
 
 	  To compile this support as a module, choose M here: the
 	  module will be called i2o_block.
@@ -50,7 +53,8 @@ config I2O_SCSI
 	help
 	  Allows direct SCSI access to SCSI devices on a SCSI or FibreChannel
 	  I2O controller. You can use both the SCSI and Block OSM together if
-	  you wish.
+	  you wish. To access a RAID array, you must use the Block OSM driver.
+	  But you could use the SCSI OSM driver to monitor the single disks.
 
 	  To compile this support as a module, choose M here: the
 	  module will be called i2o_scsi.
diff -purN linux-post-2.6.4rc2-20040307/drivers/message/i2o/i2o_block.c linux-post-2.6.4rc2-20040309/drivers/message/i2o/i2o_block.c
--- linux-post-2.6.4rc2-20040307/drivers/message/i2o/i2o_block.c	2003-08-07 09:25:25.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/message/i2o/i2o_block.c	2004-03-07 07:16:10.000000000 +0000
@@ -50,9 +50,11 @@
  *		Properly attach/detach I2O gendisk structure from the system
  *		gendisk list. The I2O block devices now appear in 
  * 		/proc/partitions.
+ *	Markus Lidel <Markus.Lidel@shadowconnect.com>:
+ *		Minor bugfixes for 2.6.
  *
- *	To do:
- *		Serial number scanning to find duplicates for FC multipathing
+ * To do:
+ *	Serial number scanning to find duplicates for FC multipathing
  */
 
 #include <linux/major.h>
@@ -109,25 +111,6 @@
 				 I2O_EVT_IND_BSA_SCSI_SMART )
 
 
-/*
- * I2O Block Error Codes - should be in a header file really...
- */
-#define I2O_BSA_DSC_SUCCESS             0x0000
-#define I2O_BSA_DSC_MEDIA_ERROR         0x0001
-#define I2O_BSA_DSC_ACCESS_ERROR        0x0002
-#define I2O_BSA_DSC_DEVICE_FAILURE      0x0003
-#define I2O_BSA_DSC_DEVICE_NOT_READY    0x0004
-#define I2O_BSA_DSC_MEDIA_NOT_PRESENT   0x0005
-#define I2O_BSA_DSC_MEDIA_LOCKED        0x0006
-#define I2O_BSA_DSC_MEDIA_FAILURE       0x0007
-#define I2O_BSA_DSC_PROTOCOL_FAILURE    0x0008
-#define I2O_BSA_DSC_BUS_FAILURE         0x0009
-#define I2O_BSA_DSC_ACCESS_VIOLATION    0x000A
-#define I2O_BSA_DSC_WRITE_PROTECTED     0x000B
-#define I2O_BSA_DSC_DEVICE_RESET        0x000C
-#define I2O_BSA_DSC_VOLUME_CHANGED      0x000D
-#define I2O_BSA_DSC_TIMEOUT             0x000E
-
 #define I2O_LOCK(unit)	(i2ob_dev[(unit)].req_queue->queue_lock)
 
 /*
@@ -1091,6 +1074,28 @@ static int i2ob_install_device(struct i2
 			d->lct_data.tid, unit);	
 
 	/*
+	 * If this is the first I2O block device found on this IOP,
+	 * we need to initialize all the queue data structures
+	 * before any I/O can be performed. If it fails, this
+	 * device is useless.
+	 */
+	if(!i2ob_queues[unit]) {
+		if(i2ob_init_iop(unit))
+			return 1;
+	}
+
+	/*
+	 * This will save one level of lookup/indirection in critical
+	 * code so that we can directly get the queue ptr from the
+	 * device instead of having to go the IOP data structure.
+	 */
+	dev->req_queue = i2ob_queues[unit]->req_queue;
+
+	/* initialize gendik structure */
+	i2ob_disk[unit>>4]->private_data = dev;
+	i2ob_disk[unit>>4]->queue = dev->req_queue;
+
+	/*
 	 *	Ask for the current media data. If that isn't supported
 	 *	then we ask for the device capacity data
 	 */
@@ -1148,6 +1153,7 @@ static int i2ob_install_device(struct i2
 	}
 
 	strcpy(d->dev_name, i2ob_disk[unit>>4]->disk_name);
+	strcpy(i2ob_disk[unit>>4]->devfs_name, i2ob_disk[unit>>4]->disk_name);
 
 	printk(KERN_INFO "%s: Max segments %d, queue depth %d, byte limit %d.\n",
 		 d->dev_name, i2ob_dev[unit].max_segments, i2ob_dev[unit].depth, i2ob_max_sectors[unit]<<9);
@@ -1193,28 +1199,6 @@ static int i2ob_install_device(struct i2
 	printk(KERN_INFO "%s: Maximum sectors/read set to %d.\n", 
 		d->dev_name, i2ob_max_sectors[unit]);
 
-	/* 
-	 * If this is the first I2O block device found on this IOP,
-	 * we need to initialize all the queue data structures
-	 * before any I/O can be performed. If it fails, this
-	 * device is useless.
-	 */
-	if(!i2ob_queues[c->unit]) {
-		if(i2ob_init_iop(c->unit))
-			return 1;
-	}
-
-	/* 
-	 * This will save one level of lookup/indirection in critical 
-	 * code so that we can directly get the queue ptr from the
-	 * device instead of having to go the IOP data structure.
-	 */
-	dev->req_queue = i2ob_queues[c->unit]->req_queue;
-
-	/* Register a size before we register for events - otherwise we
-	   might miss and overwrite an event */
-	set_capacity(i2ob_disk[unit>>4], size>>9);
-
 	/*
 	 * Register for the events we're interested in and that the
 	 * device actually supports.
@@ -1251,6 +1235,7 @@ static int i2ob_init_iop(unsigned int un
 	i2ob_queues[unit]->i2ob_qhead = &i2ob_queues[unit]->request_queue[0];
 	atomic_set(&i2ob_queues[unit]->queue_depth, 0);
 
+	i2ob_queues[unit]->lock = SPIN_LOCK_UNLOCKED;
 	i2ob_queues[unit]->req_queue = blk_init_queue(i2ob_request, &i2ob_queues[unit]->lock);
 	if (!i2ob_queues[unit]->req_queue) {
 		kfree(i2ob_queues[unit]);
@@ -1336,6 +1321,8 @@ static void i2ob_scan(int bios)
 				continue;
 			}
 
+			i2o_release_device(d, &i2o_block_handler);
+
 			if(scan_unit<MAX_I2OB<<4)
 			{
  				/*
@@ -1365,7 +1352,6 @@ static void i2ob_scan(int bios)
 				if(!warned++)
 					printk(KERN_WARNING "i2o_block: too many device, registering only %d.\n", scan_unit>>4);
 			}
-			i2o_release_device(d, &i2o_block_handler);
 		}
 		i2o_unlock_controller(c);
 	}
@@ -1699,9 +1685,9 @@ static void i2o_block_exit(void)
 	
 	if(evt_running) {
 		printk(KERN_INFO "Killing I2O block threads...");
-		i = kill_proc(evt_pid, SIGTERM, 1);
+		i = kill_proc(evt_pid, SIGKILL, 1);
 		if(!i) {
-			printk("waiting...");
+			printk("waiting...\n");
 		}
 		/* Be sure it died */
 		wait_for_completion(&i2ob_thread_dead);
diff -purN linux-post-2.6.4rc2-20040307/drivers/message/i2o/i2o_core.c linux-post-2.6.4rc2-20040309/drivers/message/i2o/i2o_core.c
--- linux-post-2.6.4rc2-20040307/drivers/message/i2o/i2o_core.c	2003-06-05 00:29:03.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/message/i2o/i2o_core.c	2004-03-07 07:16:10.000000000 +0000
@@ -13,15 +13,16 @@
  * A lot of the I2O message side code from this is taken from the 
  * Red Creek RCPCI45 adapter driver by Red Creek Communications 
  * 
- * Fixes by: 
- *		Philipp Rumpf 
- *		Juha Sievnen <Juha.Sievanen@cs.Helsinki.FI> 
- *		Auvo Hkkinen <Auvo.Hakkinen@cs.Helsinki.FI> 
- *		Deepak Saxena <deepak@plexity.net> 
- *		Boji T Kannanthanam <boji.t.kannanthanam@intel.com>
- *
- * Ported to Linux 2.5 by
- *		Alan Cox	<alan@redhat.com>
+ * Fixes/additions:
+ *	Philipp Rumpf
+ *	Juha Sievnen <Juha.Sievanen@cs.Helsinki.FI>
+ *	Auvo Hkkinen <Auvo.Hakkinen@cs.Helsinki.FI>
+ *	Deepak Saxena <deepak@plexity.net>
+ *	Boji T Kannanthanam <boji.t.kannanthanam@intel.com>
+ *	Alan Cox <alan@redhat.com>:
+ *		Ported to Linux 2.5.
+ *	Markus Lidel <Markus.Lidel@shadowconnect.com>:
+ *		Minor fixes for 2.6.
  * 
  */
 
@@ -502,6 +503,7 @@ int i2o_install_controller(struct i2o_co
 			c->unit = i;
 			c->page_frame = NULL;
 			c->hrt = NULL;
+			c->hrt_len = 0;
 			c->lct = NULL;
 			c->status_block = NULL;
 			sprintf(c->name, "i2o/iop%d", i);
@@ -564,7 +566,7 @@ int i2o_delete_controller(struct i2o_con
 	 * If this is shutdown time, the thread's already been killed
 	 */
 	if(c->lct_running) {
-		stat = kill_proc(c->lct_pid, SIGTERM, 1);
+		stat = kill_proc(c->lct_pid, SIGKILL, 1);
 		if(!stat) {
 			int count = 10 * 100;
 			while(c->lct_running && --count) {
@@ -1861,31 +1863,36 @@ int i2o_hrt_get(struct i2o_controller *c
 {
 	u32 msg[6];
 	int ret, size = sizeof(i2o_hrt);
+	int loops = 3;	/* we only try 3 times to get the HRT, this should be
+			   more then enough. Worst case should be 2 times.*/
 
 	/* First read just the header to figure out the real size */
 
 	do  {
+		/* first we allocate the memory for the HRT */
 		if (c->hrt == NULL) {
 			c->hrt=pci_alloc_consistent(c->pdev, size, &c->hrt_phys);
 			if (c->hrt == NULL) {
 				printk(KERN_CRIT "%s: Hrt Get failed; Out of memory.\n", c->name);
 				return -ENOMEM;
 			}
+			c->hrt_len = size;
 		}
 
 		msg[0]= SIX_WORD_MSG_SIZE| SGL_OFFSET_4;
 		msg[1]= I2O_CMD_HRT_GET<<24 | HOST_TID<<12 | ADAPTER_TID;
 		msg[3]= 0;
-		msg[4]= (0xD0000000 | size);	/* Simple transaction */
+		msg[4]= (0xD0000000 | c->hrt_len);	/* Simple transaction */
 		msg[5]= c->hrt_phys;		/* Dump it here */
 
-		ret = i2o_post_wait_mem(c, msg, sizeof(msg), 20, c->hrt, NULL, c->hrt_phys, 0, size, 0);
+		ret = i2o_post_wait_mem(c, msg, sizeof(msg), 20, c->hrt, NULL, c->hrt_phys, 0, c->hrt_len, 0);
 		
 		if(ret == -ETIMEDOUT)
 		{
 			/* The HRT block we used is in limbo somewhere. When the iop wakes up
 			   we will recover it */
 			c->hrt = NULL;
+			c->hrt_len = 0;
 			return ret;
 		}
 		
@@ -1896,13 +1903,20 @@ int i2o_hrt_get(struct i2o_controller *c
 			return ret;
 		}
 
-		if (c->hrt->num_entries * c->hrt->entry_len << 2 > size) {
-			int new_size = c->hrt->num_entries * c->hrt->entry_len << 2;
-			pci_free_consistent(c->pdev, size, c->hrt, c->hrt_phys);
-			size = new_size;
+		if (c->hrt->num_entries * c->hrt->entry_len << 2 > c->hrt_len) {
+			size = c->hrt->num_entries * c->hrt->entry_len << 2;
+			pci_free_consistent(c->pdev, c->hrt_len, c->hrt, c->hrt_phys);
+			c->hrt_len = 0;
 			c->hrt = NULL;
 		}
-	} while (c->hrt == NULL);
+		loops --;
+	} while (c->hrt == NULL && loops > 0);
+
+	if(c->hrt == NULL)
+	{
+		printk(KERN_ERR "%s: Unable to get HRT after three tries, giving up\n", c->name);
+		return -1;
+	}
 
 	i2o_parse_hrt(c); // just for debugging
 
@@ -3628,8 +3642,6 @@ int __init i2o_pci_install(struct pci_de
 	return 0;	
 }
 
-static int dpt;
-
 /**
  *	i2o_pci_scan	-	Scan the pci bus for controllers
  *	
@@ -3654,14 +3666,7 @@ int __init i2o_pci_scan(void)
 	{
 		if((dev->class>>8)!=PCI_CLASS_INTELLIGENT_I2O)
 			continue;
-		if(dev->vendor == PCI_VENDOR_ID_DPT && !dpt)
-		{
-			if(dev->device == 0xA501 || dev->device == 0xA511)
-			{
-				printk(KERN_INFO "i2o: Skipping Adaptec/DPT I2O raid with preferred native driver.\n");
-				continue;
-			}
-		}
+
 		if((dev->class&0xFF)>1)
 		{
 			printk(KERN_INFO "i2o: I2O Controller found but does not support I2O 1.5 (skipping).\n");
@@ -3735,22 +3740,19 @@ static void i2o_core_exit(void)
 	 */
 	if(evt_running) {
 		printk("Terminating i2o threads...");
-		stat = kill_proc(evt_pid, SIGTERM, 1);
+		stat = kill_proc(evt_pid, SIGKILL, 1);
 		if(!stat) {
-			printk("waiting...");
+			printk("waiting...\n");
 			wait_for_completion(&evt_dead);
 		}
 		printk("done.\n");
 	}
 	i2o_remove_handler(&i2o_core_handler);
-	unregister_reboot_notifier(&i2o_reboot_notifier);
 }
 
 module_init(i2o_core_init);
 module_exit(i2o_core_exit);
 
-MODULE_PARM(dpt, "i");
-MODULE_PARM_DESC(dpt, "Set this if you want to drive DPT cards normally handled by dpt_i2o");
 MODULE_PARM(verbose, "i");
 MODULE_PARM_DESC(verbose, "Verbose diagnostics");
 
diff -purN linux-post-2.6.4rc2-20040307/drivers/message/i2o/i2o_scsi.c linux-post-2.6.4rc2-20040309/drivers/message/i2o/i2o_scsi.c
--- linux-post-2.6.4rc2-20040307/drivers/message/i2o/i2o_scsi.c	2003-05-02 19:54:03.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/message/i2o/i2o_scsi.c	2004-03-07 07:16:10.000000000 +0000
@@ -29,12 +29,15 @@
  *	In general the firmware wants to help. Where its help isn't performance
  *	useful we just ignore the aid. Its not worth the code in truth.
  *
- *	Fixes:
- *		Steve Ralston	:	Scatter gather now works
+ * Fixes/additions:
+ *	Steve Ralston:
+ *		Scatter gather now works
+ *	Markus Lidel <Markus.Lidel@shadowconnect.com>:
+ *		Minor fixes for 2.6.
  *
- *	To Do
- *		64bit cleanups
- *		Fix the resource management problems.
+ * To Do:
+ *	64bit cleanups
+ *	Fix the resource management problems.
  */
 
 
@@ -66,7 +69,13 @@
 
 #define VERSION_STRING        "Version 0.1.2"
 
-#define dprintk(x)
+//#define DRIVERDEBUG
+
+#ifdef DRIVERDEBUG
+#define dprintk(s, args...) printk(s, ## args)
+#else
+#define dprintk(s, args...)
+#endif
 
 #define I2O_SCSI_CAN_QUEUE	4
 #define MAXHOSTS		32
@@ -252,15 +261,15 @@ static void i2o_scsi_reply(struct i2o_ha
 	as=(u8)le32_to_cpu(m[4]>>8);
 	st=(u8)le32_to_cpu(m[4]>>24);
 	
-	dprintk(("i2o got a scsi reply %08X: ", m[0]));
-	dprintk(("m[2]=%08X: ", m[2]));
-	dprintk(("m[4]=%08X\n", m[4]));
+	dprintk(KERN_INFO "i2o got a scsi reply %08X: ", m[0]);
+	dprintk(KERN_INFO "m[2]=%08X: ", m[2]);
+	dprintk(KERN_INFO "m[4]=%08X\n", m[4]);
  
 	if(m[2]&0x80000000)
 	{
 		if(m[2]&0x40000000)
 		{
-			dprintk(("Event.\n"));
+			dprintk(KERN_INFO "Event.\n");
 			lun_done=1;
 			return;
 		}
@@ -280,12 +289,12 @@ static void i2o_scsi_reply(struct i2o_ha
 	if(current_command==NULL)
 	{
 		if(st)
-			dprintk(("SCSI abort: %08X", m[4]));
-		dprintk(("SCSI abort completed.\n"));
+			dprintk(KERN_WARNING "SCSI abort: %08X", m[4]);
+		dprintk(KERN_INFO "SCSI abort completed.\n");
 		return;
 	}
 	
-	dprintk(("Completed %ld\n", current_command->serial_number));
+	dprintk(KERN_INFO "Completed %ld\n", current_command->serial_number);
 	
 	atomic_dec(&queue_depth);
 	
@@ -308,7 +317,7 @@ static void i2o_scsi_reply(struct i2o_ha
 	{
 		/* An error has occurred */
 
-		dprintk((KERN_DEBUG "SCSI error %08X", m[4]));
+		dprintk(KERN_WARNING "SCSI error %08X", m[4]);
 			
 		if (as == 0x0E) 
 			/* SCSI Reset */
@@ -368,7 +377,7 @@ static int i2o_find_lun(struct i2o_contr
 
 	*lun=reply[1];
 
-	dprintk(("SCSI (%d,%d)\n", *target, *lun));
+	dprintk(KERN_INFO "SCSI (%d,%d)\n", *target, *lun);
 	return 0;
 }
 
@@ -401,8 +410,8 @@ static void i2o_scsi_init(struct i2o_con
 			
 	for(unit=c->devices;unit!=NULL;unit=unit->next)
 	{
-		dprintk(("Class %03X, parent %d, want %d.\n",
-			unit->lct_data.class_id, unit->lct_data.parent_tid, d->lct_data.tid));
+		dprintk(KERN_INFO "Class %03X, parent %d, want %d.\n",
+			unit->lct_data.class_id, unit->lct_data.parent_tid, d->lct_data.tid);
 			
 		/* Only look at scsi and fc devices */
 		if (    (unit->lct_data.class_id != I2O_CLASS_SCSI_PERIPHERAL)
@@ -411,19 +420,19 @@ static void i2o_scsi_init(struct i2o_con
 			continue;
 
 		/* On our bus ? */
-		dprintk(("Found a disk (%d).\n", unit->lct_data.tid));
+		dprintk(KERN_INFO "Found a disk (%d).\n", unit->lct_data.tid);
 		if ((unit->lct_data.parent_tid == d->lct_data.tid)
 		     || (unit->lct_data.parent_tid == d->lct_data.parent_tid)
 		   )
 		{
 			u16 limit;
-			dprintk(("Its ours.\n"));
+			dprintk(KERN_INFO "Its ours.\n");
 			if(i2o_find_lun(c, unit, &target, &lun)==-1)
 			{
 				printk(KERN_ERR "i2o_scsi: Unable to get lun for tid %d.\n", unit->lct_data.tid);
 				continue;
 			}
-			dprintk(("Found disk %d %d.\n", target, lun));
+			dprintk(KERN_INFO "Found disk %d %d.\n", target, lun);
 			h->task[target][lun]=unit->lct_data.tid;
 			h->tagclock[target][lun]=jiffies;
 
@@ -439,8 +448,8 @@ static void i2o_scsi_init(struct i2o_con
 			
 			shpnt->sg_tablesize = limit;
 
-			dprintk(("i2o_scsi: set scatter-gather to %d.\n", 
-				shpnt->sg_tablesize));
+			dprintk(KERN_INFO "i2o_scsi: set scatter-gather to %d.\n",
+				shpnt->sg_tablesize);
 		}
 	}		
 }
@@ -558,6 +567,9 @@ static int i2o_scsi_release(struct Scsi_
 		del_timer(&retry_timer);
 		i2o_remove_handler(&i2o_scsi_handler);
 	}
+
+	scsi_unregister(host);
+
 	return 0;
 }
 
@@ -624,7 +636,7 @@ static int i2o_scsi_queuecommand(Scsi_Cm
 	
 	tid = hostdata->task[SCpnt->device->id][SCpnt->device->lun];
 	
-	dprintk(("qcmd: Tid = %d\n", tid));
+	dprintk(KERN_INFO "qcmd: Tid = %d\n", tid);
 	
 	current_command = SCpnt;		/* set current command                */
 	current_command->scsi_done = done;	/* set ptr to done function           */
@@ -641,7 +653,7 @@ static int i2o_scsi_queuecommand(Scsi_Cm
 		return 0;
 	}
 	
-	dprintk(("Real scsi messages.\n"));
+	dprintk(KERN_INFO "Real scsi messages.\n");
 
 	/*
 	 *	Obtain an I2O message. If there are none free then 
@@ -821,8 +833,8 @@ static int i2o_scsi_queuecommand(Scsi_Cm
 	}
 	else
 	{
-		dprintk(("non sg for %p, %d\n", SCpnt->request_buffer,
-				SCpnt->request_bufflen));
+		dprintk(KERN_INFO "non sg for %p, %d\n", SCpnt->request_buffer,
+				SCpnt->request_bufflen);
 		i2o_raw_writel(len = SCpnt->request_bufflen, lenptr);
 		if(len == 0)
 		{
@@ -861,7 +873,7 @@ static int i2o_scsi_queuecommand(Scsi_Cm
 	}
 	
 	mb();
-	dprintk(("Issued %ld\n", current_command->serial_number));
+	dprintk(KERN_INFO "Issued %ld\n", current_command->serial_number);
 	
 	return 0;
 }
diff -purN linux-post-2.6.4rc2-20040307/drivers/mtd/chips/cfi_cmdset_0020.c linux-post-2.6.4rc2-20040309/drivers/mtd/chips/cfi_cmdset_0020.c
--- linux-post-2.6.4rc2-20040307/drivers/mtd/chips/cfi_cmdset_0020.c	2004-02-04 05:29:27.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/mtd/chips/cfi_cmdset_0020.c	2004-03-07 07:16:10.000000000 +0000
@@ -1460,3 +1460,5 @@ static void __exit cfi_staa_exit(void)
 
 module_init(cfi_staa_init);
 module_exit(cfi_staa_exit);
+
+MODULE_LICENSE("GPL");
diff -purN linux-post-2.6.4rc2-20040307/drivers/mtd/maps/map_funcs.c linux-post-2.6.4rc2-20040309/drivers/mtd/maps/map_funcs.c
--- linux-post-2.6.4rc2-20040307/drivers/mtd/maps/map_funcs.c	2003-06-01 21:12:52.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/mtd/maps/map_funcs.c	2004-03-07 07:16:10.000000000 +0000
@@ -93,3 +93,4 @@ void simple_map_init(struct map_info *ma
 }
 
 EXPORT_SYMBOL(simple_map_init);
+MODULE_LICENSE("GPL");
diff -purN linux-post-2.6.4rc2-20040307/drivers/net/e100.c linux-post-2.6.4rc2-20040309/drivers/net/e100.c
--- linux-post-2.6.4rc2-20040307/drivers/net/e100.c	2004-02-25 00:49:41.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/net/e100.c	2004-03-04 17:30:48.000000000 +0000
@@ -158,7 +158,7 @@
 
 
 #define DRV_NAME		"e100"
-#define DRV_VERSION		"3.0.15"
+#define DRV_VERSION		"3.0.16"
 #define DRV_DESCRIPTION		"Intel(R) PRO/100 Network Driver"
 #define DRV_COPYRIGHT		"Copyright(c) 1999-2004 Intel Corporation"
 #define PFX			DRV_NAME ": "
@@ -1032,8 +1032,9 @@ static int e100_phy_init(struct nic *nic
 	nic->phy = (u32)id_hi << 16 | (u32)id_lo;
 	DPRINTK(HW, DEBUG, "phy ID = 0x%08X\n", nic->phy);
 
-	/* Handle National tx phy */
-	if(nic->phy == phy_nsc_tx) {
+	/* Handle National tx phys */
+#define NCS_PHY_MODEL_MASK	0xFFF0FFFF
+	if((nic->phy & NCS_PHY_MODEL_MASK) == phy_nsc_tx) {
 		/* Disable congestion control */
 		cong = mdio_read(netdev, nic->mii.phy_id, MII_NSC_CONG);
 		cong |= NSC_CONG_TXREADY;
diff -purN linux-post-2.6.4rc2-20040307/drivers/net/hp100.c linux-post-2.6.4rc2-20040309/drivers/net/hp100.c
--- linux-post-2.6.4rc2-20040307/drivers/net/hp100.c	2004-03-01 11:18:00.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/net/hp100.c	2004-03-08 22:42:53.000000000 +0000
@@ -2862,7 +2862,7 @@ static int __init hp100_eisa_probe (stru
 	SET_MODULE_OWNER(dev);
 	SET_NETDEV_DEV(dev, &edev->dev);
 
-	err = hp100_probe1(dev, edev->base_addr, HP100_BUS_EISA, NULL);
+	err = hp100_probe1(dev, edev->base_addr + 0xC38, HP100_BUS_EISA, NULL);
 	if (err)
 		goto out1;
 
diff -purN linux-post-2.6.4rc2-20040307/drivers/net/ns83820.c linux-post-2.6.4rc2-20040309/drivers/net/ns83820.c
--- linux-post-2.6.4rc2-20040307/drivers/net/ns83820.c	2004-01-10 16:34:54.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/net/ns83820.c	2004-03-07 07:04:57.000000000 +0000
@@ -598,7 +598,7 @@ static inline int rx_refill(struct net_d
 }
 
 static void FASTCALL(rx_refill_atomic(struct net_device *ndev));
-static void rx_refill_atomic(struct net_device *ndev)
+static void fastcall rx_refill_atomic(struct net_device *ndev)
 {
 	rx_refill(ndev, GFP_ATOMIC);
 }
@@ -620,7 +620,7 @@ static inline void clear_rx_desc(struct 
 }
 
 static void FASTCALL(phy_intr(struct net_device *ndev));
-static void phy_intr(struct net_device *ndev)
+static void fastcall phy_intr(struct net_device *ndev)
 {
 	struct ns83820 *dev = PRIV(ndev);
 	static char *speeds[] = { "10", "100", "1000", "1000(?)", "1000F" };
@@ -807,7 +807,7 @@ static void ns83820_cleanup_rx(struct ns
 }
 
 static void FASTCALL(ns83820_rx_kick(struct net_device *ndev));
-static void ns83820_rx_kick(struct net_device *ndev)
+static void fastcall ns83820_rx_kick(struct net_device *ndev)
 {
 	struct ns83820 *dev = PRIV(ndev);
 	/*if (nr_rx_empty(dev) >= NR_RX_DESC/4)*/ {
@@ -829,7 +829,7 @@ static void ns83820_rx_kick(struct net_d
  *	
  */
 static void FASTCALL(rx_irq(struct net_device *ndev));
-static void rx_irq(struct net_device *ndev)
+static void fastcall rx_irq(struct net_device *ndev)
 {
 	struct ns83820 *dev = PRIV(ndev);
 	struct rx_info *info = &dev->rx_info;
diff -purN linux-post-2.6.4rc2-20040307/drivers/net/pcnet32.c linux-post-2.6.4rc2-20040309/drivers/net/pcnet32.c
--- linux-post-2.6.4rc2-20040307/drivers/net/pcnet32.c	2004-02-24 16:41:49.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/net/pcnet32.c	2004-03-08 10:24:43.000000000 +0000
@@ -1452,11 +1452,12 @@ pcnet32_start_xmit(struct sk_buff *skb, 
     status = 0x8300;
     entry = (lp->cur_tx - lp->dirty_tx) & TX_RING_MOD_MASK;
     if ((lp->ltint) &&
-	((entry == TX_RING_SIZE/2) ||
+	((entry == TX_RING_SIZE/3) ||
+	 (entry == (TX_RING_SIZE*2)/3) ||
 	 (entry >= TX_RING_SIZE-2)))
     {
 	/* Enable Successful-TxDone interrupt if we have
-	 * 1/2 of, or nearly all of, our ring buffer Tx'd
+	 * 1/3, 2/3 or nearly all of, our ring buffer Tx'd
 	 * but not yet cleaned up.  Thus, most of the time,
 	 * we will not enable Successful-TxDone interrupts.
 	 */
diff -purN linux-post-2.6.4rc2-20040307/drivers/net/tg3.c linux-post-2.6.4rc2-20040309/drivers/net/tg3.c
--- linux-post-2.6.4rc2-20040307/drivers/net/tg3.c	2004-02-23 19:35:19.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/net/tg3.c	2004-03-08 19:25:23.000000000 +0000
@@ -56,8 +56,8 @@
 
 #define DRV_MODULE_NAME		"tg3"
 #define PFX DRV_MODULE_NAME	": "
-#define DRV_MODULE_VERSION	"2.8"
-#define DRV_MODULE_RELDATE	"February 23, 2004"
+#define DRV_MODULE_VERSION	"2.9"
+#define DRV_MODULE_RELDATE	"March 8, 2004"
 
 #define TG3_DEF_MAC_MODE	0
 #define TG3_DEF_RX_MODE		0
@@ -215,6 +215,21 @@ static void tg3_write_indirect_reg32(str
 	}
 }
 
+static void _tw32_flush(struct tg3 *tp, u32 off, u32 val)
+{
+	if ((tp->tg3_flags & TG3_FLAG_PCIX_TARGET_HWBUG) != 0) {
+		unsigned long flags;
+
+		spin_lock_irqsave(&tp->indirect_lock, flags);
+		pci_write_config_dword(tp->pdev, TG3PCI_REG_BASE_ADDR, off);
+		pci_write_config_dword(tp->pdev, TG3PCI_REG_DATA, val);
+		spin_unlock_irqrestore(&tp->indirect_lock, flags);
+	} else {
+		unsigned long dest = tp->regs + off;
+		writel(val, dest);
+		readl(dest);    /* always flush PCI write */
+	}
+}
 
 static inline void _tw32_rx_mbox(struct tg3 *tp, u32 off, u32 val)
 {
@@ -239,6 +254,7 @@ static inline void _tw32_tx_mbox(struct 
 #define tw32_tx_mbox(reg, val)  _tw32_tx_mbox(tp, reg, val)
 
 #define tw32(reg,val)		tg3_write_indirect_reg32(tp,(reg),(val))
+#define tw32_f(reg,val)		_tw32_flush(tp,(reg),(val))
 #define tw16(reg,val)		writew(((val) & 0xffff), tp->regs + (reg))
 #define tw8(reg,val)		writeb(((val) & 0xff), tp->regs + (reg))
 #define tr32(reg)		readl(tp->regs + (reg))
@@ -325,18 +341,15 @@ static void tg3_switch_clocks(struct tg3
 
 	if (GET_ASIC_REV(tp->pci_chip_rev_id) != ASIC_REV_5705 &&
 	    (orig_clock_ctrl & CLOCK_CTRL_44MHZ_CORE) != 0) {
-		tw32(TG3PCI_CLOCK_CTRL,
+		tw32_f(TG3PCI_CLOCK_CTRL,
 		     clock_ctrl |
 		     (CLOCK_CTRL_44MHZ_CORE | CLOCK_CTRL_ALTCLK));
-		tr32(TG3PCI_CLOCK_CTRL);
 		udelay(40);
-		tw32(TG3PCI_CLOCK_CTRL,
+		tw32_f(TG3PCI_CLOCK_CTRL,
 		     clock_ctrl | (CLOCK_CTRL_ALTCLK));
-		tr32(TG3PCI_CLOCK_CTRL);
 		udelay(40);
 	}
-	tw32(TG3PCI_CLOCK_CTRL, clock_ctrl);
-	tr32(TG3PCI_CLOCK_CTRL);
+	tw32_f(TG3PCI_CLOCK_CTRL, clock_ctrl);
 	udelay(40);
 }
 
@@ -348,9 +361,8 @@ static int tg3_readphy(struct tg3 *tp, i
 	int loops, ret;
 
 	if ((tp->mi_mode & MAC_MI_MODE_AUTO_POLL) != 0) {
-		tw32(MAC_MI_MODE,
+		tw32_f(MAC_MI_MODE,
 		     (tp->mi_mode & ~MAC_MI_MODE_AUTO_POLL));
-		tr32(MAC_MI_MODE);
 		udelay(40);
 	}
 
@@ -362,8 +374,7 @@ static int tg3_readphy(struct tg3 *tp, i
 		      MI_COM_REG_ADDR_MASK);
 	frame_val |= (MI_COM_CMD_READ | MI_COM_START);
 	
-	tw32(MAC_MI_COM, frame_val);
-	tr32(MAC_MI_COM);
+	tw32_f(MAC_MI_COM, frame_val);
 
 	loops = PHY_BUSY_LOOPS;
 	while (loops-- > 0) {
@@ -384,8 +395,7 @@ static int tg3_readphy(struct tg3 *tp, i
 	}
 
 	if ((tp->mi_mode & MAC_MI_MODE_AUTO_POLL) != 0) {
-		tw32(MAC_MI_MODE, tp->mi_mode);
-		tr32(MAC_MI_MODE);
+		tw32_f(MAC_MI_MODE, tp->mi_mode);
 		udelay(40);
 	}
 
@@ -398,9 +408,8 @@ static int tg3_writephy(struct tg3 *tp, 
 	int loops, ret;
 
 	if ((tp->mi_mode & MAC_MI_MODE_AUTO_POLL) != 0) {
-		tw32(MAC_MI_MODE,
+		tw32_f(MAC_MI_MODE,
 		     (tp->mi_mode & ~MAC_MI_MODE_AUTO_POLL));
-		tr32(MAC_MI_MODE);
 		udelay(40);
 	}
 
@@ -411,8 +420,7 @@ static int tg3_writephy(struct tg3 *tp, 
 	frame_val |= (val & MI_COM_DATA_MASK);
 	frame_val |= (MI_COM_CMD_WRITE | MI_COM_START);
 	
-	tw32(MAC_MI_COM, frame_val);
-	tr32(MAC_MI_COM);
+	tw32_f(MAC_MI_COM, frame_val);
 
 	loops = PHY_BUSY_LOOPS;
 	while (loops-- > 0) {
@@ -430,8 +438,7 @@ static int tg3_writephy(struct tg3 *tp, 
 		ret = 0;
 
 	if ((tp->mi_mode & MAC_MI_MODE_AUTO_POLL) != 0) {
-		tw32(MAC_MI_MODE, tp->mi_mode);
-		tr32(MAC_MI_MODE);
+		tw32_f(MAC_MI_MODE, tp->mi_mode);
 		udelay(40);
 	}
 
@@ -714,45 +721,41 @@ static void tg3_frob_aux_power(struct tg
 	    (tp_peer->tg3_flags & TG3_FLAG_WOL_ENABLE) != 0) {
 		if (GET_ASIC_REV(tp->pci_chip_rev_id) == ASIC_REV_5700 ||
 		    GET_ASIC_REV(tp->pci_chip_rev_id) == ASIC_REV_5701) {
-			tw32(GRC_LOCAL_CTRL, tp->grc_local_ctrl |
+			tw32_f(GRC_LOCAL_CTRL, tp->grc_local_ctrl |
 			     (GRC_LCLCTRL_GPIO_OE0 |
 			      GRC_LCLCTRL_GPIO_OE1 |
 			      GRC_LCLCTRL_GPIO_OE2 |
 			      GRC_LCLCTRL_GPIO_OUTPUT0 |
 			      GRC_LCLCTRL_GPIO_OUTPUT1));
-			tr32(GRC_LOCAL_CTRL);
 			udelay(100);
 		} else {
 			if (tp_peer != tp &&
 			    (tp_peer->tg3_flags & TG3_FLAG_INIT_COMPLETE) != 0)
 				return;
 
-			tw32(GRC_LOCAL_CTRL, tp->grc_local_ctrl |
+			tw32_f(GRC_LOCAL_CTRL, tp->grc_local_ctrl |
 			     (GRC_LCLCTRL_GPIO_OE0 |
 			      GRC_LCLCTRL_GPIO_OE1 |
 			      GRC_LCLCTRL_GPIO_OE2 |
 			      GRC_LCLCTRL_GPIO_OUTPUT1 |
 			      GRC_LCLCTRL_GPIO_OUTPUT2));
-			tr32(GRC_LOCAL_CTRL);
 			udelay(100);
 
-			tw32(GRC_LOCAL_CTRL, tp->grc_local_ctrl |
+			tw32_f(GRC_LOCAL_CTRL, tp->grc_local_ctrl |
 			     (GRC_LCLCTRL_GPIO_OE0 |
 			      GRC_LCLCTRL_GPIO_OE1 |
 			      GRC_LCLCTRL_GPIO_OE2 |
 			      GRC_LCLCTRL_GPIO_OUTPUT0 |
 			      GRC_LCLCTRL_GPIO_OUTPUT1 |
 			      GRC_LCLCTRL_GPIO_OUTPUT2));
-			tr32(GRC_LOCAL_CTRL);
 			udelay(100);
 
-			tw32(GRC_LOCAL_CTRL, tp->grc_local_ctrl |
+			tw32_f(GRC_LOCAL_CTRL, tp->grc_local_ctrl |
 			     (GRC_LCLCTRL_GPIO_OE0 |
 			      GRC_LCLCTRL_GPIO_OE1 |
 			      GRC_LCLCTRL_GPIO_OE2 |
 			      GRC_LCLCTRL_GPIO_OUTPUT0 |
 			      GRC_LCLCTRL_GPIO_OUTPUT1));
-			tr32(GRC_LOCAL_CTRL);
 			udelay(100);
 		}
 	} else {
@@ -762,27 +765,24 @@ static void tg3_frob_aux_power(struct tg
 			    (tp_peer->tg3_flags & TG3_FLAG_INIT_COMPLETE) != 0)
 				return;
 
-			tw32(GRC_LOCAL_CTRL, tp->grc_local_ctrl |
+			tw32_f(GRC_LOCAL_CTRL, tp->grc_local_ctrl |
 			     (GRC_LCLCTRL_GPIO_OE1 |
 			      GRC_LCLCTRL_GPIO_OUTPUT1));
-			tr32(GRC_LOCAL_CTRL);
 			udelay(100);
 
-			tw32(GRC_LOCAL_CTRL, tp->grc_local_ctrl |
+			tw32_f(GRC_LOCAL_CTRL, tp->grc_local_ctrl |
 			     (GRC_LCLCTRL_GPIO_OE1));
-			tr32(GRC_LOCAL_CTRL);
 			udelay(100);
 
-			tw32(GRC_LOCAL_CTRL, tp->grc_local_ctrl |
+			tw32_f(GRC_LOCAL_CTRL, tp->grc_local_ctrl |
 			     (GRC_LCLCTRL_GPIO_OE1 |
 			      GRC_LCLCTRL_GPIO_OUTPUT1));
-			tr32(GRC_LOCAL_CTRL);
 			udelay(100);
 		}
 	}
 }
 
-static int tg3_setup_phy(struct tg3 *);
+static int tg3_setup_phy(struct tg3 *, int);
 
 static int tg3_set_power_state(struct tg3 *tp, int state)
 {
@@ -808,8 +808,7 @@ static int tg3_set_power_state(struct tg
 		pci_write_config_word(tp->pdev,
 				      pm + PCI_PM_CTRL,
 				      power_control);
-		tw32(GRC_LOCAL_CTRL, tp->grc_local_ctrl);
-		tr32(GRC_LOCAL_CTRL);
+		tw32_f(GRC_LOCAL_CTRL, tp->grc_local_ctrl);
 		udelay(100);
 
 		return 0;
@@ -850,7 +849,7 @@ static int tg3_set_power_state(struct tg
 		tp->link_config.speed = SPEED_10;
 		tp->link_config.duplex = DUPLEX_HALF;
 		tp->link_config.autoneg = AUTONEG_ENABLE;
-		tg3_setup_phy(tp);
+		tg3_setup_phy(tp, 0);
 	}
 
 	pci_read_config_word(tp->pdev, pm + PCI_PM_PMC, &power_caps);
@@ -876,12 +875,10 @@ static int tg3_set_power_state(struct tg
 		     (tp->tg3_flags & TG3_FLAG_WOL_ENABLE)))
 			mac_mode |= MAC_MODE_MAGIC_PKT_ENABLE;
 
-		tw32(MAC_MODE, mac_mode);
-		tr32(MAC_MODE);
+		tw32_f(MAC_MODE, mac_mode);
 		udelay(100);
 
-		tw32(MAC_RX_MODE, RX_MODE_ENABLE);
-		tr32(MAC_RX_MODE);
+		tw32_f(MAC_RX_MODE, RX_MODE_ENABLE);
 		udelay(10);
 	}
 
@@ -894,10 +891,9 @@ static int tg3_set_power_state(struct tg
 		base_val |= (CLOCK_CTRL_RXCLK_DISABLE |
 			     CLOCK_CTRL_TXCLK_DISABLE);
 
-		tw32(TG3PCI_CLOCK_CTRL, base_val |
+		tw32_f(TG3PCI_CLOCK_CTRL, base_val |
 		     CLOCK_CTRL_ALTCLK |
 		     CLOCK_CTRL_PWRDOWN_PLL133);
-		tr32(TG3PCI_CLOCK_CTRL);
 		udelay(40);
 	} else {
 		u32 newbits1, newbits2;
@@ -916,12 +912,10 @@ static int tg3_set_power_state(struct tg
 			newbits2 = newbits1 | CLOCK_CTRL_44MHZ_CORE;
 		}
 
-		tw32(TG3PCI_CLOCK_CTRL, tp->pci_clock_ctrl | newbits1);
-		tr32(TG3PCI_CLOCK_CTRL);
+		tw32_f(TG3PCI_CLOCK_CTRL, tp->pci_clock_ctrl | newbits1);
 		udelay(40);
 
-		tw32(TG3PCI_CLOCK_CTRL, tp->pci_clock_ctrl | newbits2);
-		tr32(TG3PCI_CLOCK_CTRL);
+		tw32_f(TG3PCI_CLOCK_CTRL, tp->pci_clock_ctrl | newbits2);
 		udelay(40);
 
 		if (GET_ASIC_REV(tp->pci_chip_rev_id) != ASIC_REV_5705) {
@@ -936,8 +930,8 @@ static int tg3_set_power_state(struct tg
 				newbits3 = CLOCK_CTRL_44MHZ_CORE;
 			}
 
-			tw32(TG3PCI_CLOCK_CTRL, tp->pci_clock_ctrl | newbits3);
-			tr32(TG3PCI_CLOCK_CTRL);
+			tw32_f(TG3PCI_CLOCK_CTRL,
+					 tp->pci_clock_ctrl | newbits3);
 			udelay(40);
 		}
 	}
@@ -1051,7 +1045,7 @@ static void tg3_aux_stat_to_speed_duplex
 	};
 }
 
-static int tg3_phy_copper_begin(struct tg3 *tp, int wait_for_link)
+static int tg3_phy_copper_begin(struct tg3 *tp)
 {
 	u32 new_adv;
 	int i;
@@ -1169,7 +1163,7 @@ static int tg3_phy_copper_begin(struct t
 		tg3_readphy(tp, MII_BMCR, &orig_bmcr);
 		if (bmcr != orig_bmcr) {
 			tg3_writephy(tp, MII_BMCR, BMCR_LOOPBACK);
-			for (i = 0; i < 15000; i++) {
+			for (i = 0; i < 1500; i++) {
 				u32 tmp;
 
 				udelay(10);
@@ -1188,27 +1182,6 @@ static int tg3_phy_copper_begin(struct t
 			     BMCR_ANENABLE | BMCR_ANRESTART);
 	}
 
-	if (wait_for_link) {
-		tp->link_config.active_speed = SPEED_INVALID;
-		tp->link_config.active_duplex = DUPLEX_INVALID;
-		for (i = 0; i < 300000; i++) {
-			u32 tmp;
-
-			udelay(10);
-			tg3_readphy(tp, MII_BMSR, &tmp);
-			tg3_readphy(tp, MII_BMSR, &tmp);
-			if (!(tmp & BMSR_LSTATUS))
-				continue;
-
-			tg3_readphy(tp, MII_TG3_AUX_STAT, &tmp);
-			tg3_aux_stat_to_speed_duplex(tp, tmp,
-						     &tp->link_config.active_speed,
-						     &tp->link_config.active_duplex);
-		}
-		if (tp->link_config.active_speed == SPEED_INVALID)
-			return -EINVAL;
-	}
-
 	return 0;
 }
 
@@ -1239,7 +1212,7 @@ static int tg3_init_5401phy_dsp(struct t
 	return err;
 }
 
-static int tg3_setup_copper_phy(struct tg3 *tp)
+static int tg3_setup_copper_phy(struct tg3 *tp, int force_reset)
 {
 	int current_link_up;
 	u32 bmsr, dummy;
@@ -1249,17 +1222,15 @@ static int tg3_setup_copper_phy(struct t
 
 	tw32(MAC_EVENT, 0);
 
-	tw32(MAC_STATUS,
+	tw32_f(MAC_STATUS,
 	     (MAC_STATUS_SYNC_CHANGED |
 	      MAC_STATUS_CFG_CHANGED |
 	      MAC_STATUS_MI_COMPLETION |
 	      MAC_STATUS_LNKSTATE_CHANGED));
-	tr32(MAC_STATUS);
 	udelay(40);
 
 	tp->mi_mode = MAC_MI_MODE_BASE;
-	tw32(MAC_MI_MODE, tp->mi_mode);
-	tr32(MAC_MI_MODE);
+	tw32_f(MAC_MI_MODE, tp->mi_mode);
 	udelay(40);
 
 	tg3_writephy(tp, MII_TG3_AUX_CTRL, 0x02);
@@ -1274,8 +1245,10 @@ static int tg3_setup_copper_phy(struct t
 		tg3_readphy(tp, MII_BMSR, &bmsr);
 		tg3_readphy(tp, MII_BMSR, &bmsr);
 		if (!(bmsr & BMSR_LSTATUS))
-			tg3_phy_reset(tp, 1);
+			force_reset = 1;
 	}
+	if (force_reset)
+		tg3_phy_reset(tp, 1);
 
 	if ((tp->phy_id & PHY_ID_MASK) == PHY_ID_BCM5401) {
 		tg3_readphy(tp, MII_BMSR, &bmsr);
@@ -1411,7 +1384,7 @@ static int tg3_setup_copper_phy(struct t
 	if (current_link_up == 0) {
 		u32 tmp;
 
-		tg3_phy_copper_begin(tp, 0);
+		tg3_phy_copper_begin(tp);
 
 		tg3_readphy(tp, MII_BMSR, &tmp);
 		tg3_readphy(tp, MII_BMSR, &tmp);
@@ -1451,24 +1424,19 @@ static int tg3_setup_copper_phy(struct t
 	if ((tp->phy_id & PHY_ID_MASK) == PHY_ID_BCM5411 &&
 	    tp->pci_chip_rev_id == CHIPREV_ID_5700_ALTIMA) {
 		tp->mi_mode |= MAC_MI_MODE_AUTO_POLL;
-		tw32(MAC_MI_MODE, tp->mi_mode);
-		tr32(MAC_MI_MODE);
+		tw32_f(MAC_MI_MODE, tp->mi_mode);
 		udelay(40);
 	}
 
-	tw32(MAC_MODE, tp->mac_mode);
-	tr32(MAC_MODE);
+	tw32_f(MAC_MODE, tp->mac_mode);
 	udelay(40);
 
-	if (tp->tg3_flags &
-	    (TG3_FLAG_USE_LINKCHG_REG |
-	     TG3_FLAG_POLL_SERDES)) {
+	if (tp->tg3_flags & (TG3_FLAG_USE_LINKCHG_REG | TG3_FLAG_POLL_SERDES)) {
 		/* Polled via timer. */
-		tw32(MAC_EVENT, 0);
+		tw32_f(MAC_EVENT, 0);
 	} else {
-		tw32(MAC_EVENT, MAC_EVENT_LNKSTATE_CHANGED);
+		tw32_f(MAC_EVENT, MAC_EVENT_LNKSTATE_CHANGED);
 	}
-	tr32(MAC_EVENT);
 	udelay(40);
 
 	if (GET_ASIC_REV(tp->pci_chip_rev_id) == ASIC_REV_5700 &&
@@ -1477,10 +1445,9 @@ static int tg3_setup_copper_phy(struct t
 	    ((tp->tg3_flags & TG3_FLAG_PCIX_MODE) ||
 	     (tp->tg3_flags & TG3_FLAG_PCI_HIGH_SPEED))) {
 		udelay(120);
-		tw32(MAC_STATUS,
+		tw32_f(MAC_STATUS,
 		     (MAC_STATUS_SYNC_CHANGED |
 		      MAC_STATUS_CFG_CHANGED));
-		tr32(MAC_STATUS);
 		udelay(40);
 		tg3_write_mem(tp,
 			      NIC_SRAM_FIRMWARE_MBOX,
@@ -1642,8 +1609,7 @@ static int tg3_fiber_aneg_smachine(struc
 		ap->txconfig = 0;
 		tw32(MAC_TX_AUTO_NEG, 0);
 		tp->mac_mode |= MAC_MODE_SEND_CONFIGS;
-		tw32(MAC_MODE, tp->mac_mode);
-		tr32(MAC_MODE);
+		tw32_f(MAC_MODE, tp->mac_mode);
 		udelay(40);
 
 		ret = ANEG_TIMER_ENAB;
@@ -1668,8 +1634,7 @@ static int tg3_fiber_aneg_smachine(struc
 		ap->txconfig = (ANEG_CFG_FD | ANEG_CFG_PS1);
 		tw32(MAC_TX_AUTO_NEG, ap->txconfig);
 		tp->mac_mode |= MAC_MODE_SEND_CONFIGS;
-		tw32(MAC_MODE, tp->mac_mode);
-		tr32(MAC_MODE);
+		tw32_f(MAC_MODE, tp->mac_mode);
 		udelay(40);
 
 		ap->state = ANEG_STATE_ABILITY_DETECT;
@@ -1685,8 +1650,7 @@ static int tg3_fiber_aneg_smachine(struc
 		ap->txconfig |= ANEG_CFG_ACK;
 		tw32(MAC_TX_AUTO_NEG, ap->txconfig);
 		tp->mac_mode |= MAC_MODE_SEND_CONFIGS;
-		tw32(MAC_MODE, tp->mac_mode);
-		tr32(MAC_MODE);
+		tw32_f(MAC_MODE, tp->mac_mode);
 		udelay(40);
 
 		ap->state = ANEG_STATE_ACK_DETECT;
@@ -1772,8 +1736,7 @@ static int tg3_fiber_aneg_smachine(struc
 	case ANEG_STATE_IDLE_DETECT_INIT:
 		ap->link_time = ap->cur_time;
 		tp->mac_mode &= ~MAC_MODE_SEND_CONFIGS;
-		tw32(MAC_MODE, tp->mac_mode);
-		tr32(MAC_MODE);
+		tw32_f(MAC_MODE, tp->mac_mode);
 		udelay(40);
 
 		ap->state = ANEG_STATE_IDLE_DETECT;
@@ -1814,7 +1777,7 @@ static int tg3_fiber_aneg_smachine(struc
 	return ret;
 }
 
-static int tg3_setup_fiber_phy(struct tg3 *tp)
+static int tg3_setup_fiber_phy(struct tg3 *tp, int force_reset)
 {
 	u32 orig_pause_cfg;
 	u16 orig_active_speed;
@@ -1830,8 +1793,7 @@ static int tg3_setup_fiber_phy(struct tg
 
 	tp->mac_mode &= ~(MAC_MODE_PORT_MODE_MASK | MAC_MODE_HALF_DUPLEX);
 	tp->mac_mode |= MAC_MODE_PORT_MODE_TBI;
-	tw32(MAC_MODE, tp->mac_mode);
-	tr32(MAC_MODE);
+	tw32_f(MAC_MODE, tp->mac_mode);
 	udelay(40);
 
 	/* Reset when initting first time or we have a link. */
@@ -1879,10 +1841,9 @@ static int tg3_setup_fiber_phy(struct tg
 
 	/* Enable link change interrupt unless serdes polling.  */
 	if (!(tp->tg3_flags & TG3_FLAG_POLL_SERDES))
-		tw32(MAC_EVENT, MAC_EVENT_LNKSTATE_CHANGED);
+		tw32_f(MAC_EVENT, MAC_EVENT_LNKSTATE_CHANGED);
 	else
-		tw32(MAC_EVENT, 0);
-	tr32(MAC_EVENT);
+		tw32_f(MAC_EVENT, 0);
 	udelay(40);
 
 	current_link_up = 0;
@@ -1900,12 +1861,10 @@ static int tg3_setup_fiber_phy(struct tg
 			tw32(MAC_TX_AUTO_NEG, 0);
 
 			tmp = tp->mac_mode & ~MAC_MODE_PORT_MODE_MASK;
-			tw32(MAC_MODE, tmp | MAC_MODE_PORT_MODE_GMII);
-			tr32(MAC_MODE);
+			tw32_f(MAC_MODE, tmp | MAC_MODE_PORT_MODE_GMII);
 			udelay(40);
 
-			tw32(MAC_MODE, tp->mac_mode | MAC_MODE_SEND_CONFIGS);
-			tr32(MAC_MODE);
+			tw32_f(MAC_MODE, tp->mac_mode | MAC_MODE_SEND_CONFIGS);
 			udelay(40);
 
 			aninfo.state = ANEG_STATE_UNKNOWN;
@@ -1921,8 +1880,7 @@ static int tg3_setup_fiber_phy(struct tg
 			}
 
 			tp->mac_mode &= ~MAC_MODE_SEND_CONFIGS;
-			tw32(MAC_MODE, tp->mac_mode);
-			tr32(MAC_MODE);
+			tw32_f(MAC_MODE, tp->mac_mode);
 			udelay(40);
 
 			if (status == ANEG_DONE &&
@@ -1946,10 +1904,9 @@ static int tg3_setup_fiber_phy(struct tg
 			}
 			for (i = 0; i < 60; i++) {
 				udelay(20);
-				tw32(MAC_STATUS,
+				tw32_f(MAC_STATUS,
 				     (MAC_STATUS_SYNC_CHANGED |
 				      MAC_STATUS_CFG_CHANGED));
-				tr32(MAC_STATUS);
 				udelay(40);
 				if ((tr32(MAC_STATUS) &
 				     (MAC_STATUS_SYNC_CHANGED |
@@ -1967,8 +1924,7 @@ static int tg3_setup_fiber_phy(struct tg
 	}
 
 	tp->mac_mode &= ~MAC_MODE_LINK_POLARITY;
-	tw32(MAC_MODE, tp->mac_mode);
-	tr32(MAC_MODE);
+	tw32_f(MAC_MODE, tp->mac_mode);
 	udelay(40);
 
 	tp->hw_status->status =
@@ -1977,10 +1933,9 @@ static int tg3_setup_fiber_phy(struct tg
 
 	for (i = 0; i < 100; i++) {
 		udelay(20);
-		tw32(MAC_STATUS,
+		tw32_f(MAC_STATUS,
 		     (MAC_STATUS_SYNC_CHANGED |
 		      MAC_STATUS_CFG_CHANGED));
-		tr32(MAC_STATUS);
 		udelay(40);
 		if ((tr32(MAC_STATUS) &
 		     (MAC_STATUS_SYNC_CHANGED |
@@ -2016,12 +1971,10 @@ static int tg3_setup_fiber_phy(struct tg
 	}
 
 	if ((tr32(MAC_STATUS) & MAC_STATUS_PCS_SYNCED) == 0) {
-		tw32(MAC_MODE, tp->mac_mode | MAC_MODE_LINK_POLARITY);
-		tr32(MAC_MODE);
+		tw32_f(MAC_MODE, tp->mac_mode | MAC_MODE_LINK_POLARITY);
 		udelay(40);
 		if (tp->tg3_flags & TG3_FLAG_INIT_COMPLETE) {
-			tw32(MAC_MODE, tp->mac_mode);
-			tr32(MAC_MODE);
+			tw32_f(MAC_MODE, tp->mac_mode);
 			udelay(40);
 		}
 	}
@@ -2029,14 +1982,14 @@ static int tg3_setup_fiber_phy(struct tg
 	return 0;
 }
 
-static int tg3_setup_phy(struct tg3 *tp)
+static int tg3_setup_phy(struct tg3 *tp, int force_reset)
 {
 	int err;
 
 	if (tp->phy_id == PHY_ID_SERDES) {
-		err = tg3_setup_fiber_phy(tp);
+		err = tg3_setup_fiber_phy(tp, force_reset);
 	} else {
-		err = tg3_setup_copper_phy(tp);
+		err = tg3_setup_copper_phy(tp, force_reset);
 	}
 
 	if (tp->link_config.active_speed == SPEED_1000 &&
@@ -2399,7 +2352,7 @@ static int tg3_poll(struct net_device *n
 		if (sblk->status & SD_STATUS_LINK_CHG) {
 			sblk->status = SD_STATUS_UPDATED |
 				(sblk->status & ~SD_STATUS_LINK_CHG);
-			tg3_setup_phy(tp);
+			tg3_setup_phy(tp, 0);
 		}
 	}
 
@@ -3349,8 +3302,7 @@ static int tg3_stop_block(struct tg3 *tp
 
 	val = tr32(ofs);
 	val &= ~enable_bit;
-	tw32(ofs, val);
-	tr32(ofs);
+	tw32_f(ofs, val);
 
 	for (i = 0; i < MAX_WAIT_CNT; i++) {
 		udelay(100);
@@ -3377,8 +3329,7 @@ static int tg3_abort_hw(struct tg3 *tp)
 	tg3_disable_ints(tp);
 
 	tp->rx_mode &= ~RX_MODE_ENABLE;
-	tw32(MAC_RX_MODE, tp->rx_mode);
-	tr32(MAC_RX_MODE);
+	tw32_f(MAC_RX_MODE, tp->rx_mode);
 	udelay(10);
 
 	err  = tg3_stop_block(tp, RCVBDI_MODE, RCVBDI_MODE_ENABLE);
@@ -3399,13 +3350,11 @@ static int tg3_abort_hw(struct tg3 *tp)
 		goto out;
 
 	tp->mac_mode &= ~MAC_MODE_TDE_ENABLE;
-	tw32(MAC_MODE, tp->mac_mode);
-	tr32(MAC_MODE);
+	tw32_f(MAC_MODE, tp->mac_mode);
 	udelay(40);
 
 	tp->tx_mode &= ~TX_MODE_ENABLE;
-	tw32(MAC_TX_MODE, tp->tx_mode);
-	tr32(MAC_TX_MODE);
+	tw32_f(MAC_TX_MODE, tp->tx_mode);
 
 	for (i = 0; i < MAX_WAIT_CNT; i++) {
 		udelay(100);
@@ -3731,8 +3680,7 @@ static int tg3_halt_cpu(struct tg3 *tp, 
 		}
 
 		tw32(offset + CPU_STATE, 0xffffffff);
-		tw32(offset + CPU_MODE,  CPU_MODE_HALT);
-		tr32(offset + CPU_MODE);
+		tw32_f(offset + CPU_MODE,  CPU_MODE_HALT);
 		udelay(10);
 	} else {
 		for (i = 0; i < 10000; i++) {
@@ -3855,20 +3803,14 @@ static int tg3_load_5701_a0_firmware_fix
 
 	/* Now startup only the RX cpu. */
 	tw32(RX_CPU_BASE + CPU_STATE, 0xffffffff);
-	tw32(RX_CPU_BASE + CPU_PC,    TG3_FW_TEXT_ADDR);
+	tw32_f(RX_CPU_BASE + CPU_PC,    TG3_FW_TEXT_ADDR);
 
-	/* Flush posted writes. */
-	tr32(RX_CPU_BASE + CPU_PC);
 	for (i = 0; i < 5; i++) {
 		if (tr32(RX_CPU_BASE + CPU_PC) == TG3_FW_TEXT_ADDR)
 			break;
 		tw32(RX_CPU_BASE + CPU_STATE, 0xffffffff);
 		tw32(RX_CPU_BASE + CPU_MODE,  CPU_MODE_HALT);
-		tw32(RX_CPU_BASE + CPU_PC,    TG3_FW_TEXT_ADDR);
-
-		/* Flush posted writes. */
-		tr32(RX_CPU_BASE + CPU_PC);
-
+		tw32_f(RX_CPU_BASE + CPU_PC,    TG3_FW_TEXT_ADDR);
 		udelay(1000);
 	}
 	if (i >= 5) {
@@ -3879,10 +3821,7 @@ static int tg3_load_5701_a0_firmware_fix
 		return -ENODEV;
 	}
 	tw32(RX_CPU_BASE + CPU_STATE, 0xffffffff);
-	tw32(RX_CPU_BASE + CPU_MODE,  0x00000000);
-
-	/* Flush posted writes. */
-	tr32(RX_CPU_BASE + CPU_MODE);
+	tw32_f(RX_CPU_BASE + CPU_MODE,  0x00000000);
 
 	return 0;
 }
@@ -4440,20 +4379,14 @@ static int tg3_load_tso_firmware(struct 
 
 	/* Now startup the cpu. */
 	tw32(cpu_base + CPU_STATE, 0xffffffff);
-	tw32(cpu_base + CPU_PC,    info.text_base);
+	tw32_f(cpu_base + CPU_PC,    info.text_base);
 
-	/* Flush posted writes. */
-	tr32(cpu_base + CPU_PC);
 	for (i = 0; i < 5; i++) {
 		if (tr32(cpu_base + CPU_PC) == info.text_base)
 			break;
 		tw32(cpu_base + CPU_STATE, 0xffffffff);
 		tw32(cpu_base + CPU_MODE,  CPU_MODE_HALT);
-		tw32(cpu_base + CPU_PC,    info.text_base);
-
-		/* Flush posted writes. */
-		tr32(cpu_base + CPU_PC);
-
+		tw32_f(cpu_base + CPU_PC,    info.text_base);
 		udelay(1000);
 	}
 	if (i >= 5) {
@@ -4464,11 +4397,7 @@ static int tg3_load_tso_firmware(struct 
 		return -ENODEV;
 	}
 	tw32(cpu_base + CPU_STATE, 0xffffffff);
-	tw32(cpu_base + CPU_MODE,  0x00000000);
-
-	/* Flush posted writes. */
-	tr32(cpu_base + CPU_MODE);
-
+	tw32_f(cpu_base + CPU_MODE,  0x00000000);
 	return 0;
 }
 
@@ -4515,9 +4444,6 @@ static int tg3_set_mac_addr(struct net_d
 	struct tg3 *tp = dev->priv;
 	struct sockaddr *addr = p;
 
-	if (netif_running(dev))
-		return -EBUSY;
-
 	memcpy(dev->dev_addr, addr->sa_data, dev->addr_len);
 
 	spin_lock_irq(&tp->lock);
@@ -4577,10 +4503,9 @@ static int tg3_reset_hw(struct tg3 *tp)
 		      NIC_SRAM_FIRMWARE_MBOX_MAGIC1);
 	if (tp->phy_id == PHY_ID_SERDES) {
 		tp->mac_mode = MAC_MODE_PORT_MODE_TBI;
-		tw32(MAC_MODE, tp->mac_mode);
+		tw32_f(MAC_MODE, tp->mac_mode);
 	} else
-		tw32(MAC_MODE, 0);
-	tr32(MAC_MODE);
+		tw32_f(MAC_MODE, 0);
 	udelay(40);
 
 	/* Wait for firmware initialization to complete. */
@@ -4610,8 +4535,7 @@ static int tg3_reset_hw(struct tg3 *tp)
 	 * other revision.
 	 */
 	tp->pci_clock_ctrl |= CLOCK_CTRL_DELAY_PCI_GRANT;
-	tw32(TG3PCI_CLOCK_CTRL, tp->pci_clock_ctrl);
-	tr32(TG3PCI_CLOCK_CTRL);
+	tw32_f(TG3PCI_CLOCK_CTRL, tp->pci_clock_ctrl);
 
 	if (tp->pci_chip_rev_id == CHIPREV_ID_5704_A0 &&
 	    (tp->tg3_flags & TG3_FLAG_PCIX_MODE)) {
@@ -4955,24 +4879,21 @@ static int tg3_reset_hw(struct tg3 *tp)
 
 	tp->mac_mode = MAC_MODE_TXSTAT_ENABLE | MAC_MODE_RXSTAT_ENABLE |
 		MAC_MODE_TDE_ENABLE | MAC_MODE_RDE_ENABLE | MAC_MODE_FHDE_ENABLE;
-	tw32(MAC_MODE, tp->mac_mode | MAC_MODE_RXSTAT_CLEAR | MAC_MODE_TXSTAT_CLEAR);
-	tr32(MAC_MODE);
+	tw32_f(MAC_MODE, tp->mac_mode | MAC_MODE_RXSTAT_CLEAR | MAC_MODE_TXSTAT_CLEAR);
 	udelay(40);
 
 	tp->grc_local_ctrl = GRC_LCLCTRL_INT_ON_ATTN | GRC_LCLCTRL_AUTO_SEEPROM;
 	if (GET_ASIC_REV(tp->pci_chip_rev_id) == ASIC_REV_5700)
 		tp->grc_local_ctrl |= (GRC_LCLCTRL_GPIO_OE1 |
 				       GRC_LCLCTRL_GPIO_OUTPUT1);
-	tw32(GRC_LOCAL_CTRL, tp->grc_local_ctrl);
-	tr32(GRC_LOCAL_CTRL);
+	tw32_f(GRC_LOCAL_CTRL, tp->grc_local_ctrl);
 	udelay(100);
 
 	tw32_mailbox(MAILBOX_INTERRUPT_0 + TG3_64BIT_REG_LOW, 0);
 	tr32(MAILBOX_INTERRUPT_0);
 
 	if (GET_ASIC_REV(tp->pci_chip_rev_id) != ASIC_REV_5705) {
-		tw32(DMAC_MODE, DMAC_MODE_ENABLE);
-		tr32(DMAC_MODE);
+		tw32_f(DMAC_MODE, DMAC_MODE_ENABLE);
 		udelay(40);
 	}
 
@@ -4985,8 +4906,7 @@ static int tg3_reset_hw(struct tg3 *tp)
 	    (tr32(TG3PCI_PCISTATE) & PCISTATE_BUS_SPEED_HIGH) != 0 &&
 	    !(tp->tg3_flags2 & TG3_FLG2_IS_5788))
 		val |= WDMAC_MODE_RX_ACCEL;
-	tw32(WDMAC_MODE, val);
-	tr32(WDMAC_MODE);
+	tw32_f(WDMAC_MODE, val);
 	udelay(40);
 
 	if ((tp->tg3_flags & TG3_FLAG_PCIX_MODE) != 0) {
@@ -5004,8 +4924,7 @@ static int tg3_reset_hw(struct tg3 *tp)
 		tw32(TG3PCI_X_CAPS, val);
 	}
 
-	tw32(RDMAC_MODE, rdmac_mode);
-	tr32(RDMAC_MODE);
+	tw32_f(RDMAC_MODE, rdmac_mode);
 	udelay(40);
 
 	tw32(RCVDCC_MODE, RCVDCC_MODE_ENABLE | RCVDCC_MODE_ATTN_ENABLE);
@@ -5034,13 +4953,11 @@ static int tg3_reset_hw(struct tg3 *tp)
 #endif
 
 	tp->tx_mode = TX_MODE_ENABLE;
-	tw32(MAC_TX_MODE, tp->tx_mode);
-	tr32(MAC_TX_MODE);
+	tw32_f(MAC_TX_MODE, tp->tx_mode);
 	udelay(100);
 
 	tp->rx_mode = RX_MODE_ENABLE;
-	tw32(MAC_RX_MODE, tp->rx_mode);
-	tr32(MAC_RX_MODE);
+	tw32_f(MAC_RX_MODE, tp->rx_mode);
 	udelay(10);
 
 	if (tp->link_config.phy_is_low_power) {
@@ -5051,19 +4968,16 @@ static int tg3_reset_hw(struct tg3 *tp)
 	}
 
 	tp->mi_mode = MAC_MI_MODE_BASE;
-	tw32(MAC_MI_MODE, tp->mi_mode);
-	tr32(MAC_MI_MODE);
+	tw32_f(MAC_MI_MODE, tp->mi_mode);
 	udelay(40);
 
 	tw32(MAC_LED_CTRL, 0);
 	tw32(MAC_MI_STAT, MAC_MI_STAT_LNKSTAT_ATTN_ENAB);
 	if (tp->phy_id == PHY_ID_SERDES) {
-		tw32(MAC_RX_MODE, RX_MODE_RESET);
-		tr32(MAC_RX_MODE);
+		tw32_f(MAC_RX_MODE, RX_MODE_RESET);
 		udelay(10);
 	}
-	tw32(MAC_RX_MODE, tp->rx_mode);
-	tr32(MAC_RX_MODE);
+	tw32_f(MAC_RX_MODE, tp->rx_mode);
 	udelay(10);
 
 	if (tp->pci_chip_rev_id == CHIPREV_ID_5703_A1)
@@ -5072,10 +4986,9 @@ static int tg3_reset_hw(struct tg3 *tp)
 	/* Prevent chip from dropping frames when flow control
 	 * is enabled.
 	 */
-	tw32(MAC_LOW_WMARK_MAX_RX_FRAME, 2);
-	tr32(MAC_LOW_WMARK_MAX_RX_FRAME);
+	tw32_f(MAC_LOW_WMARK_MAX_RX_FRAME, 2);
 
-	err = tg3_setup_phy(tp);
+	err = tg3_setup_phy(tp, 1);
 	if (err)
 		return err;
 
@@ -5257,7 +5170,7 @@ static void tg3_timer(unsigned long __op
 				phy_event = 1;
 
 			if (phy_event)
-				tg3_setup_phy(tp);
+				tg3_setup_phy(tp, 0);
 		} else if (tp->tg3_flags & TG3_FLAG_POLL_SERDES) {
 			u32 mac_stat = tr32(MAC_STATUS);
 			int need_setup = 0;
@@ -5271,15 +5184,13 @@ static void tg3_timer(unsigned long __op
 				need_setup = 1;
 			}
 			if (need_setup) {
-				tw32(MAC_MODE,
+				tw32_f(MAC_MODE,
 				     (tp->mac_mode &
 				      ~MAC_MODE_PORT_MODE_MASK));
-				tr32(MAC_MODE);
 				udelay(40);
-				tw32(MAC_MODE, tp->mac_mode);
-				tr32(MAC_MODE);
+				tw32_f(MAC_MODE, tp->mac_mode);
 				udelay(40);
-				tg3_setup_phy(tp);
+				tg3_setup_phy(tp, 0);
 			}
 		}
 
@@ -5832,8 +5743,7 @@ static void __tg3_set_rx_mode(struct net
 
 	if (rx_mode != tp->rx_mode) {
 		tp->rx_mode = rx_mode;
-		tw32(MAC_RX_MODE, rx_mode);
-		tr32(MAC_RX_MODE);
+		tw32_f(MAC_RX_MODE, rx_mode);
 		udelay(10);
 	}
 }
@@ -5961,7 +5871,7 @@ static int tg3_set_settings(struct net_d
 	struct tg3 *tp = dev->priv;
   
 	if (!(tp->tg3_flags & TG3_FLAG_INIT_COMPLETE) ||
-					tp->link_config.phy_is_low_power)
+	    tp->link_config.phy_is_low_power)
 		return -EAGAIN;
 
 	spin_lock_irq(&tp->lock);
@@ -5977,7 +5887,7 @@ static int tg3_set_settings(struct net_d
 		tp->link_config.duplex = cmd->duplex;
   	}
   
-	tg3_setup_phy(tp);
+	tg3_setup_phy(tp, 1);
 	spin_unlock(&tp->tx_lock);
 	spin_unlock_irq(&tp->lock);
   
@@ -6302,7 +6212,7 @@ static void __devinit tg3_nvram_init(str
 	if (tp->tg3_flags2 & TG3_FLG2_SUN_5704)
 		return;
 
-	tw32(GRC_EEPROM_ADDR,
+	tw32_f(GRC_EEPROM_ADDR,
 	     (EEPROM_ADDR_FSM_RESET |
 	      (EEPROM_DEFAULT_CLOCK_PERIOD <<
 	       EEPROM_ADDR_CLKPERD_SHIFT)));
@@ -6312,9 +6222,8 @@ static void __devinit tg3_nvram_init(str
 		udelay(10);
 
 	/* Enable seeprom accesses. */
-	tw32(GRC_LOCAL_CTRL,
+	tw32_f(GRC_LOCAL_CTRL,
 	     tr32(GRC_LOCAL_CTRL) | GRC_LCLCTRL_AUTO_SEEPROM);
-	tr32(GRC_LOCAL_CTRL);
 	udelay(100);
 
 	if (GET_ASIC_REV(tp->pci_chip_rev_id) != ASIC_REV_5700 &&
@@ -6943,8 +6852,7 @@ static int __devinit tg3_get_invariants(
 		tp->coalesce_mode |= HOSTCC_MODE_32BYTE;
 
 	/* Initialize MAC MI mode, polling disabled. */
-	tw32(MAC_MI_MODE, tp->mi_mode);
-	tr32(MAC_MI_MODE);
+	tw32_f(MAC_MI_MODE, tp->mi_mode);
 	udelay(40);
 
 	/* Initialize data/descriptor byte/word swapping. */
@@ -7219,14 +7127,12 @@ static int __devinit tg3_do_test_dma(str
 	if (to_device) {
 		test_desc.cqid_sqid = (13 << 8) | 2;
 
-		tw32(RDMAC_MODE, RDMAC_MODE_ENABLE);
-		tr32(RDMAC_MODE);
+		tw32_f(RDMAC_MODE, RDMAC_MODE_ENABLE);
 		udelay(40);
 	} else {
 		test_desc.cqid_sqid = (16 << 8) | 7;
 
-		tw32(WDMAC_MODE, WDMAC_MODE_ENABLE);
-		tr32(WDMAC_MODE);
+		tw32_f(WDMAC_MODE, WDMAC_MODE_ENABLE);
 		udelay(40);
 	}
 	test_desc.flags = 0x00000005;
diff -purN linux-post-2.6.4rc2-20040307/drivers/net/tulip/interrupt.c linux-post-2.6.4rc2-20040309/drivers/net/tulip/interrupt.c
--- linux-post-2.6.4rc2-20040307/drivers/net/tulip/interrupt.c	2004-02-18 15:43:06.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/net/tulip/interrupt.c	2004-03-06 05:22:14.000000000 +0000
@@ -211,7 +211,7 @@ int tulip_poll(struct net_device *dev, i
                                        if (tp->rx_buffers[entry].mapping !=
                                            le32_to_cpu(tp->rx_ring[entry].buffer1)) {
                                                printk(KERN_ERR "%s: Internal fault: The skbuff addresses "
-                                                      "do not match in tulip_rx: %08x vs. %llx %p / %p.\n",
+                                                      "do not match in tulip_rx: %08x vs. %08llx %p / %p.\n",
                                                       dev->name,
                                                       le32_to_cpu(tp->rx_ring[entry].buffer1),
                                                       (unsigned long long)tp->rx_buffers[entry].mapping,
diff -purN linux-post-2.6.4rc2-20040307/drivers/net/wan/wanxl.c linux-post-2.6.4rc2-20040309/drivers/net/wan/wanxl.c
--- linux-post-2.6.4rc2-20040307/drivers/net/wan/wanxl.c	2004-02-26 11:26:03.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/net/wan/wanxl.c	2004-03-07 21:50:38.000000000 +0000
@@ -31,7 +31,7 @@
 
 #include "wanxl.h"
 
-static const char* version = "wanXL serial card driver version: 0.47";
+static const char* version = "wanXL serial card driver version: 0.48";
 
 #define PLX_CTL_RESET   0x40000000 /* adapter reset */
 
@@ -73,12 +73,11 @@ typedef struct card_t {
 
 	u8 *plx;		/* PLX PCI9060 virtual base address */
 	struct pci_dev *pdev;	/* for pdev->slot_name */
-	port_t *ports[4];
 	int rx_in;
 	struct sk_buff *rx_skbs[RX_QUEUE_LENGTH];
 	card_status_t *status;	/* shared between host and card */
 	dma_addr_t status_address;
-	port_t __ports[0];
+	port_t ports[0];	/* 1 - 4 port_t structures follow */
 }card_t;
 
 
@@ -89,18 +88,6 @@ static inline port_t* dev_to_port(struct
 }
 
 
-static inline struct net_device *port_to_dev(port_t* port)
-{
-        return port->dev;
-}
-
-
-static inline const char* port_name(port_t *port)
-{
-	return port_to_dev(port)->name;
-}
-
-
 static inline const char* card_name(struct pci_dev *pdev)
 {
 	return pdev->slot_name;
@@ -165,9 +152,9 @@ static inline void wanxl_cable_intr(port
 		dte = (value & STATUS_CABLE_DCE) ? " DCE" : " DTE";
 	}
 	printk(KERN_INFO "%s: %s%s module, %s cable%s%s\n",
-	       port_name(port), pm, dte, cable, dsr, dcd);
+	       port->dev->name, pm, dte, cable, dsr, dcd);
 
-	hdlc_set_carrier(value & STATUS_CABLE_DCD, port_to_dev(port));
+	hdlc_set_carrier(value & STATUS_CABLE_DCD, port->dev);
 }
 
 
@@ -175,7 +162,7 @@ static inline void wanxl_cable_intr(port
 /* Transmit complete interrupt service */
 static inline void wanxl_tx_intr(port_t *port)
 {
-	struct net_device *dev = port_to_dev(port);
+	struct net_device *dev = port->dev;
 	struct net_device_stats *stats = hdlc_stats(dev);
 	while (1) {
                 desc_t *desc = &get_status(port)->tx_descs[port->tx_in];
@@ -210,47 +197,49 @@ static inline void wanxl_tx_intr(port_t 
 static inline void wanxl_rx_intr(card_t *card)
 {
 	desc_t *desc;
-	while(desc = &card->status->rx_descs[card->rx_in],
-	      desc->stat != PACKET_EMPTY) {
-		struct sk_buff *skb = card->rx_skbs[card->rx_in];
-		port_t *port = card->ports[desc->stat & PACKET_PORT_MASK];
-		struct net_device *dev = port_to_dev(port);
-		struct net_device_stats *stats = hdlc_stats(dev);
-
+	while (desc = &card->status->rx_descs[card->rx_in],
+	       desc->stat != PACKET_EMPTY) {
 		if ((desc->stat & PACKET_PORT_MASK) > card->n_ports)
 			printk(KERN_CRIT "wanXL %s: received packet for"
 			       " nonexistent port\n", card_name(card->pdev));
-
-		else if (!skb)
-			stats->rx_dropped++;
-
 		else {
-			pci_unmap_single(card->pdev, desc->address,
-					 BUFFER_LENGTH, PCI_DMA_FROMDEVICE);
-			skb_put(skb, desc->length);
+			struct sk_buff *skb = card->rx_skbs[card->rx_in];
+			port_t *port = &card->ports[desc->stat &
+						    PACKET_PORT_MASK];
+			struct net_device *dev = port->dev;
+			struct net_device_stats *stats = hdlc_stats(dev);
+
+			if (!skb)
+				stats->rx_dropped++;
+			else {
+				pci_unmap_single(card->pdev, desc->address,
+						 BUFFER_LENGTH,
+						 PCI_DMA_FROMDEVICE);
+				skb_put(skb, desc->length);
 
 #ifdef DEBUG_PKT
-			printk(KERN_DEBUG "%s RX(%i):", port_name(port),
-			       skb->len);
-			debug_frame(skb);
-#endif
-			stats->rx_packets++;
-			stats->rx_bytes += skb->len;
-			skb->mac.raw = skb->data;
-			skb->dev = dev;
-			dev->last_rx = jiffies;
-			skb->protocol = hdlc_type_trans(skb, dev);
-			netif_rx(skb);
-			skb = NULL;
-		}
-
-		if (!skb) {
-			skb = dev_alloc_skb(BUFFER_LENGTH);
-			desc->address = skb ?
-				pci_map_single(card->pdev, skb->data,
-					       BUFFER_LENGTH,
-					       PCI_DMA_FROMDEVICE) : 0;
-			card->rx_skbs[card->rx_in] = skb;
+				printk(KERN_DEBUG "%s RX(%i):", dev->name,
+				       skb->len);
+				debug_frame(skb);
+#endif
+				stats->rx_packets++;
+				stats->rx_bytes += skb->len;
+				skb->mac.raw = skb->data;
+				skb->dev = dev;
+				dev->last_rx = jiffies;
+				skb->protocol = hdlc_type_trans(skb, dev);
+				netif_rx(skb);
+				skb = NULL;
+			}
+
+			if (!skb) {
+				skb = dev_alloc_skb(BUFFER_LENGTH);
+				desc->address = skb ?
+					pci_map_single(card->pdev, skb->data,
+						       BUFFER_LENGTH,
+						       PCI_DMA_FROMDEVICE) : 0;
+				card->rx_skbs[card->rx_in] = skb;
+			}
 		}
 		desc->stat = PACKET_EMPTY; /* Free descriptor */
 		card->rx_in = (card->rx_in + 1) % RX_QUEUE_LENGTH;
@@ -273,9 +262,9 @@ static irqreturn_t wanxl_intr(int irq, v
 
                 for (i = 0; i < card->n_ports; i++) {
 			if (stat & (1 << (DOORBELL_FROM_CARD_TX_0 + i)))
-				wanxl_tx_intr(card->ports[i]);
+				wanxl_tx_intr(&card->ports[i]);
 			if (stat & (1 << (DOORBELL_FROM_CARD_CABLE_0 + i)))
-				wanxl_cable_intr(card->ports[i]);
+				wanxl_cable_intr(&card->ports[i]);
 		}
 		if (stat & (1 << DOORBELL_FROM_CARD_RX))
 			wanxl_rx_intr(card);
@@ -297,8 +286,7 @@ static int wanxl_xmit(struct sk_buff *sk
         if (desc->stat != PACKET_EMPTY) {
                 /* should never happen - previous xmit should stop queue */
 #ifdef DEBUG_PKT
-                printk(KERN_DEBUG "%s: transmitter buffer full\n",
-		       port_name(port));
+                printk(KERN_DEBUG "%s: transmitter buffer full\n", dev->name);
 #endif
 		netif_stop_queue(dev);
 		spin_unlock_irq(&port->lock);
@@ -306,7 +294,7 @@ static int wanxl_xmit(struct sk_buff *sk
 	}
 
 #ifdef DEBUG_PKT
-	printk(KERN_DEBUG "%s TX(%i):", port_name(port), skb->len);
+	printk(KERN_DEBUG "%s TX(%i):", dev->name, skb->len);
 	debug_frame(skb);
 #endif
 
@@ -324,8 +312,7 @@ static int wanxl_xmit(struct sk_buff *sk
 	if (get_status(port)->tx_descs[port->tx_out].stat != PACKET_EMPTY) {
 		netif_stop_queue(dev);
 #ifdef DEBUG_PKT
-		printk(KERN_DEBUG "%s: transmitter buffer full\n",
-		       port_name(port));
+		printk(KERN_DEBUG "%s: transmitter buffer full\n", dev->name);
 #endif
 	}
 
@@ -417,7 +404,7 @@ static int wanxl_open(struct net_device 
 	int i;
 
 	if (get_status(port)->open) {
-		printk(KERN_ERR "%s: port already open\n", port_name(port));
+		printk(KERN_ERR "%s: port already open\n", dev->name);
 		return -EIO;
 	}
 	if ((i = hdlc_open(dev)) != 0)
@@ -435,7 +422,7 @@ static int wanxl_open(struct net_device 
 			return 0;
 	while (time_after(timeout, jiffies));
 
-	printk(KERN_ERR "%s: unable to open port\n", port_name(port));
+	printk(KERN_ERR "%s: unable to open port\n", dev->name);
 	/* ask the card to close the port, should it be still alive */
 	writel(1 << (DOORBELL_TO_CARD_CLOSE_0 + port->node), dbr);
 	return -EFAULT;
@@ -461,7 +448,7 @@ static int wanxl_close(struct net_device
 	while (time_after(timeout, jiffies));
 
 	if (get_status(port)->open)
-		printk(KERN_ERR "%s: unable to close port\n", port_name(port));
+		printk(KERN_ERR "%s: unable to close port\n", dev->name);
 
 	for (i = 0; i < TX_BUFFERS; i++) {
 		desc_t *desc = &get_status(port)->tx_descs[i];
@@ -528,11 +515,10 @@ static void wanxl_pci_remove_one(struct 
 	card_t *card = pci_get_drvdata(pdev);
 	int i;
 
-	for (i = 0; i < 4; i++)
-		if (card->ports[i]) {
-			struct net_device *dev = port_to_dev(card->ports[i]);
-			unregister_hdlc_device(dev);
-		}
+	for (i = 0; i < card->n_ports; i++) {
+		unregister_hdlc_device(card->ports[i].dev);
+		free_netdev(card->ports[i].dev);
+	}
 
 	/* unregister and free all host resources */
 	if (card->irq)
@@ -555,13 +541,10 @@ static void wanxl_pci_remove_one(struct 
 		pci_free_consistent(pdev, sizeof(card_status_t),
 				    card->status, card->status_address);
 
-	for (i = 0; i < card->n_ports; i++)
-		if (card->__ports[i].dev)
-			free_netdev(card->__ports[i].dev);
-
+	pci_release_regions(pdev);
+	pci_disable_device(pdev);
 	pci_set_drvdata(pdev, NULL);
 	kfree(card);
-	pci_release_regions(pdev);
 }
 
 
@@ -599,13 +582,15 @@ static int __devinit wanxl_pci_init_one(
 	   work on most platforms */
 	if (pci_set_consistent_dma_mask(pdev, 0x0FFFFFFF) ||
 	    pci_set_dma_mask(pdev, 0x0FFFFFFF)) {
-		printk(KERN_ERR "No usable DMA configuration\n");
+		printk(KERN_ERR "wanXL: No usable DMA configuration\n");
 		return -EIO;
 	}
 
 	i = pci_request_regions(pdev, "wanXL");
-	if (i)
+	if (i) {
+		pci_disable_device(pdev);
 		return i;
+	}
 
 	switch (pdev->device) {
 	case PCI_DEVICE_ID_SBE_WANXL100: ports = 1; break;
@@ -619,23 +604,13 @@ static int __devinit wanxl_pci_init_one(
 		printk(KERN_ERR "wanXL %s: unable to allocate memory\n",
 		       card_name(pdev));
 		pci_release_regions(pdev);
+		pci_disable_device(pdev);
 		return -ENOBUFS;
 	}
 	memset(card, 0, alloc_size);
 
 	pci_set_drvdata(pdev, card);
 	card->pdev = pdev;
-	card->n_ports = ports;
-
-	for (i = 0; i < ports; i++) {
-		card->__ports[i].dev = alloc_hdlcdev(&card->__ports[i]);
-		if (!card->__ports[i].dev) {
-			printk(KERN_ERR "wanXL %s: unable to allocate memory\n",
-			       card_name(pdev));
-			wanxl_pci_remove_one(pdev);
-			return -ENOMEM;
-		}
-	}
 
 	card->status = pci_alloc_consistent(pdev, sizeof(card_status_t),
 					    &card->status_address);
@@ -655,7 +630,7 @@ static int __devinit wanxl_pci_init_one(
 	   to indicate the card can do 32-bit DMA addressing */
 	if (pci_set_consistent_dma_mask(pdev, 0xFFFFFFFF) ||
 	    pci_set_dma_mask(pdev, 0xFFFFFFFF)) {
-		printk(KERN_ERR "No usable DMA configuration\n");
+		printk(KERN_ERR "wanXL: No usable DMA configuration\n");
 		wanxl_pci_remove_one(pdev);
 		return -EIO;
 	}
@@ -767,17 +742,11 @@ static int __devinit wanxl_pci_init_one(
 	ramsize = stat;
 #endif
 
-	printk(KERN_INFO "wanXL %s: at 0x%X, %u KB of RAM at 0x%X, irq"
-	       " %u\n" KERN_INFO "wanXL %s: port", card_name(pdev),
-	       plx_phy, ramsize / 1024, mem_phy, pdev->irq, card_name(pdev));
-
-	for (i = 0; i < ports; i++)
-		printk("%s #%i: %s", i ? "," : "", i,
-		       port_name(card->ports[i]));
-	printk("\n");
+	printk(KERN_INFO "wanXL %s: at 0x%X, %u KB of RAM at 0x%X, irq %u\n",
+	       card_name(pdev), plx_phy, ramsize / 1024, mem_phy, pdev->irq);
 
 	/* Allocate IRQ */
-	if(request_irq(pdev->irq, wanxl_intr, SA_SHIRQ, "wanXL", card)) {
+	if (request_irq(pdev->irq, wanxl_intr, SA_SHIRQ, "wanXL", card)) {
 		printk(KERN_WARNING "wanXL %s: could not allocate IRQ%i.\n",
 		       card_name(pdev), pdev->irq);
 		wanxl_pci_remove_one(pdev);
@@ -786,9 +755,18 @@ static int __devinit wanxl_pci_init_one(
 	card->irq = pdev->irq;
 
 	for (i = 0; i < ports; i++) {
-		port_t *port = &card->__ports[i];
-		struct net_device *dev = port_to_dev(port);
-		hdlc_device *hdlc = dev_to_hdlc(dev);
+		hdlc_device *hdlc;
+		port_t *port = &card->ports[i];
+		struct net_device *dev = alloc_hdlcdev(port);
+		if (!dev) {
+			printk(KERN_ERR "wanXL %s: unable to allocate"
+			       " memory\n", card_name(pdev));
+			wanxl_pci_remove_one(pdev);
+			return -ENOMEM;
+		}
+
+		port->dev = dev;
+		hdlc = dev_to_hdlc(dev);
 		spin_lock_init(&port->lock);
 		SET_MODULE_OWNER(dev);
 		dev->tx_queue_len = 50;
@@ -797,7 +775,6 @@ static int __devinit wanxl_pci_init_one(
 		dev->stop = wanxl_close;
 		hdlc->attach = wanxl_attach;
 		hdlc->xmit = wanxl_xmit;
-		card->ports[i] = port;
 		dev->get_stats = wanxl_get_stats;
 		port->card = card;
 		port->node = i;
@@ -805,12 +782,22 @@ static int __devinit wanxl_pci_init_one(
 		if (register_hdlc_device(dev)) {
 			printk(KERN_ERR "wanXL %s: unable to register hdlc"
 			       " device\n", card_name(pdev));
-			card->ports[i] = NULL;
+			free_netdev(dev);
 			wanxl_pci_remove_one(pdev);
 			return -ENOBUFS;
 		}
+		card->n_ports++;
 	}
 
+	printk(KERN_INFO "wanXL %s: port", card_name(pdev));
+	for (i = 0; i < ports; i++)
+		printk("%s #%i: %s", i ? "," : "", i,
+		       card->ports[i].dev->name);
+	printk("\n");
+
+	for (i = 0; i < ports; i++)
+		wanxl_cable_intr(&card->ports[i]); /* get carrier status etc.*/
+
 	return 0;
 }
 
diff -purN linux-post-2.6.4rc2-20040307/drivers/sbus/char/vfc_dev.c linux-post-2.6.4rc2-20040309/drivers/sbus/char/vfc_dev.c
--- linux-post-2.6.4rc2-20040307/drivers/sbus/char/vfc_dev.c	2004-01-05 19:02:48.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/sbus/char/vfc_dev.c	2004-03-07 07:04:56.000000000 +0000
@@ -24,6 +24,7 @@
 #include <linux/smp_lock.h>
 #include <linux/delay.h>
 #include <linux/spinlock.h>
+#include <linux/mm.h>
 
 #include <asm/openprom.h>
 #include <asm/oplib.h>
diff -purN linux-post-2.6.4rc2-20040307/drivers/scsi/ata_piix.c linux-post-2.6.4rc2-20040309/drivers/scsi/ata_piix.c
--- linux-post-2.6.4rc2-20040307/drivers/scsi/ata_piix.c	2004-03-03 07:33:28.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/scsi/ata_piix.c	2004-03-09 03:23:15.000000000 +0000
@@ -28,12 +28,13 @@
 #include <linux/libata.h>
 
 #define DRV_NAME	"ata_piix"
-#define DRV_VERSION	"1.00"
+#define DRV_VERSION	"1.01"
 
 enum {
 	PIIX_IOCFG		= 0x54, /* IDE I/O configuration register */
 	ICH5_PCS		= 0x92,	/* port control and status */
 
+	PIIX_FLAG_CHECKINTR	= (1 << 29), /* make sure PCI INTx enabled */
 	PIIX_FLAG_COMBINED	= (1 << 30), /* combined mode possible */
 
 	PIIX_COMB_PRI		= (1 << 0), /* combined mode, PATA primary */
@@ -163,7 +164,8 @@ static struct ata_port_info piix_port_in
 	/* ich5_pata */
 	{
 		.sht		= &piix_sht,
-		.host_flags	= ATA_FLAG_SLAVE_POSS | ATA_FLAG_SRST,
+		.host_flags	= ATA_FLAG_SLAVE_POSS | ATA_FLAG_SRST |
+				  PIIX_FLAG_CHECKINTR,
 		.pio_mask	= 0x03,	/* pio3-4 */
 		.udma_mask	= ATA_UDMA_MASK_40C, /* FIXME: cbl det */
 		.port_ops	= &piix_pata_ops,
@@ -172,8 +174,8 @@ static struct ata_port_info piix_port_in
 	/* ich5_sata */
 	{
 		.sht		= &piix_sht,
-		.host_flags	= ATA_FLAG_SATA | PIIX_FLAG_COMBINED |
-				  ATA_FLAG_SRST,
+		.host_flags	= ATA_FLAG_SATA | ATA_FLAG_SRST |
+				  PIIX_FLAG_COMBINED | PIIX_FLAG_CHECKINTR,
 		.pio_mask	= 0x03,	/* pio3-4 */
 		.udma_mask	= 0x7f,	/* udma0-6 ; FIXME */
 		.port_ops	= &piix_sata_ops,
@@ -518,6 +520,18 @@ static void piix_probe_combined (struct 
 		*mask |= PIIX_COMB_PRI;
 }
 
+/* move to PCI layer, integrate w/ MSI stuff */
+static void pci_enable_intx(struct pci_dev *pdev)
+{
+	u16 pci_command;
+
+	pci_read_config_word(pdev, PCI_COMMAND, &pci_command);
+	if (pci_command & PCI_COMMAND_INTX_DISABLE) {
+		pci_command &= ~PCI_COMMAND_INTX_DISABLE;
+		pci_write_config_word(pdev, PCI_COMMAND, pci_command);
+	}
+}
+
 /**
  *	piix_init_one - Register PIIX ATA PCI device with kernel services
  *	@pdev: PCI device to register
@@ -552,6 +566,15 @@ static int piix_init_one (struct pci_dev
 	if (port_info[0]->host_flags & PIIX_FLAG_COMBINED)
 		piix_probe_combined(pdev, &combined);
 
+	/* On ICH5, some BIOSen disable the interrupt using the
+	 * PCI_COMMAND_INTX_DISABLE bit added in PCI 2.3.
+	 * On ICH6, this bit has the same effect, but only when
+	 * MSI is disabled (and it is disabled, as we don't use
+	 * message-signalled interrupts currently).
+	 */
+	if (port_info[0]->host_flags & PIIX_FLAG_CHECKINTR)
+		pci_enable_intx(pdev);
+
 	if (combined & PIIX_COMB_PRI)
 		sata_comb = 1;
 	else if (combined & PIIX_COMB_SEC)
diff -purN linux-post-2.6.4rc2-20040307/drivers/scsi/libata-core.c linux-post-2.6.4rc2-20040309/drivers/scsi/libata-core.c
--- linux-post-2.6.4rc2-20040307/drivers/scsi/libata-core.c	2004-02-28 22:01:12.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/scsi/libata-core.c	2004-03-09 03:06:49.000000000 +0000
@@ -34,6 +34,7 @@
 #include <linux/delay.h>
 #include <linux/timer.h>
 #include <linux/interrupt.h>
+#include <linux/suspend.h>
 #include <scsi/scsi.h>
 #include "scsi.h"
 #include "hosts.h"
@@ -2600,6 +2601,10 @@ static int ata_thread (void *data)
 
                 if (signal_pending (current))
                         flush_signals(current);
+                        
+                if (current->flags & PF_FREEZE)
+			refrigerator(PF_IOTHREAD);
+                                                        
 
                 if ((timeout < 0) || (ap->time_to_die))
                         break;
diff -purN linux-post-2.6.4rc2-20040307/drivers/scsi/sata_promise.c linux-post-2.6.4rc2-20040309/drivers/scsi/sata_promise.c
--- linux-post-2.6.4rc2-20040307/drivers/scsi/sata_promise.c	2004-02-27 02:23:26.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/scsi/sata_promise.c	2004-03-09 03:33:20.000000000 +0000
@@ -35,7 +35,7 @@
 #include <asm/io.h>
 
 #define DRV_NAME	"sata_promise"
-#define DRV_VERSION	"0.90"
+#define DRV_VERSION	"0.91"
 
 
 enum {
@@ -1014,6 +1014,14 @@ static void pdc_eng_timeout(struct ata_p
 		goto out;
 	}
 
+	/* hack alert!  We cannot use the supplied completion
+	 * function from inside the ->eh_strategy_handler() thread.
+	 * libata is the only user of ->eh_strategy_handler() in
+	 * any kernel, so the default scsi_done() assumes it is
+	 * not being called from the SCSI EH.
+	 */
+	qc->scsidone = scsi_finish_command;
+
 	switch (qc->tf.protocol) {
 	case ATA_PROT_DMA_READ:
 	case ATA_PROT_DMA_WRITE:
diff -purN linux-post-2.6.4rc2-20040307/drivers/usb/serial/safe_serial.c linux-post-2.6.4rc2-20040309/drivers/usb/serial/safe_serial.c
--- linux-post-2.6.4rc2-20040307/drivers/usb/serial/safe_serial.c	2003-08-27 11:45:14.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/drivers/usb/serial/safe_serial.c	2004-03-07 07:16:10.000000000 +0000
@@ -93,6 +93,7 @@ static int padded = CONFIG_USB_SAFE_PADD
 
 MODULE_AUTHOR (DRIVER_AUTHOR);
 MODULE_DESCRIPTION (DRIVER_DESC);
+MODULE_LICENSE("GPL");
 
 #if defined(CONFIG_USBD_SAFE_SERIAL_VENDOR) && !defined(CONFIG_USBD_SAFE_SERIAL_PRODUCT)
 #abort "SAFE_SERIAL_VENDOR defined without SAFE_SERIAL_PRODUCT"
diff -purN linux-post-2.6.4rc2-20040307/fs/aio.c linux-post-2.6.4rc2-20040309/fs/aio.c
--- linux-post-2.6.4rc2-20040307/fs/aio.c	2003-11-11 02:05:34.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/fs/aio.c	2004-03-07 07:04:57.000000000 +0000
@@ -312,7 +312,7 @@ void wait_for_all_aios(struct kioctx *ct
 /* wait_on_sync_kiocb:
  *	Waits on the given sync kiocb to complete.
  */
-ssize_t wait_on_sync_kiocb(struct kiocb *iocb)
+ssize_t fastcall wait_on_sync_kiocb(struct kiocb *iocb)
 {
 	while (iocb->ki_users) {
 		set_current_state(TASK_UNINTERRUPTIBLE);
@@ -331,7 +331,7 @@ ssize_t wait_on_sync_kiocb(struct kiocb 
  * go away, they will call put_ioctx and release any pinned memory
  * associated with the request (held via struct page * references).
  */
-void exit_aio(struct mm_struct *mm)
+void fastcall exit_aio(struct mm_struct *mm)
 {
 	struct kioctx *ctx = mm->ioctx_list;
 	mm->ioctx_list = NULL;
@@ -356,7 +356,7 @@ void exit_aio(struct mm_struct *mm)
  *	Called when the last user of an aio context has gone away,
  *	and the struct needs to be freed.
  */
-void __put_ioctx(struct kioctx *ctx)
+void fastcall __put_ioctx(struct kioctx *ctx)
 {
 	unsigned nr_events = ctx->max_reqs;
 
@@ -383,7 +383,7 @@ void __put_ioctx(struct kioctx *ctx)
  * req (after submitting it) and aio_complete() freeing the req.
  */
 static struct kiocb *FASTCALL(__aio_get_req(struct kioctx *ctx));
-static struct kiocb *__aio_get_req(struct kioctx *ctx)
+static struct kiocb fastcall *__aio_get_req(struct kioctx *ctx)
 {
 	struct kiocb *req = NULL;
 	struct aio_ring *ring;
@@ -509,7 +509,7 @@ static int __aio_put_req(struct kioctx *
  *	Returns true if this put was the last user of the kiocb,
  *	false if the request is still in use.
  */
-int aio_put_req(struct kiocb *req)
+int fastcall aio_put_req(struct kiocb *req)
 {
 	struct kioctx *ctx = req->ki_ctx;
 	int ret;
@@ -596,7 +596,7 @@ static void aio_kick_handler(void *data)
 	unuse_mm(ctx->mm);
 }
 
-void kick_iocb(struct kiocb *iocb)
+void fastcall kick_iocb(struct kiocb *iocb)
 {
 	struct kioctx	*ctx = iocb->ki_ctx;
 
@@ -622,7 +622,7 @@ void kick_iocb(struct kiocb *iocb)
  *	Returns true if this is the last user of the request.  The 
  *	only other user of the request can be the cancellation code.
  */
-int aio_complete(struct kiocb *iocb, long res, long res2)
+int fastcall aio_complete(struct kiocb *iocb, long res, long res2)
 {
 	struct kioctx	*ctx = iocb->ki_ctx;
 	struct aio_ring_info	*info;
@@ -985,7 +985,7 @@ asmlinkage long sys_io_destroy(aio_conte
 	return -EINVAL;
 }
 
-int io_submit_one(struct kioctx *ctx, struct iocb __user *user_iocb,
+int fastcall io_submit_one(struct kioctx *ctx, struct iocb __user *user_iocb,
 			 struct iocb *iocb)
 {
 	struct kiocb *req;
diff -purN linux-post-2.6.4rc2-20040307/fs/buffer.c linux-post-2.6.4rc2-20040309/fs/buffer.c
--- linux-post-2.6.4rc2-20040307/fs/buffer.c	2004-02-19 03:42:31.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/fs/buffer.c	2004-03-07 07:16:11.000000000 +0000
@@ -97,7 +97,7 @@ void wake_up_buffer(struct buffer_head *
 }
 EXPORT_SYMBOL(wake_up_buffer);
 
-void unlock_buffer(struct buffer_head *bh)
+void fastcall unlock_buffer(struct buffer_head *bh)
 {
 	/*
 	 * unlock_buffer against a zero-count bh is a bug, if the page
@@ -404,7 +404,7 @@ __find_get_block_slow(struct block_devic
 	struct inode *bd_inode = bdev->bd_inode;
 	struct address_space *bd_mapping = bd_inode->i_mapping;
 	struct buffer_head *ret = NULL;
-	unsigned long index;
+	pgoff_t index;
 	struct buffer_head *bh;
 	struct buffer_head *head;
 	struct page *page;
@@ -1093,7 +1093,7 @@ link_dev_buffers(struct page *page, stru
  */ 
 static void
 init_page_buffers(struct page *page, struct block_device *bdev,
-			int block, int size)
+			sector_t block, int size)
 {
 	struct buffer_head *head = page_buffers(page);
 	struct buffer_head *bh = head;
@@ -1121,8 +1121,8 @@ init_page_buffers(struct page *page, str
  * This is user purely for blockdev mappings.
  */
 static struct page *
-grow_dev_page(struct block_device *bdev, unsigned long block,
-			unsigned long index, int size)
+grow_dev_page(struct block_device *bdev, sector_t block,
+		pgoff_t index, int size)
 {
 	struct inode *inode = bdev->bd_inode;
 	struct page *page;
@@ -1178,10 +1178,10 @@ failed:
  * grow_dev_page() will go BUG() if this happens.
  */
 static inline int
-grow_buffers(struct block_device *bdev, unsigned long block, int size)
+grow_buffers(struct block_device *bdev, sector_t block, int size)
 {
 	struct page *page;
-	unsigned long index;
+	pgoff_t index;
 	int sizebits;
 
 	/* Size must be multiple of hard sectorsize */
@@ -1256,7 +1256,7 @@ __getblk_slow(struct block_device *bdev,
  * mark_buffer_dirty() is atomic.  It takes bh->b_page->mapping->private_lock,
  * mapping->page_lock and the global inode_lock.
  */
-void mark_buffer_dirty(struct buffer_head *bh)
+void fastcall mark_buffer_dirty(struct buffer_head *bh)
 {
 	if (!buffer_uptodate(bh))
 		buffer_error();
@@ -1738,8 +1738,8 @@ static int __block_write_full_page(struc
 			get_block_t *get_block, struct writeback_control *wbc)
 {
 	int err;
-	unsigned long block;
-	unsigned long last_block;
+	sector_t block;
+	sector_t last_block;
 	struct buffer_head *bh, *head;
 	int nr_underway = 0;
 
@@ -2207,7 +2207,7 @@ int cont_prepare_write(struct page *page
 	struct address_space *mapping = page->mapping;
 	struct inode *inode = mapping->host;
 	struct page *new_page;
-	unsigned long pgpos;
+	pgoff_t pgpos;
 	long status;
 	unsigned zerofrom;
 	unsigned blocksize = 1 << inode->i_blkbits;
@@ -2317,6 +2317,28 @@ int generic_commit_write(struct file *fi
 	return 0;
 }
 
+
+/*
+ * nobh_prepare_write()'s prereads are special: the buffer_heads are freed
+ * immediately, while under the page lock.  So it needs a special end_io
+ * handler which does not touch the bh after unlocking it.
+ *
+ * Note: unlock_buffer() sort-of does touch the bh after unlocking it, but
+ * a race there is benign: unlock_buffer() only use the bh's address for
+ * hashing after unlocking the buffer, so it doesn't actually touch the bh
+ * itself.
+ */
+static void end_buffer_read_nobh(struct buffer_head *bh, int uptodate)
+{
+	if (uptodate) {
+		set_buffer_uptodate(bh);
+	} else {
+		/* This happens, due to failed READA attempts. */
+		clear_buffer_uptodate(bh);
+	}
+	unlock_buffer(bh);
+}
+
 /*
  * On entry, the page is fully not uptodate.
  * On exit the page is fully uptodate in the areas outside (from,to)
@@ -2408,12 +2430,25 @@ int nobh_prepare_write(struct page *page
 	}
 
 	if (nr_reads) {
-		ll_rw_block(READ, nr_reads, read_bh);
+		struct buffer_head *bh;
+
+		/*
+		 * The page is locked, so these buffers are protected from
+		 * any VM or truncate activity.  Hence we don't need to care
+		 * for the buffer_head refcounts.
+		 */
+		for (i = 0; i < nr_reads; i++) {
+			bh = read_bh[i];
+			lock_buffer(bh);
+			bh->b_end_io = end_buffer_read_nobh;
+			submit_bh(READ, bh);
+		}
 		for (i = 0; i < nr_reads; i++) {
-			wait_on_buffer(read_bh[i]);
-			if (!buffer_uptodate(read_bh[i]))
+			bh = read_bh[i];
+			wait_on_buffer(bh);
+			if (!buffer_uptodate(bh))
 				ret = -EIO;
-			free_buffer_head(read_bh[i]);
+			free_buffer_head(bh);
 			read_bh[i] = NULL;
 		}
 		if (ret)
@@ -2512,9 +2547,11 @@ EXPORT_SYMBOL(nobh_truncate_page);
 int block_truncate_page(struct address_space *mapping,
 			loff_t from, get_block_t *get_block)
 {
-	unsigned long index = from >> PAGE_CACHE_SHIFT;
+	pgoff_t index = from >> PAGE_CACHE_SHIFT;
 	unsigned offset = from & (PAGE_CACHE_SIZE-1);
-	unsigned blocksize, iblock, length, pos;
+	unsigned blocksize;
+	pgoff_t iblock;
+	unsigned length, pos;
 	struct inode *inode = mapping->host;
 	struct page *page;
 	struct buffer_head *bh;
@@ -2594,7 +2631,7 @@ int block_write_full_page(struct page *p
 {
 	struct inode * const inode = page->mapping->host;
 	loff_t i_size = i_size_read(inode);
-	const unsigned long end_index = i_size >> PAGE_CACHE_SHIFT;
+	const pgoff_t end_index = i_size >> PAGE_CACHE_SHIFT;
 	unsigned offset;
 	void *kaddr;
 
diff -purN linux-post-2.6.4rc2-20040307/fs/ext2/ialloc.c linux-post-2.6.4rc2-20040309/fs/ext2/ialloc.c
--- linux-post-2.6.4rc2-20040307/fs/ext2/ialloc.c	2004-01-19 23:37:59.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/fs/ext2/ialloc.c	2004-03-07 07:16:09.000000000 +0000
@@ -431,8 +431,8 @@ static int find_group_other(struct super
 	 * That failed: try linear search for a free inode, even if that group
 	 * has no free blocks.
 	 */
-	group = parent_group + 1;
-	for (i = 2; i < ngroups; i++) {
+	group = parent_group;
+	for (i = 0; i < ngroups; i++) {
 		if (++group >= ngroups)
 			group = 0;
 		desc = ext2_get_group_desc (sb, group, &bh);
diff -purN linux-post-2.6.4rc2-20040307/fs/ext3/ialloc.c linux-post-2.6.4rc2-20040309/fs/ext3/ialloc.c
--- linux-post-2.6.4rc2-20040307/fs/ext3/ialloc.c	2004-01-19 23:37:59.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/fs/ext3/ialloc.c	2004-03-07 07:16:09.000000000 +0000
@@ -398,8 +398,8 @@ static int find_group_other(struct super
 	 * That failed: try linear search for a free inode, even if that group
 	 * has no free blocks.
 	 */
-	group = parent_group + 1;
-	for (i = 2; i < ngroups; i++) {
+	group = parent_group;
+	for (i = 0; i < ngroups; i++) {
 		if (++group >= ngroups)
 			group = 0;
 		desc = ext3_get_group_desc (sb, group, &bh);
diff -purN linux-post-2.6.4rc2-20040307/fs/fcntl.c linux-post-2.6.4rc2-20040309/fs/fcntl.c
--- linux-post-2.6.4rc2-20040307/fs/fcntl.c	2004-01-19 06:32:50.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/fs/fcntl.c	2004-03-07 07:04:57.000000000 +0000
@@ -19,7 +19,7 @@
 #include <asm/siginfo.h>
 #include <asm/uaccess.h>
 
-void set_close_on_exec(unsigned int fd, int flag)
+void fastcall set_close_on_exec(unsigned int fd, int flag)
 {
 	struct files_struct *files = current->files;
 	spin_lock(&files->file_lock);
diff -purN linux-post-2.6.4rc2-20040307/fs/file_table.c linux-post-2.6.4rc2-20040309/fs/file_table.c
--- linux-post-2.6.4rc2-20040307/fs/file_table.c	2004-01-19 06:22:23.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/fs/file_table.c	2004-03-07 07:04:57.000000000 +0000
@@ -152,7 +152,7 @@ void close_private_file(struct file *fil
 
 EXPORT_SYMBOL(close_private_file);
 
-void fput(struct file *file)
+void fastcall fput(struct file *file)
 {
 	if (atomic_dec_and_test(&file->f_count))
 		__fput(file);
@@ -163,7 +163,7 @@ EXPORT_SYMBOL(fput);
 /* __fput is called from task context when aio completion releases the last
  * last use of a struct file *.  Do not use otherwise.
  */
-void __fput(struct file *file)
+void fastcall __fput(struct file *file)
 {
 	struct dentry *dentry = file->f_dentry;
 	struct vfsmount *mnt = file->f_vfsmnt;
@@ -192,7 +192,7 @@ void __fput(struct file *file)
 	mntput(mnt);
 }
 
-struct file *fget(unsigned int fd)
+struct file fastcall *fget(unsigned int fd)
 {
 	struct file *file;
 	struct files_struct *files = current->files;
@@ -214,7 +214,7 @@ EXPORT_SYMBOL(fget);
  * and a flag is returned to be passed to the corresponding fput_light().
  * There must not be a cloning between an fget_light/fput_light pair.
  */
-struct file *fget_light(unsigned int fd, int *fput_needed)
+struct file fastcall *fget_light(unsigned int fd, int *fput_needed)
 {
 	struct file *file;
 	struct files_struct *files = current->files;
diff -purN linux-post-2.6.4rc2-20040307/fs/jfs/acl.c linux-post-2.6.4rc2-20040309/fs/jfs/acl.c
--- linux-post-2.6.4rc2-20040307/fs/jfs/acl.c	2004-02-19 06:54:07.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/fs/jfs/acl.c	2004-03-08 21:55:48.000000000 +0000
@@ -24,7 +24,7 @@
 #include "jfs_xattr.h"
 #include "jfs_acl.h"
 
-struct posix_acl *jfs_get_acl(struct inode *inode, int type)
+static struct posix_acl *jfs_get_acl(struct inode *inode, int type)
 {
 	struct posix_acl *acl;
 	char *ea_name;
@@ -74,7 +74,7 @@ struct posix_acl *jfs_get_acl(struct ino
 	return acl;
 }
 
-int jfs_set_acl(struct inode *inode, int type, struct posix_acl *acl)
+static int jfs_set_acl(struct inode *inode, int type, struct posix_acl *acl)
 {
 	char *ea_name;
 	struct jfs_inode_info *ji = JFS_IP(inode);
@@ -247,7 +247,7 @@ cleanup:
 	return rc;
 }
 
-int jfs_acl_chmod(struct inode *inode)
+static int jfs_acl_chmod(struct inode *inode)
 {
 	struct posix_acl *acl, *clone;
 	int rc;
diff -purN linux-post-2.6.4rc2-20040307/fs/jfs/jfs_acl.h linux-post-2.6.4rc2-20040309/fs/jfs/jfs_acl.h
--- linux-post-2.6.4rc2-20040307/fs/jfs/jfs_acl.h	2003-07-18 20:08:16.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/fs/jfs/jfs_acl.h	2004-03-08 21:55:48.000000000 +0000
@@ -22,8 +22,6 @@
 
 #include <linux/xattr_acl.h>
 
-struct posix_acl *jfs_get_acl(struct inode *, int);
-int jfs_set_acl(struct inode *, int, struct posix_acl *);
 int jfs_permission(struct inode *, int, struct nameidata *);
 int jfs_init_acl(struct inode *, struct inode *);
 int jfs_setattr(struct dentry *, struct iattr *);
diff -purN linux-post-2.6.4rc2-20040307/fs/jfs/jfs_dmap.c linux-post-2.6.4rc2-20040309/fs/jfs/jfs_dmap.c
--- linux-post-2.6.4rc2-20040307/fs/jfs/jfs_dmap.c	2003-10-08 16:07:12.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/fs/jfs/jfs_dmap.c	2004-03-08 21:55:48.000000000 +0000
@@ -124,7 +124,7 @@ static int dbAllocAG(struct bmap * bmp, 
 		     s64 * results);
 static int dbAllocCtl(struct bmap * bmp, s64 nblocks, int l2nb, s64 blkno,
 		      s64 * results);
-int dbExtend(struct inode *ip, s64 blkno, s64 nblocks, s64 addnblocks);
+static int dbExtend(struct inode *ip, s64 blkno, s64 nblocks, s64 addnblocks);
 static int dbFindBits(u32 word, int l2nb);
 static int dbFindCtl(struct bmap * bmp, int l2nb, int level, s64 * blkno);
 static int dbFindLeaf(dmtree_t * tp, int l2nb, int *leafidx);
@@ -134,10 +134,10 @@ static int dbFreeDmap(struct bmap * bmp,
 		      int nblocks);
 static int dbMaxBud(u8 * cp);
 s64 dbMapFileSizeToMapSize(struct inode *ipbmap);
-int blkstol2(s64 nb);
+static int blkstol2(s64 nb);
 
-int cntlz(u32 value);
-int cnttz(u32 word);
+static int cntlz(u32 value);
+static int cnttz(u32 word);
 
 static int dbAllocDmapBU(struct bmap * bmp, struct dmap * dp, s64 blkno,
 			 int nblocks);
@@ -155,7 +155,7 @@ static int dbGetL2AGSize(s64 nblocks);
  * into the table, with the table elements yielding the maximum
  * binary buddy of free bits within the character.
  */
-signed char budtab[256] = {
+static s8 budtab[256] = {
 	3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
 	2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
 	2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
@@ -942,7 +942,7 @@ int dbAlloc(struct inode *ip, s64 hint, 
 	return (rc);
 }
 
-
+#ifdef _NOTYET
 /*
  * NAME:	dbAllocExact()
  *
@@ -1009,7 +1009,7 @@ int dbAllocExact(struct inode *ip, s64 b
 
 	return (rc);
 }
-
+#endif /* _NOTYET */
 
 /*
  * NAME:	dbReAlloc()
@@ -1092,7 +1092,7 @@ dbReAlloc(struct inode *ip,
  *      -ENOSPC	- insufficient disk resources
  *      -EIO	- i/o error
  */
-int dbExtend(struct inode *ip, s64 blkno, s64 nblocks, s64 addnblocks)
+static int dbExtend(struct inode *ip, s64 blkno, s64 nblocks, s64 addnblocks)
 {
 	struct jfs_sb_info *sbi = JFS_SBI(ip->i_sb);
 	s64 lblkno, lastblkno, extblkno;
@@ -3022,7 +3022,7 @@ static int dbMaxBud(u8 * cp)
  * RETURN VALUES:
  *      count of trailing zeros
  */
-int cnttz(u32 word)
+static int cnttz(u32 word)
 {
 	int n;
 
@@ -3047,7 +3047,7 @@ int cnttz(u32 word)
  * RETURN VALUES:
  *      count of leading zeros
  */
-int cntlz(u32 value)
+static int cntlz(u32 value)
 {
 	int n;
 
diff -purN linux-post-2.6.4rc2-20040307/fs/jfs/jfs_dmap.h linux-post-2.6.4rc2-20040309/fs/jfs/jfs_dmap.h
--- linux-post-2.6.4rc2-20040307/fs/jfs/jfs_dmap.h	2002-09-18 15:36:53.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/fs/jfs/jfs_dmap.h	2004-03-08 21:55:48.000000000 +0000
@@ -286,8 +286,6 @@ extern int dbNextAG(struct inode *ipbmap
 
 extern int dbAlloc(struct inode *ipbmap, s64 hint, s64 nblocks, s64 * results);
 
-extern int dbAllocExact(struct inode *ip, s64 blkno, int nblocks);
-
 extern int dbReAlloc(struct inode *ipbmap,
 		     s64 blkno, s64 nblocks, s64 addnblocks, s64 * results);
 
diff -purN linux-post-2.6.4rc2-20040307/fs/jfs/jfs_dtree.c linux-post-2.6.4rc2-20040309/fs/jfs/jfs_dtree.c
--- linux-post-2.6.4rc2-20040307/fs/jfs/jfs_dtree.c	2003-10-08 16:07:12.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/fs/jfs/jfs_dtree.c	2004-03-08 21:55:48.000000000 +0000
@@ -162,9 +162,6 @@ static int dtSplitRoot(tid_t tid, struct
 static int dtDeleteUp(tid_t tid, struct inode *ip, struct metapage * fmp,
 		      dtpage_t * fp, struct btstack * btstack);
 
-static int dtSearchNode(struct inode *ip,
-			s64 lmxaddr, pxd_t * kpxd, struct btstack * btstack);
-
 static int dtRelink(tid_t tid, struct inode *ip, dtpage_t * p);
 
 static int dtReadFirst(struct inode *ip, struct btstack * btstack);
@@ -2380,7 +2377,7 @@ static int dtDeleteUp(tid_t tid, struct 
 	return 0;
 }
 
-
+#ifdef _NOTYET
 /*
  * NAME:        dtRelocate()
  *
@@ -2575,7 +2572,6 @@ int dtRelocate(tid_t tid, struct inode *
 	return rc;
 }
 
-
 /*
  * NAME:	dtSearchNode()
  *
@@ -2677,7 +2673,7 @@ static int dtSearchNode(struct inode *ip
 
 	goto loop;
 }
-
+#endif /* _NOTYET */
 
 /*
  *	dtRelink()
@@ -2933,7 +2929,7 @@ struct jfs_dirent {
 /*
  * function to determine next variable-sized jfs_dirent in buffer
  */
-inline struct jfs_dirent *next_jfs_dirent(struct jfs_dirent *dirent)
+static inline struct jfs_dirent *next_jfs_dirent(struct jfs_dirent *dirent)
 {
 	return (struct jfs_dirent *)
 		((char *)dirent +
diff -purN linux-post-2.6.4rc2-20040307/fs/jfs/jfs_dtree.h linux-post-2.6.4rc2-20040309/fs/jfs/jfs_dtree.h
--- linux-post-2.6.4rc2-20040307/fs/jfs/jfs_dtree.h	2002-09-12 20:28:55.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/fs/jfs/jfs_dtree.h	2004-03-08 21:55:48.000000000 +0000
@@ -265,9 +265,6 @@ extern int dtInsert(tid_t tid, struct in
 extern int dtDelete(tid_t tid, struct inode *ip, struct component_name * key,
 		    ino_t * data, int flag);
 
-extern int dtRelocate(tid_t tid,
-		      struct inode *ip, s64 lmxaddr, pxd_t * opxd, s64 nxaddr);
-
 extern int dtModify(tid_t tid, struct inode *ip, struct component_name * key,
 		    ino_t * orig_ino, ino_t new_ino, int flag);
 
diff -purN linux-post-2.6.4rc2-20040307/fs/jfs/jfs_extent.c linux-post-2.6.4rc2-20040309/fs/jfs/jfs_extent.c
--- linux-post-2.6.4rc2-20040307/fs/jfs/jfs_extent.c	2003-10-08 16:07:12.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/fs/jfs/jfs_extent.c	2004-03-08 21:55:48.000000000 +0000
@@ -35,7 +35,6 @@ static s64 extRoundDown(s64 nb);
 /*
  * external references
  */
-extern int dbExtend(struct inode *, s64, s64, s64);
 extern int jfs_commit_inode(struct inode *, int);
 
 
diff -purN linux-post-2.6.4rc2-20040307/fs/jfs/jfs_incore.h linux-post-2.6.4rc2-20040309/fs/jfs/jfs_incore.h
--- linux-post-2.6.4rc2-20040307/fs/jfs/jfs_incore.h	2004-03-03 22:04:28.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/fs/jfs/jfs_incore.h	2004-03-08 20:40:28.000000000 +0000
@@ -114,7 +114,6 @@ struct jfs_inode_info {
  * cflag
  */
 enum cflags {
-	COMMIT_New,		/* never committed inode   */
 	COMMIT_Nolink,		/* inode committed with zero link count */
 	COMMIT_Inlineea,	/* commit inode inline EA */
 	COMMIT_Freewmap,	/* free WMAP at iClose() */
diff -purN linux-post-2.6.4rc2-20040307/fs/jfs/jfs_inode.c linux-post-2.6.4rc2-20040309/fs/jfs/jfs_inode.c
--- linux-post-2.6.4rc2-20040307/fs/jfs/jfs_inode.c	2003-01-17 20:17:14.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/fs/jfs/jfs_inode.c	2004-03-08 20:40:28.000000000 +0000
@@ -72,7 +72,6 @@ struct inode *ialloc(struct inode *paren
 	inode->i_generation = JFS_SBI(sb)->gengen++;
 
 	jfs_inode->cflag = 0;
-	set_cflag(COMMIT_New, inode);
 
 	/* Zero remaining fields */
 	memset(&jfs_inode->acl, 0, sizeof(dxd_t));
diff -purN linux-post-2.6.4rc2-20040307/fs/jfs/jfs_logmgr.c linux-post-2.6.4rc2-20040309/fs/jfs/jfs_logmgr.c
--- linux-post-2.6.4rc2-20040307/fs/jfs/jfs_logmgr.c	2004-03-03 22:04:28.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/fs/jfs/jfs_logmgr.c	2004-03-08 21:55:48.000000000 +0000
@@ -196,6 +196,7 @@ static int lbmIOWait(struct lbuf * bp, i
 static bio_end_io_t lbmIODone;
 static void lbmStartIO(struct lbuf * bp);
 static void lmGCwrite(struct jfs_log * log, int cant_block);
+static int lmLogSync(struct jfs_log * log, int nosyncwait);
 
 
 
@@ -810,7 +811,7 @@ static void lmGCwrite(struct jfs_log * l
  * NOTE:
  *	This routine is called a interrupt time by lbmIODone
  */
-void lmPostGC(struct lbuf * bp)
+static void lmPostGC(struct lbuf * bp)
 {
 	unsigned long flags;
 	struct jfs_log *log = bp->l_log;
@@ -933,7 +934,7 @@ void lmPostGC(struct lbuf * bp)
  *			
  * serialization: LOG_LOCK() held on entry/exit
  */
-int lmLogSync(struct jfs_log * log, int nosyncwait)
+static int lmLogSync(struct jfs_log * log, int nosyncwait)
 {
 	int logsize;
 	int written;		/* written since last syncpt */
diff -purN linux-post-2.6.4rc2-20040307/fs/jfs/jfs_logmgr.h linux-post-2.6.4rc2-20040309/fs/jfs/jfs_logmgr.h
--- linux-post-2.6.4rc2-20040307/fs/jfs/jfs_logmgr.h	2004-03-03 22:04:28.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/fs/jfs/jfs_logmgr.h	2004-03-08 21:55:48.000000000 +0000
@@ -505,7 +505,6 @@ struct logsyncblk {
 
 extern int lmLogOpen(struct super_block *sb);
 extern int lmLogClose(struct super_block *sb);
-extern int lmLogSync(struct jfs_log * log, int nosyncwait);
 extern int lmLogShutdown(struct jfs_log * log);
 extern int lmLogInit(struct jfs_log * log);
 extern int lmLogFormat(struct jfs_log *log, s64 logAddress, int logSize);
diff -purN linux-post-2.6.4rc2-20040307/fs/jfs/jfs_txnmgr.c linux-post-2.6.4rc2-20040309/fs/jfs/jfs_txnmgr.c
--- linux-post-2.6.4rc2-20040307/fs/jfs/jfs_txnmgr.c	2004-03-03 22:04:28.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/fs/jfs/jfs_txnmgr.c	2004-03-08 21:55:48.000000000 +0000
@@ -168,25 +168,23 @@ extern struct completion jfsIOwait;
 /*
  * forward references
  */
-int diLog(struct jfs_log * log, struct tblock * tblk, struct lrd * lrd,
-	  struct tlock * tlck, struct commit * cd);
-int dataLog(struct jfs_log * log, struct tblock * tblk, struct lrd * lrd,
-	    struct tlock * tlck);
-void dtLog(struct jfs_log * log, struct tblock * tblk, struct lrd * lrd,
-	   struct tlock * tlck);
-void inlineLog(struct jfs_log * log, struct tblock * tblk, struct lrd * lrd,
-	       struct tlock * tlck);
-void mapLog(struct jfs_log * log, struct tblock * tblk, struct lrd * lrd,
-	    struct tlock * tlck);
+static int diLog(struct jfs_log * log, struct tblock * tblk, struct lrd * lrd,
+		struct tlock * tlck, struct commit * cd);
+static int dataLog(struct jfs_log * log, struct tblock * tblk, struct lrd * lrd,
+		struct tlock * tlck);
+static void dtLog(struct jfs_log * log, struct tblock * tblk, struct lrd * lrd,
+		struct tlock * tlck);
+static void mapLog(struct jfs_log * log, struct tblock * tblk, struct lrd * lrd,
+		struct tlock * tlck);
 static void txAbortCommit(struct commit * cd);
 static void txAllocPMap(struct inode *ip, struct maplock * maplock,
-			struct tblock * tblk);
-void txForce(struct tblock * tblk);
-static int txLog(struct jfs_log * log, struct tblock * tblk, struct commit * cd);
-int txMoreLock(void);
+		struct tblock * tblk);
+static void txForce(struct tblock * tblk);
+static int txLog(struct jfs_log * log, struct tblock * tblk,
+		struct commit * cd);
 static void txUpdateMap(struct tblock * tblk);
 static void txRelease(struct tblock * tblk);
-void xtLog(struct jfs_log * log, struct tblock * tblk, struct lrd * lrd,
+static void xtLog(struct jfs_log * log, struct tblock * tblk, struct lrd * lrd,
 	   struct tlock * tlck);
 static void LogSyncRelease(struct metapage * mp);
 
@@ -1240,8 +1238,8 @@ int txCommit(tid_t tid,		/* transaction 
 	 * Ensure that inode isn't reused before
 	 * lazy commit thread finishes processing
 	 */
-	if (tblk->xflag & (COMMIT_CREATE | COMMIT_DELETE)) {
-		atomic_inc(&tblk->ip->i_count);
+	if (tblk->xflag & COMMIT_DELETE) {
+		atomic_inc(&tblk->u.ip->i_count);
 		/*
 		 * Avoid a rare deadlock
 		 *
@@ -1252,13 +1250,13 @@ int txCommit(tid_t tid,		/* transaction 
 		 * commit the transaction synchronously, so the last iput
 		 * will be done by the calling thread (or later)
 		 */
-		if (tblk->ip->i_state & I_LOCK)
+		if (tblk->u.ip->i_state & I_LOCK)
 			tblk->xflag &= ~COMMIT_LAZY;
 	}
 
 	ASSERT((!(tblk->xflag & COMMIT_DELETE)) ||
-	       ((tblk->ip->i_nlink == 0) &&
-		!test_cflag(COMMIT_Nolink, tblk->ip)));
+	       ((tblk->u.ip->i_nlink == 0) &&
+		!test_cflag(COMMIT_Nolink, tblk->u.ip)));
 
 	/*
 	 *      write COMMIT log record
@@ -1399,7 +1397,7 @@ static int txLog(struct jfs_log * log, s
  *
  * function:    log inode tlock and format maplock to update bmap;
  */
-int diLog(struct jfs_log * log, struct tblock * tblk, struct lrd * lrd,
+static int diLog(struct jfs_log * log, struct tblock * tblk, struct lrd * lrd,
 	  struct tlock * tlck, struct commit * cd)
 {
 	int rc = 0;
@@ -1514,7 +1512,7 @@ int diLog(struct jfs_log * log, struct t
  *
  * function:    log data tlock
  */
-int dataLog(struct jfs_log * log, struct tblock * tblk, struct lrd * lrd,
+static int dataLog(struct jfs_log * log, struct tblock * tblk, struct lrd * lrd,
 	    struct tlock * tlck)
 {
 	struct metapage *mp;
@@ -1560,7 +1558,7 @@ int dataLog(struct jfs_log * log, struct
  *
  * function:    log dtree tlock and format maplock to update bmap;
  */
-void dtLog(struct jfs_log * log, struct tblock * tblk, struct lrd * lrd,
+static void dtLog(struct jfs_log * log, struct tblock * tblk, struct lrd * lrd,
 	   struct tlock * tlck)
 {
 	struct metapage *mp;
@@ -1665,7 +1663,7 @@ void dtLog(struct jfs_log * log, struct 
  *
  * function:    log xtree tlock and format maplock to update bmap;
  */
-void xtLog(struct jfs_log * log, struct tblock * tblk, struct lrd * lrd,
+static void xtLog(struct jfs_log * log, struct tblock * tblk, struct lrd * lrd,
 	   struct tlock * tlck)
 {
 	struct inode *ip;
@@ -2360,23 +2358,17 @@ static void txUpdateMap(struct tblock * 
 	 * unlock mapper/write lock
 	 */
 	if (tblk->xflag & COMMIT_CREATE) {
-		ip = tblk->ip;
-
-		ASSERT(test_cflag(COMMIT_New, ip));
-		clear_cflag(COMMIT_New, ip);
-
-		diUpdatePMap(ipimap, ip->i_ino, FALSE, tblk);
+		diUpdatePMap(ipimap, tblk->ino, FALSE, tblk);
 		ipimap->i_state |= I_DIRTY;
 		/* update persistent block allocation map
 		 * for the allocation of inode extent;
 		 */
 		pxdlock.flag = mlckALLOCPXD;
-		pxdlock.pxd = JFS_IP(ip)->ixpxd;
+		pxdlock.pxd = tblk->u.ixpxd;
 		pxdlock.index = 1;
-		txAllocPMap(ip, (struct maplock *) & pxdlock, tblk);
-		iput(ip);
+		txAllocPMap(ipimap, (struct maplock *) & pxdlock, tblk);
 	} else if (tblk->xflag & COMMIT_DELETE) {
-		ip = tblk->ip;
+		ip = tblk->u.ip;
 		diUpdatePMap(ipimap, ip->i_ino, TRUE, tblk);
 		ipimap->i_state |= I_DIRTY;
 		iput(ip);
@@ -2725,7 +2717,7 @@ static void txAbortCommit(struct commit 
  *	allocation maps are updated in order.  For synchronous transactions,
  *	let the user thread finish processing after txUpdateMap() is called.
  */
-void txLazyCommit(struct tblock * tblk)
+static void txLazyCommit(struct tblock * tblk)
 {
 	struct jfs_log *log;
 
diff -purN linux-post-2.6.4rc2-20040307/fs/jfs/jfs_txnmgr.h linux-post-2.6.4rc2-20040309/fs/jfs/jfs_txnmgr.h
--- linux-post-2.6.4rc2-20040307/fs/jfs/jfs_txnmgr.h	2002-09-12 20:28:56.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/fs/jfs/jfs_txnmgr.h	2004-03-08 20:40:28.000000000 +0000
@@ -62,7 +62,11 @@ struct tblock {
 					 * ready transactions wait on this
 					 * event for group commit completion.
 					 */
-	struct inode *ip;	/* inode being created or deleted */
+	union {
+		struct inode *ip; /* inode being deleted */
+		pxd_t ixpxd;	/* pxd of inode extent for created inode */
+	} u;
+	u32 ino;		/* inode number being created */
 };
 
 extern struct tblock *TxBlock;	/* transaction block table */
diff -purN linux-post-2.6.4rc2-20040307/fs/jfs/jfs_unicode.c linux-post-2.6.4rc2-20040309/fs/jfs/jfs_unicode.c
--- linux-post-2.6.4rc2-20040307/fs/jfs/jfs_unicode.c	2004-02-12 15:23:49.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/fs/jfs/jfs_unicode.c	2004-03-08 21:55:48.000000000 +0000
@@ -34,6 +34,8 @@ int jfs_strfromUCS_le(char *to, const wc
 {
 	int i;
 	int outlen = 0;
+	static int warn_again = 5;	/* Only warn up to 5 times total */
+	int warn = !!warn_again;	/* once per string */
 
 	if (codepage) {
 		for (i = 0; (i < len) && from[i]; i++) {
@@ -48,8 +50,22 @@ int jfs_strfromUCS_le(char *to, const wc
 				to[outlen++] = '?';
 		}
 	} else {
-		for (i = 0; (i < len) && from[i]; i++)
-			to[i] = (char) (le16_to_cpu(from[i]));
+		for (i = 0; (i < len) && from[i]; i++) {
+			if (le16_to_cpu(from[i]) & 0xff00) {
+				if (warn) {
+					warn--;
+					warn_again--;
+					printk(KERN_ERR
+			"non-latin1 character 0x%x found in JFS file name\n", 
+		       			       le16_to_cpu(from[i]));
+					printk(KERN_ERR
+				"mount with iocharset=utf8 to access\n");
+				}
+				to[i] = '?';
+			}
+			else
+				to[i] = (char) (le16_to_cpu(from[i]));
+		}
 		outlen = i;
 	}
 	to[outlen] = 0;
@@ -62,8 +78,8 @@ int jfs_strfromUCS_le(char *to, const wc
  * FUNCTION:	Convert character string to unicode string
  *
  */
-int jfs_strtoUCS(wchar_t * to,
-		 const char *from, int len, struct nls_table *codepage)
+static int jfs_strtoUCS(wchar_t * to, const char *from, int len,
+		struct nls_table *codepage)
 {
 	int charlen;
 	int i;
diff -purN linux-post-2.6.4rc2-20040307/fs/jfs/jfs_xtree.c linux-post-2.6.4rc2-20040309/fs/jfs/jfs_xtree.c
--- linux-post-2.6.4rc2-20040307/fs/jfs/jfs_xtree.c	2003-10-08 16:07:12.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/fs/jfs/jfs_xtree.c	2004-03-08 21:55:48.000000000 +0000
@@ -1736,7 +1736,7 @@ int xtExtend(tid_t tid,		/* transaction 
 	return rc;
 }
 
-
+#ifdef _NOTYET
 /*
  *      xtTailgate()
  *
@@ -1918,7 +1918,7 @@ printf("xtTailgate: xoff:0x%lx xlen:0x%x
 
 	return rc;
 }
-
+#endif /* _NOTYET */
 
 /*
  *      xtUpdate()
diff -purN linux-post-2.6.4rc2-20040307/fs/jfs/jfs_xtree.h linux-post-2.6.4rc2-20040309/fs/jfs/jfs_xtree.h
--- linux-post-2.6.4rc2-20040307/fs/jfs/jfs_xtree.h	2002-09-12 20:28:57.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/fs/jfs/jfs_xtree.h	2004-03-08 21:55:48.000000000 +0000
@@ -117,8 +117,10 @@ extern int xtInsert(tid_t tid, struct in
 		    int xflag, s64 xoff, int xlen, s64 * xaddrp, int flag);
 extern int xtExtend(tid_t tid, struct inode *ip, s64 xoff, int xlen,
 		    int flag);
+#ifdef _NOTYET
 extern int xtTailgate(tid_t tid, struct inode *ip,
 		      s64 xoff, int xlen, s64 xaddr, int flag);
+#endif
 extern int xtUpdate(tid_t tid, struct inode *ip, struct xad *nxad);
 extern int xtDelete(tid_t tid, struct inode *ip, s64 xoff, int xlen,
 		    int flag);
diff -purN linux-post-2.6.4rc2-20040307/fs/jfs/namei.c linux-post-2.6.4rc2-20040309/fs/jfs/namei.c
--- linux-post-2.6.4rc2-20040307/fs/jfs/namei.c	2004-02-11 19:35:41.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/fs/jfs/namei.c	2004-03-08 21:55:48.000000000 +0000
@@ -44,7 +44,7 @@ extern int jfs_init_acl(struct inode *, 
 struct inode_operations jfs_dir_inode_operations;
 struct file_operations jfs_dir_operations;
 
-s64 commitZeroLink(tid_t, struct inode *);
+static s64 commitZeroLink(tid_t, struct inode *);
 
 /*
  * NAME:	jfs_create(dip, dentry, mode)
@@ -60,7 +60,7 @@ s64 commitZeroLink(tid_t, struct inode *
  * RETURN:	Errors from subroutines
  *
  */
-int jfs_create(struct inode *dip, struct dentry *dentry, int mode,
+static int jfs_create(struct inode *dip, struct dentry *dentry, int mode,
 		struct nameidata *nd)
 {
 	int rc = 0;
@@ -104,7 +104,8 @@ int jfs_create(struct inode *dip, struct
 
 	tblk = tid_to_tblock(tid);
 	tblk->xflag |= COMMIT_CREATE;
-	tblk->ip = ip;
+	tblk->ino = ip->i_ino;
+	tblk->u.ixpxd = JFS_IP(ip)->ixpxd;
 
 	iplist[0] = dip;
 	iplist[1] = ip;
@@ -181,7 +182,7 @@ int jfs_create(struct inode *dip, struct
  * note:
  * EACCESS: user needs search+write permission on the parent directory
  */
-int jfs_mkdir(struct inode *dip, struct dentry *dentry, int mode)
+static int jfs_mkdir(struct inode *dip, struct dentry *dentry, int mode)
 {
 	int rc = 0;
 	tid_t tid;		/* transaction id */
@@ -230,7 +231,8 @@ int jfs_mkdir(struct inode *dip, struct 
 
 	tblk = tid_to_tblock(tid);
 	tblk->xflag |= COMMIT_CREATE;
-	tblk->ip = ip;
+	tblk->ino = ip->i_ino;
+	tblk->u.ixpxd = JFS_IP(ip)->ixpxd;
 
 	iplist[0] = dip;
 	iplist[1] = ip;
@@ -314,7 +316,7 @@ int jfs_mkdir(struct inode *dip, struct 
  * but the directory is not removed until the last reference to 
  * the directory is released (cf.unlink() of regular file).
  */
-int jfs_rmdir(struct inode *dip, struct dentry *dentry)
+static int jfs_rmdir(struct inode *dip, struct dentry *dentry)
 {
 	int rc;
 	tid_t tid;		/* transaction id */
@@ -346,7 +348,7 @@ int jfs_rmdir(struct inode *dip, struct 
 
 	tblk = tid_to_tblock(tid);
 	tblk->xflag |= COMMIT_DELETE;
-	tblk->ip = ip;
+	tblk->u.ip = ip;
 
 	/*
 	 * delete the entry of target directory from parent directory
@@ -437,7 +439,7 @@ int jfs_rmdir(struct inode *dip, struct 
  * JFS does NOT support unlink() on directories.
  *
  */
-int jfs_unlink(struct inode *dip, struct dentry *dentry)
+static int jfs_unlink(struct inode *dip, struct dentry *dentry)
 {
 	int rc;
 	tid_t tid;		/* transaction id */
@@ -505,7 +507,7 @@ int jfs_unlink(struct inode *dip, struct
 		}
 		tblk = tid_to_tblock(tid);
 		tblk->xflag |= COMMIT_DELETE;
-		tblk->ip = ip;
+		tblk->u.ip = ip;
 	}
 
 	/*
@@ -590,7 +592,7 @@ int jfs_unlink(struct inode *dip, struct
  *
  * RETURN:	Errors from subroutines
  */
-s64 commitZeroLink(tid_t tid, struct inode *ip)
+static s64 commitZeroLink(tid_t tid, struct inode *ip)
 {
 	int filetype;
 	struct tblock *tblk;
@@ -758,7 +760,7 @@ int freeZeroLink(struct inode *ip)
  * EXDEV: target object and new link are on different file systems and
  * implementation does not support links between file systems [XPG4.2].
  */
-int jfs_link(struct dentry *old_dentry,
+static int jfs_link(struct dentry *old_dentry,
 	     struct inode *dir, struct dentry *dentry)
 {
 	int rc;
@@ -838,7 +840,8 @@ int jfs_link(struct dentry *old_dentry,
  * an intermediate result whose length exceeds PATH_MAX [XPG4.2]
 */
 
-int jfs_symlink(struct inode *dip, struct dentry *dentry, const char *name)
+static int jfs_symlink(struct inode *dip, struct dentry *dentry,
+		const char *name)
 {
 	int rc;
 	tid_t tid;
@@ -889,7 +892,8 @@ int jfs_symlink(struct inode *dip, struc
 
 	tblk = tid_to_tblock(tid);
 	tblk->xflag |= COMMIT_CREATE;
-	tblk->ip = ip;
+	tblk->ino = ip->i_ino;
+	tblk->u.ixpxd = JFS_IP(ip)->ixpxd;
 
 	/*
 	 * create entry for symbolic link in parent directory
@@ -1042,7 +1046,7 @@ int jfs_symlink(struct inode *dip, struc
  *
  * FUNCTION:    rename a file or directory
  */
-int jfs_rename(struct inode *old_dir, struct dentry *old_dentry,
+static int jfs_rename(struct inode *old_dir, struct dentry *old_dentry,
 	       struct inode *new_dir, struct dentry *new_dentry)
 {
 	struct btstack btstack;
@@ -1151,7 +1155,7 @@ int jfs_rename(struct inode *old_dir, st
 			}
 			tblk = tid_to_tblock(tid);
 			tblk->xflag |= COMMIT_DELETE;
-			tblk->ip = new_ip;
+			tblk->u.ip = new_ip;
 		} else if (new_ip->i_nlink == 0) {
 			assert(!test_cflag(COMMIT_Nolink, new_ip));
 			/* free block resources */
@@ -1162,7 +1166,7 @@ int jfs_rename(struct inode *old_dir, st
 			}
 			tblk = tid_to_tblock(tid);
 			tblk->xflag |= COMMIT_DELETE;
-			tblk->ip = new_ip;
+			tblk->u.ip = new_ip;
 		} else {
 			new_ip->i_ctime = CURRENT_TIME;
 			mark_inode_dirty(new_ip);
@@ -1310,7 +1314,8 @@ int jfs_rename(struct inode *old_dir, st
  *
  * FUNCTION:    Create a special file (device)
  */
-int jfs_mknod(struct inode *dir, struct dentry *dentry, int mode, dev_t rdev)
+static int jfs_mknod(struct inode *dir, struct dentry *dentry,
+		int mode, dev_t rdev)
 {
 	struct jfs_inode_info *jfs_ip;
 	struct btstack btstack;
@@ -1347,7 +1352,8 @@ int jfs_mknod(struct inode *dir, struct 
 
 	tblk = tid_to_tblock(tid);
 	tblk->xflag |= COMMIT_CREATE;
-	tblk->ip = ip;
+	tblk->ino = ip->i_ino;
+	tblk->u.ixpxd = JFS_IP(ip)->ixpxd;
 
 	ino = ip->i_ino;
 	if ((rc = dtInsert(tid, dir, &dname, &ino, &btstack)))
diff -purN linux-post-2.6.4rc2-20040307/fs/jfs/super.c linux-post-2.6.4rc2-20040309/fs/jfs/super.c
--- linux-post-2.6.4rc2-20040307/fs/jfs/super.c	2004-03-03 22:04:28.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/fs/jfs/super.c	2004-03-08 21:55:48.000000000 +0000
@@ -321,7 +321,7 @@ cleanup:
 	return 0;
 }
 
-int jfs_remount(struct super_block *sb, int *flags, char *data)
+static int jfs_remount(struct super_block *sb, int *flags, char *data)
 {
 	s64 newLVSize = 0;
 	int rc = 0;
diff -purN linux-post-2.6.4rc2-20040307/fs/jfs/xattr.c linux-post-2.6.4rc2-20040309/fs/jfs/xattr.c
--- linux-post-2.6.4rc2-20040307/fs/jfs/xattr.c	2004-01-15 23:03:15.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/fs/jfs/xattr.c	2004-03-08 18:36:56.000000000 +0000
@@ -640,6 +640,7 @@ static int ea_put(struct inode *inode, s
 	}
 
 	inode->i_blocks += LBLK2PBLK(inode->i_sb, new_blocks - old_blocks);
+	inode->i_ctime = CURRENT_TIME;
 	rc = txCommit(tid, 1, &inode, 0);
 	txEnd(tid);
 	up(&ji->commit_sem);
diff -purN linux-post-2.6.4rc2-20040307/fs/lockd/clntproc.c linux-post-2.6.4rc2-20040309/fs/lockd/clntproc.c
--- linux-post-2.6.4rc2-20040307/fs/lockd/clntproc.c	2003-02-07 20:25:20.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/fs/lockd/clntproc.c	2004-03-07 07:14:27.000000000 +0000
@@ -195,19 +195,6 @@ done:
 }
 
 /*
- * Wait while server is in grace period
- */
-static inline int
-nlmclnt_grace_wait(struct nlm_host *host)
-{
-	if (!host->h_reclaiming)
-		interruptible_sleep_on_timeout(&host->h_gracewait, 10*HZ);
-	else
-		interruptible_sleep_on(&host->h_gracewait);
-	return signalled()? -ERESTARTSYS : 0;
-}
-
-/*
  * Allocate an NLM RPC call struct
  */
 struct nlm_rqst *
diff -purN linux-post-2.6.4rc2-20040307/fs/namei.c linux-post-2.6.4rc2-20040309/fs/namei.c
--- linux-post-2.6.4rc2-20040307/fs/namei.c	2004-02-19 06:54:07.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/fs/namei.c	2004-03-07 07:04:57.000000000 +0000
@@ -571,7 +571,7 @@ fail:
  *
  * We expect 'base' to be positive and a directory.
  */
-int link_path_walk(const char * name, struct nameidata *nd)
+int fastcall link_path_walk(const char * name, struct nameidata *nd)
 {
 	struct path next;
 	struct inode *inode;
@@ -771,7 +771,7 @@ return_err:
 	return err;
 }
 
-int path_walk(const char * name, struct nameidata *nd)
+int fastcall path_walk(const char * name, struct nameidata *nd)
 {
 	current->total_link_count = 0;
 	return link_path_walk(name, nd);
@@ -858,7 +858,7 @@ walk_init_root(const char *name, struct 
 	return 1;
 }
 
-int path_lookup(const char *name, unsigned int flags, struct nameidata *nd)
+int fastcall path_lookup(const char *name, unsigned int flags, struct nameidata *nd)
 {
 	nd->last_type = LAST_ROOT; /* if there are only slashes... */
 	nd->flags = flags;
@@ -971,7 +971,7 @@ access:
  * that namei follows links, while lnamei does not.
  * SMP-safe
  */
-int __user_walk(const char __user *name, unsigned flags, struct nameidata *nd)
+int fastcall __user_walk(const char __user *name, unsigned flags, struct nameidata *nd)
 {
 	char *tmp = getname(name);
 	int err = PTR_ERR(tmp);
diff -purN linux-post-2.6.4rc2-20040307/fs/open.c linux-post-2.6.4rc2-20040309/fs/open.c
--- linux-post-2.6.4rc2-20040307/fs/open.c	2004-01-19 06:22:24.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/fs/open.c	2004-03-07 07:04:57.000000000 +0000
@@ -890,7 +890,7 @@ static inline void __put_unused_fd(struc
 		files->next_fd = fd;
 }
 
-void put_unused_fd(unsigned int fd)
+void fastcall put_unused_fd(unsigned int fd)
 {
 	struct files_struct *files = current->files;
 	spin_lock(&files->file_lock);
@@ -913,7 +913,7 @@ EXPORT_SYMBOL(put_unused_fd);
  * will follow.
  */
 
-void fd_install(unsigned int fd, struct file * file)
+void fastcall fd_install(unsigned int fd, struct file * file)
 {
 	struct files_struct *files = current->files;
 	spin_lock(&files->file_lock);
diff -purN linux-post-2.6.4rc2-20040307/fs/proc/proc_misc.c linux-post-2.6.4rc2-20040309/fs/proc/proc_misc.c
--- linux-post-2.6.4rc2-20040307/fs/proc/proc_misc.c	2004-02-04 05:37:27.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/fs/proc/proc_misc.c	2004-03-09 00:57:46.000000000 +0000
@@ -389,7 +389,7 @@ int show_stat(struct seq_file *p, void *
 		jiffies_to_clock_t(iowait),
 		jiffies_to_clock_t(irq),
 		jiffies_to_clock_t(softirq));
-	for_each_online_cpu(i) {
+	for_each_cpu(i) {
 		seq_printf(p, "cpu%d %u %u %u %u %u %u %u\n",
 			i,
 			jiffies_to_clock_t(kstat_cpu(i).cpustat.user),
@@ -424,7 +424,7 @@ int show_stat(struct seq_file *p, void *
 
 static int stat_open(struct inode *inode, struct file *file)
 {
-	unsigned size = 4096 * (1 + num_online_cpus() / 32);
+	unsigned size = 4096 * (1 + num_possible_cpus() / 32);
 	char *buf;
 	struct seq_file *m;
 	int res;
diff -purN linux-post-2.6.4rc2-20040307/include/asm-i386/cpufeature.h linux-post-2.6.4rc2-20040309/include/asm-i386/cpufeature.h
--- linux-post-2.6.4rc2-20040307/include/asm-i386/cpufeature.h	2003-09-10 06:41:41.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/include/asm-i386/cpufeature.h	2004-01-31 04:25:15.000000000 +0000
@@ -76,6 +76,9 @@
 
 /* VIA/Cyrix/Centaur-defined CPU features, CPUID level 0xC0000001, word 5 */
 #define X86_FEATURE_XSTORE	(5*32+ 2) /* on-CPU RNG present (xstore insn) */
+#define X86_FEATURE_XSTORE_EN	(5*32+ 3) /* on-CPU RNG enabled */
+#define X86_FEATURE_XCRYPT	(5*32+ 6) /* on-CPU crypto (xcrypt insn) */
+#define X86_FEATURE_XCRYPT_EN	(5*32+ 7) /* on-CPU crypto enabled */
 
 
 #define cpu_has(c, bit)		test_bit(bit, (c)->x86_capability)
@@ -101,6 +104,7 @@
 #define cpu_has_cyrix_arr	boot_cpu_has(X86_FEATURE_CYRIX_ARR)
 #define cpu_has_centaur_mcr	boot_cpu_has(X86_FEATURE_CENTAUR_MCR)
 #define cpu_has_xstore		boot_cpu_has(X86_FEATURE_XSTORE)
+#define cpu_has_xcrypt		boot_cpu_has(X86_FEATURE_XCRYPT)
 
 #endif /* __ASM_I386_CPUFEATURE_H */
 
diff -purN linux-post-2.6.4rc2-20040307/include/asm-i386/linkage.h linux-post-2.6.4rc2-20040309/include/asm-i386/linkage.h
--- linux-post-2.6.4rc2-20040307/include/asm-i386/linkage.h	2002-08-04 05:44:49.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/include/asm-i386/linkage.h	2004-03-07 07:04:57.000000000 +0000
@@ -3,6 +3,7 @@
 
 #define asmlinkage CPP_ASMLINKAGE __attribute__((regparm(0)))
 #define FASTCALL(x)	x __attribute__((regparm(3)))
+#define fastcall	__attribute__((regparm(3)))
 
 #ifdef CONFIG_X86_ALIGNMENT_16
 #define __ALIGN .align 16,0x90
diff -purN linux-post-2.6.4rc2-20040307/include/asm-i386/smp.h linux-post-2.6.4rc2-20040309/include/asm-i386/smp.h
--- linux-post-2.6.4rc2-20040307/include/asm-i386/smp.h	2004-01-19 06:32:52.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/include/asm-i386/smp.h	2004-03-07 07:05:01.000000000 +0000
@@ -38,7 +38,6 @@ extern int cpu_sibling_map[];
 
 extern void smp_flush_tlb(void);
 extern void smp_message_irq(int cpl, void *dev_id, struct pt_regs *regs);
-extern void smp_send_reschedule(int cpu);
 extern void smp_invalidate_rcv(void);		/* Process an NMI */
 extern void (*mtrr_hook) (void);
 extern void zap_low_mappings (void);
diff -purN linux-post-2.6.4rc2-20040307/include/asm-ppc64/iSeries/vio.h linux-post-2.6.4rc2-20040309/include/asm-ppc64/iSeries/vio.h
--- linux-post-2.6.4rc2-20040307/include/asm-ppc64/iSeries/vio.h	2004-02-23 16:39:09.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/include/asm-ppc64/iSeries/vio.h	2004-03-07 07:05:28.000000000 +0000
@@ -127,4 +127,8 @@ enum viorc {
 	viorc_openRejected = 0x0301
 };
 
+struct device;
+
+extern struct device *iSeries_vio_dev;
+
 #endif /* _ISERIES_VIO_H */
diff -purN linux-post-2.6.4rc2-20040307/include/asm-ppc64/mmu.h linux-post-2.6.4rc2-20040309/include/asm-ppc64/mmu.h
--- linux-post-2.6.4rc2-20040307/include/asm-ppc64/mmu.h	2004-01-31 08:15:32.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/include/asm-ppc64/mmu.h	2004-03-07 07:05:29.000000000 +0000
@@ -18,15 +18,25 @@
 
 #ifndef __ASSEMBLY__
 
-/* Default "unsigned long" context */
-typedef unsigned long mm_context_t;
+/* Time to allow for more things here */
+typedef unsigned long mm_context_id_t;
+typedef struct {
+	mm_context_id_t id;
+#ifdef CONFIG_HUGETLB_PAGE
+	int low_hpages;
+#endif
+} mm_context_t;
 
 #ifdef CONFIG_HUGETLB_PAGE
-#define CONTEXT_LOW_HPAGES	(1UL<<63)
+#define KERNEL_LOW_HPAGES	.low_hpages = 0,
 #else
-#define CONTEXT_LOW_HPAGES	0
+#define KERNEL_LOW_HPAGES
 #endif
 
+#define KERNEL_CONTEXT(ea) ({ \
+		mm_context_t ctx = { .id = REGION_ID(ea), KERNEL_LOW_HPAGES}; \
+		ctx; })
+
 /*
  * Hardware Segment Lookaside Buffer Entry
  * This structure has been padded out to two 64b doublewords (actual SLBE's are
diff -purN linux-post-2.6.4rc2-20040307/include/asm-ppc64/mmu_context.h linux-post-2.6.4rc2-20040309/include/asm-ppc64/mmu_context.h
--- linux-post-2.6.4rc2-20040307/include/asm-ppc64/mmu_context.h	2004-02-23 16:39:06.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/include/asm-ppc64/mmu_context.h	2004-03-07 07:05:29.000000000 +0000
@@ -52,7 +52,7 @@ struct mmu_context_queue_t {
 	long head;
 	long tail;
 	long size;
-	mm_context_t elements[LAST_USER_CONTEXT];
+	mm_context_id_t elements[LAST_USER_CONTEXT];
 };
 
 extern struct mmu_context_queue_t mmu_context_queue;
@@ -83,7 +83,6 @@ init_new_context(struct task_struct *tsk
 	long head;
 	unsigned long flags;
 	/* This does the right thing across a fork (I hope) */
-	unsigned long low_hpages = mm->context & CONTEXT_LOW_HPAGES;
 
 	spin_lock_irqsave(&mmu_context_queue.lock, flags);
 
@@ -93,8 +92,7 @@ init_new_context(struct task_struct *tsk
 	}
 
 	head = mmu_context_queue.head;
-	mm->context = mmu_context_queue.elements[head];
-	mm->context |= low_hpages;
+	mm->context.id = mmu_context_queue.elements[head];
 
 	head = (head < LAST_USER_CONTEXT-1) ? head+1 : 0;
 	mmu_context_queue.head = head;
@@ -132,8 +130,7 @@ destroy_context(struct mm_struct *mm)
 #endif
 
 	mmu_context_queue.size++;
-	mmu_context_queue.elements[index] =
-		mm->context & ~CONTEXT_LOW_HPAGES;
+	mmu_context_queue.elements[index] = mm->context.id;
 
 	spin_unlock_irqrestore(&mmu_context_queue.lock, flags);
 }
@@ -212,8 +209,6 @@ get_vsid( unsigned long context, unsigne
 {
 	unsigned long ordinal, vsid;
 
-	context &= ~CONTEXT_LOW_HPAGES;
-
 	ordinal = (((ea >> 28) & 0x1fffff) * LAST_USER_CONTEXT) | context;
 	vsid = (ordinal * VSID_RANDOMIZER) & VSID_MASK;
 
diff -purN linux-post-2.6.4rc2-20040307/include/asm-ppc64/page.h linux-post-2.6.4rc2-20040309/include/asm-ppc64/page.h
--- linux-post-2.6.4rc2-20040307/include/asm-ppc64/page.h	2004-02-27 22:42:19.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/include/asm-ppc64/page.h	2004-03-07 07:05:29.000000000 +0000
@@ -32,6 +32,7 @@
 /* For 64-bit processes the hugepage range is 1T-1.5T */
 #define TASK_HPAGE_BASE 	(0x0000010000000000UL)
 #define TASK_HPAGE_END 	(0x0000018000000000UL)
+
 /* For 32-bit processes the hugepage range is 2-3G */
 #define TASK_HPAGE_BASE_32	(0x80000000UL)
 #define TASK_HPAGE_END_32	(0xc0000000UL)
@@ -39,7 +40,7 @@
 #define ARCH_HAS_HUGEPAGE_ONLY_RANGE
 #define is_hugepage_only_range(addr, len) \
 	( ((addr > (TASK_HPAGE_BASE-len)) && (addr < TASK_HPAGE_END)) || \
-	  ((current->mm->context & CONTEXT_LOW_HPAGES) && \
+	  (current->mm->context.low_hpages && \
 	   (addr > (TASK_HPAGE_BASE_32-len)) && (addr < TASK_HPAGE_END_32)) )
 #define hugetlb_free_pgtables free_pgtables
 #define HAVE_ARCH_HUGETLB_UNMAPPED_AREA
@@ -47,7 +48,7 @@
 #define in_hugepage_area(context, addr) \
 	((cur_cpu_spec->cpu_features & CPU_FTR_16M_PAGE) && \
 	 ((((addr) >= TASK_HPAGE_BASE) && ((addr) < TASK_HPAGE_END)) || \
-	  (((context) & CONTEXT_LOW_HPAGES) && \
+	  ((context).low_hpages && \
 	   (((addr) >= TASK_HPAGE_BASE_32) && ((addr) < TASK_HPAGE_END_32)))))
 
 #else /* !CONFIG_HUGETLB_PAGE */
diff -purN linux-post-2.6.4rc2-20040307/include/asm-sparc64/smp.h linux-post-2.6.4rc2-20040309/include/asm-sparc64/smp.h
--- linux-post-2.6.4rc2-20040307/include/asm-sparc64/smp.h	2004-01-19 06:32:52.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/include/asm-sparc64/smp.h	2004-02-25 00:13:40.000000000 +0000
@@ -35,11 +35,6 @@ extern unsigned char boot_cpu_id;
 extern cpumask_t phys_cpu_present_map;
 #define cpu_possible_map phys_cpu_present_map
 
-#define cpu_online(cpu)		cpu_isset(cpu, cpu_online_map)
-
-extern atomic_t sparc64_num_cpus_possible;
-#define num_possible_cpus()	(atomic_read(&sparc64_num_cpus_possible))
-
 /*
  *	General functions that each host system must provide.
  */
@@ -75,10 +70,6 @@ static __inline__ int hard_smp_processor
 
 #endif /* !(__ASSEMBLY__) */
 
-#else
-
-#define num_possible_cpus()	(1)
-
 #endif /* !(CONFIG_SMP) */
 
 #define NO_PROC_ID		0xFF
diff -purN linux-post-2.6.4rc2-20040307/include/asm-um/linkage.h linux-post-2.6.4rc2-20040309/include/asm-um/linkage.h
--- linux-post-2.6.4rc2-20040307/include/asm-um/linkage.h	2002-09-06 17:29:29.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/include/asm-um/linkage.h	2004-03-07 07:04:57.000000000 +0000
@@ -2,5 +2,6 @@
 #define __ASM_LINKAGE_H
 
 #define FASTCALL(x)	x __attribute__((regparm(3)))
+#define fastcall        __attribute__((regparm(3)))
 
 #endif
diff -purN linux-post-2.6.4rc2-20040307/include/linux/blkdev.h linux-post-2.6.4rc2-20040309/include/linux/blkdev.h
--- linux-post-2.6.4rc2-20040307/include/linux/blkdev.h	2004-02-01 11:53:03.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/include/linux/blkdev.h	2004-03-08 20:59:01.000000000 +0000
@@ -369,9 +369,12 @@ struct request_queue
 #define	QUEUE_FLAG_READFULL	3	/* write queue has been filled */
 #define QUEUE_FLAG_WRITEFULL	4	/* read queue has been filled */
 #define QUEUE_FLAG_DEAD		5	/* queue being torn down */
+#define QUEUE_FLAG_REENTER	6	/* Re-entrancy avoidance */
 
 #define blk_queue_plugged(q)	!list_empty(&(q)->plug_list)
 #define blk_queue_tagged(q)	test_bit(QUEUE_FLAG_QUEUED, &(q)->queue_flags)
+#define blk_queue_stopped(q)	test_bit(QUEUE_FLAG_STOPPED, &(q)->queue_flags)
+
 #define blk_fs_request(rq)	((rq)->flags & REQ_CMD)
 #define blk_pc_request(rq)	((rq)->flags & REQ_BLOCK_PC)
 #define blk_noretry_request(rq)	((rq)->flags & REQ_FAILFAST)
diff -purN linux-post-2.6.4rc2-20040307/include/linux/compat.h linux-post-2.6.4rc2-20040309/include/linux/compat.h
--- linux-post-2.6.4rc2-20040307/include/linux/compat.h	2004-01-19 06:28:18.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/include/linux/compat.h	2004-03-07 07:05:30.000000000 +0000
@@ -45,7 +45,7 @@ typedef struct {
 
 extern int cp_compat_stat(struct kstat *, struct compat_stat *);
 extern int get_compat_timespec(struct timespec *, const struct compat_timespec *);
-extern int put_compat_timespec(struct timespec *, const struct compat_timespec *);
+extern int put_compat_timespec(const struct timespec *, struct compat_timespec *);
 
 struct compat_iovec {
 	compat_uptr_t	iov_base;
diff -purN linux-post-2.6.4rc2-20040307/include/linux/compat_ioctl.h linux-post-2.6.4rc2-20040309/include/linux/compat_ioctl.h
--- linux-post-2.6.4rc2-20040307/include/linux/compat_ioctl.h	2004-02-02 00:14:24.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/include/linux/compat_ioctl.h	2004-03-07 07:04:56.000000000 +0000
@@ -122,7 +122,6 @@ COMPATIBLE_IOCTL(STOP_ARRAY)
 COMPATIBLE_IOCTL(STOP_ARRAY_RO)
 COMPATIBLE_IOCTL(RESTART_ARRAY_RW)
 /* DM */
-#ifdef CONFIG_DM_IOCTL_V4
 COMPATIBLE_IOCTL(DM_VERSION)
 COMPATIBLE_IOCTL(DM_LIST_DEVICES)
 COMPATIBLE_IOCTL(DM_DEV_CREATE)
@@ -135,19 +134,6 @@ COMPATIBLE_IOCTL(DM_TABLE_LOAD)
 COMPATIBLE_IOCTL(DM_TABLE_CLEAR)
 COMPATIBLE_IOCTL(DM_TABLE_DEPS)
 COMPATIBLE_IOCTL(DM_TABLE_STATUS)
-#else
-COMPATIBLE_IOCTL(DM_VERSION)
-COMPATIBLE_IOCTL(DM_REMOVE_ALL)
-COMPATIBLE_IOCTL(DM_DEV_CREATE)
-COMPATIBLE_IOCTL(DM_DEV_REMOVE)
-COMPATIBLE_IOCTL(DM_DEV_RELOAD)
-COMPATIBLE_IOCTL(DM_DEV_SUSPEND)
-COMPATIBLE_IOCTL(DM_DEV_RENAME)
-COMPATIBLE_IOCTL(DM_DEV_DEPS)
-COMPATIBLE_IOCTL(DM_DEV_STATUS)
-COMPATIBLE_IOCTL(DM_TARGET_STATUS)
-COMPATIBLE_IOCTL(DM_TARGET_WAIT)
-#endif
 /* Big K */
 COMPATIBLE_IOCTL(PIO_FONT)
 COMPATIBLE_IOCTL(GIO_FONT)
diff -purN linux-post-2.6.4rc2-20040307/include/linux/cpu.h linux-post-2.6.4rc2-20040309/include/linux/cpu.h
--- linux-post-2.6.4rc2-20040307/include/linux/cpu.h	2004-02-04 05:28:12.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/include/linux/cpu.h	2004-03-09 00:57:46.000000000 +0000
@@ -21,6 +21,8 @@
 
 #include <linux/sysdev.h>
 #include <linux/node.h>
+#include <linux/compiler.h>
+#include <linux/cpumask.h>
 #include <asm/semaphore.h>
 
 struct cpu {
@@ -56,9 +58,20 @@ extern struct sysdev_class cpu_sysdev_cl
 extern struct semaphore cpucontrol;
 #define lock_cpu_hotplug()	down(&cpucontrol)
 #define unlock_cpu_hotplug()	up(&cpucontrol)
+#define lock_cpu_hotplug_interruptible() down_interruptible(&cpucontrol)
+#define hotcpu_notifier(fn, pri) {				\
+	static struct notifier_block fn##_nb = { fn, pri };	\
+	register_cpu_notifier(&fn##_nb);			\
+}
+#define cpu_is_offline(cpu) unlikely(!cpu_online(cpu))
 #else
 #define lock_cpu_hotplug()	do { } while (0)
 #define unlock_cpu_hotplug()	do { } while (0)
+#define lock_cpu_hotplug_interruptible() 0
+#define hotcpu_notifier(fn, pri)
+
+/* CPUs don't go offline once they're online w/o CONFIG_HOTPLUG_CPU */
+#define cpu_is_offline(cpu) 0
 #endif
 
 #endif /* _LINUX_CPU_H_ */
diff -purN linux-post-2.6.4rc2-20040307/include/linux/cpumask.h linux-post-2.6.4rc2-20040309/include/linux/cpumask.h
--- linux-post-2.6.4rc2-20040307/include/linux/cpumask.h	2004-02-19 03:42:58.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/include/linux/cpumask.h	2004-03-09 00:57:46.000000000 +0000
@@ -12,6 +12,7 @@ extern cpumask_t cpu_online_map;
 extern cpumask_t cpu_possible_map;
 
 #define num_online_cpus()		cpus_weight(cpu_online_map)
+#define num_possible_cpus()		cpus_weight(cpu_possible_map)
 #define cpu_online(cpu)			cpu_isset(cpu, cpu_online_map)
 #define cpu_possible(cpu)		cpu_isset(cpu, cpu_possible_map)
 
@@ -24,7 +25,9 @@ extern cpumask_t cpu_possible_map;
 #define for_each_online_cpu(cpu) for_each_cpu_mask(cpu, cpu_online_map)
 #else
 #define	cpu_online_map			cpumask_of_cpu(0)
+#define	cpu_possible_map		cpumask_of_cpu(0)
 #define num_online_cpus()		1
+#define num_possible_cpus()		1
 #define cpu_online(cpu)			({ BUG_ON((cpu) != 0); 1; })
 #define cpu_possible(cpu)		({ BUG_ON((cpu) != 0); 1; })
 
diff -purN linux-post-2.6.4rc2-20040307/include/linux/dm-ioctl-v1.h linux-post-2.6.4rc2-20040309/include/linux/dm-ioctl-v1.h
--- linux-post-2.6.4rc2-20040307/include/linux/dm-ioctl-v1.h	2003-09-23 04:16:30.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/include/linux/dm-ioctl-v1.h	1970-01-01 00:00:00.000000000 +0000
@@ -1,149 +0,0 @@
-/*
- * Copyright (C) 2001 Sistina Software (UK) Limited.
- *
- * This file is released under the LGPL.
- */
-
-#ifndef _LINUX_DM_IOCTL_V1_H
-#define _LINUX_DM_IOCTL_V1_H
-
-#include <linux/types.h>
-
-#define DM_DIR "mapper"	/* Slashes not supported */
-#define DM_MAX_TYPE_NAME 16
-#define DM_NAME_LEN 128
-#define DM_UUID_LEN 129
-
-/*
- * Implements a traditional ioctl interface to the device mapper.
- */
-
-/*
- * All ioctl arguments consist of a single chunk of memory, with
- * this structure at the start.  If a uuid is specified any
- * lookup (eg. for a DM_INFO) will be done on that, *not* the
- * name.
- */
-struct dm_ioctl {
-	/*
-	 * The version number is made up of three parts:
-	 * major - no backward or forward compatibility,
-	 * minor - only backwards compatible,
-	 * patch - both backwards and forwards compatible.
-	 *
-	 * All clients of the ioctl interface should fill in the
-	 * version number of the interface that they were
-	 * compiled with.
-	 *
-	 * All recognised ioctl commands (ie. those that don't
-	 * return -ENOTTY) fill out this field, even if the
-	 * command failed.
-	 */
-	uint32_t version[3];	/* in/out */
-	uint32_t data_size;	/* total size of data passed in
-				 * including this struct */
-
-	uint32_t data_start;	/* offset to start of data
-				 * relative to start of this struct */
-
-	uint32_t target_count;	/* in/out */
-	uint32_t open_count;	/* out */
-	uint32_t flags;		/* in/out */
-
-	__kernel_old_dev_t dev;	/* in/out */
-
-	char name[DM_NAME_LEN];	/* device name */
-	char uuid[DM_UUID_LEN];	/* unique identifier for
-				 * the block device */
-};
-
-/*
- * Used to specify tables.  These structures appear after the
- * dm_ioctl.
- */
-struct dm_target_spec {
-	int32_t status;		/* used when reading from kernel only */
-	uint64_t sector_start;
-	uint32_t length;
-
-	/*
-	 * Offset in bytes (from the start of this struct) to
-	 * next target_spec.
-	 */
-	uint32_t next;
-
-	char target_type[DM_MAX_TYPE_NAME];
-
-	/*
-	 * Parameter string starts immediately after this object.
-	 * Be careful to add padding after string to ensure correct
-	 * alignment of subsequent dm_target_spec.
-	 */
-};
-
-/*
- * Used to retrieve the target dependencies.
- */
-struct dm_target_deps {
-	uint32_t count;
-
-	__kernel_old_dev_t dev[0];	/* out */
-};
-
-/*
- * If you change this make sure you make the corresponding change
- * to dm-ioctl.c:lookup_ioctl()
- */
-enum {
-	/* Top level cmds */
-	DM_VERSION_CMD = 0,
-	DM_REMOVE_ALL_CMD,
-
-	/* device level cmds */
-	DM_DEV_CREATE_CMD,
-	DM_DEV_REMOVE_CMD,
-	DM_DEV_RELOAD_CMD,
-	DM_DEV_RENAME_CMD,
-	DM_DEV_SUSPEND_CMD,
-	DM_DEV_DEPS_CMD,
-	DM_DEV_STATUS_CMD,
-
-	/* target level cmds */
-	DM_TARGET_STATUS_CMD,
-	DM_TARGET_WAIT_CMD
-};
-
-#define DM_IOCTL 0xfd
-
-#define DM_VERSION       _IOWR(DM_IOCTL, DM_VERSION_CMD, struct dm_ioctl)
-#define DM_REMOVE_ALL    _IOWR(DM_IOCTL, DM_REMOVE_ALL_CMD, struct dm_ioctl)
-
-#define DM_DEV_CREATE    _IOWR(DM_IOCTL, DM_DEV_CREATE_CMD, struct dm_ioctl)
-#define DM_DEV_REMOVE    _IOWR(DM_IOCTL, DM_DEV_REMOVE_CMD, struct dm_ioctl)
-#define DM_DEV_RELOAD    _IOWR(DM_IOCTL, DM_DEV_RELOAD_CMD, struct dm_ioctl)
-#define DM_DEV_SUSPEND   _IOWR(DM_IOCTL, DM_DEV_SUSPEND_CMD, struct dm_ioctl)
-#define DM_DEV_RENAME    _IOWR(DM_IOCTL, DM_DEV_RENAME_CMD, struct dm_ioctl)
-#define DM_DEV_DEPS      _IOWR(DM_IOCTL, DM_DEV_DEPS_CMD, struct dm_ioctl)
-#define DM_DEV_STATUS    _IOWR(DM_IOCTL, DM_DEV_STATUS_CMD, struct dm_ioctl)
-
-#define DM_TARGET_STATUS _IOWR(DM_IOCTL, DM_TARGET_STATUS_CMD, struct dm_ioctl)
-#define DM_TARGET_WAIT   _IOWR(DM_IOCTL, DM_TARGET_WAIT_CMD, struct dm_ioctl)
-
-#define DM_VERSION_MAJOR	1
-#define DM_VERSION_MINOR	0
-#define DM_VERSION_PATCHLEVEL	6
-#define DM_VERSION_EXTRA	"-ioctl (2002-10-15)"
-
-/* Status bits */
-#define DM_READONLY_FLAG	0x00000001
-#define DM_SUSPEND_FLAG		0x00000002
-#define DM_EXISTS_FLAG		0x00000004
-#define DM_PERSISTENT_DEV_FLAG	0x00000008
-
-/*
- * Flag passed into ioctl STATUS command to get table information
- * rather than current status.
- */
-#define DM_STATUS_TABLE_FLAG	0x00000010
-
-#endif				/* _LINUX_DM_IOCTL_H */
diff -purN linux-post-2.6.4rc2-20040307/include/linux/dm-ioctl-v4.h linux-post-2.6.4rc2-20040309/include/linux/dm-ioctl-v4.h
--- linux-post-2.6.4rc2-20040307/include/linux/dm-ioctl-v4.h	2003-07-18 05:30:58.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/include/linux/dm-ioctl-v4.h	1970-01-01 00:00:00.000000000 +0000
@@ -1,237 +0,0 @@
-/*
- * Copyright (C) 2001 - 2003 Sistina Software (UK) Limited.
- *
- * This file is released under the LGPL.
- */
-
-#ifndef _LINUX_DM_IOCTL_V4_H
-#define _LINUX_DM_IOCTL_V4_H
-
-#include <linux/types.h>
-
-#define DM_DIR "mapper"		/* Slashes not supported */
-#define DM_MAX_TYPE_NAME 16
-#define DM_NAME_LEN 128
-#define DM_UUID_LEN 129
-
-/*
- * A traditional ioctl interface for the device mapper.
- *
- * Each device can have two tables associated with it, an
- * 'active' table which is the one currently used by io passing
- * through the device, and an 'inactive' one which is a table
- * that is being prepared as a replacement for the 'active' one.
- *
- * DM_VERSION:
- * Just get the version information for the ioctl interface.
- *
- * DM_REMOVE_ALL:
- * Remove all dm devices, destroy all tables.  Only really used
- * for debug.
- *
- * DM_LIST_DEVICES:
- * Get a list of all the dm device names.
- *
- * DM_DEV_CREATE:
- * Create a new device, neither the 'active' or 'inactive' table
- * slots will be filled.  The device will be in suspended state
- * after creation, however any io to the device will get errored
- * since it will be out-of-bounds.
- *
- * DM_DEV_REMOVE:
- * Remove a device, destroy any tables.
- *
- * DM_DEV_RENAME:
- * Rename a device.
- *
- * DM_SUSPEND:
- * This performs both suspend and resume, depending which flag is
- * passed in.
- * Suspend: This command will not return until all pending io to
- * the device has completed.  Further io will be deferred until
- * the device is resumed.
- * Resume: It is no longer an error to issue this command on an
- * unsuspended device.  If a table is present in the 'inactive'
- * slot, it will be moved to the active slot, then the old table
- * from the active slot will be _destroyed_.  Finally the device
- * is resumed.
- *
- * DM_DEV_STATUS:
- * Retrieves the status for the table in the 'active' slot.
- *
- * DM_DEV_WAIT:
- * Wait for a significant event to occur to the device.  This
- * could either be caused by an event triggered by one of the
- * targets of the table in the 'active' slot, or a table change.
- *
- * DM_TABLE_LOAD:
- * Load a table into the 'inactive' slot for the device.  The
- * device does _not_ need to be suspended prior to this command.
- *
- * DM_TABLE_CLEAR:
- * Destroy any table in the 'inactive' slot (ie. abort).
- *
- * DM_TABLE_DEPS:
- * Return a set of device dependencies for the 'active' table.
- *
- * DM_TABLE_STATUS:
- * Return the targets status for the 'active' table.
- */
-
-/*
- * All ioctl arguments consist of a single chunk of memory, with
- * this structure at the start.  If a uuid is specified any
- * lookup (eg. for a DM_INFO) will be done on that, *not* the
- * name.
- */
-struct dm_ioctl {
-	/*
-	 * The version number is made up of three parts:
-	 * major - no backward or forward compatibility,
-	 * minor - only backwards compatible,
-	 * patch - both backwards and forwards compatible.
-	 *
-	 * All clients of the ioctl interface should fill in the
-	 * version number of the interface that they were
-	 * compiled with.
-	 *
-	 * All recognised ioctl commands (ie. those that don't
-	 * return -ENOTTY) fill out this field, even if the
-	 * command failed.
-	 */
-	uint32_t version[3];	/* in/out */
-	uint32_t data_size;	/* total size of data passed in
-				 * including this struct */
-
-	uint32_t data_start;	/* offset to start of data
-				 * relative to start of this struct */
-
-	uint32_t target_count;	/* in/out */
-	int32_t open_count;	/* out */
-	uint32_t flags;		/* in/out */
-	uint32_t event_nr;      	/* in/out */
-	uint32_t padding;
-
-	uint64_t dev;		/* in/out */
-
-	char name[DM_NAME_LEN];	/* device name */
-	char uuid[DM_UUID_LEN];	/* unique identifier for
-				 * the block device */
-};
-
-/*
- * Used to specify tables.  These structures appear after the
- * dm_ioctl.
- */
-struct dm_target_spec {
-	uint64_t sector_start;
-	uint64_t length;
-	int32_t status;		/* used when reading from kernel only */
-
-	/*
-	 * Offset in bytes (from the start of this struct) to
-	 * next target_spec.
-	 */
-	uint32_t next;
-
-	char target_type[DM_MAX_TYPE_NAME];
-
-	/*
-	 * Parameter string starts immediately after this object.
-	 * Be careful to add padding after string to ensure correct
-	 * alignment of subsequent dm_target_spec.
-	 */
-};
-
-/*
- * Used to retrieve the target dependencies.
- */
-struct dm_target_deps {
-	uint32_t count;	/* Array size */
-	uint32_t padding;	/* unused */
-	uint64_t dev[0];	/* out */
-};
-
-/*
- * Used to get a list of all dm devices.
- */
-struct dm_name_list {
-	uint64_t dev;
-	uint32_t next;		/* offset to the next record from
-				   the _start_ of this */
-	char name[0];
-};
-
-/*
- * If you change this make sure you make the corresponding change
- * to dm-ioctl.c:lookup_ioctl()
- */
-enum {
-	/* Top level cmds */
-	DM_VERSION_CMD = 0,
-	DM_REMOVE_ALL_CMD,
-	DM_LIST_DEVICES_CMD,
-
-	/* device level cmds */
-	DM_DEV_CREATE_CMD,
-	DM_DEV_REMOVE_CMD,
-	DM_DEV_RENAME_CMD,
-	DM_DEV_SUSPEND_CMD,
-	DM_DEV_STATUS_CMD,
-	DM_DEV_WAIT_CMD,
-
-	/* Table level cmds */
-	DM_TABLE_LOAD_CMD,
-	DM_TABLE_CLEAR_CMD,
-	DM_TABLE_DEPS_CMD,
-	DM_TABLE_STATUS_CMD,
-};
-
-#define DM_IOCTL 0xfd
-
-#define DM_VERSION       _IOWR(DM_IOCTL, DM_VERSION_CMD, struct dm_ioctl)
-#define DM_REMOVE_ALL    _IOWR(DM_IOCTL, DM_REMOVE_ALL_CMD, struct dm_ioctl)
-#define DM_LIST_DEVICES  _IOWR(DM_IOCTL, DM_LIST_DEVICES_CMD, struct dm_ioctl)
-
-#define DM_DEV_CREATE    _IOWR(DM_IOCTL, DM_DEV_CREATE_CMD, struct dm_ioctl)
-#define DM_DEV_REMOVE    _IOWR(DM_IOCTL, DM_DEV_REMOVE_CMD, struct dm_ioctl)
-#define DM_DEV_RENAME    _IOWR(DM_IOCTL, DM_DEV_RENAME_CMD, struct dm_ioctl)
-#define DM_DEV_SUSPEND   _IOWR(DM_IOCTL, DM_DEV_SUSPEND_CMD, struct dm_ioctl)
-#define DM_DEV_STATUS    _IOWR(DM_IOCTL, DM_DEV_STATUS_CMD, struct dm_ioctl)
-#define DM_DEV_WAIT      _IOWR(DM_IOCTL, DM_DEV_WAIT_CMD, struct dm_ioctl)
-
-#define DM_TABLE_LOAD    _IOWR(DM_IOCTL, DM_TABLE_LOAD_CMD, struct dm_ioctl)
-#define DM_TABLE_CLEAR   _IOWR(DM_IOCTL, DM_TABLE_CLEAR_CMD, struct dm_ioctl)
-#define DM_TABLE_DEPS    _IOWR(DM_IOCTL, DM_TABLE_DEPS_CMD, struct dm_ioctl)
-#define DM_TABLE_STATUS  _IOWR(DM_IOCTL, DM_TABLE_STATUS_CMD, struct dm_ioctl)
-
-#define DM_VERSION_MAJOR	4
-#define DM_VERSION_MINOR	0
-#define DM_VERSION_PATCHLEVEL	0
-#define DM_VERSION_EXTRA	"-ioctl (2003-06-04)"
-
-/* Status bits */
-#define DM_READONLY_FLAG	(1 << 0) /* In/Out */
-#define DM_SUSPEND_FLAG		(1 << 1) /* In/Out */
-#define DM_PERSISTENT_DEV_FLAG	(1 << 3) /* In */
-
-/*
- * Flag passed into ioctl STATUS command to get table information
- * rather than current status.
- */
-#define DM_STATUS_TABLE_FLAG	(1 << 4) /* In */
-
-/*
- * Flags that indicate whether a table is present in either of
- * the two table slots that a device has.
- */
-#define DM_ACTIVE_PRESENT_FLAG   (1 << 5) /* Out */
-#define DM_INACTIVE_PRESENT_FLAG (1 << 6) /* Out */
-
-/*
- * Indicates that the buffer passed in wasn't big enough for the
- * results.
- */
-#define DM_BUFFER_FULL_FLAG	(1 << 8) /* Out */
-
-#endif				/* _LINUX_DM_IOCTL_H */
diff -purN linux-post-2.6.4rc2-20040307/include/linux/dm-ioctl.h linux-post-2.6.4rc2-20040309/include/linux/dm-ioctl.h
--- linux-post-2.6.4rc2-20040307/include/linux/dm-ioctl.h	2003-07-18 05:30:58.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/include/linux/dm-ioctl.h	2004-03-07 07:04:56.000000000 +0000
@@ -1,18 +1,237 @@
 /*
- * Copyright (C) 2003 Sistina Software (UK) Limited.
+ * Copyright (C) 2001 - 2003 Sistina Software (UK) Limited.
  *
  * This file is released under the LGPL.
  */
 
-#ifndef _LINUX_DM_IOCTL_H
-#define _LINUX_DM_IOCTL_H
+#ifndef _LINUX_DM_IOCTL_V4_H
+#define _LINUX_DM_IOCTL_V4_H
 
-#include <linux/config.h>
+#include <linux/types.h>
 
-#ifdef CONFIG_DM_IOCTL_V4
-#include "dm-ioctl-v4.h"
-#else
-#include "dm-ioctl-v1.h"
-#endif
+#define DM_DIR "mapper"		/* Slashes not supported */
+#define DM_MAX_TYPE_NAME 16
+#define DM_NAME_LEN 128
+#define DM_UUID_LEN 129
 
-#endif
+/*
+ * A traditional ioctl interface for the device mapper.
+ *
+ * Each device can have two tables associated with it, an
+ * 'active' table which is the one currently used by io passing
+ * through the device, and an 'inactive' one which is a table
+ * that is being prepared as a replacement for the 'active' one.
+ *
+ * DM_VERSION:
+ * Just get the version information for the ioctl interface.
+ *
+ * DM_REMOVE_ALL:
+ * Remove all dm devices, destroy all tables.  Only really used
+ * for debug.
+ *
+ * DM_LIST_DEVICES:
+ * Get a list of all the dm device names.
+ *
+ * DM_DEV_CREATE:
+ * Create a new device, neither the 'active' or 'inactive' table
+ * slots will be filled.  The device will be in suspended state
+ * after creation, however any io to the device will get errored
+ * since it will be out-of-bounds.
+ *
+ * DM_DEV_REMOVE:
+ * Remove a device, destroy any tables.
+ *
+ * DM_DEV_RENAME:
+ * Rename a device.
+ *
+ * DM_SUSPEND:
+ * This performs both suspend and resume, depending which flag is
+ * passed in.
+ * Suspend: This command will not return until all pending io to
+ * the device has completed.  Further io will be deferred until
+ * the device is resumed.
+ * Resume: It is no longer an error to issue this command on an
+ * unsuspended device.  If a table is present in the 'inactive'
+ * slot, it will be moved to the active slot, then the old table
+ * from the active slot will be _destroyed_.  Finally the device
+ * is resumed.
+ *
+ * DM_DEV_STATUS:
+ * Retrieves the status for the table in the 'active' slot.
+ *
+ * DM_DEV_WAIT:
+ * Wait for a significant event to occur to the device.  This
+ * could either be caused by an event triggered by one of the
+ * targets of the table in the 'active' slot, or a table change.
+ *
+ * DM_TABLE_LOAD:
+ * Load a table into the 'inactive' slot for the device.  The
+ * device does _not_ need to be suspended prior to this command.
+ *
+ * DM_TABLE_CLEAR:
+ * Destroy any table in the 'inactive' slot (ie. abort).
+ *
+ * DM_TABLE_DEPS:
+ * Return a set of device dependencies for the 'active' table.
+ *
+ * DM_TABLE_STATUS:
+ * Return the targets status for the 'active' table.
+ */
+
+/*
+ * All ioctl arguments consist of a single chunk of memory, with
+ * this structure at the start.  If a uuid is specified any
+ * lookup (eg. for a DM_INFO) will be done on that, *not* the
+ * name.
+ */
+struct dm_ioctl {
+	/*
+	 * The version number is made up of three parts:
+	 * major - no backward or forward compatibility,
+	 * minor - only backwards compatible,
+	 * patch - both backwards and forwards compatible.
+	 *
+	 * All clients of the ioctl interface should fill in the
+	 * version number of the interface that they were
+	 * compiled with.
+	 *
+	 * All recognised ioctl commands (ie. those that don't
+	 * return -ENOTTY) fill out this field, even if the
+	 * command failed.
+	 */
+	uint32_t version[3];	/* in/out */
+	uint32_t data_size;	/* total size of data passed in
+				 * including this struct */
+
+	uint32_t data_start;	/* offset to start of data
+				 * relative to start of this struct */
+
+	uint32_t target_count;	/* in/out */
+	int32_t open_count;	/* out */
+	uint32_t flags;		/* in/out */
+	uint32_t event_nr;      	/* in/out */
+	uint32_t padding;
+
+	uint64_t dev;		/* in/out */
+
+	char name[DM_NAME_LEN];	/* device name */
+	char uuid[DM_UUID_LEN];	/* unique identifier for
+				 * the block device */
+};
+
+/*
+ * Used to specify tables.  These structures appear after the
+ * dm_ioctl.
+ */
+struct dm_target_spec {
+	uint64_t sector_start;
+	uint64_t length;
+	int32_t status;		/* used when reading from kernel only */
+
+	/*
+	 * Offset in bytes (from the start of this struct) to
+	 * next target_spec.
+	 */
+	uint32_t next;
+
+	char target_type[DM_MAX_TYPE_NAME];
+
+	/*
+	 * Parameter string starts immediately after this object.
+	 * Be careful to add padding after string to ensure correct
+	 * alignment of subsequent dm_target_spec.
+	 */
+};
+
+/*
+ * Used to retrieve the target dependencies.
+ */
+struct dm_target_deps {
+	uint32_t count;	/* Array size */
+	uint32_t padding;	/* unused */
+	uint64_t dev[0];	/* out */
+};
+
+/*
+ * Used to get a list of all dm devices.
+ */
+struct dm_name_list {
+	uint64_t dev;
+	uint32_t next;		/* offset to the next record from
+				   the _start_ of this */
+	char name[0];
+};
+
+/*
+ * If you change this make sure you make the corresponding change
+ * to dm-ioctl.c:lookup_ioctl()
+ */
+enum {
+	/* Top level cmds */
+	DM_VERSION_CMD = 0,
+	DM_REMOVE_ALL_CMD,
+	DM_LIST_DEVICES_CMD,
+
+	/* device level cmds */
+	DM_DEV_CREATE_CMD,
+	DM_DEV_REMOVE_CMD,
+	DM_DEV_RENAME_CMD,
+	DM_DEV_SUSPEND_CMD,
+	DM_DEV_STATUS_CMD,
+	DM_DEV_WAIT_CMD,
+
+	/* Table level cmds */
+	DM_TABLE_LOAD_CMD,
+	DM_TABLE_CLEAR_CMD,
+	DM_TABLE_DEPS_CMD,
+	DM_TABLE_STATUS_CMD,
+};
+
+#define DM_IOCTL 0xfd
+
+#define DM_VERSION       _IOWR(DM_IOCTL, DM_VERSION_CMD, struct dm_ioctl)
+#define DM_REMOVE_ALL    _IOWR(DM_IOCTL, DM_REMOVE_ALL_CMD, struct dm_ioctl)
+#define DM_LIST_DEVICES  _IOWR(DM_IOCTL, DM_LIST_DEVICES_CMD, struct dm_ioctl)
+
+#define DM_DEV_CREATE    _IOWR(DM_IOCTL, DM_DEV_CREATE_CMD, struct dm_ioctl)
+#define DM_DEV_REMOVE    _IOWR(DM_IOCTL, DM_DEV_REMOVE_CMD, struct dm_ioctl)
+#define DM_DEV_RENAME    _IOWR(DM_IOCTL, DM_DEV_RENAME_CMD, struct dm_ioctl)
+#define DM_DEV_SUSPEND   _IOWR(DM_IOCTL, DM_DEV_SUSPEND_CMD, struct dm_ioctl)
+#define DM_DEV_STATUS    _IOWR(DM_IOCTL, DM_DEV_STATUS_CMD, struct dm_ioctl)
+#define DM_DEV_WAIT      _IOWR(DM_IOCTL, DM_DEV_WAIT_CMD, struct dm_ioctl)
+
+#define DM_TABLE_LOAD    _IOWR(DM_IOCTL, DM_TABLE_LOAD_CMD, struct dm_ioctl)
+#define DM_TABLE_CLEAR   _IOWR(DM_IOCTL, DM_TABLE_CLEAR_CMD, struct dm_ioctl)
+#define DM_TABLE_DEPS    _IOWR(DM_IOCTL, DM_TABLE_DEPS_CMD, struct dm_ioctl)
+#define DM_TABLE_STATUS  _IOWR(DM_IOCTL, DM_TABLE_STATUS_CMD, struct dm_ioctl)
+
+#define DM_VERSION_MAJOR	4
+#define DM_VERSION_MINOR	0
+#define DM_VERSION_PATCHLEVEL	0
+#define DM_VERSION_EXTRA	"-ioctl (2003-06-04)"
+
+/* Status bits */
+#define DM_READONLY_FLAG	(1 << 0) /* In/Out */
+#define DM_SUSPEND_FLAG		(1 << 1) /* In/Out */
+#define DM_PERSISTENT_DEV_FLAG	(1 << 3) /* In */
+
+/*
+ * Flag passed into ioctl STATUS command to get table information
+ * rather than current status.
+ */
+#define DM_STATUS_TABLE_FLAG	(1 << 4) /* In */
+
+/*
+ * Flags that indicate whether a table is present in either of
+ * the two table slots that a device has.
+ */
+#define DM_ACTIVE_PRESENT_FLAG   (1 << 5) /* Out */
+#define DM_INACTIVE_PRESENT_FLAG (1 << 6) /* Out */
+
+/*
+ * Indicates that the buffer passed in wasn't big enough for the
+ * results.
+ */
+#define DM_BUFFER_FULL_FLAG	(1 << 8) /* Out */
+
+#endif				/* _LINUX_DM_IOCTL_H */
diff -purN linux-post-2.6.4rc2-20040307/include/linux/i2o-dev.h linux-post-2.6.4rc2-20040309/include/linux/i2o-dev.h
--- linux-post-2.6.4rc2-20040307/include/linux/i2o-dev.h	2002-02-05 07:52:37.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/include/linux/i2o-dev.h	2004-03-07 07:16:10.000000000 +0000
@@ -182,7 +182,7 @@ typedef struct _i2o_hrt_entry
 {
 	u32	adapter_id;
 	u32	parent_tid:12;
-	u32 	tate:4;
+	u32 	state:4;
 	u32	bus_num:8;
 	u32	bus_type:8;
 	union
diff -purN linux-post-2.6.4rc2-20040307/include/linux/i2o.h linux-post-2.6.4rc2-20040309/include/linux/i2o.h
--- linux-post-2.6.4rc2-20040307/include/linux/i2o.h	2003-03-13 20:35:36.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/include/linux/i2o.h	2004-03-07 07:16:10.000000000 +0000
@@ -544,6 +544,25 @@ extern int i2o_delete_controller(struct 
 #define I2O_DSC_DEVICE_BUSY                    0x001B
 #define I2O_DSC_DEVICE_NOT_AVAILABLE           0x001C
 
+/* DetailedStatusCode defines for Block Storage Operation: Table 6-7 Detailed
+   Status Codes.*/
+
+#define I2O_BSA_DSC_SUCCESS               0x0000
+#define I2O_BSA_DSC_MEDIA_ERROR           0x0001
+#define I2O_BSA_DSC_ACCESS_ERROR          0x0002
+#define I2O_BSA_DSC_DEVICE_FAILURE        0x0003
+#define I2O_BSA_DSC_DEVICE_NOT_READY      0x0004
+#define I2O_BSA_DSC_MEDIA_NOT_PRESENT     0x0005
+#define I2O_BSA_DSC_MEDIA_LOCKED          0x0006
+#define I2O_BSA_DSC_MEDIA_FAILURE         0x0007
+#define I2O_BSA_DSC_PROTOCOL_FAILURE      0x0008
+#define I2O_BSA_DSC_BUS_FAILURE           0x0009
+#define I2O_BSA_DSC_ACCESS_VIOLATION      0x000A
+#define I2O_BSA_DSC_WRITE_PROTECTED       0x000B
+#define I2O_BSA_DSC_DEVICE_RESET          0x000C
+#define I2O_BSA_DSC_VOLUME_CHANGED        0x000D
+#define I2O_BSA_DSC_TIMEOUT               0x000E
+
 /* FailureStatusCodes, Table 3-3 Message Failure Codes */
 
 #define I2O_FSC_TRANSPORT_SERVICE_SUSPENDED             0x81
diff -purN linux-post-2.6.4rc2-20040307/include/linux/linkage.h linux-post-2.6.4rc2-20040309/include/linux/linkage.h
--- linux-post-2.6.4rc2-20040307/include/linux/linkage.h	2002-08-04 05:44:49.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/include/linux/linkage.h	2004-03-07 07:04:57.000000000 +0000
@@ -37,6 +37,7 @@
 
 #ifndef FASTCALL
 #define FASTCALL(x)	x
+#define fastcall
 #endif
 
 #endif
diff -purN linux-post-2.6.4rc2-20040307/include/linux/mm.h linux-post-2.6.4rc2-20040309/include/linux/mm.h
--- linux-post-2.6.4rc2-20040307/include/linux/mm.h	2004-02-25 10:34:43.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/include/linux/mm.h	2004-03-08 14:21:20.000000000 +0000
@@ -530,7 +530,8 @@ extern void si_meminfo_node(struct sysin
 
 /* mmap.c */
 extern void insert_vm_struct(struct mm_struct *, struct vm_area_struct *);
-extern void build_mmap_rb(struct mm_struct *);
+extern void __vma_link_rb(struct mm_struct *, struct vm_area_struct *,
+	struct rb_node **, struct rb_node *);
 extern void exit_mmap(struct mm_struct *);
 
 extern unsigned long get_unmapped_area(struct file *, unsigned long, unsigned long, unsigned long, unsigned long);
diff -purN linux-post-2.6.4rc2-20040307/include/linux/sched.h linux-post-2.6.4rc2-20040309/include/linux/sched.h
--- linux-post-2.6.4rc2-20040307/include/linux/sched.h	2004-02-25 10:34:54.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/include/linux/sched.h	2004-03-07 07:05:01.000000000 +0000
@@ -602,7 +602,7 @@ extern void do_timer(struct pt_regs *);
 extern int FASTCALL(wake_up_state(struct task_struct * tsk, unsigned int state));
 extern int FASTCALL(wake_up_process(struct task_struct * tsk));
 #ifdef CONFIG_SMP
- extern void FASTCALL(kick_process(struct task_struct * tsk));
+ extern void kick_process(struct task_struct *tsk);
 #else
  static inline void kick_process(struct task_struct *tsk) { }
 #endif
diff -purN linux-post-2.6.4rc2-20040307/include/linux/serial_core.h linux-post-2.6.4rc2-20040309/include/linux/serial_core.h
--- linux-post-2.6.4rc2-20040307/include/linux/serial_core.h	2004-02-20 00:00:00.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/include/linux/serial_core.h	2004-03-07 07:16:08.000000000 +0000
@@ -84,6 +84,7 @@
 #include <linux/interrupt.h>
 #include <linux/circ_buf.h>
 #include <linux/spinlock.h>
+#include <linux/sched.h>
 
 struct uart_port;
 struct uart_info;
diff -purN linux-post-2.6.4rc2-20040307/include/linux/smp.h linux-post-2.6.4rc2-20040309/include/linux/smp.h
--- linux-post-2.6.4rc2-20040307/include/linux/smp.h	2004-01-19 06:32:52.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/include/linux/smp.h	2004-03-07 07:05:01.000000000 +0000
@@ -30,7 +30,7 @@ extern void smp_send_stop(void);
 /*
  * sends a 'reschedule' event to another CPU:
  */
-extern void FASTCALL(smp_send_reschedule(int cpu));
+extern void smp_send_reschedule(int cpu);
 
 
 /*
diff -purN linux-post-2.6.4rc2-20040307/include/linux/stop_machine.h linux-post-2.6.4rc2-20040309/include/linux/stop_machine.h
--- linux-post-2.6.4rc2-20040307/include/linux/stop_machine.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/include/linux/stop_machine.h	2004-02-07 09:50:38.000000000 +0000
@@ -0,0 +1,52 @@
+#ifndef _LINUX_STOP_MACHINE
+#define _LINUX_STOP_MACHINE
+/* "Bogolock": stop the entire machine, disable interrupts.  This is a
+   very heavy lock, which is equivalent to grabbing every spinlock
+   (and more).  So the "read" side to such a lock is anything which
+   diables preeempt. */
+#include <linux/config.h>
+#include <linux/cpu.h>
+#include <asm/system.h>
+
+#ifdef CONFIG_SMP
+/**
+ * stop_machine_run: freeze the machine on all CPUs and run this function
+ * @fn: the function to run
+ * @data: the data ptr for the @fn()
+ * @cpu: the cpu to run @fn() on (or any, if @cpu == NR_CPUS.
+ *
+ * Description: This causes a thread to be scheduled on every other cpu,
+ * each of which disables interrupts, and finally interrupts are disabled
+ * on the current CPU.  The result is that noone is holding a spinlock
+ * or inside any other preempt-disabled region when @fn() runs.
+ *
+ * This can be thought of as a very heavy write lock, equivalent to
+ * grabbing every spinlock in the kernel. */
+int stop_machine_run(int (*fn)(void *), void *data, unsigned int cpu);
+
+/**
+ * __stop_machine_run: freeze the machine on all CPUs and run this function
+ * @fn: the function to run
+ * @data: the data ptr for the @fn
+ * @cpu: the cpu to run @fn on (or any, if @cpu == NR_CPUS.
+ *
+ * Description: This is a special version of the above, which returns the
+ * thread which has run @fn(): kthread_stop will return the return value
+ * of @fn().  Used by hotplug cpu.
+ */
+struct task_struct *__stop_machine_run(int (*fn)(void *), void *data,
+				       unsigned int cpu);
+
+#else
+
+static inline int stop_machine_run(int (*fn)(void *), void *data,
+				   unsigned int cpu)
+{
+	int ret;
+	local_irq_disable();
+	ret = fn(data);
+	local_irq_enable();
+	return ret;
+}
+#endif /* CONFIG_SMP */
+#endif /* _LINUX_STOP_MACHINE */
diff -purN linux-post-2.6.4rc2-20040307/include/linux/sysctl.h linux-post-2.6.4rc2-20040309/include/linux/sysctl.h
--- linux-post-2.6.4rc2-20040307/include/linux/sysctl.h	2004-03-05 22:17:31.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/include/linux/sysctl.h	2004-03-08 20:15:03.000000000 +0000
@@ -405,7 +405,8 @@ enum {
 	NET_IPV6_IP6FRAG_HIGH_THRESH=21,
 	NET_IPV6_IP6FRAG_LOW_THRESH=22,
 	NET_IPV6_IP6FRAG_TIME=23,
-	NET_IPV6_IP6FRAG_SECRET_INTERVAL=24
+	NET_IPV6_IP6FRAG_SECRET_INTERVAL=24,
+	NET_IPV6_MLD_MAX_MSF=25,
 };
 
 enum {
diff -purN linux-post-2.6.4rc2-20040307/include/net/ipv6.h linux-post-2.6.4rc2-20040309/include/net/ipv6.h
--- linux-post-2.6.4rc2-20040307/include/net/ipv6.h	2004-02-20 18:10:03.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/include/net/ipv6.h	2004-03-08 20:15:03.000000000 +0000
@@ -108,6 +108,7 @@ struct frag_hdr {
 
 /* sysctls */
 extern int sysctl_ipv6_bindv6only;
+extern int sysctl_mld_max_msf;
 
 /* MIBs */
 DECLARE_SNMP_STAT(struct ipv6_mib, ipv6_statistics);
diff -purN linux-post-2.6.4rc2-20040307/init/Kconfig linux-post-2.6.4rc2-20040309/init/Kconfig
--- linux-post-2.6.4rc2-20040307/init/Kconfig	2004-03-02 03:01:47.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/init/Kconfig	2004-02-07 09:50:38.000000000 +0000
@@ -304,4 +304,10 @@ config KMOD
 	  runs modprobe with the appropriate arguments, thereby
 	  loading the module if it is available.  If unsure, say Y.
 
+config STOP_MACHINE
+	bool
+	default y
+	depends on (SMP && MODULE_UNLOAD) || HOTPLUG_CPU
+	help
+	  Need stop_machine() primitive.
 endmenu
diff -purN linux-post-2.6.4rc2-20040307/kernel/Makefile linux-post-2.6.4rc2-20040309/kernel/Makefile
--- linux-post-2.6.4rc2-20040307/kernel/Makefile	2004-02-19 03:42:29.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/kernel/Makefile	2004-03-09 01:12:39.000000000 +0000
@@ -20,6 +20,7 @@ obj-$(CONFIG_BSD_PROCESS_ACCT) += acct.o
 obj-$(CONFIG_COMPAT) += compat.o
 obj-$(CONFIG_IKCONFIG) += configs.o
 obj-$(CONFIG_IKCONFIG_PROC) += configs.o
+obj-$(CONFIG_STOP_MACHINE) += stop_machine.o
 
 ifneq ($(CONFIG_IA64),y)
 # According to Alan Modra <alan@linuxcare.com.au>, the -fno-omit-frame-pointer is
diff -purN linux-post-2.6.4rc2-20040307/kernel/acct.c linux-post-2.6.4rc2-20040309/kernel/acct.c
--- linux-post-2.6.4rc2-20040307/kernel/acct.c	2003-10-09 22:13:54.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/kernel/acct.c	2004-03-08 19:22:26.000000000 +0000
@@ -235,8 +235,11 @@ asmlinkage long sys_acct(const char *nam
 	}
 
 	error = security_acct(file);
-	if (error)
+	if (error) {
+		if (file)
+			filp_close(file, NULL);
 		return error;
+	}
 
 	spin_lock(&acct_globals.lock);
 	acct_file_reopen(file);
diff -purN linux-post-2.6.4rc2-20040307/kernel/compat.c linux-post-2.6.4rc2-20040309/kernel/compat.c
--- linux-post-2.6.4rc2-20040307/kernel/compat.c	2004-02-26 11:21:52.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/kernel/compat.c	2004-03-07 07:05:30.000000000 +0000
@@ -30,7 +30,7 @@ int get_compat_timespec(struct timespec 
 			__get_user(ts->tv_nsec, &cts->tv_nsec)) ? -EFAULT : 0;
 }
 
-int put_compat_timespec(struct timespec *ts, const struct compat_timespec *cts)
+int put_compat_timespec(const struct timespec *ts, struct compat_timespec *cts)
 {
 	return (verify_area(VERIFY_WRITE, cts, sizeof(*cts)) ||
 			__put_user(ts->tv_sec, &cts->tv_sec) ||
diff -purN linux-post-2.6.4rc2-20040307/kernel/exit.c linux-post-2.6.4rc2-20040309/kernel/exit.c
--- linux-post-2.6.4rc2-20040307/kernel/exit.c	2004-02-25 10:42:02.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/kernel/exit.c	2004-03-07 07:04:57.000000000 +0000
@@ -386,7 +386,7 @@ static inline void close_files(struct fi
 	}
 }
 
-void put_files_struct(struct files_struct *files)
+void fastcall put_files_struct(struct files_struct *files)
 {
 	if (atomic_dec_and_test(&files->count)) {
 		close_files(files);
@@ -810,7 +810,7 @@ asmlinkage long sys_exit(int error_code)
 	do_exit((error_code&0xff)<<8);
 }
 
-task_t *next_thread(task_t *p)
+task_t fastcall *next_thread(task_t *p)
 {
 	struct pid_link *link = p->pids + PIDTYPE_TGID;
 	struct list_head *tmp, *head = &link->pidptr->task_list;
diff -purN linux-post-2.6.4rc2-20040307/kernel/fork.c linux-post-2.6.4rc2-20040309/kernel/fork.c
--- linux-post-2.6.4rc2-20040307/kernel/fork.c	2004-02-25 10:34:43.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/kernel/fork.c	2004-03-08 14:21:20.000000000 +0000
@@ -91,7 +91,7 @@ void __put_task_struct(struct task_struc
 	free_task(tsk);
 }
 
-void add_wait_queue(wait_queue_head_t *q, wait_queue_t * wait)
+void fastcall add_wait_queue(wait_queue_head_t *q, wait_queue_t * wait)
 {
 	unsigned long flags;
 
@@ -103,7 +103,7 @@ void add_wait_queue(wait_queue_head_t *q
 
 EXPORT_SYMBOL(add_wait_queue);
 
-void add_wait_queue_exclusive(wait_queue_head_t *q, wait_queue_t * wait)
+void fastcall add_wait_queue_exclusive(wait_queue_head_t *q, wait_queue_t * wait)
 {
 	unsigned long flags;
 
@@ -115,7 +115,7 @@ void add_wait_queue_exclusive(wait_queue
 
 EXPORT_SYMBOL(add_wait_queue_exclusive);
 
-void remove_wait_queue(wait_queue_head_t *q, wait_queue_t * wait)
+void fastcall remove_wait_queue(wait_queue_head_t *q, wait_queue_t * wait)
 {
 	unsigned long flags;
 
@@ -139,7 +139,7 @@ EXPORT_SYMBOL(remove_wait_queue);
  * stops them from bleeding out - it would still allow subsequent
  * loads to move into the the critical region).
  */
-void prepare_to_wait(wait_queue_head_t *q, wait_queue_t *wait, int state)
+void fastcall prepare_to_wait(wait_queue_head_t *q, wait_queue_t *wait, int state)
 {
 	unsigned long flags;
 
@@ -153,7 +153,7 @@ void prepare_to_wait(wait_queue_head_t *
 
 EXPORT_SYMBOL(prepare_to_wait);
 
-void
+void fastcall
 prepare_to_wait_exclusive(wait_queue_head_t *q, wait_queue_t *wait, int state)
 {
 	unsigned long flags;
@@ -168,7 +168,7 @@ prepare_to_wait_exclusive(wait_queue_hea
 
 EXPORT_SYMBOL(prepare_to_wait_exclusive);
 
-void finish_wait(wait_queue_head_t *q, wait_queue_t *wait)
+void fastcall finish_wait(wait_queue_head_t *q, wait_queue_t *wait)
 {
 	unsigned long flags;
 
@@ -265,6 +265,7 @@ static struct task_struct *dup_task_stru
 static inline int dup_mmap(struct mm_struct * mm, struct mm_struct * oldmm)
 {
 	struct vm_area_struct * mpnt, *tmp, **pprev;
+	struct rb_node **rb_link, *rb_parent;
 	int retval;
 	unsigned long charge = 0;
 
@@ -277,6 +278,9 @@ static inline int dup_mmap(struct mm_str
 	mm->map_count = 0;
 	mm->rss = 0;
 	cpus_clear(mm->cpu_vm_mask);
+	mm->mm_rb = RB_ROOT;
+	rb_link = &mm->mm_rb.rb_node;
+	rb_parent = NULL;
 	pprev = &mm->mmap;
 
 	/*
@@ -324,11 +328,17 @@ static inline int dup_mmap(struct mm_str
 
 		/*
 		 * Link in the new vma and copy the page table entries:
-		 * link in first so that swapoff can see swap entries.
+		 * link in first so that swapoff can see swap entries,
+		 * and try_to_unmap_one's find_vma find the new vma.
 		 */
 		spin_lock(&mm->page_table_lock);
 		*pprev = tmp;
 		pprev = &tmp->vm_next;
+
+		__vma_link_rb(mm, tmp, rb_link, rb_parent);
+		rb_link = &tmp->vm_rb.rb_right;
+		rb_parent = &tmp->vm_rb;
+
 		mm->map_count++;
 		retval = copy_page_range(mm, current->mm, tmp);
 		spin_unlock(&mm->page_table_lock);
@@ -340,7 +350,6 @@ static inline int dup_mmap(struct mm_str
 			goto fail;
 	}
 	retval = 0;
-	build_mmap_rb(mm);
 
 out:
 	flush_tlb_mm(current->mm);
@@ -418,7 +427,7 @@ struct mm_struct * mm_alloc(void)
  * is dropped: either by a lazy thread or by
  * mmput. Free the page directory and the mm.
  */
-void __mmdrop(struct mm_struct *mm)
+void fastcall __mmdrop(struct mm_struct *mm)
 {
 	BUG_ON(mm == &init_mm);
 	mm_free_pgd(mm);
diff -purN linux-post-2.6.4rc2-20040307/kernel/module.c linux-post-2.6.4rc2-20040309/kernel/module.c
--- linux-post-2.6.4rc2-20040307/kernel/module.c	2004-02-27 05:25:16.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/kernel/module.c	2004-02-06 06:57:11.000000000 +0000
@@ -33,7 +33,7 @@
 #include <linux/err.h>
 #include <linux/vermagic.h>
 #include <linux/notifier.h>
-#include <linux/kthread.h>
+#include <linux/stop_machine.h>
 #include <asm/uaccess.h>
 #include <asm/semaphore.h>
 #include <asm/pgalloc.h>
@@ -474,190 +474,36 @@ static inline int try_force(unsigned int
 }
 #endif /* CONFIG_MODULE_FORCE_UNLOAD */
 
-static int try_stop_module_local(struct module *mod, int flags, int *forced)
-{
-	local_irq_disable();
-
-	/* If it's not unused, quit unless we are told to block. */
-	if ((flags & O_NONBLOCK) && module_refcount(mod) != 0) {
-		if (!(*forced = try_force(flags))) {
-			local_irq_enable();
-			return -EWOULDBLOCK;
-		}
-	}
-
-	/* Mark it as dying. */
-	mod->waiter = current;
-	mod->state = MODULE_STATE_GOING;
-	local_irq_enable();
-	return 0;
-}
-
-#ifdef CONFIG_SMP
-/* Thread to stop each CPU in user context. */
-enum stopref_state {
-	STOPREF_WAIT,
-	STOPREF_PREPARE,
-	STOPREF_DISABLE_IRQ,
-	STOPREF_EXIT,
-};
-
-static enum stopref_state stopref_state;
-static unsigned int stopref_num_threads;
-static atomic_t stopref_thread_ack;
-
-static int stopref(void *cpu)
-{
-	int irqs_disabled = 0;
-	int prepared = 0;
-
-	set_cpus_allowed(current, cpumask_of_cpu((int)(long)cpu));
-
-	/* Ack: we are alive */
-	mb(); /* Theoretically the ack = 0 might not be on this CPU yet. */
-	atomic_inc(&stopref_thread_ack);
-
-	/* Simple state machine */
-	while (stopref_state != STOPREF_EXIT) {
-		if (stopref_state == STOPREF_DISABLE_IRQ && !irqs_disabled) {
-			local_irq_disable();
-			irqs_disabled = 1;
-			/* Ack: irqs disabled. */
-			mb(); /* Must read state first. */
-			atomic_inc(&stopref_thread_ack);
-		} else if (stopref_state == STOPREF_PREPARE && !prepared) {
-			/* Everyone is in place, hold CPU. */
-			preempt_disable();
-			prepared = 1;
-			mb(); /* Must read state first. */
-			atomic_inc(&stopref_thread_ack);
-		}
-		if (irqs_disabled || prepared)
-			cpu_relax();
-		else
-			yield();
-	}
-
-	/* Ack: we are exiting. */
-	mb(); /* Must read state first. */
-	atomic_inc(&stopref_thread_ack);
-
-	if (irqs_disabled)
-		local_irq_enable();
-	if (prepared)
-		preempt_enable();
-
-	return 0;
-}
-
-/* Change the thread state */
-static void stopref_set_state(enum stopref_state state, int sleep)
-{
-	atomic_set(&stopref_thread_ack, 0);
-	wmb();
-	stopref_state = state;
-	while (atomic_read(&stopref_thread_ack) != stopref_num_threads) {
-		if (sleep)
-			yield();
-		else
-			cpu_relax();
-	}
-}
-
 struct stopref
 {
 	struct module *mod;
 	int flags;
 	int *forced;
-	struct completion started;
 };
 
-static int spawn_stopref(void *data)
+/* Whole machine is stopped with interrupts off when this runs. */
+static inline int __try_stop_module(void *_sref)
 {
-	struct stopref *sref = data;
-	struct sched_param param = { .sched_priority = MAX_RT_PRIO-1 };
-	unsigned int i, cpu = smp_processor_id();
-	int ret = 0;
-
-	complete(&sref->started);
-
-	/* One high-prio thread per cpu.  We'll do one (any one). */
-	set_cpus_allowed(current, cpumask_of_cpu(cpu));
-	sys_sched_setscheduler(current->pid, SCHED_FIFO, &param);
-
-	atomic_set(&stopref_thread_ack, 0);
-	stopref_num_threads = 0;
-	stopref_state = STOPREF_WAIT;
-
-	for_each_online_cpu(i) {
-		if (i == cpu)
-			continue;
-		ret = kernel_thread(stopref, (void *)(long)i, CLONE_KERNEL);
-		if (ret < 0)
-			break;
-		stopref_num_threads++;
-	}
-
-	/* Wait for them all to come to life. */
-	while (atomic_read(&stopref_thread_ack) != stopref_num_threads)
-		yield();
+	struct stopref *sref = _sref;
 
-	/* If some failed, kill them all. */
-	if (ret < 0) {
-		stopref_set_state(STOPREF_EXIT, 1);
-		goto out;
+	/* If it's not unused, quit unless we are told to block. */
+	if ((sref->flags & O_NONBLOCK) && module_refcount(sref->mod) != 0) {
+		if (!(*sref->forced = try_force(sref->flags)))
+			return -EWOULDBLOCK;
 	}
 
-	/* Don't schedule us away at this point, please. */
-	preempt_disable();
-
-	/* Now they are all started, make them hold the CPUs, ready. */
-	stopref_set_state(STOPREF_PREPARE, 0);
-
-	/* Make them disable irqs. */
-	stopref_set_state(STOPREF_DISABLE_IRQ, 0);
-
-	/* Atomically disable module if possible */
-	ret = try_stop_module_local(sref->mod, sref->flags, sref->forced);
-
-	stopref_set_state(STOPREF_EXIT, 0);
-	preempt_enable();
-
-out:
-	/* Wait for kthread_stop */
-	while (!kthread_should_stop()) {
-		__set_current_state(TASK_INTERRUPTIBLE);
-		schedule();
-	}
-	return ret;
+	/* Mark it as dying. */
+	sref->mod->waiter = current;
+	sref->mod->state = MODULE_STATE_GOING;
+	return 0;
 }
 
 static int try_stop_module(struct module *mod, int flags, int *forced)
 {
-	struct task_struct *p;
 	struct stopref sref = { mod, flags, forced };
-	int ret;
-
-	init_completion(&sref.started);
 
-	/* No CPUs can come up or down during this. */
-	lock_cpu_hotplug();
-	p = kthread_run(spawn_stopref, &sref, "krmmod");
-	if (IS_ERR(p))
-		ret = PTR_ERR(p);
-	else {
-		wait_for_completion(&sref.started);
-		ret = kthread_stop(p);
-	}
-	unlock_cpu_hotplug();
-	return ret;
+	return stop_machine_run(__try_stop_module, &sref, NR_CPUS);
 }
-#else /* ...!SMP */
-static inline int try_stop_module(struct module *mod, int flags, int *forced)
-{
-	return try_stop_module_local(mod, flags, forced);
-}
-#endif
 
 unsigned int module_refcount(struct module *mod)
 {
diff -purN linux-post-2.6.4rc2-20040307/kernel/pid.c linux-post-2.6.4rc2-20040309/kernel/pid.c
--- linux-post-2.6.4rc2-20040307/kernel/pid.c	2003-10-09 22:13:53.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/kernel/pid.c	2004-03-07 07:04:57.000000000 +0000
@@ -57,7 +57,7 @@ static pidmap_t *map_limit = pidmap_arra
 
 static spinlock_t pidmap_lock __cacheline_aligned_in_smp = SPIN_LOCK_UNLOCKED;
 
-inline void free_pidmap(int pid)
+fastcall void free_pidmap(int pid)
 {
 	pidmap_t *map = pidmap_array + pid / BITS_PER_PAGE;
 	int offset = pid & BITS_PER_PAGE_MASK;
@@ -146,7 +146,7 @@ failure:
 	return -1;
 }
 
-inline struct pid *find_pid(enum pid_type type, int nr)
+fastcall struct pid *find_pid(enum pid_type type, int nr)
 {
 	struct list_head *elem, *bucket = &pid_hash[type][pid_hashfn(nr)];
 	struct pid *pid;
@@ -159,14 +159,14 @@ inline struct pid *find_pid(enum pid_typ
 	return NULL;
 }
 
-void link_pid(task_t *task, struct pid_link *link, struct pid *pid)
+void fastcall link_pid(task_t *task, struct pid_link *link, struct pid *pid)
 {
 	atomic_inc(&pid->count);
 	list_add_tail(&link->pid_chain, &pid->task_list);
 	link->pidptr = pid;
 }
 
-int attach_pid(task_t *task, enum pid_type type, int nr)
+int fastcall attach_pid(task_t *task, enum pid_type type, int nr)
 {
 	struct pid *pid = find_pid(type, nr);
 
@@ -209,7 +209,7 @@ static void _detach_pid(task_t *task, en
 	__detach_pid(task, type);
 }
 
-void detach_pid(task_t *task, enum pid_type type)
+void fastcall detach_pid(task_t *task, enum pid_type type)
 {
 	int nr = __detach_pid(task, type);
 
diff -purN linux-post-2.6.4rc2-20040307/kernel/printk.c linux-post-2.6.4rc2-20040309/kernel/printk.c
--- linux-post-2.6.4rc2-20040307/kernel/printk.c	2004-02-19 03:42:41.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/kernel/printk.c	2004-03-09 00:57:46.000000000 +0000
@@ -522,7 +522,7 @@ asmlinkage int printk(const char *fmt, .
 			log_level_unknown = 1;
 	}
 
-	if (!cpu_online(smp_processor_id())) {
+	if (!cpu_online(smp_processor_id()) && !system_running) {
 		/*
 		 * Some console drivers may assume that per-cpu resources have
 		 * been allocated.  So don't allow them to be called by this
diff -purN linux-post-2.6.4rc2-20040307/kernel/rcupdate.c linux-post-2.6.4rc2-20040309/kernel/rcupdate.c
--- linux-post-2.6.4rc2-20040307/kernel/rcupdate.c	2003-10-02 07:12:13.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/kernel/rcupdate.c	2004-03-07 07:04:57.000000000 +0000
@@ -66,7 +66,7 @@ static DEFINE_PER_CPU(struct tasklet_str
  * The read-side of critical section that use call_rcu() for updation must 
  * be protected by rcu_read_lock()/rcu_read_unlock().
  */
-void call_rcu(struct rcu_head *head, void (*func)(void *arg), void *arg)
+void fastcall call_rcu(struct rcu_head *head, void (*func)(void *arg), void *arg)
 {
 	int cpu;
 	unsigned long flags;
diff -purN linux-post-2.6.4rc2-20040307/kernel/sched.c linux-post-2.6.4rc2-20040309/kernel/sched.c
--- linux-post-2.6.4rc2-20040307/kernel/sched.c	2004-02-19 21:08:09.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/kernel/sched.c	2004-03-09 00:57:46.000000000 +0000
@@ -33,6 +33,7 @@
 #include <linux/suspend.h>
 #include <linux/blkdev.h>
 #include <linux/delay.h>
+#include <linux/smp.h>
 #include <linux/timer.h>
 #include <linux/rcupdate.h>
 #include <linux/cpu.h>
@@ -700,7 +701,7 @@ repeat_lock_task:
 
 	return success;
 }
-int wake_up_process(task_t * p)
+int fastcall wake_up_process(task_t * p)
 {
 	return try_to_wake_up(p, TASK_STOPPED |
 		       		 TASK_INTERRUPTIBLE | TASK_UNINTERRUPTIBLE, 0);
@@ -708,7 +709,7 @@ int wake_up_process(task_t * p)
 
 EXPORT_SYMBOL(wake_up_process);
 
-int wake_up_state(task_t *p, unsigned int state)
+int fastcall wake_up_state(task_t *p, unsigned int state)
 {
 	return try_to_wake_up(p, state, 0);
 }
@@ -717,7 +718,7 @@ int wake_up_state(task_t *p, unsigned in
  * Perform scheduler related setup for a newly forked process p.
  * p is forked by current.
  */
-void sched_fork(task_t *p)
+void fastcall sched_fork(task_t *p)
 {
 	/*
 	 * We mark the process as running here, but have not actually
@@ -773,7 +774,7 @@ void sched_fork(task_t *p)
  * This function will do some initial scheduler statistics housekeeping
  * that must be done for every newly created process.
  */
-void wake_up_forked_process(task_t * p)
+void fastcall wake_up_forked_process(task_t * p)
 {
 	unsigned long flags;
 	runqueue_t *rq = task_rq_lock(current, &flags);
@@ -817,7 +818,7 @@ void wake_up_forked_process(task_t * p)
  * artificially, because any timeslice recovered here
  * was given away by the parent in the first place.)
  */
-void sched_exit(task_t * p)
+void fastcall sched_exit(task_t * p)
 {
 	unsigned long flags;
 	runqueue_t *rq;
@@ -1796,7 +1797,7 @@ static void __wake_up_common(wait_queue_
  * @mode: which threads
  * @nr_exclusive: how many wake-one or wake-many threads to wake up
  */
-void __wake_up(wait_queue_head_t *q, unsigned int mode, int nr_exclusive)
+void fastcall __wake_up(wait_queue_head_t *q, unsigned int mode, int nr_exclusive)
 {
 	unsigned long flags;
 
@@ -1810,7 +1811,7 @@ EXPORT_SYMBOL(__wake_up);
 /*
  * Same as __wake_up but called with the spinlock in wait_queue_head_t held.
  */
-void __wake_up_locked(wait_queue_head_t *q, unsigned int mode)
+void fastcall __wake_up_locked(wait_queue_head_t *q, unsigned int mode)
 {
 	__wake_up_common(q, mode, 1, 0);
 }
@@ -1828,7 +1829,7 @@ void __wake_up_locked(wait_queue_head_t 
  *
  * On UP it can prevent extra preemption.
  */
-void __wake_up_sync(wait_queue_head_t *q, unsigned int mode, int nr_exclusive)
+void fastcall __wake_up_sync(wait_queue_head_t *q, unsigned int mode, int nr_exclusive)
 {
 	unsigned long flags;
 
@@ -1845,7 +1846,7 @@ void __wake_up_sync(wait_queue_head_t *q
 
 EXPORT_SYMBOL_GPL(__wake_up_sync);	/* For internal use only */
 
-void complete(struct completion *x)
+void fastcall complete(struct completion *x)
 {
 	unsigned long flags;
 
@@ -1858,7 +1859,7 @@ void complete(struct completion *x)
 
 EXPORT_SYMBOL(complete);
 
-void complete_all(struct completion *x)
+void fastcall complete_all(struct completion *x)
 {
 	unsigned long flags;
 
@@ -1869,7 +1870,7 @@ void complete_all(struct completion *x)
 	spin_unlock_irqrestore(&x->wait.lock, flags);
 }
 
-void wait_for_completion(struct completion *x)
+void fastcall wait_for_completion(struct completion *x)
 {
 	might_sleep();
 	spin_lock_irq(&x->wait.lock);
@@ -1907,7 +1908,7 @@ EXPORT_SYMBOL(wait_for_completion);
 	__remove_wait_queue(q, &wait);			\
 	spin_unlock_irqrestore(&q->lock, flags);
 
-void interruptible_sleep_on(wait_queue_head_t *q)
+void fastcall interruptible_sleep_on(wait_queue_head_t *q)
 {
 	SLEEP_ON_VAR
 
@@ -1920,7 +1921,7 @@ void interruptible_sleep_on(wait_queue_h
 
 EXPORT_SYMBOL(interruptible_sleep_on);
 
-long interruptible_sleep_on_timeout(wait_queue_head_t *q, long timeout)
+long fastcall interruptible_sleep_on_timeout(wait_queue_head_t *q, long timeout)
 {
 	SLEEP_ON_VAR
 
@@ -1935,7 +1936,7 @@ long interruptible_sleep_on_timeout(wait
 
 EXPORT_SYMBOL(interruptible_sleep_on_timeout);
 
-void sleep_on(wait_queue_head_t *q)
+void fastcall sleep_on(wait_queue_head_t *q)
 {
 	SLEEP_ON_VAR
 
@@ -1948,7 +1949,7 @@ void sleep_on(wait_queue_head_t *q)
 
 EXPORT_SYMBOL(sleep_on);
 
-long sleep_on_timeout(wait_queue_head_t *q, long timeout)
+long fastcall sleep_on_timeout(wait_queue_head_t *q, long timeout)
 {
 	SLEEP_ON_VAR
 
@@ -2365,7 +2366,7 @@ asmlinkage long sys_sched_getaffinity(pi
 		goto out_unlock;
 
 	retval = 0;
-	cpus_and(mask, p->cpus_allowed, cpu_online_map);
+	cpus_and(mask, p->cpus_allowed, cpu_possible_map);
 
 out_unlock:
 	read_unlock(&tasklist_lock);
diff -purN linux-post-2.6.4rc2-20040307/kernel/signal.c linux-post-2.6.4rc2-20040309/kernel/signal.c
--- linux-post-2.6.4rc2-20040307/kernel/signal.c	2004-02-26 11:26:02.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/kernel/signal.c	2004-03-07 07:04:57.000000000 +0000
@@ -213,7 +213,7 @@ static inline int has_pending_signals(si
 
 #define PENDING(p,b) has_pending_signals(&(p)->signal, (b))
 
-inline void recalc_sigpending_tsk(struct task_struct *t)
+fastcall void recalc_sigpending_tsk(struct task_struct *t)
 {
 	if (t->signal->group_stop_count > 0 ||
 	    PENDING(&t->pending, &t->blocked) ||
diff -purN linux-post-2.6.4rc2-20040307/kernel/softirq.c linux-post-2.6.4rc2-20040309/kernel/softirq.c
--- linux-post-2.6.4rc2-20040307/kernel/softirq.c	2004-02-19 03:42:32.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/kernel/softirq.c	2004-03-07 07:04:57.000000000 +0000
@@ -130,7 +130,7 @@ EXPORT_SYMBOL(local_bh_enable);
 /*
  * This function must run with irqs disabled!
  */
-inline void raise_softirq_irqoff(unsigned int nr)
+inline fastcall void raise_softirq_irqoff(unsigned int nr)
 {
 	__raise_softirq_irqoff(nr);
 
@@ -149,7 +149,7 @@ inline void raise_softirq_irqoff(unsigne
 
 EXPORT_SYMBOL(raise_softirq_irqoff);
 
-void raise_softirq(unsigned int nr)
+void fastcall raise_softirq(unsigned int nr)
 {
 	unsigned long flags;
 
@@ -179,7 +179,7 @@ struct tasklet_head
 static DEFINE_PER_CPU(struct tasklet_head, tasklet_vec) = { NULL };
 static DEFINE_PER_CPU(struct tasklet_head, tasklet_hi_vec) = { NULL };
 
-void __tasklet_schedule(struct tasklet_struct *t)
+void fastcall __tasklet_schedule(struct tasklet_struct *t)
 {
 	unsigned long flags;
 
@@ -192,7 +192,7 @@ void __tasklet_schedule(struct tasklet_s
 
 EXPORT_SYMBOL(__tasklet_schedule);
 
-void __tasklet_hi_schedule(struct tasklet_struct *t)
+void fastcall __tasklet_hi_schedule(struct tasklet_struct *t)
 {
 	unsigned long flags;
 
diff -purN linux-post-2.6.4rc2-20040307/kernel/stop_machine.c linux-post-2.6.4rc2-20040309/kernel/stop_machine.c
--- linux-post-2.6.4rc2-20040307/kernel/stop_machine.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/kernel/stop_machine.c	2004-02-07 09:50:38.000000000 +0000
@@ -0,0 +1,199 @@
+#include <linux/stop_machine.h>
+#include <linux/kthread.h>
+#include <linux/sched.h>
+#include <linux/cpu.h>
+#include <linux/err.h>
+#include <asm/atomic.h>
+#include <asm/semaphore.h>
+
+/* Since we effect priority and affinity (both of which are visible
+ * to, and settable by outside processes) we do indirection via a
+ * kthread. */
+
+/* Thread to stop each CPU in user context. */
+enum stopmachine_state {
+	STOPMACHINE_WAIT,
+	STOPMACHINE_PREPARE,
+	STOPMACHINE_DISABLE_IRQ,
+	STOPMACHINE_EXIT,
+};
+
+static enum stopmachine_state stopmachine_state;
+static unsigned int stopmachine_num_threads;
+static atomic_t stopmachine_thread_ack;
+static DECLARE_MUTEX(stopmachine_mutex);
+
+static int stopmachine(void *cpu)
+{
+	int irqs_disabled = 0;
+	int prepared = 0;
+
+	set_cpus_allowed(current, cpumask_of_cpu((int)(long)cpu));
+
+	/* Ack: we are alive */
+	mb(); /* Theoretically the ack = 0 might not be on this CPU yet. */
+	atomic_inc(&stopmachine_thread_ack);
+
+	/* Simple state machine */
+	while (stopmachine_state != STOPMACHINE_EXIT) {
+		if (stopmachine_state == STOPMACHINE_DISABLE_IRQ 
+		    && !irqs_disabled) {
+			local_irq_disable();
+			irqs_disabled = 1;
+			/* Ack: irqs disabled. */
+			mb(); /* Must read state first. */
+			atomic_inc(&stopmachine_thread_ack);
+		} else if (stopmachine_state == STOPMACHINE_PREPARE
+			   && !prepared) {
+			/* Everyone is in place, hold CPU. */
+			preempt_disable();
+			prepared = 1;
+			mb(); /* Must read state first. */
+			atomic_inc(&stopmachine_thread_ack);
+		}
+		cpu_relax();
+	}
+
+	/* Ack: we are exiting. */
+	mb(); /* Must read state first. */
+	atomic_inc(&stopmachine_thread_ack);
+
+	if (irqs_disabled)
+		local_irq_enable();
+	if (prepared)
+		preempt_enable();
+
+	return 0;
+}
+
+/* Change the thread state */
+static void stopmachine_set_state(enum stopmachine_state state)
+{
+	atomic_set(&stopmachine_thread_ack, 0);
+	wmb();
+	stopmachine_state = state;
+	while (atomic_read(&stopmachine_thread_ack) != stopmachine_num_threads)
+		cpu_relax();
+}
+
+static int stop_machine(void)
+{
+	int i, ret = 0;
+	struct sched_param param = { .sched_priority = MAX_RT_PRIO-1 };
+
+	/* One high-prio thread per cpu.  We'll do this one. */
+	sys_sched_setscheduler(current->pid, SCHED_FIFO, &param);
+
+	atomic_set(&stopmachine_thread_ack, 0);
+	stopmachine_num_threads = 0;
+	stopmachine_state = STOPMACHINE_WAIT;
+
+	for_each_online_cpu(i) {
+		if (i == smp_processor_id())
+			continue;
+		ret = kernel_thread(stopmachine, (void *)(long)i,CLONE_KERNEL);
+		if (ret < 0)
+			break;
+		stopmachine_num_threads++;
+	}
+
+	/* Wait for them all to come to life. */
+	while (atomic_read(&stopmachine_thread_ack) != stopmachine_num_threads)
+		yield();
+
+	/* If some failed, kill them all. */
+	if (ret < 0) {
+		stopmachine_set_state(STOPMACHINE_EXIT);
+		up(&stopmachine_mutex);
+		return ret;
+	}
+
+	/* Don't schedule us away at this point, please. */
+	local_irq_disable();
+
+	/* Now they are all started, make them hold the CPUs, ready. */
+	stopmachine_set_state(STOPMACHINE_PREPARE);
+
+	/* Make them disable irqs. */
+	stopmachine_set_state(STOPMACHINE_DISABLE_IRQ);
+
+	return 0;
+}
+
+static void restart_machine(void)
+{
+	stopmachine_set_state(STOPMACHINE_EXIT);
+	local_irq_enable();
+}
+
+struct stop_machine_data
+{
+	int (*fn)(void *);
+	void *data;
+	struct completion done;
+};
+
+static int do_stop(void *_smdata)
+{
+	struct stop_machine_data *smdata = _smdata;
+	int ret;
+
+	ret = stop_machine();
+	if (ret == 0) {
+		ret = smdata->fn(smdata->data);
+		restart_machine();
+	}
+
+	/* We're done: you can kthread_stop us now */
+	complete(&smdata->done);
+
+	/* Wait for kthread_stop */
+	while (!kthread_should_stop()) {
+		__set_current_state(TASK_INTERRUPTIBLE);
+		schedule();
+	}
+	return ret;
+}
+
+struct task_struct *__stop_machine_run(int (*fn)(void *), void *data,
+				       unsigned int cpu)
+{
+	struct stop_machine_data smdata;
+	struct task_struct *p;
+
+	smdata.fn = fn;
+	smdata.data = data;
+	init_completion(&smdata.done);
+
+	down(&stopmachine_mutex);
+
+	/* If they don't care which CPU fn runs on, bind to any online one. */
+	if (cpu == NR_CPUS)
+		cpu = smp_processor_id();
+
+	p = kthread_create(do_stop, &smdata, "kstopmachine");
+	if (!IS_ERR(p)) {
+		kthread_bind(p, cpu);
+		wake_up_process(p);
+		wait_for_completion(&smdata.done);
+	}
+	up(&stopmachine_mutex);
+	return p;
+}
+
+int stop_machine_run(int (*fn)(void *), void *data, unsigned int cpu)
+{
+	struct task_struct *p;
+	int ret;
+
+	/* No CPUs can come up or down during this. */
+	lock_cpu_hotplug();
+	p = __stop_machine_run(fn, data, cpu);
+	if (!IS_ERR(p))
+		ret = kthread_stop(p);
+	else
+		ret = PTR_ERR(p);
+	unlock_cpu_hotplug();
+
+	return ret;
+}
diff -purN linux-post-2.6.4rc2-20040307/kernel/timer.c linux-post-2.6.4rc2-20040309/kernel/timer.c
--- linux-post-2.6.4rc2-20040307/kernel/timer.c	2004-03-02 03:01:45.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/kernel/timer.c	2004-03-07 07:04:57.000000000 +0000
@@ -997,7 +997,7 @@ static void process_timeout(unsigned lon
  *
  * In all cases the return value is guaranteed to be non-negative.
  */
-signed long schedule_timeout(signed long timeout)
+fastcall signed long schedule_timeout(signed long timeout)
 {
 	struct timer_list timer;
 	unsigned long expire;
diff -purN linux-post-2.6.4rc2-20040307/kernel/workqueue.c linux-post-2.6.4rc2-20040309/kernel/workqueue.c
--- linux-post-2.6.4rc2-20040307/kernel/workqueue.c	2004-02-19 03:42:30.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/kernel/workqueue.c	2004-03-07 07:04:57.000000000 +0000
@@ -78,7 +78,7 @@ static void __queue_work(struct cpu_work
  * We queue the work to the CPU it was submitted, but there is no
  * guarantee that it will be processed by that CPU.
  */
-int queue_work(struct workqueue_struct *wq, struct work_struct *work)
+int fastcall queue_work(struct workqueue_struct *wq, struct work_struct *work)
 {
 	int ret = 0, cpu = get_cpu();
 
@@ -99,7 +99,7 @@ static void delayed_work_timer_fn(unsign
 	__queue_work(wq->cpu_wq + smp_processor_id(), work);
 }
 
-int queue_delayed_work(struct workqueue_struct *wq,
+int fastcall queue_delayed_work(struct workqueue_struct *wq,
 			struct work_struct *work, unsigned long delay)
 {
 	int ret = 0;
@@ -203,7 +203,7 @@ static int worker_thread(void *__cwq)
  * This function used to run the workqueues itself.  Now we just wait for the
  * helper threads to do it.
  */
-void flush_workqueue(struct workqueue_struct *wq)
+void fastcall flush_workqueue(struct workqueue_struct *wq)
 {
 	struct cpu_workqueue_struct *cwq;
 	int cpu;
@@ -310,12 +310,12 @@ void destroy_workqueue(struct workqueue_
 
 static struct workqueue_struct *keventd_wq;
 
-int schedule_work(struct work_struct *work)
+int fastcall schedule_work(struct work_struct *work)
 {
 	return queue_work(keventd_wq, work);
 }
 
-int schedule_delayed_work(struct work_struct *work, unsigned long delay)
+int fastcall schedule_delayed_work(struct work_struct *work, unsigned long delay)
 {
 	return queue_delayed_work(keventd_wq, work, delay);
 }
diff -purN linux-post-2.6.4rc2-20040307/lib/rwsem-spinlock.c linux-post-2.6.4rc2-20040309/lib/rwsem-spinlock.c
--- linux-post-2.6.4rc2-20040307/lib/rwsem-spinlock.c	2002-08-12 17:03:31.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/lib/rwsem-spinlock.c	2004-03-07 07:04:57.000000000 +0000
@@ -29,7 +29,7 @@ void rwsemtrace(struct rw_semaphore *sem
 /*
  * initialise the semaphore
  */
-void init_rwsem(struct rw_semaphore *sem)
+void fastcall init_rwsem(struct rw_semaphore *sem)
 {
 	sem->activity = 0;
 	spin_lock_init(&sem->wait_lock);
@@ -117,7 +117,7 @@ static inline struct rw_semaphore *__rws
 /*
  * get a read lock on the semaphore
  */
-void __down_read(struct rw_semaphore *sem)
+void fastcall __down_read(struct rw_semaphore *sem)
 {
 	struct rwsem_waiter waiter;
 	struct task_struct *tsk;
@@ -162,7 +162,7 @@ void __down_read(struct rw_semaphore *se
 /*
  * trylock for reading -- returns 1 if successful, 0 if contention
  */
-int __down_read_trylock(struct rw_semaphore *sem)
+int fastcall __down_read_trylock(struct rw_semaphore *sem)
 {
 	int ret = 0;
 	rwsemtrace(sem,"Entering __down_read_trylock");
@@ -185,7 +185,7 @@ int __down_read_trylock(struct rw_semaph
  * get a write lock on the semaphore
  * - note that we increment the waiting count anyway to indicate an exclusive lock
  */
-void __down_write(struct rw_semaphore *sem)
+void fastcall __down_write(struct rw_semaphore *sem)
 {
 	struct rwsem_waiter waiter;
 	struct task_struct *tsk;
@@ -230,7 +230,7 @@ void __down_write(struct rw_semaphore *s
 /*
  * trylock for writing -- returns 1 if successful, 0 if contention
  */
-int __down_write_trylock(struct rw_semaphore *sem)
+int fastcall __down_write_trylock(struct rw_semaphore *sem)
 {
 	int ret = 0;
 	rwsemtrace(sem,"Entering __down_write_trylock");
@@ -252,7 +252,7 @@ int __down_write_trylock(struct rw_semap
 /*
  * release a read lock on the semaphore
  */
-void __up_read(struct rw_semaphore *sem)
+void fastcall __up_read(struct rw_semaphore *sem)
 {
 	rwsemtrace(sem,"Entering __up_read");
 
@@ -269,7 +269,7 @@ void __up_read(struct rw_semaphore *sem)
 /*
  * release a write lock on the semaphore
  */
-void __up_write(struct rw_semaphore *sem)
+void fastcall __up_write(struct rw_semaphore *sem)
 {
 	rwsemtrace(sem,"Entering __up_write");
 
@@ -288,7 +288,7 @@ void __up_write(struct rw_semaphore *sem
  * downgrade a write lock into a read lock
  * - just wake up any readers at the front of the queue
  */
-void __downgrade_write(struct rw_semaphore *sem)
+void fastcall __downgrade_write(struct rw_semaphore *sem)
 {
 	rwsemtrace(sem,"Entering __downgrade_write");
 
diff -purN linux-post-2.6.4rc2-20040307/lib/rwsem.c linux-post-2.6.4rc2-20040309/lib/rwsem.c
--- linux-post-2.6.4rc2-20040307/lib/rwsem.c	2002-07-29 08:35:47.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/lib/rwsem.c	2004-03-07 07:04:57.000000000 +0000
@@ -162,7 +162,7 @@ static inline struct rw_semaphore *rwsem
 /*
  * wait for the read lock to be granted
  */
-struct rw_semaphore *rwsem_down_read_failed(struct rw_semaphore *sem)
+struct rw_semaphore fastcall *rwsem_down_read_failed(struct rw_semaphore *sem)
 {
 	struct rwsem_waiter waiter;
 
@@ -178,7 +178,7 @@ struct rw_semaphore *rwsem_down_read_fai
 /*
  * wait for the write lock to be granted
  */
-struct rw_semaphore *rwsem_down_write_failed(struct rw_semaphore *sem)
+struct rw_semaphore fastcall *rwsem_down_write_failed(struct rw_semaphore *sem)
 {
 	struct rwsem_waiter waiter;
 
@@ -195,7 +195,7 @@ struct rw_semaphore *rwsem_down_write_fa
  * handle waking up a waiter on the semaphore
  * - up_read has decremented the active part of the count if we come here
  */
-struct rw_semaphore *rwsem_wake(struct rw_semaphore *sem)
+struct rw_semaphore fastcall *rwsem_wake(struct rw_semaphore *sem)
 {
 	rwsemtrace(sem,"Entering rwsem_wake");
 
@@ -217,7 +217,7 @@ struct rw_semaphore *rwsem_wake(struct r
  * - caller incremented waiting part of count, and discovered it to be still negative
  * - just wake up any readers at the front of the queue
  */
-struct rw_semaphore *rwsem_downgrade_wake(struct rw_semaphore *sem)
+struct rw_semaphore fastcall *rwsem_downgrade_wake(struct rw_semaphore *sem)
 {
 	rwsemtrace(sem,"Entering rwsem_downgrade_wake");
 
diff -purN linux-post-2.6.4rc2-20040307/mm/filemap.c linux-post-2.6.4rc2-20040309/mm/filemap.c
--- linux-post-2.6.4rc2-20040307/mm/filemap.c	2004-02-08 07:33:56.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/mm/filemap.c	2004-03-08 14:21:17.000000000 +0000
@@ -161,13 +161,15 @@ EXPORT_SYMBOL(filemap_fdatawrite);
 
 /*
  * This is a mostly non-blocking flush.  Not suitable for data-integrity
- * purposes.
+ * purposes - I/O may not be started against all dirty pages.
  */
 int filemap_flush(struct address_space *mapping)
 {
 	return __filemap_fdatawrite(mapping, WB_SYNC_NONE);
 }
 
+EXPORT_SYMBOL(filemap_flush);
+
 /**
  * filemap_fdatawait - walk the list of locked pages of the given address
  *                     space and wait for all of them.
@@ -292,7 +294,7 @@ static wait_queue_head_t *page_waitqueue
 	return &zone->wait_table[hash_ptr(page, zone->wait_table_bits)];
 }
 
-void wait_on_page_bit(struct page *page, int bit_nr)
+void fastcall wait_on_page_bit(struct page *page, int bit_nr)
 {
 	wait_queue_head_t *waitqueue = page_waitqueue(page);
 	DEFINE_WAIT(wait);
@@ -324,7 +326,7 @@ EXPORT_SYMBOL(wait_on_page_bit);
  * the clear_bit and the read of the waitqueue (to avoid SMP races with a
  * parallel wait_on_page_locked()).
  */
-void unlock_page(struct page *page)
+void fastcall unlock_page(struct page *page)
 {
 	wait_queue_head_t *waitqueue = page_waitqueue(page);
 	smp_mb__before_clear_bit();
@@ -365,7 +367,7 @@ EXPORT_SYMBOL(end_page_writeback);
  * chances are that on the second loop, the block layer's plug list is empty,
  * so sync_page() will then return in state TASK_UNINTERRUPTIBLE.
  */
-void __lock_page(struct page *page)
+void fastcall __lock_page(struct page *page)
 {
 	wait_queue_head_t *wqh = page_waitqueue(page);
 	DEFINE_WAIT(wait);
@@ -953,7 +955,7 @@ asmlinkage ssize_t sys_readahead(int fd,
  * and schedules an I/O to read in its contents from disk.
  */
 static int FASTCALL(page_cache_read(struct file * file, unsigned long offset));
-static int page_cache_read(struct file * file, unsigned long offset)
+static int fastcall page_cache_read(struct file * file, unsigned long offset)
 {
 	struct address_space *mapping = file->f_mapping;
 	struct page *page; 
diff -purN linux-post-2.6.4rc2-20040307/mm/highmem.c linux-post-2.6.4rc2-20040309/mm/highmem.c
--- linux-post-2.6.4rc2-20040307/mm/highmem.c	2004-03-02 03:01:25.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/mm/highmem.c	2004-03-07 07:04:57.000000000 +0000
@@ -147,7 +147,7 @@ start:
 	return vaddr;
 }
 
-void *kmap_high(struct page *page)
+void fastcall *kmap_high(struct page *page)
 {
 	unsigned long vaddr;
 
@@ -170,7 +170,7 @@ void *kmap_high(struct page *page)
 
 EXPORT_SYMBOL(kmap_high);
 
-void kunmap_high(struct page *page)
+void fastcall kunmap_high(struct page *page)
 {
 	unsigned long vaddr;
 	unsigned long nr;
diff -purN linux-post-2.6.4rc2-20040307/mm/memory.c linux-post-2.6.4rc2-20040309/mm/memory.c
--- linux-post-2.6.4rc2-20040307/mm/memory.c	2004-02-19 06:54:01.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/mm/memory.c	2004-03-07 07:04:57.000000000 +0000
@@ -145,7 +145,7 @@ void clear_page_tables(struct mmu_gather
 	} while (--nr);
 }
 
-pte_t * pte_alloc_map(struct mm_struct *mm, pmd_t *pmd, unsigned long address)
+pte_t fastcall * pte_alloc_map(struct mm_struct *mm, pmd_t *pmd, unsigned long address)
 {
 	if (!pmd_present(*pmd)) {
 		struct page *new;
@@ -171,7 +171,7 @@ out:
 	return pte_offset_map(pmd, address);
 }
 
-pte_t * pte_alloc_kernel(struct mm_struct *mm, pmd_t *pmd, unsigned long address)
+pte_t fastcall * pte_alloc_kernel(struct mm_struct *mm, pmd_t *pmd, unsigned long address)
 {
 	if (!pmd_present(*pmd)) {
 		pte_t *new;
@@ -1646,7 +1646,7 @@ int handle_mm_fault(struct mm_struct *mm
  * On a two-level page table, this ends up actually being entirely
  * optimized away.
  */
-pmd_t *__pmd_alloc(struct mm_struct *mm, pgd_t *pgd, unsigned long address)
+pmd_t fastcall *__pmd_alloc(struct mm_struct *mm, pgd_t *pgd, unsigned long address)
 {
 	pmd_t *new;
 
diff -purN linux-post-2.6.4rc2-20040307/mm/mmap.c linux-post-2.6.4rc2-20040309/mm/mmap.c
--- linux-post-2.6.4rc2-20040307/mm/mmap.c	2004-02-25 10:34:43.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/mm/mmap.c	2004-03-08 14:21:20.000000000 +0000
@@ -222,8 +222,8 @@ __vma_link_list(struct mm_struct *mm, st
 	}
 }
 
-static void __vma_link_rb(struct mm_struct *mm, struct vm_area_struct *vma,
-			struct rb_node **rb_link, struct rb_node *rb_parent)
+void __vma_link_rb(struct mm_struct *mm, struct vm_area_struct *vma,
+		struct rb_node **rb_link, struct rb_node *rb_parent)
 {
 	rb_link_node(&vma->vm_rb, rb_parent, rb_link);
 	rb_insert_color(&vma->vm_rb, &mm->mm_rb);
@@ -1404,22 +1404,6 @@ out:
 
 EXPORT_SYMBOL(do_brk);
 
-/* Build the RB tree corresponding to the VMA list. */
-void build_mmap_rb(struct mm_struct * mm)
-{
-	struct vm_area_struct * vma;
-	struct rb_node ** rb_link, * rb_parent;
-
-	mm->mm_rb = RB_ROOT;
-	rb_link = &mm->mm_rb.rb_node;
-	rb_parent = NULL;
-	for (vma = mm->mmap; vma; vma = vma->vm_next) {
-		__vma_link_rb(mm, vma, rb_link, rb_parent);
-		rb_parent = &vma->vm_rb;
-		rb_link = &rb_parent->rb_right;
-	}
-}
-
 /* Release all mmaps. */
 void exit_mmap(struct mm_struct *mm)
 {
diff -purN linux-post-2.6.4rc2-20040307/mm/page_alloc.c linux-post-2.6.4rc2-20040309/mm/page_alloc.c
--- linux-post-2.6.4rc2-20040307/mm/page_alloc.c	2004-02-19 03:43:04.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/mm/page_alloc.c	2004-02-17 06:22:10.000000000 +0000
@@ -390,6 +390,27 @@ static int rmqueue_bulk(struct zone *zon
 	return allocated;
 }
 
+#if defined(CONFIG_PM) || defined(CONFIG_HOTPLUG_CPU)
+static void __drain_pages(unsigned int cpu)
+{
+	struct zone *zone;
+	int i;
+
+	for_each_zone(zone) {
+		struct per_cpu_pageset *pset;
+
+		pset = &zone->pageset[cpu];
+		for (i = 0; i < ARRAY_SIZE(pset->pcp); i++) {
+			struct per_cpu_pages *pcp;
+
+			pcp = &pset->pcp[i];
+			pcp->count -= free_pages_bulk(zone, pcp->count,
+						&pcp->list, 0);
+		}
+	}
+}
+#endif /* CONFIG_PM || CONFIG_HOTPLUG_CPU */
+
 #ifdef CONFIG_PM
 int is_head_of_free_region(struct page *page)
 {
@@ -419,22 +440,9 @@ int is_head_of_free_region(struct page *
 void drain_local_pages(void)
 {
 	unsigned long flags;
-	struct zone *zone;
-	int i;
 
 	local_irq_save(flags);	
-	for_each_zone(zone) {
-		struct per_cpu_pageset *pset;
-
-		pset = &zone->pageset[smp_processor_id()];
-		for (i = 0; i < ARRAY_SIZE(pset->pcp); i++) {
-			struct per_cpu_pages *pcp;
-
-			pcp = &pset->pcp[i];
-			pcp->count -= free_pages_bulk(zone, pcp->count,
-						&pcp->list, 0);
-		}
-	}
+	__drain_pages(smp_processor_id());
 	local_irq_restore(flags);	
 }
 #endif /* CONFIG_PM */
@@ -443,7 +451,7 @@ void drain_local_pages(void)
  * Free a 0-order page
  */
 static void FASTCALL(free_hot_cold_page(struct page *page, int cold));
-static void free_hot_cold_page(struct page *page, int cold)
+static void fastcall free_hot_cold_page(struct page *page, int cold)
 {
 	struct zone *zone = page_zone(page);
 	struct per_cpu_pages *pcp;
@@ -462,12 +470,12 @@ static void free_hot_cold_page(struct pa
 	put_cpu();
 }
 
-void free_hot_page(struct page *page)
+void fastcall free_hot_page(struct page *page)
 {
 	free_hot_cold_page(page, 0);
 }
 	
-void free_cold_page(struct page *page)
+void fastcall free_cold_page(struct page *page)
 {
 	free_hot_cold_page(page, 1);
 }
@@ -532,7 +540,7 @@ static struct page *buffered_rmqueue(str
  * sized machine, GFP_HIGHMEM and GFP_KERNEL requests basically leave the DMA
  * zone untouched.
  */
-struct page *
+struct page * fastcall
 __alloc_pages(unsigned int gfp_mask, unsigned int order,
 		struct zonelist *zonelist)
 {
@@ -685,7 +693,7 @@ EXPORT_SYMBOL(__alloc_pages);
 /*
  * Common helper functions.
  */
-unsigned long __get_free_pages(unsigned int gfp_mask, unsigned int order)
+fastcall unsigned long __get_free_pages(unsigned int gfp_mask, unsigned int order)
 {
 	struct page * page;
 
@@ -697,7 +705,7 @@ unsigned long __get_free_pages(unsigned 
 
 EXPORT_SYMBOL(__get_free_pages);
 
-unsigned long get_zeroed_page(unsigned int gfp_mask)
+fastcall unsigned long get_zeroed_page(unsigned int gfp_mask)
 {
 	struct page * page;
 
@@ -726,7 +734,7 @@ void __pagevec_free(struct pagevec *pvec
 		free_hot_cold_page(pvec->pages[i], pvec->cold);
 }
 
-void __free_pages(struct page *page, unsigned int order)
+fastcall void __free_pages(struct page *page, unsigned int order)
 {
 	if (!PageReserved(page) && put_page_testzero(page)) {
 		if (order == 0)
@@ -738,7 +746,7 @@ void __free_pages(struct page *page, uns
 
 EXPORT_SYMBOL(__free_pages);
 
-void free_pages(unsigned long addr, unsigned int order)
+fastcall void free_pages(unsigned long addr, unsigned int order)
 {
 	if (addr != 0) {
 		BUG_ON(!virt_addr_valid(addr));
diff -purN linux-post-2.6.4rc2-20040307/mm/rmap.c linux-post-2.6.4rc2-20040309/mm/rmap.c
--- linux-post-2.6.4rc2-20040307/mm/rmap.c	2004-02-19 06:54:03.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/mm/rmap.c	2004-03-07 07:04:57.000000000 +0000
@@ -112,7 +112,7 @@ pte_chain_encode(struct pte_chain *pte_c
  * If the page has a single-entry pte_chain, collapse that back to a PageDirect
  * representation.  This way, it's only done under memory pressure.
  */
-int page_referenced(struct page * page)
+int fastcall page_referenced(struct page * page)
 {
 	struct pte_chain *pc;
 	int referenced = 0;
@@ -165,7 +165,7 @@ int page_referenced(struct page * page)
  * Add a new pte reverse mapping to a page.
  * The caller needs to hold the mm->page_table_lock.
  */
-struct pte_chain *
+struct pte_chain * fastcall
 page_add_rmap(struct page *page, pte_t *ptep, struct pte_chain *pte_chain)
 {
 	pte_addr_t pte_paddr = ptep_to_paddr(ptep);
@@ -221,7 +221,7 @@ out:
  * the page.
  * Caller needs to hold the mm->page_table_lock.
  */
-void page_remove_rmap(struct page *page, pte_t *ptep)
+void fastcall page_remove_rmap(struct page *page, pte_t *ptep)
 {
 	pte_addr_t pte_paddr = ptep_to_paddr(ptep);
 	struct pte_chain *pc;
@@ -293,7 +293,7 @@ out_unlock:
  *		    mm->page_table_lock	try_to_unmap_one(), trylock
  */
 static int FASTCALL(try_to_unmap_one(struct page *, pte_addr_t));
-static int try_to_unmap_one(struct page * page, pte_addr_t paddr)
+static int fastcall try_to_unmap_one(struct page * page, pte_addr_t paddr)
 {
 	pte_t *ptep = rmap_ptep_map(paddr);
 	unsigned long address = ptep_to_address(ptep);
@@ -382,7 +382,7 @@ out_unlock:
  * SWAP_AGAIN	- we missed a trylock, try again later
  * SWAP_FAIL	- the page is unswappable
  */
-int try_to_unmap(struct page * page)
+int fastcall try_to_unmap(struct page * page)
 {
 	struct pte_chain *pc, *next_pc, *start;
 	int ret = SWAP_SUCCESS;
diff -purN linux-post-2.6.4rc2-20040307/mm/slab.c linux-post-2.6.4rc2-20040309/mm/slab.c
--- linux-post-2.6.4rc2-20040307/mm/slab.c	2004-02-19 06:54:02.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/mm/slab.c	2004-03-09 06:27:21.000000000 +0000
@@ -521,9 +521,19 @@ enum {
 static DEFINE_PER_CPU(struct timer_list, reap_timers);
 
 static void reap_timer_fnc(unsigned long data);
-
+static void free_block(kmem_cache_t* cachep, void** objpp, int len);
 static void enable_cpucache (kmem_cache_t *cachep);
 
+static inline void ** ac_entry(struct array_cache *ac)
+{
+	return (void**)(ac+1);
+}
+
+static inline struct array_cache *ac_data(kmem_cache_t *cachep)
+{
+	return cachep->array[smp_processor_id()];
+}
+
 /* Cal the num objs, wastage, and bytes left over for a given slab size. */
 static void cache_estimate (unsigned long gfporder, size_t size,
 		 int flags, size_t *left_over, unsigned int *num)
@@ -573,6 +583,7 @@ static void start_cpu_timer(int cpu)
 	if (rt->function == NULL) {
 		init_timer(rt);
 		rt->expires = jiffies + HZ + 3*cpu;
+		rt->data = cpu;
 		rt->function = reap_timer_fnc;
 		add_timer_on(rt, cpu);
 	}
@@ -589,16 +600,15 @@ static int __devinit cpuup_callback(stru
 				  void *hcpu)
 {
 	long cpu = (long)hcpu;
-	struct list_head *p;
+	kmem_cache_t* cachep;
 
 	switch (action) {
 	case CPU_UP_PREPARE:
 		down(&cache_chain_sem);
-		list_for_each(p, &cache_chain) {
+		list_for_each_entry(cachep, &cache_chain, next) {
 			int memsize;
 			struct array_cache *nc;
 
-			kmem_cache_t* cachep = list_entry(p, kmem_cache_t, next);
 			memsize = sizeof(void*)*cachep->limit+sizeof(struct array_cache);
 			nc = kmalloc(memsize, GFP_KERNEL);
 			if (!nc)
@@ -618,15 +628,13 @@ static int __devinit cpuup_callback(stru
 		up(&cache_chain_sem);
 		break;
 	case CPU_ONLINE:
-		if (g_cpucache_up == FULL)
-			start_cpu_timer(cpu);
+		start_cpu_timer(cpu);
 		break;
 	case CPU_UP_CANCELED:
 		down(&cache_chain_sem);
 
-		list_for_each(p, &cache_chain) {
+		list_for_each_entry(cachep, &cache_chain, next) {
 			struct array_cache *nc;
-			kmem_cache_t* cachep = list_entry(p, kmem_cache_t, next);
 
 			nc = cachep->array[cpu];
 			cachep->array[cpu] = NULL;
@@ -643,16 +651,6 @@ bad:
 
 static struct notifier_block cpucache_notifier = { &cpuup_callback, NULL, 0 };
 
-static inline void ** ac_entry(struct array_cache *ac)
-{
-	return (void**)(ac+1);
-}
-
-static inline struct array_cache *ac_data(kmem_cache_t *cachep)
-{
-	return cachep->array[smp_processor_id()];
-}
-
 /* Initialisation.
  * Called after the gfp() functions have been enabled, and before smp_init().
  */
@@ -1368,7 +1366,6 @@ static void smp_call_function_all_cpus(v
 	preempt_enable();
 }
 
-static void free_block (kmem_cache_t* cachep, void** objpp, int len);
 static void drain_array_locked(kmem_cache_t* cachep,
 				struct array_cache *ac, int force);
 
@@ -2134,7 +2131,7 @@ EXPORT_SYMBOL(kmem_cache_alloc);
  *
  * Currently only used for dentry validation.
  */
-int kmem_ptr_validate(kmem_cache_t *cachep, void *ptr)
+int fastcall kmem_ptr_validate(kmem_cache_t *cachep, void *ptr)
 {
 	unsigned long addr = (unsigned long) ptr;
 	unsigned long min_addr = PAGE_OFFSET;
@@ -2601,17 +2598,19 @@ next:
 }
 
 /*
- * This is a timer handler.  There is on per CPU.  It is called periodially
+ * This is a timer handler.  There is one per CPU.  It is called periodially
  * to shrink this CPU's caches.  Otherwise there could be memory tied up
  * for long periods (or for ever) due to load changes.
  */
-static void reap_timer_fnc(unsigned long data)
+static void reap_timer_fnc(unsigned long cpu)
 {
-	int cpu = smp_processor_id();
 	struct timer_list *rt = &__get_cpu_var(reap_timers);
 
-	cache_reap();
-	mod_timer(rt, jiffies + REAPTIMEOUT_CPUC + cpu);
+	/* CPU hotplug can drag us off cpu: don't run on wrong CPU */
+	if (!cpu_is_offline(cpu)) {
+		cache_reap();
+		mod_timer(rt, jiffies + REAPTIMEOUT_CPUC + cpu);
+	}
 }
 
 #ifdef CONFIG_PROC_FS
diff -purN linux-post-2.6.4rc2-20040307/mm/swap.c linux-post-2.6.4rc2-20040309/mm/swap.c
--- linux-post-2.6.4rc2-20040307/mm/swap.c	2003-12-29 21:37:36.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/mm/swap.c	2004-03-07 07:04:57.000000000 +0000
@@ -76,7 +76,7 @@ int rotate_reclaimable_page(struct page 
 /*
  * FIXME: speed this up?
  */
-void activate_page(struct page *page)
+void fastcall activate_page(struct page *page)
 {
 	struct zone *zone = page_zone(page);
 
@@ -97,7 +97,7 @@ void activate_page(struct page *page)
  * inactive,referenced		->	active,unreferenced
  * active,unreferenced		->	active,referenced
  */
-void mark_page_accessed(struct page *page)
+void fastcall mark_page_accessed(struct page *page)
 {
 	if (!PageActive(page) && PageReferenced(page) && PageLRU(page)) {
 		activate_page(page);
@@ -116,7 +116,7 @@ EXPORT_SYMBOL(mark_page_accessed);
 static DEFINE_PER_CPU(struct pagevec, lru_add_pvecs) = { 0, };
 static DEFINE_PER_CPU(struct pagevec, lru_add_active_pvecs) = { 0, };
 
-void lru_cache_add(struct page *page)
+void fastcall lru_cache_add(struct page *page)
 {
 	struct pagevec *pvec = &get_cpu_var(lru_add_pvecs);
 
@@ -126,7 +126,7 @@ void lru_cache_add(struct page *page)
 	put_cpu_var(lru_add_pvecs);
 }
 
-void lru_cache_add_active(struct page *page)
+void fastcall lru_cache_add_active(struct page *page)
 {
 	struct pagevec *pvec = &get_cpu_var(lru_add_active_pvecs);
 
@@ -152,7 +152,7 @@ void lru_add_drain(void)
  * This path almost never happens for VM activity - pages are normally
  * freed via pagevecs.  But it gets used by networking.
  */
-void __page_cache_release(struct page *page)
+void fastcall __page_cache_release(struct page *page)
 {
 	unsigned long flags;
 	struct zone *zone = page_zone(page);
diff -purN linux-post-2.6.4rc2-20040307/net/bluetooth/rfcomm/core.c linux-post-2.6.4rc2-20040309/net/bluetooth/rfcomm/core.c
--- linux-post-2.6.4rc2-20040307/net/bluetooth/rfcomm/core.c	2004-03-05 22:06:33.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/net/bluetooth/rfcomm/core.c	2004-03-07 07:04:57.000000000 +0000
@@ -409,7 +409,7 @@ int rfcomm_dlc_send(struct rfcomm_dlc *d
 	return len;
 }
 
-void __rfcomm_dlc_throttle(struct rfcomm_dlc *d)
+void fastcall __rfcomm_dlc_throttle(struct rfcomm_dlc *d)
 {
 	BT_DBG("dlc %p state %ld", d, d->state);
 
@@ -420,7 +420,7 @@ void __rfcomm_dlc_throttle(struct rfcomm
 	rfcomm_schedule(RFCOMM_SCHED_TX);
 }
 
-void __rfcomm_dlc_unthrottle(struct rfcomm_dlc *d)
+void fastcall __rfcomm_dlc_unthrottle(struct rfcomm_dlc *d)
 {
 	BT_DBG("dlc %p state %ld", d, d->state);
 
diff -purN linux-post-2.6.4rc2-20040307/net/core/netfilter.c linux-post-2.6.4rc2-20040309/net/core/netfilter.c
--- linux-post-2.6.4rc2-20040307/net/core/netfilter.c	2004-02-26 11:26:02.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/net/core/netfilter.c	2004-03-08 19:55:24.000000000 +0000
@@ -636,6 +636,7 @@ int ip_route_me_harder(struct sk_buff **
 #ifdef CONFIG_IP_ROUTE_FWMARK
 		fl.nl_u.ip4_u.fwmark = (*pskb)->nfmark;
 #endif
+		fl.proto = iph->protocol;
 		if (ip_route_output_key(&rt, &fl) != 0)
 			return -1;
 
diff -purN linux-post-2.6.4rc2-20040307/net/ipv4/ip_sockglue.c linux-post-2.6.4rc2-20040309/net/ipv4/ip_sockglue.c
--- linux-post-2.6.4rc2-20040307/net/ipv4/ip_sockglue.c	2004-03-05 22:17:31.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/net/ipv4/ip_sockglue.c	2004-03-08 20:15:03.000000000 +0000
@@ -771,6 +771,8 @@ int ip_setsockopt(struct sock *sk, int l
 		}
 		case MCAST_MSFILTER:
 		{
+			extern int sysctl_optmem_max;
+			extern int sysctl_igmp_max_msf;
 			struct sockaddr_in *psin;
 			struct ip_msfilter *msf = 0;
 			struct group_filter *gsf = 0;
@@ -778,6 +780,10 @@ int ip_setsockopt(struct sock *sk, int l
 
 			if (optlen < GROUP_FILTER_SIZE(0))
 				goto e_inval;
+			if (optlen > sysctl_optmem_max) {
+				err = -ENOBUFS;
+				break;
+			}
 			gsf = (struct group_filter *)kmalloc(optlen,GFP_KERNEL);
 			if (gsf == 0) {
 				err = -ENOBUFS;
@@ -787,7 +793,13 @@ int ip_setsockopt(struct sock *sk, int l
 			if (copy_from_user(gsf, optval, optlen)) {
 				goto mc_msf_out;
 			}
-			if (GROUP_FILTER_SIZE(gsf->gf_numsrc) < optlen) {
+			/* numsrc >= (4G-140)/128 overflow in 32 bits */
+			if (gsf->gf_numsrc >= 0x1ffffff ||
+			    gsf->gf_numsrc > sysctl_igmp_max_msf) {
+				err = -ENOBUFS;
+				goto mc_msf_out;
+			}
+			if (GROUP_FILTER_SIZE(gsf->gf_numsrc) > optlen) {
 				err = EINVAL;
 				goto mc_msf_out;
 			}
diff -purN linux-post-2.6.4rc2-20040307/net/ipv4/ipvs/ip_vs_ctl.c linux-post-2.6.4rc2-20040309/net/ipv4/ipvs/ip_vs_ctl.c
--- linux-post-2.6.4rc2-20040307/net/ipv4/ipvs/ip_vs_ctl.c	2004-02-18 21:03:52.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/net/ipv4/ipvs/ip_vs_ctl.c	2004-03-08 20:01:22.000000000 +0000
@@ -1836,9 +1836,9 @@ do_ip_vs_set_ctl(struct sock *sk, int cm
 
 	/* Check for valid protocol: TCP or UDP, even for fwmark!=0 */
 	if (usvc->protocol!=IPPROTO_TCP && usvc->protocol!=IPPROTO_UDP) {
-		IP_VS_INFO("vs_ctl: invalid protocol: %d %d.%d.%d.%d:%d %s",
-			   ntohs(usvc->protocol), NIPQUAD(usvc->addr),
-			   ntohs(usvc->port), usvc->sched_name);
+		IP_VS_ERR("set_ctl: invalid protocol: %d %d.%d.%d.%d:%d %s\n",
+			  usvc->protocol, NIPQUAD(usvc->addr),
+			  ntohs(usvc->port), usvc->sched_name);
 		ret = -EFAULT;
 		goto out_unlock;
 	}
diff -purN linux-post-2.6.4rc2-20040307/net/ipv6/ipv6_sockglue.c linux-post-2.6.4rc2-20040309/net/ipv6/ipv6_sockglue.c
--- linux-post-2.6.4rc2-20040307/net/ipv6/ipv6_sockglue.c	2004-02-25 08:24:26.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/net/ipv6/ipv6_sockglue.c	2004-03-08 20:15:03.000000000 +0000
@@ -437,6 +437,7 @@ done:
 	case MCAST_MSFILTER:
 	{
 		extern int sysctl_optmem_max;
+		extern int sysctl_mld_max_msf;
 		struct group_filter *gsf;
 
 		if (optlen < GROUP_FILTER_SIZE(0))
@@ -455,8 +456,14 @@ done:
 			kfree(gsf);
 			break;
 		}
-		if (GROUP_FILTER_SIZE(gsf->gf_numsrc) < GROUP_FILTER_SIZE(0) ||
-		    GROUP_FILTER_SIZE(gsf->gf_numsrc) > optlen) {
+		/* numsrc >= (4G-140)/128 overflow in 32 bits */
+		if (gsf->gf_numsrc >= 0x1ffffffU ||
+		    gsf->gf_numsrc > sysctl_mld_max_msf) {
+			kfree(gsf);
+			retv = -ENOBUFS;
+			break;
+		}
+		if (GROUP_FILTER_SIZE(gsf->gf_numsrc) > optlen) {
 			kfree(gsf);
 			retv = -EINVAL;
 			break;
diff -purN linux-post-2.6.4rc2-20040307/net/ipv6/mcast.c linux-post-2.6.4rc2-20040309/net/ipv6/mcast.c
--- linux-post-2.6.4rc2-20040307/net/ipv6/mcast.c	2004-02-17 06:49:11.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/net/ipv6/mcast.c	2004-03-08 20:15:03.000000000 +0000
@@ -166,6 +166,10 @@ int ip6_mc_leave_src(struct sock *sk, st
 #define MLDV2_QQIC(value) MLDV2_EXP(0x80, 4, 3, value)
 #define MLDV2_MRC(value) MLDV2_EXP(0x8000, 12, 3, value)
 
+#define IPV6_MLD_MAX_MSF	10
+
+int sysctl_mld_max_msf = IPV6_MLD_MAX_MSF;
+
 /*
  *	socket join on multicast group
  */
@@ -404,6 +408,10 @@ int ip6_mc_source(int add, int omode, st
 	}
 	/* else, add a new source to the filter */
 
+	if (psl && psl->sl_count >= sysctl_mld_max_msf) {
+		err = -ENOBUFS;
+		goto done;
+	}
 	if (!psl || psl->sl_count == psl->sl_max) {
 		struct ip6_sf_socklist *newpsl;
 		int count = IP6_SFBLOCK;
diff -purN linux-post-2.6.4rc2-20040307/net/ipv6/sysctl_net_ipv6.c linux-post-2.6.4rc2-20040309/net/ipv6/sysctl_net_ipv6.c
--- linux-post-2.6.4rc2-20040307/net/ipv6/sysctl_net_ipv6.c	2004-02-21 21:16:31.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/net/ipv6/sysctl_net_ipv6.c	2004-03-08 20:15:03.000000000 +0000
@@ -76,6 +76,14 @@ ctl_table ipv6_table[] = {
 		.proc_handler	= &proc_dointvec_jiffies,
 		.strategy	= &sysctl_jiffies
 	},
+	{
+		.ctl_name	= NET_IPV6_MLD_MAX_MSF,
+		.procname	= "mld_max_msf",
+		.data		= &sysctl_mld_max_msf,
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= &proc_dointvec
+	},
 	{ .ctl_name = 0 }
 };
 
diff -purN linux-post-2.6.4rc2-20040307/net/sched/sch_red.c linux-post-2.6.4rc2-20040309/net/sched/sch_red.c
--- linux-post-2.6.4rc2-20040307/net/sched/sch_red.c	2004-02-21 02:37:25.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/net/sched/sch_red.c	2004-03-06 07:23:09.000000000 +0000
@@ -41,9 +41,6 @@
 #include <net/pkt_sched.h>
 #include <net/inet_ecn.h>
 
-#define RED_ECN_ECT  0x02
-#define RED_ECN_CE   0x01
-
 
 /*	Random Early Detection (RED) algorithm.
 	=======================================
@@ -165,28 +162,16 @@ static int red_ecn_mark(struct sk_buff *
 
 	switch (skb->protocol) {
 	case __constant_htons(ETH_P_IP):
-	{
-		u8 tos = skb->nh.iph->tos;
-
-		if (!(tos & RED_ECN_ECT))
+		if (!INET_ECN_is_capable(skb->nh.iph->tos))
 			return 0;
-
-		if (!(tos & RED_ECN_CE))
+		if (INET_ECN_is_not_ce(skb->nh.iph->tos))
 			IP_ECN_set_ce(skb->nh.iph);
-
 		return 1;
-	}
-
 	case __constant_htons(ETH_P_IPV6):
-	{
-		u32 label = *(u32*)skb->nh.raw;
-
-		if (!(label & __constant_htonl(RED_ECN_ECT<<20)))
+		if (!INET_ECN_is_capable(ip6_get_dsfield(skb->nh.ipv6h)))
 			return 0;
-		label |= __constant_htonl(RED_ECN_CE<<20);
+		IP6_ECN_set_ce(skb->nh.ipv6h);
 		return 1;
-	}
-
 	default:
 		return 0;
 	}
diff -purN linux-post-2.6.4rc2-20040307/net/sunrpc/auth_gss/svcauth_gss.c linux-post-2.6.4rc2-20040309/net/sunrpc/auth_gss/svcauth_gss.c
--- linux-post-2.6.4rc2-20040307/net/sunrpc/auth_gss/svcauth_gss.c	2004-02-27 20:27:21.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/net/sunrpc/auth_gss/svcauth_gss.c	2004-03-07 07:04:55.000000000 +0000
@@ -594,12 +594,13 @@ gss_write_verf(struct svc_rqst *rqstp, s
 	iov.iov_len = sizeof(xdr_seq);
 	xdr_buf_from_iov(&iov, &verf_data);
 	p = rqstp->rq_res.head->iov_base + rqstp->rq_res.head->iov_len;
+	mic.data = (u8 *)(p + 1);
 	maj_stat = gss_get_mic(ctx_id, 0, &verf_data, &mic);
 	if (maj_stat != GSS_S_COMPLETE)
 		return -1;
-	p = xdr_encode_netobj(rqstp->rq_res.head->iov_base
-				+ rqstp->rq_res.head->iov_len, &mic);
-	kfree(mic.data);
+	*p++ = htonl(mic.len);
+	memset((u8 *)p + mic.len, 0, round_up_to_quad(mic.len) - mic.len);
+	p += XDR_QUADLEN(mic.len);
 	if (!xdr_ressize_check(rqstp, p))
 		return -1;
 	return 0;
diff -purN linux-post-2.6.4rc2-20040307/sound/oss/Makefile linux-post-2.6.4rc2-20040309/sound/oss/Makefile
--- linux-post-2.6.4rc2-20040307/sound/oss/Makefile	2003-07-18 23:45:47.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/sound/oss/Makefile	2004-03-07 07:17:44.000000000 +0000
@@ -68,7 +68,7 @@ obj-$(CONFIG_SOUND_RME96XX)     += rme96
 obj-$(CONFIG_SOUND_BT878)	+= btaudio.o
 obj-$(CONFIG_SOUND_ALI5455)	+= ali5455.o ac97_codec.o
 obj-$(CONFIG_SOUND_IT8172)	+= ite8172.o ac97_codec.o
-obj-$(CONFIG_SOUND_FORTE)	+= forte.o
+obj-$(CONFIG_SOUND_FORTE)	+= forte.o ac97_codec.o
 
 obj-$(CONFIG_SOUND_AD1980)	+= ac97_plugin_ad1980.o
 obj-$(CONFIG_SOUND_WM97XX)	+= ac97_plugin_wm97xx.o
diff -purN linux-post-2.6.4rc2-20040307/sound/oss/ac97_plugin_ad1980.c linux-post-2.6.4rc2-20040309/sound/oss/ac97_plugin_ad1980.c
--- linux-post-2.6.4rc2-20040307/sound/oss/ac97_plugin_ad1980.c	2003-10-05 06:51:01.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/sound/oss/ac97_plugin_ad1980.c	2004-03-07 07:16:10.000000000 +0000
@@ -123,3 +123,4 @@ static int ad1980_init(void)
 
 module_init(ad1980_init);
 module_exit(ad1980_exit);
+MODULE_LICENSE("GPL");
diff -purN linux-post-2.6.4rc2-20040307/sound/oss/cs46xx_wrapper-24.h linux-post-2.6.4rc2-20040309/sound/oss/cs46xx_wrapper-24.h
--- linux-post-2.6.4rc2-20040307/sound/oss/cs46xx_wrapper-24.h	2003-07-11 16:07:37.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/sound/oss/cs46xx_wrapper-24.h	2004-03-07 07:12:57.000000000 +0000
@@ -28,7 +28,7 @@
 
 #include <linux/spinlock.h>
 
-#define CS_OWNER owner:
+#define CS_OWNER .owner =
 #define CS_THIS_MODULE THIS_MODULE,
 void cs46xx_null(struct pci_dev *pcidev) { return; }
 #define cs4x_mem_map_reserve(page) SetPageReserved(page)
diff -purN linux-post-2.6.4rc2-20040307/sound/oss/emu10k1/cardwi.c linux-post-2.6.4rc2-20040309/sound/oss/emu10k1/cardwi.c
--- linux-post-2.6.4rc2-20040307/sound/oss/emu10k1/cardwi.c	2003-02-17 00:30:06.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/sound/oss/emu10k1/cardwi.c	2004-03-07 07:16:11.000000000 +0000
@@ -164,7 +164,6 @@ int emu10k1_wavein_open(struct emu10k1_w
 
 	if (alloc_buffer(card, &wiinst->buffer) < 0) {
 		ERROR();
-		emu10k1_wavein_close(wave_dev);
 		return -1;
 	}
 
diff -purN linux-post-2.6.4rc2-20040307/sound/oss/sb_audio.c linux-post-2.6.4rc2-20040309/sound/oss/sb_audio.c
--- linux-post-2.6.4rc2-20040307/sound/oss/sb_audio.c	2003-04-03 22:35:48.000000000 +0000
+++ linux-post-2.6.4rc2-20040309/sound/oss/sb_audio.c	2004-03-07 07:16:09.000000000 +0000
@@ -882,7 +882,7 @@ sb16_copy_from_user(int dev,
 			c -= locallen; p += locallen;
 		}
 		/* used = ( samples * 16 bits size ) */
-		*used = len << 1;
+		*used =  max_in  > ( max_out << 1) ? (max_out << 1) : max_in;
 		/* returned = ( samples * 8 bits size ) */
 		*returned = len;
 	}
